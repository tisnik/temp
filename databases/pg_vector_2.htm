<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>pgvector, embedding a sémantické vyhledávání (1. část)</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>pgvector, embedding a sémantické vyhledávání (1. část)</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>V dnešním článku si ukážeme kombinaci možností databáze PostgreSQL, jejího rozšíření pgvector a taktéž knihovny Sentence transformers, která dokáže převádět texty do podoby vektorů reprezentujících jejich sémantiku. Výsledkem bude systém pro sémantické vyhledávání.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Rozšíření Postgresu pgvector, embedding a sémantické vyhledávání (1. část)</a></p>
<p><a href="#k02">2. Proč se omezujeme pouze na sémantické vyhledávání jednotlivých vět?</a></p>
<p><a href="#k03">3. Konfigurace a spuštění Postgresu</a></p>
<p><a href="#k04">4. Projektový soubor využitelný pro všechny demonstrační příklady</a></p>
<p><a href="#k05">5. Programové vytvoření tabulky, která obsahuje sloupec s&nbsp;vektory</a></p>
<p><a href="#k06">6. Zápis vektorů do tabulky <strong>v2</strong></a></p>
<p><a href="#k07">7. Výběr pěti vektorů nejpodobnějších zadanému vstupu</a></p>
<p><a href="#k08">8. Příprava tabulky pro uložení výsledku embeddingu: vektorů s&nbsp;384 dimenzemi</a></p>
<p><a href="#k09">9. Výsledky embeddingu kompatibilní s&nbsp;rozšířením <strong>pgvector</strong></a></p>
<p><a href="#k10">10. Vložení vektoru reprezentujícího jedinou větu do tabulky se sloupcem typu vektor</a></p>
<p><a href="#k11">11. Embedding většího množství vět</a></p>
<p><a href="#k12">12. Naplnění tabulky <strong>v384</strong> výsledky vektorizace většího množství vět</a></p>
<p><a href="#k13">13. Sémantické vyhledávání s&nbsp;využitím rozšíření <strong>pgvector</strong></a></p>
<p><a href="#k14">14. Výsledky sémantického vyhledávání</a></p>
<p><a href="#k15">15. Databázová tabulka obsahující jak původní věty (texty), tak i jejich vektorizovanou podobu</a></p>
<p><a href="#k16">16. Skript pro konstrukci embedding modelu původních vět s&nbsp;jejich uložením do databáze</a></p>
<p><a href="#k17">17. Sémantické vyhledávání podruhé: nyní vracející původní věty</a></p>
<p><a href="#k18">18. Výsledky vylepšeného sémantického vyhledávání</a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Rozšíření Postgresu pgvector, embedding a sémantické vyhledávání (1. část)</h2>

<p>V&nbsp;dnešním článku si ukážeme, jakým způsobem je možné zkombinovat
možnosti známé databáze PostgreSQL, jejího rozšíření <i>pgvector</i> a taktéž
knihovny <i>Sentence transformers</i> (určené pro programovací jazyk Python),
která dokáže převádět texty do podoby vektorů reprezentujících (samozřejmě, že
pouze do určité míry) sémantiku těchto vět. Navážeme tak jak na úvodní článek o
rozšíření <i>pgvector</i> [<a
href="https://www.root.cz/clanky/pgvector-vektorova-databaze-postavena-na-postgresu/">1</a>],
tak i na trojici článků o knihovně FAISS [<a
href="https://www.root.cz/clanky/faiss-knihovna-pro-rychle-a-efektivni-vyhledavani-podobnych-vektoru/">2</a>]
[<a
href="https://www.root.cz/clanky/faiss-knihovna-pro-rychle-a-efektivni-vyhledavani-podobnych-vektoru-2-cast/">3</a>]
[<a
href="https://www.root.cz/clanky/knihovna-faiss-a-embedding-zaklad-jazykovych-modelu/">4</a>].</p>

<p>Postupně si v&nbsp;dnešním článku ukážeme několik kroků, které povedou
k&nbsp;tomu, že na konci článku budeme mít v&nbsp;Postgresové tabulce uloženy
věty (nebo jiné texty &ndash; kratší či delší) jak ve vektorizované podobě
(sémantika), tak i v&nbsp;původní podobě, čehož bude možné později využít pro
takzvané <i>hybridní vyhledávání</i>:</p>

<ol>
<li>Instalace rozšíření <i>pgvector</i></li>
<li>Povolení rozšíření <i>pgvector</i> v&nbsp;běžícím Postgresu</li>
<li>Vytvoření tabulky se sloupcem typu &bdquo;vektor&ldquo; (s&nbsp;pevným počtem prvků)</li>
<li>Vektorizace vět s&nbsp;jejich uložením do této tabulky</li>
<li>Sémantické vyhledávání v&nbsp;tabulce s&nbsp;využitím nových operátorů, které rozšiřují původní možnosti SQL Postgresu</li>
<li>Vytvoření tabulky se sloupcem typu &bdquo;vektor&ldquo; (s&nbsp;pevným počtem prvků) a sloupcem typu &bdquo;text&ldquo;</li>
<li>Vektorizace vět s&nbsp;jejich uložením do této nové tabulky</li>
<li>Sémantické vyhledávání v&nbsp;nové tabulce, vrátí se přímo nejpodobnější věty v&nbsp;jejich původní podobě</li>
</ol>



<p><a name="k02"></a></p>
<h2 id="k02">2. Proč se omezujeme pouze na sémantické vyhledávání jednotlivých vět?</h2>

<p>Na tomto místě se může čtenář ptát, z&nbsp;jakého důvodu se vlastně
omezujeme na převody (vektorizaci) jednotlivých vět; proč se například nejedná
o jednotlivá slova, kratší slovní spojení, nebo naopak o celé odstavce nebo
kapitoly? Modely, které přes knihovnu <i>Sentence transformers</i> používáme
pro vektorizaci, převádí vstupní text (pokud problém značně zjednodušíme: bez
ohledu na jeho délku) na vektor pevné délky, přičemž v&nbsp;jednotlivých
prvcích tohoto vektoru je nějakým způsobem zakódována sémantika textu.</p>

<p>Pokud bychom pracovali s&nbsp;jednotlivými slovy nebo s&nbsp;krátkými
slovními spojeními, může být vše po technické stránce v&nbsp;pořádku, ovšem
otázkou je, k&nbsp;jakému účelu by taková databáze vektorů byla, protože by se
pro daný vstup opět vracela pouze jednotlivá slova nebo slovní spojení (což
může být pro některé účely dostačující, většinou &ndash; například při
konstrukci RAG databáze &ndash; ovšem nikoli).</p>

<p>Problém může nastat u vektorizace delších textů, protože model tento text
bez ohledu na jeho délku vždy transformuje do již zmíněného vektoru konstantní
délky. Zde tedy musí dojít ke zobecnění textu a výsledky vyhledání podle
kontextu nebudou přesné. U mnoha modelů navíc existuje limitní délka vstupních
textů. Pokud se omezíme na jednotlivé věty, většinou na tuto délku nenarazíme
(pokud se ovšem nejedná o schválně natahované věty &ndash; viz například známou
knihu Obsluhoval jsem anglického krále).</p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Konfigurace a spuštění Postgresu</h2>

<p>Nejdříve je nutné spustit a nakonfigurovat samotnou databázi
<i>PostgreSQL</i> i její rozšíření <i>pgvector</i>. Celý postup již byl popsán
v&nbsp;článku <a
href="https://www.root.cz/clanky/pgvector-vektorova-databaze-postavena-na-postgresu/">pgvector:
vektorová databáze postavená na Postgresu</a>, takže celý postup uvedu pouze ve
stručnosti. Databáze PostgreSQL samozřejmě musí být nejdříve nainstalována,
typicky s&nbsp;využitím balíčkovacího mechanismu vaší distribuce Linuxu.</p>

<p>Před instalací rozšíření <i>pgvector</i> zjistíme verzi Postgresu (a
současně otestujeme, jestli je databáze nainstalována):</p>

<pre>
$ <strong>postgres --version</strong>
nbsp;
postgres (PostgreSQL) 16.x nebo 17.x.
</pre>

<p>V&nbsp;dalším kroku nainstalujeme rozšíření <i>pgvector</i>, typicky opět
s&nbsp;využitím balíčkovacího mechanismu distribuce Linuxu. Číslo v&nbsp;názvu
balíčku (zde konkrétně 17) musí odpovídat hlavnímu číslu verze samotného
Postgresu:</p>

<pre>
$ <strong>sudo dnf install pgvector_17</strong>
</pre>

<p>Spustíme službu s&nbsp;Postgresem (pokud již neběží):</p>

<pre>
$ <strong>sudo service postgresql start</strong>
&nbsp;
Redirecting to /bin/systemctl start postgresql.service
</pre>

<p>Ověříme si, že služba skutečně běží:</p>

<pre>
$ <strong>service postgresql status</strong>
</pre>

<p>Výsledek může vypadat například takto:</p>

<pre>
Redirecting to /bin/systemctl status postgresql.service
● postgresql.service - PostgreSQL database server
     Loaded: loaded (/usr/lib/systemd/system/postgresql.service; enabled; preset: disabled)
    Drop-In: /usr/lib/systemd/system/service.d
             └─10-timeout-abort.conf
     Active: active (running) since Thu 2025-08-07 12:51:07 CEST; 46s ago
    Process: 2779867 ExecStartPre=/usr/libexec/postgresql-check-db-dir postgresql (code=exited, status=0/SUCCESS)
   Main PID: 2779869 (postgres)
      Tasks: 7 (limit: 37947)
     Memory: 29.6M (peak: 31.9M)
        CPU: 132ms
     CGroup: /system.slice/postgresql.service
             ├─2779869 /usr/bin/postgres -D /var/lib/pgsql/data
             ├─2779871 "postgres: logger "
             ├─2779872 "postgres: checkpointer "
             ├─2779873 "postgres: background writer "
             ├─2779875 "postgres: walwriter "
             ├─2779876 "postgres: autovacuum launcher "
             └─2779877 "postgres: logical replication launcher "
&nbsp;
Aug 07 12:51:07 ptisnovs-thinkpadt14gen3.xyzzy.cz systemd[1]: Starting postgresql.service - PostgreSQL database server...
Aug 07 12:51:07 ptisnovs-thinkpadt14gen3.xyzzy.cz postgres[2779869]: 2025-08-07 12:51:07.555 CEST [2779869] LOG:  redirecting log output to logging collector p&gt;
Aug 07 12:51:07 ptisnovs-thinkpadt14gen3.xyzzy.cz postgres[2779869]: 2025-08-07 12:51:07.555 CEST [2779869] HINT:  Future log output will appear in directory "&gt;
Aug 07 12:51:07 ptisnovs-thinkpadt14gen3.xyzzy.cz systemd[1]: Started postgresql.service - PostgreSQL database server.
</pre>

<p>Pokud je vše v&nbsp;pořádku, nastavíme konfiguraci rozšíření
<i>pgvector</i>, resp.&nbsp;si ověříme, jaká je jeho konfigurace:</p>

<pre>
$ <strong>cat `pg_config --sharedir`/extension/vector.control</strong>
&nbsp;
comment = 'vector data type and ivfflat and hnsw access methods'
default_version = '0.6.2'
module_pathname = '$libdir/vector'
relocatable = true
trusted = true
</pre>

<p><div class="rs-tip-major">Poznámka: pokud do konfiguračního souboru
nepřidáte poslední řádek, nebude možné rozšíření <i>pgvector</i> aktivovat pro
další uživatele databáze (což ovšem nutně nemusí vadit).</div></p>

<p>Posledním krokem, který je nutné udělat před založením
&bdquo;vektorové&ldquo; tabulky, je registrace rozšíření pro uživatele, který
je přihlášen přes <strong>psql</strong> (ale i s&nbsp;využitím dalších
klientů). Tato registrace probíhá příkazem <strong>CREATE</strong> (což může
být poněkud matoucí):</p>

<pre>
test=&gt; <strong>CREATE EXTENSION IF NOT EXISTS vector;</strong>
</pre>

<p>To, zda je rozšíření zaregistrováno, zjistíme takto (nezapomeňte na zápis
příkazu včetně zpětného lomítka):</p>

<pre>
test=&gt; <strong>\dx</strong>
                             List of installed extensions
  Name   | Version |   Schema   |                     Description                      
---------+---------+------------+------------------------------------------------------
 plpgsql | 1.0     | pg_catalog | PL/pgSQL procedural language
 vector  | 0.6.2   | public     | vector data type and ivfflat and hnsw access methods
(2 rows)
</pre>

<p><div class="rs-tip-major">Poznámka: existují i další způsoby zjištění,
jestli se <i>pgvector</i> používá, ale <strong>\dx</strong> je
nejjednodušší.</div></p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Projektový soubor využitelný pro všechny demonstrační příklady</h2>

<p>Ve druhém kroku si, a to naprosto stejným způsobem, jako jsme to provedli u
demonstračních příkladů využívajících knihovnu FAISS, připravíme projekt
v&nbsp;Pythonu a následně do něj nainstalujeme všechny potřebné knihovny. Pro
vytvoření projektu použijeme buď nástroj <i>PDM</i> &ndash; viz též <a
href="https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/">PDM:
moderní správce balíčků a virtuálních prostředí Pythonu</a> nebo (což je
v&nbsp;současnosti výhodnější) nástroj <a
href="https://docs.astral.sh/uv/">uv</a>. Projekt bude vytvořen v&nbsp;novém
(původně prázdném) adresáři a jeho projektový soubor
<strong>pyproject.toml</strong> může vypadat následovně:</p>

<pre>
[project]
name = "sentence-transformer-and-pgvector"
version = "0.1.0"
description = "Sentence transformer and pgvector demos"
authors = [
    {name = "Pavel Tisnovsky", email = "tisnik@centrum.cz"},
]
dependencies = [
]
requires-python = "==3.12.*"
readme = "README.md"
license = {text = "MIT"}
&nbsp;
&nbsp;
[tool.pdm]
distribution = false
</pre>

<p>Příkazem <strong>pdm add</strong> nebo <strong>uv add</strong> do projektu
přidáme všechny potřebné balíčky:</p>

<pre>
$ <strong>uv add datasets sentence-transformers matplotlib psycopg2 pgvector</strong>
</pre>

<p>Výsledný projektový soubor by měl vypadat takto:</p>

<pre>
[project]
name = "sentence-transformer-and-pgvector"
version = "0.1.0"
description = "Sentence transformer and pgvector demos"
authors = [
    {name = "Pavel Tisnovsky", email = "tisnik@centrum.cz"},
]
dependencies = [
    "datasets&gt;=4.0.0",
    "matplotlib&gt;=3.10.5",
    "pgvector&gt;=0.4.1",
    "psycopg2&gt;=2.9.10",
    "sentence-transformers&gt;=5.0.0",
]
requires-python = "==3.12.*"
readme = "README.md"
license = {text = "MIT"}
&nbsp;
&nbsp;
[tool.pdm]
distribution = false
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Programové vytvoření tabulky, která obsahuje sloupec s&nbsp;vektory</h2>

<p>Ukažme si nyní, jak je možné programově, konkrétně pouze s&nbsp;využitím
Pythonu a modulu <strong>psycopg2</strong>, vytvořit v&nbsp;databázi PostgreSQL
tabulku se sloupcem, do kterého bude možné zapisovat vektory s&nbsp;předem
známým počtem dimenzí. Tabulku pojmenujeme <strong>v2</strong>, kde dvojka
značí počet dimenzí a <strong>v</strong> pochopitelně znamená <i>vector</i>.
Tato tabulka bude obsahovat pouze dva sloupce: sloupec s&nbsp;automaticky
generovanými primárními klíči a již zmíněný sloupec určeny pro dvourozměrné
vektory. Po vytvoření tabulky (pokud již neexistuje) se ještě vypíše seznam
všech tabulek získaných z&nbsp;výchozího schématu <strong>public</strong>:</p>

<pre>
import psycopg2
&nbsp;
from pgvector.psycopg2 import register_vector
&nbsp;
connection = psycopg2.connect(
    host="", port=5432, user="tester", password="123qwe", dbname="test"
)
&nbsp;
print(connection)
&nbsp;
CREATE_TABLE_STATEMENT = """
    CREATE TABLE IF NOT EXISTS v2 (
        id bigserial PRIMARY KEY,
        embedding vector(2) NOT NULL
    );
"""
&nbsp;
LIST_TABLES_QUERY = """
    SELECT table_schema,table_name
      FROM information_schema.tables
     WHERE table_schema='public'
     ORDER BY table_schema,table_name;
"""
&nbsp;
with connection.cursor() as cursor:
    print(CREATE_TABLE_STATEMENT);
    cursor.execute(CREATE_TABLE_STATEMENT);
    connection.commit()
&nbsp;
    print(LIST_TABLES_QUERY)
    cursor.execute(LIST_TABLES_QUERY)
    tables = cursor.fetchall()
&nbsp;
    for table in tables:
        print(table)
</pre>

<p>Výsledek po spuštění tohoto skriptu by mohl vypadat následovně:</p>

<pre>
$ <strong>python create_table_v2.py</strong>
&nbsp;
&lt;connection object at 0x7fcbb3d2cb80; dsn: 'user=tester password=xxx dbname=test host='' port=5432', closed: 0&gt;
&nbsp;
    CREATE TABLE IF NOT EXISTS v2 (
        id bigserial PRIMARY KEY,
        embedding vector(2) NOT NULL
    );
&nbsp;
&nbsp;
    SELECT table_schema,table_name
      FROM information_schema.tables
     WHERE table_schema='public'
     ORDER BY table_schema,table_name;
&nbsp;
('public', 'v2')
</pre>

<p>Tabulku si můžeme zobrazit i z&nbsp;<strong>psql</strong>:</p>

<pre>
$ <strong>psql -U tester -d test</strong>
&nbsp;
Password for user tester: 
psql (16.8)
Type "help" for help.
&nbsp;
test=&gt; <strong>\dt</strong>
        List of relations
 Schema | Name  | Type  | Owner  
--------+-------+-------+--------
 public | v2    | table | tester
(1 row)
&nbsp;
test=&gt; <strong>\d v2</strong>
&nbsp;
                               Table "public.v2"
  Column   |   Type    | Collation | Nullable |            Default             
-----------+-----------+-----------+----------+--------------------------------
 id        | bigint    |           | not null | nextval('v2_id_seq'::regclass)
 embedding | vector(2) |           | not null | 
Indexes:
    "v2_pkey" PRIMARY KEY, btree (id)
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. Zápis vektorů do tabulky <strong>v2</strong></h2>

<p>Jeden z&nbsp;důvodů, proč vektorové databáze existují, je požadavek na
nalezení podobných vektorů na základě zvolené metriky (těch se používá hned
několik, jak si ostatně řekneme v&nbsp;dalším textu). Pro ilustraci, jakým
způsobem se vlastně podobné vektory hledají, si vytvoříme tabulky, do které
budou uloženy dvoudimenzionální vektory, tj.&nbsp;pouze dvojice numerických
hodnot. Takové vektory lze snadno vizualizovat v&nbsp;rovině.</p>

<p>Do již vytvořené tabulky nazvané <strong>v2</strong> vložíme patnáct
záznamů. Při zápisu je každý zapisovaný vektor reprezentován objektem typu
<strong>numpy.ndarray</strong>; konkrétně se jedná o jednorozměrné pole (tedy o
skutečný vektor):</p>

<pre>
import psycopg2
&nbsp;
import numpy as np
from pgvector.psycopg2 import register_vector
&nbsp;
connection = psycopg2.connect(
    host="", port=5432, user="tester", password="123qwe", dbname="test"
)
&nbsp;
register_vector(connection)
&nbsp;
x = [-5, -4, -3,    3,  4,  5,   3, 3, 3, 4, 4, 4, 5, 5, 5]
y = [ 5,  3,  5,   -5, -3, -5,   3, 4, 5, 3, 4, 5, 3, 4, 5]
&nbsp;
with connection.cursor() as cursor:
    for i in range(len(x)):
        vector = np.array([x[i], y[i]])
        print(type(vector), vector)
        cursor.execute("INSERT INTO v2 (embedding) VALUES (%s)", (vector, ))
    connection.commit()
</pre>

<p>Po skončení činnosti skriptu (a zejména po závěrečném <i>commitu</i>) si
prohlédneme obsah tabulky <strong>v2</strong>. Zajímat nás bude zejména obsah
sloupce <strong>embedding</strong>, protože <strong>id</strong> jsou
generována:</p>

<pre>
test=&gt; <strong>select * from v2;</strong>
&nbsp;
 id | embedding 
----+-----------
 31 | [-5,5]
 32 | [-4,3]
 33 | [-3,5]
 34 | [3,-5]
 35 | [4,-3]
 36 | [5,-5]
 37 | [3,3]
 38 | [3,4]
 39 | [3,5]
 40 | [4,3]
 41 | [4,4]
 42 | [4,5]
 43 | [5,3]
 44 | [5,4]
 45 | [5,5]
(15 rows)
</pre>

<p><div class="rs-tip-major">Poznámka: ve skutečnosti pravděpodobně uvidíte, že
<strong>id</strong> začínají od nuly. V&nbsp;mém konkrétním případě jsem skript
několikrát zkoušel (a mezitím původní záznamy vymazal), takže se počitadlo
<strong>id</strong> stačilo posunout.</div></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Výběr pěti vektorů nejpodobnějších zadanému vstupu</h2>

<p>V&nbsp;rámci rozšíření <i>pgvector</i> je umožněno v&nbsp;podmínkách
v&nbsp;příkazech <strong>SELECT</strong>, <strong>DELETE</strong> a
<strong>UPDATE</strong> použít nové operátory. Jeden z&nbsp;těchto operátorů se
zapisuje těmito třemi znaky:</p>

<pre>
&lt;-&gt;
</pre>

<p>Tento operátor dokáže porovnat dvojici vektorů na základě jejich
vzdálenosti, přičemž se pro výpočet vzdálenosti používá klasická Eukleidovská
metrika L<sup>2</sup>, které zjistí vzdálenosti koncových bodů vektorů
(v&nbsp;našem případě ve dvourozměrném prostoru). V&nbsp;navazujících
kapitolách si ukážeme některá možná použití tohoto operátoru i operátorů
dalších, pomocí nichž se vektory porovnávají na základě odlišných metrik.</p>

<p>Výše zmíněný operátor &lt;-&gt; můžeme použít v&nbsp;klauzuli <strong>ORDER
BY</strong>, která zajistí uspořádání vektorů na základě jejich vzdálenosti od
zadaného vektoru (nebo, chcete-li, na základě podobnosti vektorů z&nbsp;tabulky
se zadaným vektorem). Podívejme se na jednoduchý příklad z&nbsp;předchozího
článku:</p>

<pre>
import psycopg2
&nbsp;
from pgvector.psycopg2 import register_vector
&nbsp;
connection = psycopg2.connect(
    host="", port=5432, user="tester", password="123qwe", dbname="test"
)
&nbsp;
register_vector(connection)
&nbsp;
with connection.cursor() as cursor:
    query = """
        SELECT embedding
          FROM v2
         ORDER BY embedding &lt;-&gt; %s::vector
         LIMIT 5
    """
    cursor.execute(query, ([3, 3], ))
    records = cursor.fetchall()
    for record in records:
        print(record[0])
</pre>

<p>Výsledkem výše uvedeného dotazu je pětice vektorů, které jsou nejpodobnější
vektoru [3, 3]:</p>

<pre>
[3. 3.]
[3. 4.]
[4. 3.]
[4. 4.]
[3. 5.]
</pre>

<p>Výsledných pět vrácených vektorů si můžeme vizualizovat v&nbsp;2D
rovině:</p>

<pre>
                                       │ y
                                       │
                                       │
                                       │
                                       │
                     .       .         │          .   o   .
                         .             │          o   *   o
                         .             │          .   o   .
                                       │
                                       │
─────────────────────────────────────[0,0]──────────────────────────────────────
                                       │                                       x
                                       │
                                       │              .
                                       │
                                       │          .       .
                                       │
                                       │
                                       │
                                       │
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. Příprava tabulky pro uložení výsledku embeddingu: vektorů s&nbsp;384 dimenzemi</h2>

<p>Nyní již vlastně máme k&nbsp;dispozici všechny potřebné znalosti nutné pro
to, abychom využili databázi PostgreSQL s&nbsp;rozšířením <i>pgvector</i> pro
vyhledávání textů na základě jejich sémantiky. Připomeňme si, že pro
vektorizaci textů budeme používat modely, které produkují vektory s&nbsp;384
dimenzemi. Připravíme si tedy tabulku nazvanou <strong>v384</strong>, jejíž
jeden sloupec bude obsahovat vektory s&nbsp;právě 384 prvky. K&nbsp;vytvoření
této tabulky použijeme skript:</p>

<pre>
import psycopg2
&nbsp;
from pgvector.psycopg2 import register_vector
&nbsp;
connection = psycopg2.connect(
    host="", port=5432, user="tester", password="123qwe", dbname="test"
)
&nbsp;
print(connection)
&nbsp;
CREATE_TABLE_STATEMENT = """
    CREATE TABLE IF NOT EXISTS v384 (
        id bigserial PRIMARY KEY,
        embedding vector(384) NOT NULL
    );
"""
&nbsp;
LIST_TABLES_QUERY = """
    SELECT table_schema,table_name
      FROM information_schema.tables
     WHERE table_schema='public'
     ORDER BY table_schema,table_name;
"""
&nbsp;
with connection.cursor() as cursor:
    print(CREATE_TABLE_STATEMENT);
    cursor.execute(CREATE_TABLE_STATEMENT);
    connection.commit()
&nbsp;
    print(LIST_TABLES_QUERY)
    cursor.execute(LIST_TABLES_QUERY)
    tables = cursor.fetchall()
&nbsp;
    for table in tables:
        print(table)
</pre>

<p>Po dokončení skriptu si v&nbsp;konzoli <strong>psql</strong> vypíšeme
všechny tabulky:</p>

<pre>
test=&gt; <strong>\dt</strong>
&nbsp;
       List of relations
 Schema | Name | Type  | Owner  
--------+------+-------+--------
 public | v2   | table | tester
 public | v384 | table | tester
(2 rows)
</pre>

<p>Pro zajímavost se ještě podíváme na podrobnější informace o tabulce
<strong>v384</strong>:</p>

<pre>
test=&gt; <strong>\d v384</strong>
&nbsp;
                                Table "public.v384"
  Column   |    Type     | Collation | Nullable |             Default              
-----------+-------------+-----------+----------+----------------------------------
 id        | bigint      |           | not null | nextval('v384_id_seq'::regclass)
 embedding | vector(384) |           | not null | 
Indexes:
    "v384_pkey" PRIMARY KEY, btree (id)
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Výsledky embeddingu kompatibilní s&nbsp;rozšířením <strong>pgvector</strong></h2>

<p>V&nbsp;článcích o knihovně FAISS (viz <a href="#k20">dvacátou kapitolu</a>
s&nbsp;odkazy) jsme si mj.&nbsp;ukázali, že modely nabízené knihovnou
<i>Sentence-transformers</i> dokážou ze vstupního textu vytvořit vektory
s&nbsp;pevným počtem prvků (typicky 256, 384, 512 nebo 768 prvků). Tyto vektory
obsahující sémantiku vstupního textu jsou typu <strong>numpy.ndarray</strong>,
což je &ndash; nikoli náhodou &ndash; naprosto stejný typ, jaký akceptuje
rozšíření <strong>pgvector</strong> při ukládání vektorů do databáze.</p>

<p>Ostatně si toto tvrzení můžeme velmi snadno ověřit vektorizací jedné
věty:</p>

<pre>
from sentence_transformers import SentenceTransformer
&nbsp;
model = SentenceTransformer("paraphrase-MiniLM-L6-v2")
&nbsp;
print(model)
&nbsp;
sentence = "The rain in Spain falls mainly on the plain"
&nbsp;
embeddings = model.encode(sentence)
print(f"Embeddings shape: {embeddings.shape}")
&nbsp;
vector = embeddings
print(type(vector), vector.shape)
</pre>

<p>Výsledky vypsané tímto skriptem by měly vypadat takto:</p>

<pre>
SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
)
Embeddings shape: (384,)
&lt;class 'numpy.ndarray&gt; (384,)
</pre>

<p><div class="rs-tip-major">Poznámka: navíc nás ještě budou později zajímat
typy prvků vektoru (<strong>float32</strong>, <strong>float16</strong>,
<strong>bfloat16</strong>) a taktéž to, jestli jsou vektory normalizovány či
nikoli. K&nbsp;tomu se však ještě vrátíme.</div></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Vložení vektoru reprezentujícího jedinou větu do tabulky se sloupcem typu vektor</h2>

<p>Vyzkoušejme si, jak vlastně bude vypadat skript, který po svém spuštění
provede převod jediné věty do podoby vektoru obsahujícího informace o sémantice
této věty. Následně bude obsah vypočteného vektoru uložen do tabulky
<strong>v384</strong> pro pozdější využití. Všechny kroky, které skript
provádí, jsme si popsali a taktéž ukázali v&nbsp;předchozích kapitolách; nyní
pouze spojíme dva koncepty do jediného programu:</p>

<pre>
import psycopg2
&nbsp;
import numpy as np
from pgvector.psycopg2 import register_vector
from sentence_transformers import SentenceTransformer
&nbsp;
model = SentenceTransformer("paraphrase-MiniLM-L6-v2")
&nbsp;
print(model)
&nbsp;
sentence = "The rain in Spain falls mainly on the plain"
&nbsp;
embeddings = model.encode(sentence)
print(f"Embeddings shape: {embeddings.shape}")
&nbsp;
vector = embeddings
&nbsp;
connection = psycopg2.connect(
    host="", port=5432, user="tester", password="123qwe", dbname="test"
)
&nbsp;
register_vector(connection)
&nbsp;
with connection.cursor() as cursor:
    cursor.execute("INSERT INTO v384 (embedding) VALUES (%s)", (vector, ))
    connection.commit()
</pre>

<p>Skript po svém spuštění vypíše základní informace o modelu a taktéž tvar
(<i>shape</i>) výsledného n-rozměrného pole:</p>

<pre>
SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
)
Embeddings shape: (384,)
</pre>

<p>V&nbsp;konzoli <strong>psql</strong> prozkoumáme obsah tabulky
<strong>v384</strong>. Měla by obsahovat jeden záznam:</p>

<pre>
test=&gt; <strong>select count(*) from v384;</strong>
&nbsp;
 count 
-------
     1
(1 row)
</pre>

<p>Tento záznam obsahuje vektor s&nbsp;384 hodnotami typu
<strong>float32</strong>:</p>

<pre>
test=&gt; <strong>select * from v384;</strong>
</pre>

<pre>
  1 | [0.3478463,0.1651683,0.80891263,0.72986645,1.3382668,0.06676822,-0.21522364,-0.09888732,-0.14145306,-0.52012527,-0.00875917,-0.098080724,-0.2633922,0.402
8185,0.3994093,-0.20971194,-0.12567759,-0.37587926,0.33004197,-0.28925693,0.37450206,0.26958337,-0.29575813,-0.16029944,-0.2659341,0.10839906,-0.18690287,0.065
46495,0.14089231,-0.00020084734,0.10801713,-0.12372175,0.34069282,0.15052913,-0.067606784,-0.63805515,0.46768042,-0.18611597,-0.062298153,0.022772968,-0.725291
8,0.4015648,-0.23507196,0.140735,0.28050125,-0.010708517,0.26216206,0.24861158,0.40079835,0.33300167,0.27957687,-0.014675101,-0.17867266,0.26503685,-0.12559552
,-0.21344356,-0.23851794,-0.22829832,0.59133744,0.54733306,0.123978466,0.07607324,-0.60898393,0.1268554,0.20776464,0.26186323,0.005309312,0.521085,0.16896497,-
0.24492708,-0.2067925,0.062349096,-0.04011694,-0.14361992,-0.64163506,-0.3978676,-0.3735655,0.02888419,-0.4679453,0.3147229,0.13757025,0.0809049,-0.15652154,0.
25277814,-0.0958617,-0.49047896,0.43949178,0.13820027,0.40036076,-0.5461719,0.11023465,-0.13689366,-0.5629067,0.9595211,0.44364336,0.65416235,0.7172294,-0.3110
0145,0.26710993,0.05519587,-0.019064216,0.052905,0.37381804,0.46188784,-0.2905547,0.25999615,0.07007515,-0.7525602,0.21104497,-0.18804012,0.15200639,-0.4752462
5,0.11918416,-0.40177488,-0.06337302,0.36457422,0.10553891,-0.015762012,-0.6414942,-0.29428843,0.108376496,0.039354797,0.22881092,0.28008914,0.6463641,0.360770
73,-0.47816375,-0.1615384,-0.06412483,-0.96497214,-0.0532971,0.50177723,0.51708335,-0.13628031,-0.1958101,0.20123464,-0.40123847,0.2829893,-0.036858603,-0.6490
6794,-0.34043348,0.075107746,0.05149603,0.12959899,0.738389,-0.59792465,-0.4481514,-0.123061426,-0.41743317,-0.26054513,0.08430738,-0.043441627,0.3164697,0.006
5179546,-0.5136731,0.15219939,0.27004403,-0.11969745,0.041190986,0.028731616,0.18188754,-0.072593756,0.4525503,-0.023671113,0.15453857,0.645053,-0.40997618,0.1
5929341,0.62040216,-0.316236,-0.087189525,-0.47167242,0.02946538,-0.3533273,-0.09394767,0.45658416,-0.06863275,-0.23714565,-0.07764846,-0.08026797,0.62771624,0
.32355314,0.2669482,0.5486583,-0.3239251,-0.12113338,-0.044172402,-0.24990128,0.3756979,-0.07775865,0.0505999,-0.38591337,0.87621766,-0.20538129,-0.26248366,0.
77906,0.14090697,0.08597355,-0.3895502,0.4853258,-0.23761,0.20602818,0.33449268,-0.20086986,0.3318084,0.015541857,0.5247317,0.2244594,-0.0144861825,-0.28824165
,-0.029353546,-0.5679604,-0.27332273,0.2440015,0.22435383,0.3931917,0.42644545,-0.107593566,-0.70814306,0.57140315,0.3234386,-0.8088993,0.25423485,-0.18235168,
0.09815521,-0.17610633,-0.20705642,0.21467887,-0.08414001,0.36776218,0.2151859,0.41030267,-0.21997021,0.1556591,-0.45738858,-0.375895,0.042969152,0.1592543,0.2
3224005,0.8167258,-0.31846842,0.040264476,0.35690776,0.401083,-0.32581365,-1.1366388,0.1314889,-0.19686675,-0.6279306,-0.0013781949,-0.3910677,0.15773045,-0.44
587424,0.051197443,-0.24650817,0.55354327,-0.7592172,-0.5219158,-0.64309293,0.34288883,-0.012695101,-0.0847227,-0.17499705,0.23765267,-0.53753257,-0.08776954,0
.41179326,-0.18145639,0.044225227,-0.28497654,0.12960373,-0.4727863,-0.23930912,-0.9899117,0.7786404,-0.15647528,-0.332171,0.67442405,0.8531017,-0.39849016,-0.
31563175,-0.23753914,-0.69903916,0.06594103,-0.100104384,0.4190483,-0.78987145,-0.31334054,-0.18987493,-0.35639513,-0.42602998,0.7332483,0.59794927,-0.06998656
,-0.3528726,-0.50578934,-0.27034423,-0.16521432,-0.4324772,-0.3757722,-0.10690414,0.29796785,-0.5734284,-0.010504636,-0.0290119,-0.20384084,0.22323895,-0.09243
289,0.3657885,-0.35423923,-0.49107325,-0.23372331,0.16865791,0.24685413,-0.2899907,-0.3106801,-0.08246122,-0.11810763,0.082611725,0.0680243,-0.41308358,-0.1096
9818,-0.24324872,0.28386712,0.23900475,-0.61941475,0.5347494,0.25323942,-0.1517316,-0.6160019,-0.45625067,-0.23615155,0.10238915,0.034416072,-0.13215332,-0.111
7928,-0.028137358,0.34055436,-0.022248073,-0.10388828,0.41457003,0.60157514,-0.64496595,0.18863411,0.66177106,-0.24609046,0.058639564,0.026280224,-0.17290074,0
.10932419,0.006086925,0.34558168,-0.21488343,-0.96902615,0.20507286,-0.17184074,0.37967455,-0.3468344,-0.35829875,-0.0062513067,0.33113906,-0.0027895935,-0.000
4822151,-0.043646622,0.07335393,0.14621384,-0.29227698,0.046420466,0.43824196,0.09155101,0.2274449,0.33601317,0.09329631,0.7676583,0.15852436,-0.43436182,0.316
23447,0.4198514,0.504068,0.31218696,-0.63812673,0.30405572,-0.031397928,0.017359529]
(1 row)
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. Embedding většího množství vět</h2>

<p>Embedding (&bdquo;vektorizace&ldquo;) jediné věty je vhodný pouze pro
demonstrační účely. V&nbsp;praxi bude v&nbsp;tabulce uloženo mnohem větší
množství textů &ndash; od několika tisíc do několika milionů (ostatně příště se
pokusíme vektorizovat a uložit milion vět, abychom si ověřili výkonnost
Postgresu s&nbsp;rozšířením <i>pgvector</i>). Pokusme se nyní do tabulky
<strong>v384</strong> uložit sedm vektorizovaných vět, které jsme
v&nbsp;předchozích článcích používali pro otestování embedding modelů. Samotný
postup vektorizace většího množství vět již dobře známe, takže opět jen pro
úplnost:</p>

<pre>
from sentence_transformers import SentenceTransformer
&nbsp;
model = SentenceTransformer("paraphrase-MiniLM-L6-v2")
&nbsp;
print(model)
&nbsp;
sentences = [
    "The rain in Spain falls mainly on the plain",
    "The tesselated polygon is a special type of polygon",
    "The quick brown fox jumps over the lazy dog",
    "To be or not to be, that is the question",
    "It is a truth universally acknowledged...",
    "How old are you?",
    "The goat ran down the hill"
]
&nbsp;
embeddings = model.encode(sentences)
print(f"Embeddings shape: {embeddings.shape}")
&nbsp;
for vector in embeddings:
    print(type(vector), vector.shape)
</pre>

<p>Po spuštění tohoto skriptu se nejdříve zobrazí informace o modelu (již dobře
známe):</p>

<pre>
SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
)
</pre>

<p>Posléze se vypíše tvar n-rozměrného pole s&nbsp;vektorizovaným textem.
Z&nbsp;výpisu je patrné, že se jedná o matici se sedmi řádky a 384 sloupci:</p>

<pre>
Embeddings shape: (7, 384)
</pre>

<p>Následně si necháme vypsat typy a tvary všech řádků vypočtené matice. Jedná
se (pochopitelně) o vektory s&nbsp;384 prvky:</p>

<pre>
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Naplnění tabulky <strong>v384</strong> výsledky vektorizace většího množství vět</h2>

<p>Nyní konečně můžeme přistoupit k&nbsp;uložení <a href="#k11">výše uvedených
sedmi vektorizovaných vět</a> do tabulky nazvané <strong>v384</strong>.
Nejdříve ovšem z&nbsp;této tabulky vymažeme původní větu. Mělo by se jednat o
jediný záznam, pokud jste ovšem nespustili skript <a href="#k06">ze šesté
kapitoly</a> několikrát za sebou:</p>

<pre>
test=&gt; <strong>delete from v384;</strong>
&nbsp;
DELETE 1
</pre>

<p><div class="rs-tip-major">Poznámka: z&nbsp;odpovědi zobrazené v&nbsp;konzoli
<strong>psql</strong> je patrné, že se skutečně vymazal jen jeden
záznam.</div></p>

<p>Následující skript provede dvojici operací, které již dobře známe:
vektorizaci sedmi vět s&nbsp;jejich následným uložením do Postgresu:</p>

<pre>
import psycopg2
&nbsp;
import numpy as np
from pgvector.psycopg2 import register_vector
from sentence_transformers import SentenceTransformer
&nbsp;
model = SentenceTransformer("paraphrase-MiniLM-L6-v2")
&nbsp;
print(model)
&nbsp;
sentences = [
    "The rain in Spain falls mainly on the plain",
    "The tesselated polygon is a special type of polygon",
    "The quick brown fox jumps over the lazy dog",
    "To be or not to be, that is the question",
    "It is a truth universally acknowledged...",
    "How old are you?",
    "The goat ran down the hill"
]
&nbsp;
embeddings = model.encode(sentences)
print(f"Embeddings shape: {embeddings.shape}")
&nbsp;
connection = psycopg2.connect(
    host="", port=5432, user="tester", password="123qwe", dbname="test"
)
&nbsp;
register_vector(connection)
&nbsp;
for vector in embeddings:
    print(type(vector), vector.shape)
    with connection.cursor() as cursor:
        cursor.execute("INSERT INTO v384 (embedding) VALUES (%s)", (vector, ))
&nbsp;
connection.commit()
</pre>

<p>Z&nbsp;výpisů bude patrné, jaké operace skript provádí:</p>

<pre>
SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
)
Embeddings shape: (7, 384)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
&lt;class 'numpy.ndarray'&gt; (384,)
</pre>

<p>Přesvědčíme se, kolik záznamů je nyní v&nbsp;tabulce <strong>v384</strong> uloženo:</p>

<pre>
test=&gt; <strong>select count(*) from v384;</strong>
 count 
-------
     7
(1 row)
</pre>

<p>Teoreticky si samozřejmě můžeme vypsat celý obsah této tabulky, ovšem jedná
se jen o (na první pohled) nicneříkající číselné údaje, takže výpis
v&nbsp;článku nebudu uvádět.</p>



<p><a name="k13"></a></p>
<h2 id="k13">13. Sémantické vyhledávání s&nbsp;využitím rozšíření <strong>pgvector</strong></h2>

<p>Nyní již konečně můžeme přistoupit k&nbsp;hlavnímu tématu dnešního článku
&ndash; k&nbsp;vlastnímu sémantickému vyhledávání. Vyhledávaný termín (slovo,
sousloví, větu) nejdříve převedeme na vektor s&nbsp;využitím stejného modelu,
jaký byl použit pro vektorizaci původních sedmi vět:</p>

<pre>
vector = model.encode(query_sentence)
</pre>

<p>Dále v&nbsp;tabulce <strong>v384</strong> vyhledáme <i>k</i> nejbližších
vektorů s&nbsp;využitím L<sup>2</sup> metriky. Proměnné části SQL dotazu jsou
<u>podtrženy</u>:</p>

<pre>
SELECT id, embedding
  FROM v384
 ORDER BY embedding &lt;-&gt; <u>vector</u>
 LIMIT <u>k</u>
</pre>

<p><div class="rs-tip-major">Poznámka: prozatím musíme používat L<sup>2</sup>
metriku, protože vektory nejsou normalizovány a tudíž by výsledky skalárního
součinu (nebo výpočtu kosinu úhlu mezi vektory) nebyly dobře
použitelné.</div></p>

<p>V&nbsp;programovacím jazyku Python, pokud použijeme knihovnu
<i>Psycopg2</i>, může být vyhledání a výpis <i>k</i> sémanticky nejbližších vět
realizováno tímto způsobem:</p>

<pre>
vector = model.encode(query_sentence)
&nbsp;
with connection.cursor() as cursor:
    query = """
        SELECT id, embedding
          FROM v384
         ORDER BY embedding &lt;-&gt; %s::vector
         LIMIT %s
    """
    cursor.execute(query, (vector, k))
    records = cursor.fetchall()
    for record in records:
        print(record[0])
</pre>

<p>Celý skript bude vypadat takto:</p>

<pre>
import psycopg2
from pgvector.psycopg2 import register_vector
&nbsp;
from sentence_transformers import SentenceTransformer
import faiss
&nbsp;
&nbsp;
connection = psycopg2.connect(
    host="", port=5432, user="tester", password="123qwe", dbname="test"
)
&nbsp;
print(connection)
register_vector(connection)
&nbsp;
&nbsp;
model = SentenceTransformer("paraphrase-MiniLM-L6-v2")
print(model)
&nbsp;
&nbsp;
def <strong>find_similar_sentences</strong>(connection, query_sentence, k):
    print(f"Query: {query_sentence}")
    print(f"Most {k} similar sentences:")
&nbsp;
    vector = model.encode(query_sentence)
&nbsp;
    with connection.cursor() as cursor:
        query = """
            SELECT id, embedding
              FROM v384
             ORDER BY embedding <-> %s::vector
             LIMIT %s
        """
        cursor.execute(query, (vector, k))
        records = cursor.fetchall()
        for record in records:
            print(record[0])
    print("-"*40)
&nbsp;
&nbsp;
find_similar_sentences(connection, "The quick brown fox jumps over the lazy dog", 3)
find_similar_sentences(connection, "quick brown fox jumps over lazy dog", 3)
find_similar_sentences(connection, "The quick brown fox jumps over the angry dog", 3)
find_similar_sentences(connection, "The quick brown cat jumps over the lazy dog", 3)
find_similar_sentences(connection, "What is your age?", 3)
find_similar_sentences(connection, "Shakespeare", 3)
find_similar_sentences(connection, "animal", 3)
find_similar_sentences(connection, "geometry", 3)
find_similar_sentences(connection, "weather", 3)
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Výsledky sémantického vyhledávání</h2>

<p>Podívejme se nyní na výsledky vyhledávání přesně tak, jak je vypíše skript
uvedený <a href="#k13">v&nbsp;předchozí kapitole</a>. Nejdříve se, jak je
zvykem, zobrazí informace o navázaném připojení k&nbsp;databázi:</p>

<pre>
&lt;connection object at 0x7fec54362d40; dsn: 'user=tester password=xxx dbname=test host='' port=5432', closed: 0&gt;
</pre>

<p>Dále se zobrazí informace o použitém embedding modelu:</p>

<pre>
SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
)
</pre>

<p>Poté již následuje výpis obsahující vyhledávaný termín (slovo, větu) a
<strong>ID</strong> (skutečně pouze ID) nejbližších záznamů získaných
z&nbsp;databáze:</p>

<pre>
Query: The quick brown fox jumps over the lazy dog
Most 3 similar sentences:
5
9
4
----------------------------------------
Query: quick brown fox jumps over lazy dog
Most 3 similar sentences:
5
9
4
----------------------------------------
Query: The quick brown fox jumps over the angry dog
Most 3 similar sentences:
5
9
6
----------------------------------------
Query: The quick brown cat jumps over the lazy dog
Most 3 similar sentences:
5
6
4
----------------------------------------
Query: What is your age?
Most 3 similar sentences:
8
6
4
----------------------------------------
Query: Shakespeare
Most 3 similar sentences:
6
4
3
----------------------------------------
Query: animal
Most 3 similar sentences:
9
5
6
----------------------------------------
Query: geometry
Most 3 similar sentences:
4
6
9
----------------------------------------
Query: weather
Most 3 similar sentences:
3
6
8
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. Databázová tabulka obsahující jak původní věty (texty), tak i jejich vektorizovanou podobu</h2>

<p>Jak je z&nbsp;výsledků <a href="#k14">předchozího skriptu</a> patrné,
získali jsme pouze ID záznamů, ovšem nikoli původní věty. Kromě toho můžeme
získat prvky vektoru, ovšem původní větu (text) nelze z&nbsp;vektoru obnovit.
Samozřejmě je možné do tabulky zapsat například index původních vět a mapování
mezi indexem a větou provést v&nbsp;Pythonu, ve kterém můžeme mít
k&nbsp;dispozici seznam nebo n-tici s&nbsp;původními větami:</p>

<pre>
sentences = [
    "The rain in Spain falls mainly on the plain",
    "The tesselated polygon is a special type of polygon",
    "The quick brown fox jumps over the lazy dog",
    "To be or not to be, that is the question",
    "It is a truth universally acknowledged...",
    "How old are you?",
    "The goat ran down the hill"
]
</pre>

<p>Ovšem proč nevyužít toho, že máme k&nbsp;dispozici plnohodnotný PostgreSQL?
Věty přece můžeme zapsat v&nbsp;jejich původní textové formě do stejné tabulky,
konkrétně do sloupce typu <strong>text</strong>, <strong>varchar</strong> atd.
Konstrukce takové tabulky je snadná, pouze tabulku rozšíříme o sloupec
<strong>sentence</strong>. Následující skript vytvoří novou prázdnou tabulku
nazvanou <strong>v384b</strong>:</p>

<pre>
import psycopg2
&nbsp;
from pgvector.psycopg2 import register_vector
&nbsp;
connection = psycopg2.connect(
    host="", port=5432, user="tester", password="123qwe", dbname="test"
)
&nbsp;
print(connection)
&nbsp;
CREATE_TABLE_STATEMENT = """
    CREATE TABLE IF NOT EXISTS v384b (
        id bigserial PRIMARY KEY,
        embedding vector(384) NOT NULL,
        sentence TEXT NOT NULL
    );
"""
&nbsp;
LIST_TABLES_QUERY = """
    SELECT table_schema,table_name
      FROM information_schema.tables
     WHERE table_schema='public'
     ORDER BY table_schema,table_name;
"""
&nbsp;
with connection.cursor() as cursor:
    print(CREATE_TABLE_STATEMENT);
    cursor.execute(CREATE_TABLE_STATEMENT);
    connection.commit()
&nbsp;
    print(LIST_TABLES_QUERY)
    cursor.execute(LIST_TABLES_QUERY)
    tables = cursor.fetchall()
&nbsp;
    for table in tables:
        print(table)
</pre>

<p>Po spuštění tohoto skriptu by se měl vypsat seznam všech tabulek. Tento
seznam získáme i příkazem <strong>\dt</strong> v&nbsp;konzoli
<strong>psql</strong>:</p>

<pre>
test=&gt; <strong>\dt</strong>
&nbsp;
       List of relations
 Schema | Name  | Type  | Owner  
--------+-------+-------+--------
 public | v2    | table | tester
 public | v384  | table | tester
 public | v384b | table | tester
(3 rows)
</pre>

<p>Schéma nové tabulky <strong>v384b</strong> bude vypadat takto:</p>

<pre>
test=&gt; <strong>\d v384b</strong>
&nbsp;
                                Table "public.v384b"
  Column   |    Type     | Collation | Nullable |              Default              
-----------+-------------+-----------+----------+-----------------------------------
 id        | bigint      |           | not null | nextval('v384b_id_seq'::regclass)
 embedding | vector(384) |           | not null | 
 sentence  | text        |           | not null | 
Indexes:
    "v384b_pkey" PRIMARY KEY, btree (id)
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. Skript pro konstrukci embedding modelu původních vět s&nbsp;jejich uložením do databáze</h2>

<p>Do tabulky <strong>v384b</strong> se ukládá jak původní věta (formou textu),
tak i její vektorizovaná podoba:</p>

<pre>
INSERT INTO v384b (embedding, sentence) VALUES (<u>vektor</u>, <u>původní věta</u>)
</pre>

<p>Skript, který byl uveden <a href="#k12">ve dvanácté kapitole</a>, je možné
nepatrně upravit tak, aby do tabulky ukládal i původní věty:</p>

<pre>
import psycopg2
&nbsp;
import numpy as np
from pgvector.psycopg2 import register_vector
from sentence_transformers import SentenceTransformer
&nbsp;
model = SentenceTransformer("paraphrase-MiniLM-L6-v2")
&nbsp;
print(model)
&nbsp;
sentences = [
    "The rain in Spain falls mainly on the plain",
    "The tesselated polygon is a special type of polygon",
    "The quick brown fox jumps over the lazy dog",
    "To be or not to be, that is the question",
    "It is a truth universally acknowledged...",
    "How old are you?",
    "The goat ran down the hill"
]
&nbsp;
embeddings = model.encode(sentences)
print(f"Embeddings shape: {embeddings.shape}")
&nbsp;
connection = psycopg2.connect(
    host="", port=5432, user="tester", password="123qwe", dbname="test"
)
&nbsp;
register_vector(connection)
&nbsp;
for sentence, vector in zip(sentences, embeddings):
    print(type(vector), vector.shape)
    with connection.cursor() as cursor:
        cursor.execute("INSERT INTO v384b (embedding, sentence) VALUES (%s, %s)", (vector, sentence))
&nbsp;
connection.commit()
</pre>

<p>O tom, že do tabulky byly mj.&nbsp;uloženy i původní věty, se přesvědčíme
velmi snadno, a to opět z&nbsp;konzole <strong>psql</strong>:</p>

<pre>
test=&gt; <strong>select sentence from v384b;</strong>
&nbsp;
                      sentence                       
-----------------------------------------------------
 The rain in Spain falls mainly on the plain
 The tesselated polygon is a special type of polygon
 The quick brown fox jumps over the lazy dog
 To be or not to be, that is the question
 It is a truth universally acknowledged...
 How old are you?
 The goat ran down the hill
(7 rows)
</pre>



<p><a name="k17"></a></p>
<h2 id="k17">17. Sémantické vyhledávání podruhé: nyní vracející původní věty</h2>

<p>Původně jsme z&nbsp;tabulky <strong>v384</strong> načítali ID sémanticky
nejbližších vět, takže prováděný dotaz vypadal následovně:</p>

<pre>
SELECT id, embedding
  FROM v384
 ORDER BY embedding &lt;-&gt; %s::vector
 LIMIT <u>nastavená hodnota k</u>
</pre>

<p>Nyní ovšem máme v&nbsp;tabulce <strong>v384b</strong> uloženy i původní
věty, takže dotaz můžeme položit takovým způsobem, že pro vzorek získáme přímo
<i>k</i> sémanticky nejpodobnějších vět:</p>

<pre>
SELECT sentence
  FROM v384b
 ORDER BY embedding &lt;-&gt; <u>query_vektor</u>
 LIMIT <u>nastavená hodnota k</u>
</pre>

<p>A právě tento druhý dotaz je použit v&nbsp;dnešním posledním demonstračním
příkladu, jehož zdrojový kód vypadá následovně:</p>

<pre>
import psycopg2
from pgvector.psycopg2 import register_vector
&nbsp;
from sentence_transformers import SentenceTransformer
import faiss
&nbsp;
&nbsp;
connection = psycopg2.connect(
    host="", port=5432, user="tester", password="123qwe", dbname="test"
)
&nbsp;
print(connection)
register_vector(connection)
&nbsp;
&nbsp;
model = SentenceTransformer("paraphrase-MiniLM-L6-v2")
print(model)
&nbsp;
&nbsp;
def <strong>find_similar_sentences</strong>(connection, query_sentence, k):
    print(f"Query: {query_sentence}")
    print(f"Most {k} similar sentences:")
&nbsp;
    vector = model.encode(query_sentence)
&nbsp;
    with connection.cursor() as cursor:
        query = """
            SELECT sentence
              FROM v384b
             ORDER BY embedding &lt;-&gt; %s::vector
             LIMIT %s
        """
        cursor.execute(query, (vector, k))
        records = cursor.fetchall()
        for i, record in enumerate(records):
            print(f"    #{i}: {record[0]}")
    print("-"*40)
&nbsp;
&nbsp;
find_similar_sentences(connection, "The quick brown fox jumps over the lazy dog", 3)
find_similar_sentences(connection, "quick brown fox jumps over lazy dog", 3)
find_similar_sentences(connection, "The quick brown fox jumps over the angry dog", 3)
find_similar_sentences(connection, "The quick brown cat jumps over the lazy dog", 3)
find_similar_sentences(connection, "What is your age?", 3)
find_similar_sentences(connection, "Shakespeare", 3)
find_similar_sentences(connection, "animal", 3)
find_similar_sentences(connection, "geometry", 3)
find_similar_sentences(connection, "weather", 3)
</pre>



<p><a name="k18"></a></p>
<h2 id="k18">18. Výsledky vylepšeného sémantického vyhledávání</h2>

<p>Výše uvedený skript by měl po svém spuštění (opět) vypsat informaci o
navázaném připojení k&nbsp;databázi i o použitém modelu:</p>

<pre>
&lt;connection object at 0x7efcd7ac6d40; dsn: 'user=tester password=xxx dbname=test host='' port=5432', closed: 0&gt;
SentenceTransformer(
  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False, 'architecture': 'BertModel'})
  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})
)
</pre>

<p>Následně se již vypíše zadaný vzorek a vždy trojice sémanticky nejbližších
vět k&nbsp;tomuto vzorku. Povšimněte si, že ve všech případech je první
sémanticky nejbližší věta skutečně vybrána zcela korektně (snad až na otázku
&bdquo;animal&ldquo;, pro kterou existuje více odpovědí):</p>

<pre>
Query: The quick brown fox jumps over the lazy dog
Most 3 similar sentences:
    #0: The quick brown fox jumps over the lazy dog
    #1: The goat ran down the hill
    #2: The tesselated polygon is a special type of polygon
----------------------------------------
Query: quick brown fox jumps over lazy dog
Most 3 similar sentences:
    #0: The quick brown fox jumps over the lazy dog
    #1: The goat ran down the hill
    #2: The tesselated polygon is a special type of polygon
----------------------------------------
Query: The quick brown fox jumps over the angry dog
Most 3 similar sentences:
    #0: The quick brown fox jumps over the lazy dog
    #1: The goat ran down the hill
    #2: To be or not to be, that is the question
----------------------------------------
Query: The quick brown cat jumps over the lazy dog
Most 3 similar sentences:
    #0: The quick brown fox jumps over the lazy dog
    #1: To be or not to be, that is the question
    #2: The tesselated polygon is a special type of polygon
----------------------------------------
Query: What is your age?
Most 3 similar sentences:
    #0: How old are you?
    #1: To be or not to be, that is the question
    #2: The tesselated polygon is a special type of polygon
----------------------------------------
Query: Shakespeare
Most 3 similar sentences:
    #0: To be or not to be, that is the question
    #1: The tesselated polygon is a special type of polygon
    #2: The rain in Spain falls mainly on the plain
----------------------------------------
Query: animal
Most 3 similar sentences:
    #0: The goat ran down the hill
    #1: The quick brown fox jumps over the lazy dog
    #2: To be or not to be, that is the question
----------------------------------------
Query: geometry
Most 3 similar sentences:
    #0: The tesselated polygon is a special type of polygon
    #1: To be or not to be, that is the question
    #2: The goat ran down the hill
----------------------------------------
Query: weather
Most 3 similar sentences:
    #0: The rain in Spain falls mainly on the plain
    #1: To be or not to be, that is the question
    #2: How old are you?
----------------------------------------
</pre>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Zdrojové kódy všech prozatím popsaných demonstračních příkladů určených pro
programovací jazyk Python s&nbsp;nainstalovanými balíčky
<strong>psycopg2</strong> a <strong>pgvector</strong> byly uloženy do
repositáře dostupného na adrese <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
V&nbsp;tabulce zobrazené níže jsou odkazy na jednotlivé příklady:</p>

<table>
<tr><th> #</th><th>Demonstrační příklad</th><th>Stručný popis příkladu</th><th>Cesta</th></tr>
<tr><td> 1</td><td>create_extension.py</td><td>registrace rozšíření <i>vector</i> pro uživatele připojeného k&nbsp;databázi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_extension.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_extension.py</a></td></tr>
<tr><td> 2</td><td>insert_into_v2.py</td><td>zápis 2D vektorů do tabulky <i>v2</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/insert_into_v2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/insert_into_v2.py</a></td></tr>
<tr><td> 3</td><td>insert_normalized.py</td><td>zápis normalizovaných 2D vektorů do tabulky <i>normalized</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/insert_normalized.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/insert_normalized.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 4</td><td>read_vectors_1.py</td><td>přečtení vektorů bez jejich konverze na skutečné vektory</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/read_vectors_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/read_vectors_1.py</a></td></tr>
<tr><td> 5</td><td>read_vectors_2.py</td><td>důkaz, že přečtené vektory jsou vráceny jako řetězce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/read_vectors_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/read_vectors_2.py</a></td></tr>
<tr><td> 6</td><td>read_vectors_3.py</td><td>přečtení vektorů z&nbsp;databáze ve formě N-dimenzionálních polí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/read_vectors_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/read_vectors_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 7</td><td>select_by_distance_1.py</td><td>výběr vektorů na základě jejich odlišnosti od zadaného vektoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/select_by_distance_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/select_by_distance_1.py</a></td></tr>
<tr><td> 8</td><td>select_by_distance_2.py</td><td>dtto, ale s&nbsp;lepším naformátováním SQL dotazu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/select_by_distance_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/select_by_distance_2.py</a></td></tr>
<tr><td> 9</td><td>select_by_distance_3.py</td><td>výběr vektorů s&nbsp;nejmenší odlišností (vzdáleností)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/select_by_distance_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/select_by_distance_3.py</a></td></tr>
<tr><td>10</td><td>select_by_distance_4.py</td><td>výběr vektorů se zadanou nejmenší odlišností (vzdáleností)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/select_by_distance_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/select_by_distance_4.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>11</td><td>various_distances.py</td><td>použití různých metrik na nenormalizované vektory</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/various_distances.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/various_distances.py</a></td></tr>
<tr><td>12</td><td>various_distances_normalized.py</td><td>použití různých metrik na normalizované vektory</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/various_distances_normalized.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/various_distances_normalized.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>13</td><td>create_table_v2.py</td><td>vytvoření tabulky se sloupcem, který bude obsahovat dvouprvkové vektory</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_table_v2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_table_v2.py</a></td></tr>
<tr><td>14</td><td>create_table_v384.py</td><td>vytvoření tabulky se sloupcem, který bude obsahovat vektory s&nbsp;384 prvky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_table_v384.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_table_v384.py</a></td></tr>
<tr><td>16</td><td>create_embeddings_one_sentence.py</td><td>vektorizace jediné věty na základě zvoleného modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_embeddings_one_sentence.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_embeddings_one_sentence.py</a></td></tr>
<tr><td>17</td><td>create_embeddings.py</td><td>vektorizace většího počtu vět na základě zvoleného modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_embeddings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_embeddings.py</a></td></tr>
<tr><td>18</td><td>sentence_into_v384.py</td><td>vložení vektoru reprezentujícího jedinou větu do tabulky se sloupcem typu vektor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/sentence_into_v384.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/sentence_into_v384.py</a></td></tr>
<tr><td>19</td><td>sentences_into_v384.py</td><td>vložení většího množství vět do tabulky se sloupcem typu vektor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/sentences_into_v384.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/sentences_into_v384.py</a></td></tr>
<tr><td>20</td><td>sentence_similarity_1.py</td><td>sémantické vyhledávání přes rozšíření <strong>pgvector</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/sentence_similarity_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/sentence_similarity_1.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>21</td><td>create_table_v384B.py</td><td>vytvoření tabulky se sloupcem typu vektor a sloupcem s&nbsp;původním textem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_table_v384B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/create_table_v384B.py</a></td></tr>
<tr><td>22</td><td>sentences_into_v384b.py</td><td>vložení vektorizovaného i původního textu do tabulky <strong>v384b</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/sentences_into_v384b.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/sentences_into_v384b.py</a></td></tr>
<tr><td>23</td><td>sentence_similarity_2.py</td><td>sémantické vyhledávání přes rozšíření <strong>pgvector</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/sentence_similarity_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/sentence_similarity_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>24</td><td>pyproject.toml</td><td>soubor s&nbsp;definicí Pythonovského projektu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/pyproject.toml">https://github.com/tisnik/most-popular-python-libs/blob/master/pgvector/pyproject.toml</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>pgvector: vektorová databáze postavená na Postgresu<br />
<a href="https://www.root.cz/clanky/pgvector-vektorova-databaze-postavena-na-postgresu/">https://www.root.cz/clanky/pgvector-vektorova-databaze-postavena-na-postgresu/</a>
</li>

<li>FAISS: knihovna pro rychlé a efektivní vyhledávání podobných vektorů<br />
<a href="https://www.root.cz/clanky/faiss-knihovna-pro-rychle-a-efektivni-vyhledavani-podobnych-vektoru/">https://www.root.cz/clanky/faiss-knihovna-pro-rychle-a-efektivni-vyhledavani-podobnych-vektoru/</a>
</li>

<li>FAISS: knihovna pro rychlé a efektivní vyhledávání podobných vektorů (2. část)<br />
<a href="https://www.root.cz/clanky/faiss-knihovna-pro-rychle-a-efektivni-vyhledavani-podobnych-vektoru-2-cast/">https://www.root.cz/clanky/faiss-knihovna-pro-rychle-a-efektivni-vyhledavani-podobnych-vektoru-2-cast/</a>
</li>

<li>Knihovna FAISS a embedding: základ jazykových modelů<br />
<a href="https://www.root.cz/clanky/knihovna-faiss-a-embedding-zaklad-jazykovych-modelu/">https://www.root.cz/clanky/knihovna-faiss-a-embedding-zaklad-jazykovych-modelu/</a>
</li>

<li>Vector database<br />
<a href="https://en.wikipedia.org/wiki/Vector_database">https://en.wikipedia.org/wiki/Vector_database</a>
</li>

<li>Nearest neighbor search<br />
<a href="https://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximation_methods">https://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximation_methods</a>
</li>

<li>RAG - Retrieval-augmented generation<br />
<a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation">https://en.wikipedia.org/wiki/Retrieval-augmented_generation</a>
</li>

<li>pgvector na GitHubu<br />
<a href="https://github.com/pgvector/pgvector">https://github.com/pgvector/pgvector</a>
</li>

<li>Why we replaced Pinecone with PGVector<br />
<a href="https://www.confident-ai.com/blog/why-we-replaced-pinecone-with-pgvector">https://www.confident-ai.com/blog/why-we-replaced-pinecone-with-pgvector</a>
</li>

<li>PostgreSQL as VectorDB - Beginner Tutorial<br />
<a href="https://www.youtube.com/watch?v=Ff3tJ4pJEa4">https://www.youtube.com/watch?v=Ff3tJ4pJEa4</a>
</li>

<li>What is a Vector Database? (neobsahuje odpověď na otázku v titulku :-)<br />
<a href="https://www.youtube.com/watch?v=t9IDoenf-lo">https://www.youtube.com/watch?v=t9IDoenf-lo</a>
</li>

<li>PGVector: Turn PostgreSQL Into A Vector Database<br />
<a href="https://www.youtube.com/watch?v=j1QcPSLj7u0">https://www.youtube.com/watch?v=j1QcPSLj7u0</a>
</li>

<li>Milvus<br />
<a href="https://milvus.io/">https://milvus.io/</a>
</li>

<li>Vector Databases simply explained! (Embeddings &amp; Indexes)<br />
<a href="https://www.youtube.com/watch?v=dN0lsF2cvm4">https://www.youtube.com/watch?v=dN0lsF2cvm4</a>
</li>

<li>Vector databases are so hot right now. WTF are they?<br />
<a href="https://www.youtube.com/watch?v=klTvEwg3oJ4">https://www.youtube.com/watch?v=klTvEwg3oJ4</a>
</li>

<li>Step-by-Step Guide to Installing “pgvector” and Loading Data in PostgreSQL<br />
<a href="https://medium.com/@besttechreads/step-by-step-guide-to-installing-pgvector-and-loading-data-in-postgresql-f2cffb5dec43">https://medium.com/@besttechreads/step-by-step-guide-to-installing-pgvector-and-loading-data-in-postgresql-f2cffb5dec43</a>
</li>

<li>Best 17 Vector Databases for 2025<br />
<a href="https://lakefs.io/blog/12-vector-databases-2023/">https://lakefs.io/blog/12-vector-databases-2023/</a>
</li>

<li>Top 15 Vector Databases that You Must Try in 2025<br />
<a href="https://www.geeksforgeeks.org/top-vector-databases/">https://www.geeksforgeeks.org/top-vector-databases/</a>
</li>

<li>Picking a vector database: a comparison and guide for 2023<br />
<a href="https://benchmark.vectorview.ai/vectordbs.html">https://benchmark.vectorview.ai/vectordbs.html</a>
</li>

<li>Top 9 Vector Databases as of Feburary 2025<br />
<a href="https://www.shakudo.io/blog/top-9-vector-databases">https://www.shakudo.io/blog/top-9-vector-databases</a>
</li>

<li>What is a vector database?<br />
<a href="https://www.ibm.com/think/topics/vector-database">https://www.ibm.com/think/topics/vector-database</a>
</li>

<li>SQL injection<br />
<a href="https://en.wikipedia.org/wiki/SQL_injection">https://en.wikipedia.org/wiki/SQL_injection</a>
</li>

<li>Cosine similarity<br />
<a href="https://en.wikipedia.org/wiki/Cosine_similarity">https://en.wikipedia.org/wiki/Cosine_similarity</a>
</li>

<li>Hammingova vzdálenost<br />
<a href="https://cs.wikipedia.org/wiki/Hammingova_vzd%C3%A1lenost">https://cs.wikipedia.org/wiki/Hammingova_vzd%C3%A1lenost</a>
</li>

<li>Jaccard index<br />
<a href="https://en.wikipedia.org/wiki/Jaccard_index">https://en.wikipedia.org/wiki/Jaccard_index</a>
</li>

<li>Manhattanská metrika<br />
<a href="https://cs.wikipedia.org/wiki/Manhattansk%C3%A1_metrika">https://cs.wikipedia.org/wiki/Manhattansk%C3%A1_metrika</a>
</li>

<li>FAISS (Facebook AI Similarity Search)<br />
<a href="https://en.wikipedia.org/wiki/FAISS">https://en.wikipedia.org/wiki/FAISS</a>
</li>

<li>FAISS documentation<br />
<a href="https://faiss.ai/">https://faiss.ai/</a>
</li>

<li>Introduction to Facebook AI Similarity Search (Faiss)<br />
<a href="https://www.pinecone.io/learn/series/faiss/faiss-tutorial/">https://www.pinecone.io/learn/series/faiss/faiss-tutorial/</a>
</li>

<li>Faiss: Efficient Similarity Search and Clustering of Dense Vectors<br />
<a href="https://medium.com/@pankaj_pandey/faiss-efficient-similarity-search-and-clustering-of-dense-vectors-dace1df1e235">https://medium.com/@pankaj_pandey/faiss-efficient-similarity-search-and-clustering-of-dense-vectors-dace1df1e235</a>
</li>

<li>Cosine Distance vs Dot Product vs Euclidean in vector similarity search<br />
<a href="https://medium.com/data-science-collective/cosine-distance-vs-dot-product-vs-euclidean-in-vector-similarity-search-227a6db32edb">https://medium.com/data-science-collective/cosine-distance-vs-dot-product-vs-euclidean-in-vector-similarity-search-227a6db32edb</a>
</li>

<li>F16C<br />
<a href="https://en.wikipedia.org/wiki/F16C">https://en.wikipedia.org/wiki/F16C</a>
</li>

<li>FP16 (AVX-512)<br />
<a href="https://en.wikipedia.org/wiki/AVX-512#FP16">https://en.wikipedia.org/wiki/AVX-512#FP16</a>
</li>

<li>Top 8 Vector Databases in 2025: Features, Use Cases, and Comparisons<br />
<a href="https://synapsefabric.com/top-8-vector-databases-in-2025-features-use-cases-and-comparisons/">https://synapsefabric.com/top-8-vector-databases-in-2025-features-use-cases-and-comparisons/</a>
</li>

<li>Is FAISS a Vector Database? Complete Guide<br />
<a href="https://mljourney.com/is-faiss-a-vector-database-complete-guide/">https://mljourney.com/is-faiss-a-vector-database-complete-guide/</a>
</li>

<li>FAISS and sentence-transformers in 5 Minutes<br />
<a href="https://www.stephendiehl.com/posts/faiss/">https://www.stephendiehl.com/posts/faiss/</a>
</li>

<li>Sentence Transformer: Quickstart<br />
<a href="https://sbert.net/docs/quickstart.html#sentence-transformer">https://sbert.net/docs/quickstart.html#sentence-transformer</a>
</li>

<li>Sentence Transformers: Embeddings, Retrieval, and Reranking<br />
<a href="https://pypi.org/project/sentence-transformers/">https://pypi.org/project/sentence-transformers/</a>
</li>

<li>uv<br />
<a href="https://docs.astral.sh/uv/">https://docs.astral.sh/uv/</a>
</li>

<li>A Gentle Introduction to Retrieval Augmented Generation (RAG)<br />
<a href="https://wandb.ai/cosmo3769/RAG/reports/A-Gentle-Introduction-to-Retrieval-Augmented-Generation-RAG---Vmlldzo1MjM4Mjk1">https://wandb.ai/cosmo3769/RAG/reports/A-Gentle-Introduction-to-Retrieval-Augmented-Generation-RAG---Vmlldzo1MjM4Mjk1</a>
</li>

<li>The Beginner’s Guide to Text Embeddings<br />
<a href="https://www.deepset.ai/blog/the-beginners-guide-to-text-embeddings">https://www.deepset.ai/blog/the-beginners-guide-to-text-embeddings</a>
</li>

<li>What are Word Embeddings?<br />
<a href="https://www.youtube.com/watch?v=wgfSDrqYMJ4">https://www.youtube.com/watch?v=wgfSDrqYMJ4</a>
</li>

<li>How to choose an embedding model<br />
<a href="https://www.youtube.com/watch?v=djp4205tHGU">https://www.youtube.com/watch?v=djp4205tHGU</a>
</li>

<li>What is a Vector Database? Powering Semantic Search &amp; AI Applications<br />
<a href="https://www.youtube.com/watch?v=gl1r1XV0SLw">https://www.youtube.com/watch?v=gl1r1XV0SLw</a>
</li>

<li>How do Sentence Transformers differ from traditional word embedding models like Word2Vec or GloVe?<br />
<a href="https://zilliz.com/ai-faq/how-do-sentence-transformers-differ-from-traditional-word-embedding-models-like-word2vec-or-glove">https://zilliz.com/ai-faq/how-do-sentence-transformers-differ-from-traditional-word-embedding-models-like-word2vec-or-glove</a>
</li>

<li>BERT (language model)<br />
<a href="https://en.wikipedia.org/wiki/BERT_(language_model)">https://en.wikipedia.org/wiki/BERT_(language_model)</a>
</li>

<li>Levenštejnova vzdálenost<br />
<a href="https://cs.wikipedia.org/wiki/Leven%C5%A1tejnova_vzd%C3%A1lenost">https://cs.wikipedia.org/wiki/Leven%C5%A1tejnova_vzd%C3%A1lenost</a>
</li>

<li>pgvector Tutorial: Integrate Vector Search into PostgreSQL<br />
<a href="https://www.datacamp.com/tutorial/pgvector-tutorial">https://www.datacamp.com/tutorial/pgvector-tutorial</a>
</li>

<li>pgvectorbench<br />
<a href="https://github.com/pgvectorBench/pgvectorBench">https://github.com/pgvectorBench/pgvectorBench</a>
</li>

<li>pgvector 0.4.0 performance<br />
<a href="https://supabase.com/blog/pgvector-performance">https://supabase.com/blog/pgvector-performance</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="https://github.com/tisnik/">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

