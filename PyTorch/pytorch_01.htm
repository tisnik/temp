<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">1. Od projektu Scikit-learn ke knihovně PyTorch</a></p>
<p><a href="#k02">2. Přímý předchůdce knihovny PyTorch: nástroj Torch</a></p>
<p><a href="#k03">3. Zpracování vektorů, matic a tenzorů</a></p>
<p><a href="#k04">4. Instalace knihovny PyTorch</a></p>
<p><a href="#k05">5. Konfigurace projektu (<strong>pyproject.toml</strong>)</a></p>
<p><a href="#k06">6. Základní datová struktura, s&nbsp;níž se v&nbsp;knihovně PyTorch pracuje</a></p>
<p><a href="#k07">*** 7. Tenzor: homogenní n-dimenzionální pole s&nbsp;volitelným typem</a></p>
<p><a href="#k08">8. Datové typy pro tenzory uložené v&nbsp;paměti CPU i GPU kompatibilní se staršími verzemi Torche a PyTorche</a></p>
<p><a href="#k09">*** 9. </a></p>
<p><a href="#k10">*** 10. </a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Od projektu Scikit-learn ke knihovně PyTorch</h2>

<p>V&nbsp;seriálu <a
href="https://www.root.cz/serialy/datova-analyza-s-vyuzitim-jazyka-python/">o
datové analýze s&nbsp;využitím programovacího jazyka Python</a> jsme se až
doposud zabývali projektem <i>Scikit-learn</i>, který uživatelům-programátorům
nabízí mnoho postupů a nástrojů pro zpracování dat, tvorbu různě složitých či
naopak interně jednoduchých modelů, shlukovou analýzu (<i>clustering</i>) atd.
Tento projekt mj.&nbsp;umožňuje konstrukci a trénink neuronových sítí, přičemž
výsledkem bude model provádějící buď <i>klasifikaci</i> či <i>regresi</i>. Díky
tomu, že se se všemi modely pracuje prakticky totožným způsobem a uživatelé
mají k&nbsp;dispozici i nástroje pro ověření kvality modelů, se
<i>Scikit-learn</i> v&nbsp;oblasti zpracování dat i strojového učení využívá
velmi často a mnohdy se jedná o první projekt, s&nbsp;nímž se zájemci o oblast
zpracování dat, strojového učení (a částečně i umělé inteligence) setkají. A
v&nbsp;mnoha oblastech se skutečně jedná ideální nástroj.</p>

<img src="https://i.iinfo.cz/images/542/scikit-learn-1-4.webp" class="image-1110846" width="180" height="97" alt="&#160;" title="Autor: Scikit-learn autoři podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 1: Logo projektu Scikit-learn.</i></p>

<p>Ovšem v&nbsp;případě, že běžná shluková analýza či jednodušší modely
nedostačují, což jsou typicky oblasti &bdquo;hlubokého&ldquo; strojového učení
(<i>deep learning</i>) a především tehdy, pokud je zapotřebí například
rozpoznávat audio signály nebo rastrové obrázky, se ukazuje, že by bylo
vhodnější mít k&nbsp;dispozici specializovanější nástroj, který by dokázal
pracovat s&nbsp;rozsáhlými neuronovými sítěmi, s&nbsp;konvolučními sítěmi atd.
A vzhledem k&nbsp;tomu, že výpočty prováděné při tréninku těchto sítí jsou
velmi náročné (a na druhou stranu unifikované a prováděné nad dlouhými vektory)
by takový nástroj měl umožnit výpočty s&nbsp;využitím moderních GPU. Takové
projekty pochopitelně existují a v&nbsp;ekosystému programovacího jazyka Python
se jedná zejména o knihovnu <i>PyTorch</i>. A právě popisem možností této
knihovny se budeme zabývat v&nbsp;tomto článku i v&nbsp;článcích
navazujících.</p>

*** image ***
<p><i>Obrázek 2: Logo projektu PyTorch.</i></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Přímý předchůdce knihovny PyTorch: nástroj Torch</h2>

<p>Knihovna <i>PyTorch</i>, kterou se budeme zabývat, ve skutečnosti nevznikla
na zelené louce. Jejím přímým předchůdcem je knihovna nazvaná <i>Torch</i>,
která byla (a vlastně ještě doposud je) používána nejenom v&nbsp;oboru
strojového učení (<i>machine learning</i>), ale i pro &bdquo;obyčejné&ldquo;
zpracování vektorů a tenzorů. Pro psaní skriptů se v&nbsp;Torchi používá <a
href="https://www.root.cz/serialy/programovaci-jazyk-lua/">programovací jazyk
Lua</a>. Ten je interpretovaný a i když se jedná o jeden z&nbsp;nejrychlejších
interpretrů, tak pochopitelně nemůže soutěžit s&nbsp;překladači
resp.&nbsp;překládanými programovacími jazyky. Interně se ovšem v&nbsp;Torchi
prakticky všechny výpočty provádí v&nbsp;nativních céčkových knihovnách a
popř.&nbsp;se využívá i CUDA, tj.&nbsp;využívají se zde možnosti grafických
akcelerátorů. Možnosti knihovny <i>Torch</i> však ve skutečnosti přesahují
&bdquo;pouhou&ldquo; práci s&nbsp;tenzory, protože obsahuje i moduly pro
lineární algebru a především pro neuronové sítě, což je poměrně rozsáhlé téma,
kterému se budeme věnovat v&nbsp;samostatném článku (již zaměřeného na
PyTorch).</p>

*** image ***
<p><i>Obrázek 3: Logo projektu Torch.</i></p>

<p>Společně se zvyšujícím se počtem vývojářů, kteří začali používat
programovací jazyk Python, se ukazovalo, že by bylo namísto jazyka Lua (což je
sice skvělý jazyk, který ovšem nikdy významně nepřesáhl oblast své niky)
vhodnější založit projekt na Pythonu. To se skutečně stalo a přibližně od roku
2017 se vývoj přesunul od projektu <i>Torch</i> k&nbsp;<i>PyTorchi</i>. Oba
projekty jsou sice stále dosti podobné, ale jak uvidíme v&nbsp;dalších
kapitolách, některé operace se přece jen odlišují. Na rozdíly narazíme vlastně
hned na začátku, protože v&nbsp;jazyce Lua se prvky polí indexují od jedničky,
kdežto v&nbsp;Pythonu se prvky seznamů (o od nich specializovaných polí)
indexují od nuly. Nicméně i přes tyto rozdíly je přechod od Torche
k&nbsp;PyTorchi relativně snadný, protože i základy, na nichž jsou obě knihovny
postaveny, jsou podobné.</p>

*** image ***
<p><i>Obrázek 4: Logo programovacího jazyka Lua, který svými vlastnostmi
soutěží s&nbsp;Pythonem. Ovšem Lua se využívá primárně jako jazyk vkládaný do
dalších aplikací (příkladem z&nbsp;moderní éry je Neovim), kdežto Python se
z&nbsp;původně pouze skriptovacího jazyka stal plnohodnotný projekt využívaný i
pro skutečně rozsáhlé aplikace.</i></p>

<p><div class="rs-tip-major">Poznámka: zde může docházet k&nbsp;určitým
zmatkům, protože Pythonovský balíček s&nbsp;PyTorchem se ve skutečnosti jmenuje
<strong>torch</strong>. Ovšem skutečně se jedná o PyTorch a nikoli o předchůdce
této knihovny.</div></p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Zpracování vektorů, matic a tenzorů</h2>

<p>Jednou poměrně rozsáhlou oblastí v&nbsp;IT je zpracování vektorů, matic i
tenzorů, protože s&nbsp;těmito strukturami se můžeme setkat v&nbsp;různých
disciplínách, například ve finančnictví, pojišťovnictví, statistice, zpracování
numerických dat, simulacích, strojovém učení (a s&nbsp;klasickými tenzory třeba
ve fyzice) atd. Současně se jedná i o velmi zajímavou oblast, neboť právě kvůli
co nejrychlejší práci s&nbsp;velkými maticemi byly vytvořeny speciální
výpočetní bloky v&nbsp;některých superpočítačích (příkladem mohou být
superpočítače <i>Cray</i>). Současné knihovny dokážou v&nbsp;případě potřeby
využít jak některá rozšíření instrukčních sad (SIMD instrukce typu AXV(512),
SSE-x, původně též MMX či 3DNow!), tak i programovatelné grafické akcelerátory
(GPU, v&nbsp;současnosti je lídrem v&nbsp;tomto oboru NVidia.</p>

<p>Práce s&nbsp;vektory a maticemi byla (a samozřejmě doposud je) podporována
v&nbsp;překladačích FORTRANu, které začaly být po vzniku superpočítačů vybaveny
algoritmy, které dokázaly převést některé typy programových smyček na
&bdquo;vektorové operace&ldquo;. Paralelně vznikly i specializované jazyky
určené téměř výhradně pro práci s&nbsp;vektory i maticemi &ndash; příkladem
jsou jazyky <i>APL</i> a <i>J</i>.</p>

<p>V&nbsp;současnosti je používáno relativně velké množství programovacích
jazyků popř.&nbsp;specializovaných knihoven orientovaných na práci
s&nbsp;vektory, maticemi, tenzory atd. Z&nbsp;komerčních nástrojů je zapotřebí
jmenovat především známý <i>MATLAB</i> vydávaný společností <i>MathWorks</i>,
nativní práci s&nbsp;maticemi a vektory ovšem velmi dobře podporuje také
nástroj <a
href="https://www.gnu.org/software/octave/doc/interpreter/Matrices.html">GNU
Octave</a> (<a
href="https://gnu.org/software/octave/">https://gnu.org/software/octave/</a>),
<a href="http://www.ats.ucla.edu/stat/r/library/matrix_alg.htm">jazyk R</a> (<a
href="http://www.r-project.org/">http://www.r-project.org/</a>) a také
relativně nový jazyk <a
href="https://www.root.cz/serialy/programovaci-jazyk-julia/">Julia</a> (<a
href="http://julialang.org/">http://julialang.org/</a>, zajímavé výsledky
benchmarků lze najít na adrese <a
href="http://julialang.org/benchmarks/">http://julialang.org/benchmarks/</a>).
Z&nbsp;knihoven jmenujme především oblíbenou a dnes dosti intenzivně využívanou
Pythonovskou knihovnu <i>NumPy</i> (<a
href="http://www.numpy.org/">http://www.numpy.org/</a>).</p>

<p>Framework <i>PyTorch</i> je mj.&nbsp;určen pro zpracování vektorů, matic i
tenzorů (tj.&nbsp;zobecnění vektorů), a to s&nbsp;využitím programovacího
jazyka Python namísto specializovaného jazyka (Julia, Matlab, R). A tyto datové
struktury jsou dále využívány v&nbsp;dalších oblastech, které PyTorch podporuje
&ndash; v&nbsp;první řadě se jedná o neuronové sítě.</p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Instalace knihovny PyTorch</h2>

<p>Před prvními pokusy s&nbsp;knihovnou PyTorch si ji pochopitelně musíme
nainstalovat. To je ovšem složitější, než v&nbsp;případě běžných Pythonovských
balíčků, protože se přímo nepoužívá PyPi, ale vlastní registr s&nbsp;balíčky.
Přejděte tedy na stránku <a
href="https://pytorch.org/get-started/locally/#start-locally">https://pytorch.org/get-started/locally/#start-locally</a>,
kde si můžete vybrat svoji platformu (Linux, Windows, Mac), správce balíčků
(což bude s&nbsp;velkou pravděpodobností <strong>pip</strong>), jazyk
(pochopitelně <strong>Python</strong>) a taktéž to, zda budete chtít
nainstalovat PyTorch s&nbsp;podporou CUDA či bez této podpory. Využití
platformy CUDA sice povede k&nbsp;velkému nárůstu rychlosti tréninku
neuronových sítí, ovšem na druhou stranu samotná instalace naroste o přibližně
4GB (!). Proto může být pro první kroky snazší si nainstalovat pouze
&bdquo;CPU&ldquo; variantu PyTorche &ndash; všechny vlastnosti zůstanou
zachovány, pouze se pro výpočty bude stále používat běžný mikroprocesor a
nikoli GPU.</p>

<p>Na výše uvedené stránce se po výběru kritérií zobrazí příkaz, který lze
použít pro instalaci PyTorche.</p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Konfigurace projektu (<strong>pyproject.toml</strong>)</h2>

<p>V&nbsp;případě, že pro správu Pythonovských projektů používáte projektový
soubor <strong>pyproject.toml</strong> a například <a
href="https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/">nástroj
PDM</a>, je možné specifikovat konfiguraci projektu takovým způsobem, že se
stáhne a nainstaluje korektní varianta PyTorche. Příkladem může být specifikace
PyTorche ve variantě pro CPU:</p>

<pre>
[[tool.pdm.source]]
type = "find_links"
url = "https://download.pytorch.org/whl/cpu/torch_stable.html"
name = "torch"
&nbsp;
[build-system]
requires = ["pdm-backend"]
build-backend = "pdm.backend"
&nbsp;
[project]
name = "skvely projekt zalozeny na PyTorchi"
version = "0.1.0"
description = "skvely projekt zalozeny na PyTorchi"
authors = []
dependencies = [
    ...
    ...
    ...
    "torch==2.5.1+cpu",
    ...
    ...
    ...
]
# PyTorch vyzaduje minimalne Python 3.9 (priklady otestovany v 3.11 a 3.12)
requires-python = "==3.9.*"
readme = "README.md"
license = {file = "LICENSE"}
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. Základní datová struktura, s&nbsp;níž se v&nbsp;knihovně PyTorch pracuje</h2>

<p>V&nbsp;knihovně <i>PyTorch</i> se základní datová struktura jmenuje
<strong>Tensor</strong>. Tato struktura umožňuje reprezentovat skalární hodnoty
(tenzory nultého řádu), běžné vektory (tenzory prvního řádu), běžné matice,
&bdquo;3D matice&ldquo; atd. Interně je struktura objektů typu
<strong>Tensor</strong> až překvapivě jednoduchá &ndash; základem je
jednorozměrné pole doplněné o metadata, v&nbsp;nichž je uložen počet dimenzí,
velikost dimenzí, hodnoty <i>stride</i> používané při přístupu k&nbsp;prvkům
interního pole atd. Nad tenzory je navíc možné vytvářet různé pohledy
(<i>views</i>), které mohou být určeny buď pouze pro čtení či pro čtení i zápis
(pohled může například reprezentovat tenzor se změněným tvarem &ndash;
<i>shape</i>).</p>

<p><div class="rs-tip-major">Poznámka: pojem <i>tensor</i> může být
v&nbsp;tomto kontextu poněkud matoucí, protože v&nbsp;matematice a fyzice má
tento termín velmi specifický význam a tenzory nejsou totožné
s&nbsp;n-dimenzionálními poli (chybí nám totiž například informace o bázových
vektorech, pro tenzory jsou definována pravidla pro jejich transformaci a i
samotný tenzor má svoji obdobu v&nbsp;modelovaném systému, zatímco
n-dimenzionální pole je skutečně jen polem čísel). Matematici a fyzici rádi
zdůrazňují rozdíly mezi tenzory a n-dimenzionálními poli (vektory, matice, ...)
a mají pochopitelně pravdu. Ovšem z&nbsp;pohledu knihovny <i>PyTorch</i> se
fyzikální význam tenzorů ztrácí a skutečně s&nbsp;nimi můžeme pracovat jako
s&nbsp;n-dimenzionálními poli.</div></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Tenzor: homogenní n-dimenzionální pole s&nbsp;volitelným typem</h2>

<p>Samotné interní pole objektů typu <strong>Tensor</strong> je vždy
<i>homogenní</i>, což znamená že může obsahovat pouze prvky stejného typu,
ovšem tento typ je konfigurovatelný. Implicitně se jedná o hodnoty typu
<i>double</i> (celý objekt má v&nbsp;takovém případě konkrétní typ
<strong>DoubleTensor</strong>), ovšem existují i další typy, které je možné
v&nbsp;případě potřeby zvolit (například při zpracování obrázků, audio dat
atd.):</p>

<table>
<tr><th>Jméno typu</th><th>Význam</th></tr>
<tr><td>torch.bool</td><td>tenzor s&nbsp;prvky typu <i>bool</i></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.int8</td><td>tenzor s&nbsp;prvky typu <i>signed char</i> (osmibitové celé číslo)</td></tr>
<tr><td>torch.int16</td><td>tenzor s&nbsp;prvky typu <i>signed short</i> (16bitové celé číslo)</td></tr>
<tr><td>torch.int32</td><td>tenzor s&nbsp;prvky typu <i>signed int</i> (32bitové celé číslo)</td></tr>
<tr><td>torch.int64</td><td>tenzor s&nbsp;prvky typu <i>signed long</i> (64bitové celé číslo)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.uint8</td><td>tenzor s&nbsp;prvky typu <i>unsigned char</i> (osmibitové celé číslo)</td></tr>
<tr><td>torch.uint16</td><td>tenzor s&nbsp;prvky typu <i>unsigned short</i> (16bitové celé číslo)</td></tr>
<tr><td>torch.uint32</td><td>tenzor s&nbsp;prvky typu <i>unsigned int</i> (32bitové celé číslo)</td></tr>
<tr><td>torch.uint64</td><td>tenzor s&nbsp;prvky typu <i>unsigned long</i> (64bitové celé číslo)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.bfloat16</td><td>tenzor s&nbsp;prvky typu <i>bfloat16</i> (<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.float16 nebo torch.half</td><td>tenzor s&nbsp;prvky typu <i>half float</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k10">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k10</a>)</td></tr>
<tr><td>torch.float32 nebo torch.float</td><td>tenzor s&nbsp;prvky typu <i>float</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k04">32bitová FP hodnota</a>)</td></tr>
<tr><td>torch.float64 nebo torch.double</td><td>tenzor s&nbsp;prvky typu <i>double</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k05">64bitová FP hodnota</a>)</td></tr>
</table>



<p><a name="k08"></a></p>
<h2 id="k08">8. Datové typy pro tenzory uložené v&nbsp;paměti CPU i GPU kompatibilní se staršími verzemi Torche a PyTorche</h2>

<p>Pro zajištění zpětné kompatibility lze použít i tyto názvy datových
typů:</p>

<table>
<tr><th>Jméno typu</th><th>Význam</th></tr>
<tr><td>torch.BoolTensor</td><td>tenzor s&nbsp;prvky typu <i>bool</i></td></tr>
<tr><td>torch.CharTensor</td><td>tenzor s&nbsp;prvky typu <i>char</i></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.ByteTensor</td><td>tenzor s&nbsp;prvky typu <i>unsigned char</i> (osmibitové celé číslo)</td></tr>
<tr><td>torch.ShortTensor</td><td>tenzor s&nbsp;prvky typu <i>short</i> (16bitové celé číslo)</td></tr>
<tr><td>torch.IntTensor</td><td>tenzor s&nbsp;prvky typu <i>int</i> (32bitové celé číslo)</td></tr>
<tr><td>torch.LongTensor</td><td>tenzor s&nbsp;prvky typu <i>long</i> (64bitové celé číslo)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.BFloat16Tensor</td><td>tenzor s&nbsp;prvky typu <i>bfloat16</i> (<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.HalfTensor</td><td>tenzor s&nbsp;prvky typu <i>half float</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k10">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k10</a>)</td></tr>
<tr><td>torch.FloatTensor</td><td>tenzor s&nbsp;prvky typu <i>float</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k04">32bitová FP hodnota</a>)</td></tr>
<tr><td>torch.DoubleTensor</td><td>tenzor s&nbsp;prvky typu <i>double</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k05">64bitová FP hodnota</a>)</td></tr>
</table>

<p>Varianty ukládané do paměti GPU se jmenují nepatrně odlišně:</p>

<table>
<tr><th>Jméno typu</th></tr>
<tr><td>torch.cuda.BoolTensor</td></tr>
<tr><td>torch.cuda.CharTensor</td></tr>
<tr><td>torch.cuda.ByteTensor</td></tr>
<tr><td>torch.cuda.ShortTensor</td></tr>
<tr><td>torch.cuda.IntTensor</td></tr>
<tr><td>torch.cuda.LongTensor</td></tr>
<tr><td>torch.cuda.BFloat16Tensor</td></tr>
<tr><td>torch.cuda.HalfTensor</td></tr>
<tr><td>torch.cuda.FloatTensor</td></tr>
<tr><td>torch.cuda.DoubleTensor</td></tr>
<table>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu PyTorch lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td> 2</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td> 3</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td> 4</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td> 5</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td> 6</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td> 7</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td> 8</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td> 8</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td>10</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td>11</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td>12</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td>13</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td>14</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
<tr><td>15</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Seriál Programovací jazyk Lua na Rootu</ br>
<a href="https://www.root.cz/serialy/programovaci-jazyk-lua/">https://www.root.cz/serialy/programovaci-jazyk-lua/</a>
</li>

<li>PDM: moderní správce balíčků a virtuálních prostředí Pythonu</ br>
<a href="https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/">https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008</ br>
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008 (dokončení)</ br>
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/</a>
</li>

<li>Brain Floating Point &ndash; nový formát uložení čísel pro strojové učení a chytrá čidla</ br>
<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>
</li>

<li>Stránky projektu PyTorch</ br>
<a href="https://pytorch.org/">https://pytorch.org/</a>
</li>

<li>Informace o instalaci PyTorche</ br>
<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>
</li>

<li>Tenzor (Wikipedia)</ br>
<a href="https://cs.wikipedia.org/wiki/Tenzor">https://cs.wikipedia.org/wiki/Tenzor</a>
</li>

<li>Introduction to Tensors</ br>
<a href="https://www.youtube.com/watch?v=uaQeXi4E7gA">https://www.youtube.com/watch?v=uaQeXi4E7gA</a>
</li>

<li>Introduction to Tensors: Transformation Rules</ br>
<a href="https://www.youtube.com/watch?v=j6DazQDbEhQ">https://www.youtube.com/watch?v=j6DazQDbEhQ</a>
</li>

<li>Tensor Attributes</ br>
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Tensors Explained Intuitively: Covariant, Contravariant, Rank </ br>
<a href="https://www.youtube.com/watch?v=CliW7kSxxWU">https://www.youtube.com/watch?v=CliW7kSxxWU</a>
</li>

<li>What is the relationship between PyTorch and Torch?</ br>
<a href="https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch">https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch</a>
</li>

<li>What is a tensor anyway?? (from a mathematician)</ br>
<a href="https://www.youtube.com/watch?v=K7f2pCQ3p3U">https://www.youtube.com/watch?v=K7f2pCQ3p3U</a>
</li>

<li>Visualization of tensors - part 1 </ br>
<a href="https://www.youtube.com/watch?v=YxXyN2ifK8A">https://www.youtube.com/watch?v=YxXyN2ifK8A</a>
</li>

<li>Visualization of tensors - part 2A</ br>
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>Visualization of tensors - part 2B</ br>
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>What the HECK is a Tensor?!?</ br>
<a href="https://www.youtube.com/watch?v=bpG3gqDM80w">https://www.youtube.com/watch?v=bpG3gqDM80w</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>An Introduction to Tensors<br />
<a href="https://math.stackexchange.com/questions/10282/an-introduction-to-tensors">https://math.stackexchange.com/questions/10282/an-introduction-to-tensors</a>
</li>

<li>Differences between a matrix and a tensor<br />
<a href="https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor">https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor</a>
</li>

<li>Qualitatively, what is the difference between a matrix and a tensor?<br />
<a href="https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?">https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

