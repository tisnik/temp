<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Od projektu Scikit-learn ke knihovně PyTorch</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Od projektu Scikit-learn ke knihovně PyTorch</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>Na sérii článků s popisem možností knihovny scikit-learn dnes částečně navážeme. Začneme se totiž zabývat knihovnou PyTorch, která je poměrně intenzivně využívána v oblasti strojového učení (machine learning) a zejména pak hlubokého učení (deep learning).</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Od projektu Scikit-learn ke knihovně PyTorch</a></p>
<p><a href="#k02">2. Přímý předchůdce knihovny PyTorch: nástroj Torch</a></p>
<p><a href="#k03">3. Zpracování vektorů, matic a tenzorů</a></p>
<p><a href="#k04">4. Instalace knihovny PyTorch</a></p>
<p><a href="#k05">5. Konfigurace projektu (<strong>pyproject.toml</strong>)</a></p>
<p><a href="#k06">6. Základní datová struktura, s&nbsp;níž se v&nbsp;knihovně PyTorch pracuje</a></p>
<p><a href="#k07">7. Tenzor: homogenní n-dimenzionální pole s&nbsp;volitelným typem</a></p>
<p><a href="#k08">8. Datové typy pro tenzory uložené v&nbsp;paměti CPU i GPU kompatibilní se staršími verzemi Torche a PyTorche</a></p>
<p><a href="#k09">9. Základní konstruktory tenzorů</a></p>
<p><a href="#k10">10. Tenzory vyšších řádů</a></p>
<p><a href="#k11">11. Vynulování všech prvků tenzoru libovolného řádu metodou <strong>zero_</strong></a></p>
<p><a href="#k12">12. Použití konstruktoru <strong>zeros</strong> pro tenzory různých řádů a tvarů</a></p>
<p><a href="#k13">13. Použití konstruktoru <strong>ones</strong> pro tenzory různých řádů a tvarů</a></p>
<p><a href="#k14">14. Konstrukce jednotkové matice</a></p>
<p><a href="#k15">15. Použití konstruktoru <strong>range</strong></a></p>
<p><a href="#k16">16. Konstruktor <strong>arange</strong></a></p>
<p><a href="#k17">17. Obsah navazujícího článku</a></p>
<p><a href="#k18">18. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k19">19. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Od projektu Scikit-learn ke knihovně PyTorch</h2>

<p>V&nbsp;seriálu <a
href="https://www.root.cz/serialy/datova-analyza-s-vyuzitim-jazyka-python/">o
datové analýze s&nbsp;využitím programovacího jazyka Python</a> jsme se až
doposud zabývali projektem <i>Scikit-learn</i>, který uživatelům-programátorům
nabízí mnoho postupů a nástrojů pro zpracování dat, tvorbu různě složitých či
naopak interně jednoduchých modelů, shlukovou analýzu (<i>clustering</i>) atd.
Tento projekt mj.&nbsp;umožňuje konstrukci a trénink neuronových sítí, přičemž
výsledkem bude model provádějící buď <i>klasifikaci</i> či <i>regresi</i>. Díky
tomu, že se se všemi modely pracuje prakticky totožným způsobem a uživatelé
mají k&nbsp;dispozici i nástroje pro ověření kvality modelů, se
<i>Scikit-learn</i> v&nbsp;oblasti zpracování dat i strojového učení využívá
velmi často a mnohdy se jedná o první projekt, s&nbsp;nímž se zájemci o oblast
zpracování dat, strojového učení (a částečně i umělé inteligence) setkají. A
v&nbsp;mnoha oblastech se skutečně jedná ideální nástroj.</p>

<img src="https://i.iinfo.cz/images/542/scikit-learn-1-4.webp" class="image-1110846" width="180" height="97" alt="&#160;" title="Autor: Scikit-learn autoři podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 1: Logo projektu Scikit-learn.</i></p>

<p>Ovšem v&nbsp;případě, že běžná shluková analýza či jednodušší modely
nedostačují, což jsou typicky oblasti &bdquo;hlubokého&ldquo; strojového učení
(<i>deep learning</i>) a především tehdy, pokud je zapotřebí například
rozpoznávat audio signály nebo rastrové obrázky, se ukazuje, že by bylo
vhodnější mít k&nbsp;dispozici specializovanější nástroj, který by dokázal
pracovat s&nbsp;rozsáhlými neuronovými sítěmi, s&nbsp;konvolučními sítěmi atd.
A vzhledem k&nbsp;tomu, že výpočty prováděné při tréninku těchto sítí jsou
velmi náročné (a na druhou stranu unifikované a prováděné nad dlouhými vektory)
by takový nástroj měl umožnit výpočty s&nbsp;využitím moderních GPU. Takové
projekty pochopitelně existují a v&nbsp;ekosystému programovacího jazyka Python
se jedná zejména o knihovnu <i>PyTorch</i>. A právě popisem možností této
knihovny se budeme zabývat v&nbsp;tomto článku i v&nbsp;článcích
navazujících.</p>

<a href="https://www.root.cz/obrazek/1148745/"><img src="https://i.iinfo.cz/images/401/pytorch-01-1-prev.webp" class="image-1148745" width="370" height="98" data-prev-filename="https://i.iinfo.cz/images/401/pytorch-01-1-prev.webp" data-prev-width="370" data-prev-height="98" data-large-filename="https://i.iinfo.cz/images/401/pytorch-01-1-large.webp" data-large-width="720" data-large-height="191" alt="&#160;" title="Autor: Various authors, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" /></a>
<p><i>Obrázek 2: Logo projektu PyTorch.</i></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Přímý předchůdce knihovny PyTorch: nástroj Torch</h2>

<p>Knihovna <i>PyTorch</i>, kterou se budeme zabývat, ve skutečnosti nevznikla
na zelené louce. Jejím přímým předchůdcem je knihovna nazvaná <i>Torch</i>,
která byla (a vlastně ještě doposud je) používána nejenom v&nbsp;oboru
strojového učení (<i>machine learning</i>), ale i pro &bdquo;obyčejné&ldquo;
zpracování vektorů a tenzorů. Pro psaní skriptů se v&nbsp;Torchi používá <a
href="https://www.root.cz/serialy/programovaci-jazyk-lua/">programovací jazyk
Lua</a>. Ten je interpretovaný a i když se jedná o jeden z&nbsp;nejrychlejších
interpretrů, tak pochopitelně nemůže soutěžit s&nbsp;překladači
resp.&nbsp;překládanými programovacími jazyky. Interně se ovšem v&nbsp;Torchi
prakticky všechny výpočty provádí v&nbsp;nativních céčkových knihovnách a
popř.&nbsp;se využívá i CUDA, tj.&nbsp;využívají se zde možnosti grafických
akcelerátorů. Možnosti knihovny <i>Torch</i> však ve skutečnosti přesahují
&bdquo;pouhou&ldquo; práci s&nbsp;tenzory, protože obsahuje i moduly pro
lineární algebru a především pro neuronové sítě, což je poměrně rozsáhlé téma,
kterému se budeme věnovat v&nbsp;samostatném článku (již zaměřeného na
PyTorch).</p>

<a href="https://www.root.cz/obrazek/1148754/"><img src="https://i.iinfo.cz/images/578/pytorch-01-b.webp" class="image-1148754" width="203" height="199" data-prev-filename="https://i.iinfo.cz/images/578/pytorch-01-b.webp" data-prev-width="203" data-prev-height="199" data-large-filename="https://i.iinfo.cz/images/578/pytorch-01-b.webp" data-large-width="203" data-large-height="199" alt="&#160;" title="Autor: Torch authors, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" /></a>
<p><i>Obrázek 3: Logo projektu Torch.</i></p>

<p>Společně se zvyšujícím se počtem vývojářů, kteří začali používat
programovací jazyk Python, se ukazovalo, že by bylo namísto jazyka Lua (což je
sice skvělý jazyk, který ovšem nikdy významně nepřesáhl oblast své niky)
vhodnější založit projekt na Pythonu. To se skutečně stalo a přibližně od roku
2017 se vývoj přesunul od projektu <i>Torch</i> k&nbsp;<i>PyTorchi</i>. Oba
projekty jsou sice stále dosti podobné, ale jak uvidíme v&nbsp;dalších
kapitolách, některé operace se přece jen odlišují. Na rozdíly narazíme vlastně
hned na začátku, protože v&nbsp;jazyce Lua se prvky polí indexují od jedničky,
kdežto v&nbsp;Pythonu se prvky seznamů (o od nich specializovaných polí)
indexují od nuly. Nicméně i přes tyto rozdíly je přechod od Torche
k&nbsp;PyTorchi relativně snadný, protože i základy, na nichž jsou obě knihovny
postaveny, jsou podobné.</p>

<a href="https://www.root.cz/obrazek/1148751/"><img src="https://i.iinfo.cz/images/401/pytorch-01-3-prev.webp" class="image-1148751" width="268" height="270" data-prev-filename="https://i.iinfo.cz/images/401/pytorch-01-3-prev.webp" data-prev-width="268" data-prev-height="270" data-large-filename="https://i.iinfo.cz/images/401/pytorch-01-3.webp" data-large-width="300" data-large-height="302" alt="&#160;" title="Autor: Various authors, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" /></a>
<p><i>Obrázek 4: Logo programovacího jazyka Lua, který svými vlastnostmi
soutěží s&nbsp;Pythonem. Ovšem Lua se využívá primárně jako jazyk vkládaný do
dalších aplikací (příkladem z&nbsp;moderní éry je Neovim), kdežto Python se
z&nbsp;původně pouze skriptovacího jazyka stal plnohodnotný projekt využívaný i
pro skutečně rozsáhlé aplikace.</i></p>

<p><div class="rs-tip-major">Poznámka: zde může docházet k&nbsp;určitým
zmatkům, protože Pythonovský balíček s&nbsp;PyTorchem se ve skutečnosti jmenuje
<strong>torch</strong>. Ovšem skutečně se jedná o PyTorch a nikoli o předchůdce
této knihovny.</div></p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Zpracování vektorů, matic a tenzorů</h2>

<p>Jednou poměrně rozsáhlou oblastí v&nbsp;IT je zpracování vektorů, matic i
tenzorů, protože s&nbsp;těmito strukturami se můžeme setkat v&nbsp;různých
disciplínách, například ve finančnictví, pojišťovnictví, statistice, zpracování
numerických dat, simulacích, strojovém učení (a s&nbsp;klasickými tenzory třeba
ve fyzice) atd. Současně se jedná i o velmi zajímavou oblast, neboť právě kvůli
co nejrychlejší práci s&nbsp;velkými maticemi byly vytvořeny speciální
výpočetní bloky v&nbsp;některých superpočítačích (příkladem mohou být
superpočítače <i>Cray</i>). Současné knihovny dokážou v&nbsp;případě potřeby
využít jak některá rozšíření instrukčních sad (SIMD instrukce typu AXV(512),
SSE-x, původně též MMX či 3DNow!), tak i programovatelné grafické akcelerátory
(GPU, v&nbsp;současnosti je lídrem v&nbsp;tomto oboru NVidia.</p>

<p>Práce s&nbsp;vektory a maticemi byla (a samozřejmě doposud je) podporována
v&nbsp;překladačích FORTRANu, které začaly být po vzniku superpočítačů vybaveny
algoritmy, které dokázaly převést některé typy programových smyček na
&bdquo;vektorové operace&ldquo;. Paralelně vznikly i specializované jazyky
určené téměř výhradně pro práci s&nbsp;vektory i maticemi &ndash; příkladem
jsou jazyky <i>APL</i> a <i>J</i>.</p>

<p>V&nbsp;současnosti je používáno relativně velké množství programovacích
jazyků popř.&nbsp;specializovaných knihoven orientovaných na práci
s&nbsp;vektory, maticemi, tenzory atd. Z&nbsp;komerčních nástrojů je zapotřebí
jmenovat především známý <i>MATLAB</i> vydávaný společností <i>MathWorks</i>,
nativní práci s&nbsp;maticemi a vektory ovšem velmi dobře podporuje také
nástroj <a
href="https://www.gnu.org/software/octave/doc/interpreter/Matrices.html">GNU
Octave</a> (<a
href="https://gnu.org/software/octave/">https://gnu.org/software/octave/</a>),
<a href="http://www.ats.ucla.edu/stat/r/library/matrix_alg.htm">jazyk R</a> (<a
href="http://www.r-project.org/">http://www.r-project.org/</a>) a také
relativně nový jazyk <a
href="https://www.root.cz/serialy/programovaci-jazyk-julia/">Julia</a> (<a
href="http://julialang.org/">http://julialang.org/</a>, zajímavé výsledky
benchmarků lze najít na adrese <a
href="http://julialang.org/benchmarks/">http://julialang.org/benchmarks/</a>).
Z&nbsp;knihoven jmenujme především oblíbenou a dnes dosti intenzivně využívanou
Pythonovskou knihovnu <i>NumPy</i> (<a
href="http://www.numpy.org/">http://www.numpy.org/</a>).</p>

<p>Framework <i>PyTorch</i> je mj.&nbsp;určen pro zpracování vektorů, matic i
tenzorů (tj.&nbsp;zobecnění vektorů), a to s&nbsp;využitím programovacího
jazyka Python namísto specializovaného jazyka (Julia, Matlab, R). A tyto datové
struktury jsou dále využívány v&nbsp;dalších oblastech, které PyTorch podporuje
&ndash; v&nbsp;první řadě se jedná o neuronové sítě.</p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Instalace knihovny PyTorch</h2>

<p>Před prvními pokusy s&nbsp;knihovnou PyTorch si ji pochopitelně musíme
nainstalovat. To je ovšem složitější, než v&nbsp;případě běžných Pythonovských
balíčků, protože se přímo nepoužívá PyPi, ale vlastní registr s&nbsp;balíčky.
Přejděte tedy na stránku <a
href="https://pytorch.org/get-started/locally/#start-locally">https://pytorch.org/get-started/locally/#start-locally</a>,
kde si můžete vybrat svoji platformu (Linux, Windows, Mac), správce balíčků
(což bude s&nbsp;velkou pravděpodobností <strong>pip</strong>), jazyk
(pochopitelně <strong>Python</strong>) a taktéž to, zda budete chtít
nainstalovat PyTorch s&nbsp;podporou CUDA či bez této podpory. Využití
platformy CUDA sice povede k&nbsp;velkému nárůstu rychlosti tréninku
neuronových sítí, ovšem na druhou stranu samotná instalace naroste o přibližně
4GB (!). Proto může být pro první kroky snazší si nainstalovat pouze
&bdquo;CPU&ldquo; variantu PyTorche &ndash; všechny vlastnosti zůstanou
zachovány, pouze se pro výpočty bude stále používat běžný mikroprocesor a
nikoli GPU.</p>

<p>Na výše uvedené stránce se po výběru kritérií zobrazí příkaz, který lze
použít pro instalaci PyTorche.</p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Konfigurace projektu (<strong>pyproject.toml</strong>)</h2>

<p>V&nbsp;případě, že pro správu Pythonovských projektů používáte projektový
soubor <strong>pyproject.toml</strong> a například <a
href="https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/">nástroj
PDM</a>, je možné specifikovat konfiguraci projektu takovým způsobem, že se
stáhne a nainstaluje korektní varianta PyTorche. Příkladem může být specifikace
PyTorche ve variantě pro CPU:</p>

<pre>
[[tool.pdm.source]]
type = "find_links"
url = "https://download.pytorch.org/whl/cpu/torch_stable.html"
name = "torch"
&nbsp;
[build-system]
requires = ["pdm-backend"]
build-backend = "pdm.backend"
&nbsp;
[project]
name = "skvely projekt zalozeny na PyTorchi"
version = "0.1.0"
description = "skvely projekt zalozeny na PyTorchi"
authors = []
dependencies = [
    ...
    ...
    ...
    "torch==2.5.1+cpu",
    ...
    ...
    ...
]
# PyTorch vyzaduje minimalne Python 3.9 (priklady otestovany v 3.11 a 3.12)
requires-python = "==3.9.*"
readme = "README.md"
license = {file = "LICENSE"}
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. Základní datová struktura, s&nbsp;níž se v&nbsp;knihovně PyTorch pracuje</h2>

<p>V&nbsp;knihovně <i>PyTorch</i> se základní datová struktura jmenuje
<strong>Tensor</strong>. Tato struktura umožňuje reprezentovat skalární hodnoty
(tenzory nultého řádu), běžné vektory (tenzory prvního řádu), běžné matice,
&bdquo;3D matice&ldquo; atd. Interně je struktura objektů typu
<strong>Tensor</strong> až překvapivě jednoduchá &ndash; základem je
jednorozměrné pole doplněné o metadata, v&nbsp;nichž je uložen počet dimenzí,
velikost dimenzí, hodnoty <i>stride</i> používané při přístupu k&nbsp;prvkům
interního pole atd. Nad tenzory je navíc možné vytvářet různé pohledy
(<i>views</i>), které mohou být určeny buď pouze pro čtení či pro čtení i zápis
(pohled může například reprezentovat tenzor se změněným tvarem &ndash;
<i>shape</i>).</p>

<p><div class="rs-tip-major">Poznámka: pojem <i>tensor</i> může být
v&nbsp;tomto kontextu poněkud matoucí, protože v&nbsp;matematice a fyzice má
tento termín velmi specifický význam a tenzory nejsou totožné
s&nbsp;n-dimenzionálními poli (chybí nám totiž například informace o bázových
vektorech, pro tenzory jsou definována pravidla pro jejich transformaci a i
samotný tenzor má svoji obdobu v&nbsp;modelovaném systému, zatímco
n-dimenzionální pole je skutečně jen polem čísel). Matematici a fyzici rádi
zdůrazňují rozdíly mezi tenzory a n-dimenzionálními poli (vektory, matice, ...)
a mají pochopitelně pravdu. Ovšem z&nbsp;pohledu knihovny <i>PyTorch</i> se
fyzikální význam tenzorů ztrácí a skutečně s&nbsp;nimi můžeme pracovat jako
s&nbsp;n-dimenzionálními poli. A podobně s&nbsp;nimi pracují i TPU (<i>Tensor
Processing Unit(s)</i>) v&nbsp;akcelerátorech.</div></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Tenzor: homogenní n-dimenzionální pole s&nbsp;volitelným typem</h2>

<p>Samotné interní pole objektů typu <strong>Tensor</strong> je vždy
<i>homogenní</i>, což znamená že může obsahovat pouze prvky stejného typu,
ovšem tento typ je konfigurovatelný. Implicitně se jedná o hodnoty typu
<i>double</i> (celý objekt má v&nbsp;takovém případě konkrétní typ
<strong>DoubleTensor</strong>), ovšem existují i další typy, které je možné
v&nbsp;případě potřeby zvolit (například při zpracování obrázků, audio dat
atd.):</p>

<table>
<tr><th>Jméno typu</th><th>Význam</th></tr>
<tr><td>torch.bool</td><td>tenzor s&nbsp;prvky typu <i>bool</i></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.int8</td><td>tenzor s&nbsp;prvky typu <i>signed char</i> (osmibitové celé číslo)</td></tr>
<tr><td>torch.int16</td><td>tenzor s&nbsp;prvky typu <i>signed short</i> (16bitové celé číslo)</td></tr>
<tr><td>torch.int32</td><td>tenzor s&nbsp;prvky typu <i>signed int</i> (32bitové celé číslo)</td></tr>
<tr><td>torch.int64</td><td>tenzor s&nbsp;prvky typu <i>signed long</i> (64bitové celé číslo)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.uint8</td><td>tenzor s&nbsp;prvky typu <i>unsigned char</i> (osmibitové celé číslo)</td></tr>
<tr><td>torch.uint16</td><td>tenzor s&nbsp;prvky typu <i>unsigned short</i> (16bitové celé číslo)</td></tr>
<tr><td>torch.uint32</td><td>tenzor s&nbsp;prvky typu <i>unsigned int</i> (32bitové celé číslo)</td></tr>
<tr><td>torch.uint64</td><td>tenzor s&nbsp;prvky typu <i>unsigned long</i> (64bitové celé číslo)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.quint8 nebo torch.qint8</td><td>diskretizované celočíselné hodnoty (8bit)</td></tr>
<tr><td>torch.quint4x2</td><td>diskretizované celočíselné hodnoty (4bit), velmi omezené použití</td></tr>
<tr><td>torch.qint32</td><td>diskretizované celočíselné hodnoty (32bit)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.bfloat16</td><td>tenzor s&nbsp;prvky typu <i>bfloat16</i> (<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.float16 nebo torch.half</td><td>tenzor s&nbsp;prvky typu <i>half float</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k10">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k10</a>)</td></tr>
<tr><td>torch.float32 nebo torch.float</td><td>tenzor s&nbsp;prvky typu <i>float</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k04">32bitová FP hodnota</a>)</td></tr>
<tr><td>torch.float64 nebo torch.double</td><td>tenzor s&nbsp;prvky typu <i>double</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k05">64bitová FP hodnota</a>)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.float8_e4m3fn</td><td>speciální formát osmibitových hodnot s&nbsp;plovoucí řádovou čárkou</td></tr>
<tr><td>torch.float8_e5m2</td><td>speciální formát osmibitových hodnot s&nbsp;plovoucí řádovou čárkou</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.complex32 nebo torch.chalf</td><td>komplexní čísla s&nbsp;16bitovými FP hodnotami</td></tr>
<tr><td>torch.complex64 nebo torch.cfloat</td><td>komplexní čísla s&nbsp;32bitovými FP hodnotami</td></tr>
<tr><td>torch.complex128 nebo torch.cdouble</td><td>komplexní čísla s&nbsp;64bitovými FP hodnotami</td></tr>
</table>



<p><a name="k08"></a></p>
<h2 id="k08">8. Datové typy pro tenzory uložené v&nbsp;paměti CPU i GPU kompatibilní se staršími verzemi Torche a PyTorche</h2>

<p>Pro zajištění zpětné kompatibility lze použít i tyto názvy datových
typů:</p>

<table>
<tr><th>Jméno typu</th><th>Význam</th></tr>
<tr><td>torch.BoolTensor</td><td>tenzor s&nbsp;prvky typu <i>bool</i></td></tr>
<tr><td>torch.CharTensor</td><td>tenzor s&nbsp;prvky typu <i>char</i></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.ByteTensor</td><td>tenzor s&nbsp;prvky typu <i>unsigned char</i> (osmibitové celé číslo)</td></tr>
<tr><td>torch.ShortTensor</td><td>tenzor s&nbsp;prvky typu <i>short</i> (16bitové celé číslo)</td></tr>
<tr><td>torch.IntTensor</td><td>tenzor s&nbsp;prvky typu <i>int</i> (32bitové celé číslo)</td></tr>
<tr><td>torch.LongTensor</td><td>tenzor s&nbsp;prvky typu <i>long</i> (64bitové celé číslo)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.BFloat16Tensor</td><td>tenzor s&nbsp;prvky typu <i>bfloat16</i> (<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.HalfTensor</td><td>tenzor s&nbsp;prvky typu <i>half float</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k10">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k10</a>)</td></tr>
<tr><td>torch.FloatTensor</td><td>tenzor s&nbsp;prvky typu <i>float</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k04">32bitová FP hodnota</a>)</td></tr>
<tr><td>torch.DoubleTensor</td><td>tenzor s&nbsp;prvky typu <i>double</i> (<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/#k05">64bitová FP hodnota</a>)</td></tr>
</table>

<p>Varianty ukládané do paměti GPU se jmenují nepatrně odlišně:</p>

<table>
<tr><th>Jméno typu</th></tr>
<tr><td>torch.cuda.BoolTensor</td></tr>
<tr><td>torch.cuda.CharTensor</td></tr>
<tr><td>torch.cuda.ByteTensor</td></tr>
<tr><td>torch.cuda.ShortTensor</td></tr>
<tr><td>torch.cuda.IntTensor</td></tr>
<tr><td>torch.cuda.LongTensor</td></tr>
<tr><td>torch.cuda.BFloat16Tensor</td></tr>
<tr><td>torch.cuda.HalfTensor</td></tr>
<tr><td>torch.cuda.FloatTensor</td></tr>
<tr><td>torch.cuda.DoubleTensor</td></tr>
<table>



<p><a name="k09"></a></p>
<h2 id="k09">9. Základní konstruktory tenzorů</h2>

<p>Již v&nbsp;úvodních kapitolách dnešního článku jsme si řekli, že základní
datovou strukturou knihovny PyTorch jsou N-dimenzionální pole, která mohou být
použita pro uložení komponent tenzorů. V&nbsp;této kapitole si ukážeme základní
konstruktory objektů typu Tensor (prozatím se omezíme na komponenty tenzorů,
které jsou typu <strong>Double</strong>).</p>

<p>Vytvoření skaláru, neboli tenzoru nultého řádu a inicializace jeho (jediné)
komponenty:</p>

<pre>
<i># skutecny skalar - tenzor nulteho radu</i>
s1 = torch.tensor(100)
print(s1)
</pre>

<p>Povšimněte si rozdílu mezi skalárem a jednoprvkovým vektorem &ndash; tyto
struktury se chovají značně odlišně (i zápis je odlišný &ndash;
<strong>tensor</strong> vs. <strong>Tensor</strong>):</p>

<pre>
<i># konstrukce tenzoru prvniho radu (jednoprvkovy vektor)</i>
s2 = torch.Tensor(1)
print(s2)
</pre>

<p>Výsledky:</p>

<pre>
tensor(100)
tensor([-1.0842e-19])
</pre>

<p><div class="rs-tip-major">Poznámka: ve druhém případě nebyl vektor
inicializován.</div></p>

<p>Přístup k&nbsp;jediné složce jednoprvkového vektoru s&nbsp;její
modifikací:</p>

<pre>
s2[0] = 42
print(s2)
</pre>

<p>Inicializace jednoprvkového vektoru:</p>

<pre>
<i># konstrukce tenzoru (jednoprvkovy vektor) s jeho inicializaci</i>
s2 = torch.tensor([-1])
print(s2)
&nbsp;
<i># pristup k (jedine) slozce tenzoru</i>
s2[0] = 42
print(s2)
</pre>

<p>Výsledky:</p>

<pre>
tensor([-1])
tensor([42])
</pre>

<p>Vytvoření vektoru, neboli tenzoru prvního řádu. V&nbsp;tomto konkrétním
případě se jedná o tříprvkový vektor:</p>

<pre>
<i># konstrukce tenzoru prvniho radu (vektoru)</i>
v1 = torch.Tensor(3)
print(v1)
</pre>

<p>Inicializace komponent vektoru:</p>

<pre>
<i># inicializace jednotlivych prvku vektoru</i>
v1[0] = 10
v1[1] = 20
v1[2] = 30
print(v1)
</pre>

<p>Výsledek:</p>

<pre>
tensor([10., 20., 30.])
</pre>

<p>Alternativně lze vektor (tenzor prvního řádu) vytvořit a současně
inicializovat jeho komponenty. Použije se přitom běžný seznam tak, jak ho známe
z&nbsp;programovacího jazyka Python:</p>

<pre>
<i># konstrukce tenzoru prvniho radu (vektoru) s inicializaci prvku</i>
v2 = torch.Tensor([1, 2, 3])
print(v2)
</pre>

<p>Výsledek:</p>

<pre>
tensor([1., 2., 3.])
</pre>

<p>Možná je i tato konstrukce:</p>

<pre>
<i># konstrukce tenzoru prvniho radu (tenzoru)</i>
<i># s inicializací výsledkem generátoru range</i>
v3 = torch.Tensor(range(10))
print(v3)
</pre>

<p>Výsledek:</p>

<pre>
tensor([0., 1., 2., 3., 4., 5., 6., 7., 8., 9.])
</pre>



<p><a name="k10"></a></p>
<h2 id="k10">10. Tenzory vyšších řádů</h2>

<p>Vytvoření a inicializace tenzoru druhého řádu, který může být reprezentován
maticí:</p>

<pre>
<i># konstrukce tenzoru druheho radu (matice)</i>
m1 = torch.Tensor(3, 3)
print(m1)
</pre>

<p>Výsledná matice se zobrazí následujícím způsobem (prvky nejsou
inicializovány):</p>

<pre>
tensor([[ 9.8455e-42,  2.7700e+30,  2.6378e+23],
        [ 1.7259e+25,  4.8953e-26, -9.0072e+15],
        [ 4.1205e+21,  1.7036e+19,  2.6177e+30]])
</pre>

<p>Inicializace prvků matice:</p>

<pre>
<i># konstrukce tenzoru druheho radu (matice)</i>
m2 = torch.Tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(m2)
</pre>

<p>Výsledky:</p>

<pre>
tensor([[1., 2., 3.],
        [4., 5., 6.],
        [7., 8., 9.]])
</pre>

<p>A konečně tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo;:</p>

<pre>
<i># 2D struktury - matice</i>
m1 = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
m2 = [[10, 20, 30], [40, 50, 60], [70, 80, 90]]
&nbsp;
<i># konstrukce tenzoru tretiho radu</i>
c = torch.Tensor([m1, m2])
print(c)
</pre>

<p>Výsledek se na 2D obrazovce zobrazí takto:</p>

<pre>
tensor([[[ 1.,  2.,  3.],
         [ 4.,  5.,  6.],
         [ 7.,  8.,  9.]],
&nbsp;
        [[10., 20., 30.],
         [40., 50., 60.],
         [70., 80., 90.]]])
</pre>

<p>Nebo přímý zápis:</p>

<pre>
<i># 3D struktura</i>
m3 = [[[1, 2, 3], [4, 5, 6], [7, 8, 9]],
      [[10, 20, 30], [40, 50, 60], [70, 80, 90]]]
&nbsp;
<i># konstrukce tenzoru tretiho radu</i>
c = torch.Tensor(m3)
print(c)
</pre>

<p>Výsledek:</p>

<pre>
tensor([[[ 1.,  2.,  3.],
         [ 4.,  5.,  6.],
         [ 7.,  8.,  9.]],
&nbsp;
        [[10., 20., 30.],
         [40., 50., 60.],
         [70., 80., 90.]]])
</pre>

<p><div class="rs-tip-major">Poznámka: obecně není počet dimenzí
<i>prakticky</i> omezen, ovšem setkáme se zejména s&nbsp;výše popsanými
skaláry, vektory, maticemi a 3D poli.</div></p>



<p><a name="k11"></a></p>
<h2 id="k11">11. Vynulování všech prvků tenzoru libovolného řádu metodou <strong>zero_</strong></h2>

<p>Metodou nazvanou <strong>zero_</strong> je možné tenzor libovolného řádu
modifikovat, a to konkrétně takovým způsobem, že se nastaví hodnoty všech jeho
prvků na nulu. Je to snadné, pouze nesmíme zapomenout na podtržítko uvedené na
konci jména této metody:</p>

<p>Skalár a vektor s&nbsp;jedním prvkem:</p>

<pre>
<i># toto je skutecny skalar</i>
s1 = torch.tensor(1).zero_()
print(s1)
&nbsp;
<i># konstrukce tenzoru prvniho radu s jednim prvkem</i>
<i># vynulovani prvku</i>
s2 = torch.Tensor(1).zero_()
print(s2)
</pre>

<p>Výsledky:</p>

<pre>
tensor(0)
tensor([0.])
</pre>

<p>Vektor (tenzor prvního řádu) s&nbsp;vynulovanými prvky:</p>

<pre>
<i># konstrukce tenzoru prvniho radu</i>
<i># s vynulovanim vsech prvku</i>
v1 = torch.Tensor(3).zero_()
print(v1)
</pre>

<p>Výsledek:</p>

<pre>
tensor([0., 0., 0.])
</pre>

<p>Matice (tenzor druhého řádu) s&nbsp;vynulovanými prvky:</p>

<pre>
<i># konstrukce tenzoru druheho radu</i>
<i># s vynulovanim vsech prvku</i>
m1 = torch.Tensor(3, 3).zero_()
print(m1)
</pre>

<p>Výsledek:</p>

<pre>
tensor([[0., 0., 0.],
        [0., 0., 0.],
        [0., 0., 0.]])
</pre>

<p>3D pole:</p>

<pre>
<i># konstrukce tenzoru tretiho radu</i>
<i># vynulovanim vsech prvku</i>
c = torch.Tensor(2, 3, 4).zero_()
print(c)
</pre>

<p>Výsledky:</p>

<pre>
tensor([[[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]],
&nbsp;
        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Použití konstruktoru <strong>zeros</strong> pro tenzory různých řádů a tvarů</h2>

<p>Výhodnější a rychlejší cesta ke konstrukci tenzoru zvoleného řádu (a tvaru)
však spočívá v&nbsp;použití konstruktoru <strong>zeros()</strong>, kterému se
předá <i>n</i> hodnot reprezentujících velikosti jednotlivých dimenzí. Opět se
podívejme na příklady:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru prvniho radu, vyplneni nulami </i>
v1 = torch.zeros(1)
print(v1)
&nbsp;
<i># konstrukce tenzoru prvniho radu, vyplneni nulami </i>
v2 = torch.zeros(10)
print(v2)
&nbsp;
<i># konstrukce tenzoru druheho radu, vyplneni nulami </i>
m1 = torch.zeros(3, 4)
print(m1)
&nbsp;
<i># konstrukce tenzoru tretiho radu, vyplneni nulami </i>
c1 = torch.zeros(3, 4, 5)
print(c1)
</pre>

<p>Ze zobrazených výsledků je patrné, jakým způsobem jsou tenzory zkonstruovány
a vyplněny nulami:</p>

<pre>
tensor([0.])
&nbsp;
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
&nbsp;
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]])
&nbsp;
tensor([[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]],
&nbsp;
        [[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]],
&nbsp;
        [[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
</pre>



<p><a name="k13"></a></p>
<h2 id="k13">13. Použití konstruktoru <strong>ones</strong> pro tenzory různých řádů a tvarů</h2>

<p>Způsob reprezentace tenzorů druhého řádu sice připomíná matice, ovšem zde se
nesmíme nechat zmýlit &ndash; další konstruktor tenzorů se sice jmenuje
<strong>ones</strong>, ale nevytváří (v&nbsp;2D případě) jednotkovou matici
s&nbsp;jedničkami pouze na hlavní diagonále, nýbrž matici, v&nbsp;níž mají
všechny prvky hodnotu 1. V&nbsp;ostatních ohledech se konstruktor
<strong>ones</strong> podobá výše popsanému konstruktoru
<strong>zeros</strong>, takže jen velmi krátce:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru, vyplneni jednickami</i>
v1 = torch.ones(1)
print(v1)
print()
&nbsp;
<i># konstrukce tenzoru prvniho radu, vyplneni jednickami </i>
v2 = torch.ones(10)
print(v2)
print()
&nbsp;
<i># konstrukce tenzoru druheho radu, vyplneni jednickami </i>
m1 = torch.ones(3, 4)
print(m1)
print()
&nbsp;
<i># konstrukce tenzoru tretiho radu, vyplneni jednickami </i>
c1 = torch.ones(3, 4, 5)
print(c1)
print()
</pre>

<p>Takto zkonstruované tenzory vypadají následovně:</p>

<pre>
tensor([1.])
&nbsp;
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
&nbsp;
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]])
&nbsp;
tensor([[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]],
&nbsp;
        [[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]],
&nbsp;
        [[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]])
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Konstrukce jednotkové matice</h2>

<p>Pro konstrukci jednotkové matice, v&nbsp;níž jsou jedničky uloženy jen na
hlavní diagonále a zbylé prvky jsou nulové, se používá konstruktor pojmenovaný
<strong>eye</strong>. Tomu lze předat jen jedinou hodnotu &ndash; a to velikost
čtvercové matice:</p>

<pre>
import torch
&nbsp;
<i># konstrukce jednotkove matice</i>
m1 = torch.eye(10)
print(m1)
print()
</pre>

<p>Výsledná matice bude vypadat následovně:</p>

<pre>
tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])
</pre>

<p>I když je to divné, je možné specifikovat i počet sloupců. Výsledkem pak
bude (nejednotková) obdélníková matice:</p>

<pre>
<i># konstrukce jednotkove matice se specifikaci sloupcu</i>
m2 = torch.eye(10, 15)
print(m2)
print()
</pre>

<p>Opět se podívejme na výsledek:</p>

<pre>
tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]])
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. Použití konstruktoru <strong>range</strong></h2>

<p>Další typ konstruktoru je možné použít pro vytvoření vektoru obsahujícího
aritmetickou řadu s&nbsp;volitelným krokem. Tento konstruktor se jmenuje
<strong>range</strong> a lze mu předat hodnotu prvního a posledního prvku
popř.&nbsp;i krok mezi hodnotami sousedních prvků. Krok může být kladný i
záporný a samozřejmě se <i>nemusí</i> jednat o celé číslo. Podle očekávání je
implicitní hodnota kroku rovna jedné. Knihovna <i>PyTorch</i> kontroluje
nenulovost kroku a taktéž to, zda se skutečně vytvoří korektní aritmetická
řada. Opět se podívejme na několik jednoduchých příkladů:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.range(10, 20)
print(v1)
&nbsp;
<i># specifikace kroku</i>
v2 = torch.range(10, 20, 2)
print(v2)
&nbsp;
<i># zaporny krok</i>
v3 = torch.range(10, 0, -1)
print(v3)
&nbsp;
<i># krok, ktery neni celociselny</i>
v4 = torch.range(0, 10, 0.5)
print(v4)
</pre>

<p>Čtveřice vektorů, která byla zkonstruována tímto skriptem, má následující
obsah:</p>

<pre>
  v1 = torch.range(10, 20)
tensor([10., 11., 12., 13., 14., 15., 16., 17., 18., 19., 20.])
&nbsp;
  v2 = torch.range(10, 20, 2)
tensor([10., 12., 14., 16., 18., 20.])
&nbsp;
  v3 = torch.range(10, 0, -1)
tensor([10.,  9.,  8.,  7.,  6.,  5.,  4.,  3.,  2.,  1.,  0.])
&nbsp;
  v4 = torch.range(0, 10, 0.5)
tensor([ 0.0000,  0.5000,  1.0000,  1.5000,  2.0000,  2.5000,  3.0000,  3.5000,
         4.0000,  4.5000,  5.0000,  5.5000,  6.0000,  6.5000,  7.0000,  7.5000,
         8.0000,  8.5000,  9.0000,  9.5000, 10.0000])
</pre>

<p><div class="rs-tip-major">Poznámka: za povšimnutí stojí i varování, že tento
konstruktor může být v&nbsp;budoucnosti z&nbsp;knihovny PyTorch odstraněn,
protože jeho chování je odlišné od klasického Pythonu a jeho generátoru
<strong>range</strong>.</div></p>



<p><a name="k16"></a></p>
<h2 id="k16">16. Konstruktor <strong>arange</strong></h2>

<p>V&nbsp;knihovně Numpy je <strong>range</strong> nahrazena za konstruktor
<strong>arange</strong> (což znamená <i>array range</i>). Ta se chová tak, že
horní mez již není do výsledného vektoru uložena. A stejný konstruktor je
v&nbsp;současnosti k&nbsp;dispozici i v&nbsp;knihovně <i>PyTorch</i>:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.arange(10, 20)
print(v1)
&nbsp;
<i># specifikace kroku</i>
v2 = torch.arange(10, 20, 2)
print(v2)
&nbsp;
<i># zaporny krok</i>
v3 = torch.arange(10, 0, -1)
print(v3)
&nbsp;
<i># krok, ktery neni celociselny</i>
v4 = torch.arange(0, 10, 0.5)
print(v4)
</pre>

<p>Povšimněte si, že získané výsledky jsou skutečně odlišné od výsledků skriptu
<a href="#k15">z&nbsp;předchozí kapitoly</a> &ndash; vždy chybí poslední prvek
vektoru:</p>

<pre>
  v1 = torch.range(10, 20)
tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
&nbsp;
  v2 = torch.range(10, 20, 2)
tensor([10, 12, 14, 16, 18])
&nbsp;
  v3 = torch.range(10, 0, -1)
tensor([10,  9,  8,  7,  6,  5,  4,  3,  2,  1])
&nbsp;
  v4 = torch.range(0, 10, 0.5)
tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000,
        4.5000, 5.0000, 5.5000, 6.0000, 6.5000, 7.0000, 7.5000, 8.0000, 8.5000,
        9.0000, 9.5000])
</pre>



<p><a name="k17"></a></p>
<h2 id="k17">17. Obsah navazujícího článku</h2>

<p>V&nbsp;navazujícím článku si vysvětlíme, jakým způsobem jsou tenzory uloženy
v&nbsp;paměti počítače resp.&nbsp;alternativně v&nbsp;paměti GPU (nebo spíše
TPU &ndash; <i>Tensor Processing Unit</i>). Se způsobem uložení do jisté míry
souvisí i získání pohledu (<i>view</i>) na tenzor. A následně si popíšeme i
různé operace, které je možné s&nbsp;tenzory provádět jako s&nbsp;celkem
&ndash; změna tvaru (<i>shape</i>), takzvaný <i>broadcasting</i>, operace
&bdquo;zúžení&ldquo; a pochopitelně i operace prováděné mezi prvky dvou
tenzorů. Získáme tak velmi dobrý základ, který využijeme při konstrukci,
tréninku a provádění predikcí neuronovými sítěmi.</p>



<p><a name="k18"></a></p>
<h2 id="k18">18. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu PyTorch lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td>tensor_constructor_scalar_1.py</td><td>konstrukce tenzoru nultého a prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py</a></td></tr>
<tr><td> 2</td><td>tensor_constructor_scalar_2.py</td><td>inicializace tenzoru prvního řádu s&nbsp;jedním prvkem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py</a></td></tr>
<tr><td> 3</td><td>tensor_constructor_vector_1.py</td><td>konstrukce tenzoru prvního řádu (tříprvkový vektor)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py</a></td></tr>
<tr><td> 4</td><td>tensor_constructor_vector_2.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;inicializací prvků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py</a></td></tr>
<tr><td> 5</td><td>tensor_constructor_vector_3.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;využitím generátoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py</a></td></tr>
<tr><td> 6</td><td>tensor_constructor_matrix_1.py</td><td>vytvoření a inicializace tenzoru druhého řádu, který může být reprezentován maticí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py</a></td></tr>
<tr><td> 7</td><td>tensor_constructor_matrix_2.py</td><td>inicializace prvků matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py</a></td></tr>
<tr><td> 8</td><td>tensor_constructor_3D_1.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py</a></td></tr>
<tr><td> 9</td><td>tensor_constructor_3D_2.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo; (jiná forma inicializace)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>10</td><td>tensor_constructor_scalar_zero.py</td><td>vynulování prvků tenzoru nultého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py</a></td></tr>
<tr><td>11</td><td>tensor_constructor_vector_zero.py</td><td>vynulování prvků tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py</a></td></tr>
<tr><td>12</td><td>tensor_constructor_matrix_zero.py</td><td>vynulování prvků tenzoru druhého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py</a></td></tr>
<tr><td>13</td><td>tensor_constructor_3D_zero.py</td><td>vynulování prvků tenzoru třetího řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>14</td><td>tensor_zeros_shape.py</td><td>použití konstruktoru <strong>zeros</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td>15</td><td>tensor_ones_shape.py</td><td>použití konstruktoru <strong>ones</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td>16</td><td>tensor_eye.py</td><td>konstrukce jednotkové matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>17</td><td>tensor_range.py</td><td>využití konstruktoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py</a></td></tr>
<tr><td>18</td><td>tensor_arange.py</td><td>využití konstruktoru <strong>arange</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py</a></td></tr>
</table>



<p><a name="k19"></a></p>
<h2 id="k19">19. Odkazy na Internetu</h2>

<ol>

<li>Seriál Programovací jazyk Lua na Rootu</ br>
<a href="https://www.root.cz/serialy/programovaci-jazyk-lua/">https://www.root.cz/serialy/programovaci-jazyk-lua/</a>
</li>

<li>PDM: moderní správce balíčků a virtuálních prostředí Pythonu</ br>
<a href="https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/">https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008</ br>
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008 (dokončení)</ br>
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/</a>
</li>

<li>Brain Floating Point &ndash; nový formát uložení čísel pro strojové učení a chytrá čidla</ br>
<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>
</li>

<li>Stránky projektu PyTorch</ br>
<a href="https://pytorch.org/">https://pytorch.org/</a>
</li>

<li>Informace o instalaci PyTorche</ br>
<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>
</li>

<li>Tenzor (Wikipedia)</ br>
<a href="https://cs.wikipedia.org/wiki/Tenzor">https://cs.wikipedia.org/wiki/Tenzor</a>
</li>

<li>Introduction to Tensors</ br>
<a href="https://www.youtube.com/watch?v=uaQeXi4E7gA">https://www.youtube.com/watch?v=uaQeXi4E7gA</a>
</li>

<li>Introduction to Tensors: Transformation Rules</ br>
<a href="https://www.youtube.com/watch?v=j6DazQDbEhQ">https://www.youtube.com/watch?v=j6DazQDbEhQ</a>
</li>

<li>Tensor Attributes</ br>
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Tensors Explained Intuitively: Covariant, Contravariant, Rank </ br>
<a href="https://www.youtube.com/watch?v=CliW7kSxxWU">https://www.youtube.com/watch?v=CliW7kSxxWU</a>
</li>

<li>What is the relationship between PyTorch and Torch?</ br>
<a href="https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch">https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch</a>
</li>

<li>What is a tensor anyway?? (from a mathematician)</ br>
<a href="https://www.youtube.com/watch?v=K7f2pCQ3p3U">https://www.youtube.com/watch?v=K7f2pCQ3p3U</a>
</li>

<li>Visualization of tensors - part 1 </ br>
<a href="https://www.youtube.com/watch?v=YxXyN2ifK8A">https://www.youtube.com/watch?v=YxXyN2ifK8A</a>
</li>

<li>Visualization of tensors - part 2A</ br>
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>Visualization of tensors - part 2B</ br>
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>What the HECK is a Tensor?!?</ br>
<a href="https://www.youtube.com/watch?v=bpG3gqDM80w">https://www.youtube.com/watch?v=bpG3gqDM80w</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>An Introduction to Tensors<br />
<a href="https://math.stackexchange.com/questions/10282/an-introduction-to-tensors">https://math.stackexchange.com/questions/10282/an-introduction-to-tensors</a>
</li>

<li>Differences between a matrix and a tensor<br />
<a href="https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor">https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor</a>
</li>

<li>Qualitatively, what is the difference between a matrix and a tensor?<br />
<a href="https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?">https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?</a>
</li>

<li>Tensors for Neural Networks, Clearly Explained!!!</ br>
<a href="https://www.youtube.com/watch?v=L35fFDpwIM4">https://www.youtube.com/watch?v=L35fFDpwIM4</a>
</li>

<li>Tensor Processing Unit</ br>
<a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit">https://en.wikipedia.org/wiki/Tensor_Processing_Unit</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

