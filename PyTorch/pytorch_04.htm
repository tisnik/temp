<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. </a></p>
<p><a href="#k02">2. Idealizovaný model neuronu používaný v&nbsp;umělých neuronových sítích</a></p>
<p><a href="#k03">3. Role <i>biasu</i> ve výpočtech prováděných neurony</a></p>
<p><a href="#k04">4. Malá odbočka: neuronové sítě a operace skalárního součinu</a></p>
<p><a href="#k05">5. Aktivační funkce ve výpočtech prováděných neurony</a></p>
<p><a href="#k06">6. Vytvoření feed-forward sítě z&nbsp;jednotlivých neuronů</a></p>
<p><a href="#k07">*** 7. Vstupní vrstva, výstupní vrstva a skryté vrstvy neuronů</a></p>
<p><a href="#k08">*** 8. </a></p>
<p><a href="#k09">*** 9. </a></p>
<p><a href="#k10">*** 10. </a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. </h2>

<p>V&nbsp;dnešním článku si ukážeme tu nejdůležitější funkcionalitu celého balíčku <i>PyTorch</i>. Je jím konstrukce neuronových sítí zvoleného typu a tvaru, trénink těchto sítí a jejich následné použití pro řešení konkrétních úloh. Zejména trénink neuronových sítí je přitom velmi náročný na výpočetní čas a z&nbsp;tohoto důvodu knihovna PyTorch umožňuje realizovat tyto výpočty na GPU, který je přesně pro tento typ úloh navržen.</p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Idealizovaný model neuronu používaný v&nbsp;umělých neuronových sítích</h2>

<p>Při práci s&nbsp;umělými neuronovými sítěmi je vhodné alespoň do jisté míry
chápat, jakým způsobem je vlastně taková síť zkonstruována a z&nbsp;jakých
prvků se interně skládá. Základním stavebním prvkem těchto sítí je takzvaný
<i>umělý neuron</i>, resp.&nbsp;přesněji řečeno velmi zjednodušený a
idealizovaný model skutečného neuronu (čím více rozumíme lidskému mozku, tím
více je zřejmé, o jak primitivní model se vlastně jedná &ndash; to však zdá se
v&nbsp;praxi nevadí). Původní model neuronu byl navržen Warrenem McCullochem a
Walterem Pittsem (MCP) již ve čtyřicátých letech minulého století, z&nbsp;čehož
plyne, že neuronové sítě nejsou jen módním výstřelkem poslední doby (naopak,
moderní GPU umožňují jejich nasazení i tam, kde to dříve nebylo možné, to je
však téma na samostatný článek.). Na dalším obrázku jsou naznačeny prvky tohoto
zjednodušeného modelu neuronu:</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-1.png" class="image-312261" alt="&#160;" width="459" height="140" />
<p><i>Obrázek 1: Idealizovaný model neuronu.</i></p>

<p>Z&nbsp;obrázku je patrné, že neuron může mít libovolný počet vstupů (na
prvním obrázku jsou konkrétně zobrazeny tři vstupy
<strong>x<sub>1</sub></strong>, <strong>x<sub>2</sub></strong> a
<strong>x<sub>3</sub></strong>, ovšem může to být jen jeden vstup nebo naopak i
sto vstupů) a má pouze jeden výstup <strong>y</strong>. Vstupem a výstupem jsou
reálná čísla. Typicky přitom bývá výstup upraven <i>aktivační funkcí</i>
takovým způsobem, že leží v&nbsp;rozsahu &lt;-1..1&gt; nebo &lt;0..1&gt;. A i
vstupy jsou typicky v&nbsp;rozsahu -1..1 nebo 0..1.</p>

<p>Dále na schématu zobrazeném na prvním obrázku vidíme váhy
<strong>w<sub>1</sub></strong>, <strong>w<sub>2</sub></strong> a
<strong>w<sub>3</sub></strong>. Těmito váhami jsou vynásobeny vstupní hodnoty.
Váhy vlastně představují stav neuronu, tj.&nbsp;jde o funkci, na kterou byl
neuron natrénován (naučen). Vstupní hodnoty <strong>x<sub>1</sub></strong> až
<strong>x<sub>n</sub></strong> jsou tedy postupně vynásobeny váhami
<strong>w<sub>1</sub></strong> až <strong>w<sub>n</sub></strong> a výsledky
takto provedeného součinu jsou v&nbsp;neuronu sečteny, takže získáme jediné
reálné číslo. Toto číslo je zpracováno <i>aktivační funkcí</i> (ta již většinou
žádný stav nemá, ostatně stejně jako funkce pro výpočet sumy) výsledek této
funkce je poslán na výstup neuronu.</p>

<p>Idealizovaný a značně zjednodušený model neuronu tedy provádí tento
výpočet:</p>

<p>
y = f(w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + ... + w<sub>n</sub>x<sub>n</sub>)
</p>

<p><div class="rs-tip-major">Poznámka: nejjednodušší neuronová síť obsahuje
jediný takový neuron. Taková síť se nazývá <i>perceptron</i>. Naopak síť
složená z&nbsp;více vrstev neuronů se nazývá vícevrstvý perceptron neboli
<i>Multi-Layer Perceptron (MLP)</i>.</div></p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Role <i>biasu</i> ve výpočtech prováděných neurony</h2>

<p>Ve skutečnosti není stav neuronu pro <i>n</i> vstupů
<strong>x<sub>1</sub></strong> až <strong>x<sub>n</sub></strong> určen pouze
<i>n</i> vahami <strong>w<sub>1</sub></strong> až
<strong>w<sub>n</sub></strong> tak, jak jsme si to uvedli <a
href="#k02">v&nbsp;předchozí kapitole</a>. Navíc totiž musíme přidat ještě váhu
<strong>w<sub>0</sub></strong>, na kterou je připojena konstanta 1 (někdy se
proto můžeme setkat s&nbsp;nákresem neuronové sítě, v&nbsp;níž se nachází
speciální neurony bez vstupů a s&nbsp;jedničkou na výstupu). Idealizovaný model
neuronu se přidáním nového vstupu nepatrně zkomplikuje:</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-2.png" class="image-312262" alt="&#160;" width="465" height="145" />
<p><i>Obrázek 2: Idealizovaný model neuronu s&nbsp;biasem.</i></p>

<p>I výpočet bude vypadat (nepatrně) odlišně, neboť do něho přidáme nový člen
<strong>w<sub>0</sub></strong> (na začátku):</p>

<p>
y = f(<strong>w<sub>0</sub></strong> + w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + ... + w<sub>n</sub>x<sub>n</sub>)
</p>

<p>Tato přidaná váha se někdy nazývá <i>bias</i>, protože vlastně umožňuje
posouvat <a
href="https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks">průběh
aktivační funkce nalevo a napravo</a>, v&nbsp;závislosti na jeho hodnotě.</p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Malá odbočka: neuronové sítě a operace skalárního součinu</h2>

<p>V&nbsp;paralelně běžícím seriálu o vektorových operacích podporovaných na
moderních mikroprocesorech s&nbsp;architekturou <i>x86</i> a <i>x86-64</i> jsme
si řekli, že s&nbsp;rozvojem neuronových sítí a umělé inteligence (ale nejenom
zde) se začal masivně využívat známý algoritmus pro výpočet skalárního součinu
(<i>dot product</i>, <i>scalar product</i>). Tento algoritmus se používá
v&nbsp;oblasti velkých jazykových modelů (LLM) pro zjišťování podobnosti
dlouhých vektorů s&nbsp;numerickými hodnotami (<i>vector similarity</i>). Kromě
klasického skalárního součinu se v&nbsp;této oblasti používá i
tzv.&nbsp;<i>cosinus similarity</i>, což je varianta skalárního součinu,
v&nbsp;níž nezáleží na délce vektorů, ale pouze na jejich vzájemné orientaci
(výpočet je tedy doplněn o normalizaci vektorů, ovšem základ zůstává stále
stejný). A toto porovnávání vektorů se v&nbsp;LLM provádí neustále a většinou
je optimalizováno a výpočty běží na GPU.</p>

<p>To však není zdaleka vše. Pokud se zaměříme na oblast klasických neuronových
sítí (<i>NN &ndash; neural networks</i>), což je téma dnešního článku,
zjistíme, že se tyto sítě skládají z&nbsp;takzvaných <i>perceptronů</i>, což je
vlastně značně zjednodušený model neuronů s&nbsp;jejich složením do několika
vrstev. A na vstup každého neuronu se přivádí nějaké množství numerických
vstupů popsaných <a href="#k03">v&nbsp;předchozí kapitole</a>. Každý
z&nbsp;těchto vstupů je váhován, tj.&nbsp;vynásoben určitou konstantou a
výsledky tohoto váhování jsou nakonec sečteny. Když se ovšem nad touto operací
zamyslíme, zjistíme, že se vlastně nejedná o nic jiného, než opět o aplikaci
výpočtu skalárního součinu. První z&nbsp;vektorů, který do tohoto součinu
vstupuje jako operand, jsou vstupy do neuronu, druhým vektorem je pak vektor
vah, které si neuron zapamatoval. A samotný trénink neuronové sítě vlastně není
nic jiného, než rekonfigurace těchto vah &ndash; vektorů.</p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Aktivační funkce ve výpočtech prováděných neurony</h2>

<p>Bez aktivační funkce by se neuron choval velmi jednoduše a především
&bdquo;lineárně &ldquo;&ndash; spočítal by vážený součet vstupů a výsledek by
poslal na svůj výstup. Aktivační funkce, kterou jsme v&nbsp;předchozích
kapitolách označovali symbolem <i>f</i>, do celého výpočtu vnáší nelinearitu.
Ta je přitom pro praktické využití sítě velmi důležitá. Nejjednodušší aktivační
funkce může pro vstupní hodnoty &lt;0 vracet -1 a pro hodnoty &ge;0 vracet 1,
což vlastně říká, že je nutné dosáhnout určité hraniční hodnoty váženého součtu
vstupů, aby byl neuron aktivován (tj.&nbsp;na výstup vyslal jedničku a nikoli
-1). Ostatně právě zde znovu vidíme význam biasu, který onu hraniční hodnotu
posunuje.</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-3.png" class="image-312263" alt="&#160;" width="640" height="480" />
<p><i>Obrázek 3: Aktivační funkce ReLU.</i></p>

<p>V&nbsp;praxi je však aktivační funkce složitější, než zmíněný jednotkový
skok. Často se používá <i>ReLU</i>, <i>sigmoid</i> nebo <i>hyperbolický
tangent</i>. Pro specializovanější účely se však používají i další funkce,
které dokonce nemusí mít monotonní průběh. S&nbsp;dalšími podporovanými
funkcemi se seznámíme příště.</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-4.png" class="image-312264" alt="&#160;" width="640" height="480" />
<p><i>Obrázek 4: Aktivační funkce Tanh.</i></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Vytvoření feed-forward sítě z&nbsp;jednotlivých neuronů</h2>

<p>Samostatné neurony i s&nbsp;aktivační funkcí stále provádí velmi jednoduchou
činnost, ovšem aby se mohly stát součástí složitějšího systému (řekněme
automatického řízení auta nebo rozpoznávání obličejů), musíme z&nbsp;nich
vytvořit síť. Jedna z&nbsp;nejjednodušších forem umělé neuronové sítě se nazývá
<i>feed-forward</i>, a to z&nbsp;toho důvodu, že informace (tedy vstupní
hodnoty, mezihodnoty i hodnoty výstupní) touto sítí tečou jen jedním směrem
(při učení je tomu jinak, tehdy jsou naopak hodnoty posílány ve směru opačném).
Neurony jsou typicky uspořádány pravidelně do vrstev:</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-5.png" class="image-312265" alt="&#160;" width="600" height="400" />
<p><i>Obrázek 5: Uspořádání neuronů do vrstev ve feed-forward síti.</i></p>

<p>Kolečka na obrázku představují jednotlivé neurony, přičemž žlutě jsou
označeny neurony na vstupu, zeleně &bdquo;interní&ldquo; (skryté) neurony a
červeně neurony, které produkují kýžený výstup neuronové sítě.</p>

<p>Zcela nalevo jsou šipkami naznačeny vstupy. Jejich počet je prakticky zcela
závislý na řešeném problému. Může se jednat jen o několik vstupů (viz naše
testovací síť popsaná níže), ovšem pokud například budeme tvořit síť určenou
pro rozpoznání objektů v&nbsp;rastrovém obrázku, může být počet vstupů roven
počtu pixelů (což ovšem v&nbsp;praxi realizujeme odlišně &ndash; konkrétně
takzvanými <i>konvolučními sítěmi</i>).</p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Vstupní vrstva, výstupní vrstva a skryté vrstvy neuronů</h2>

<p>Vraťme se ještě jednou k&nbsp;obrázku číslo 5.</p>

<p>Povšimněte si, že vstupní neurony mají vlastně zjednodušenou funkci, protože
mají jen jeden vstup. V&nbsp;mnoha typech sítí tyto neurony jen rozesílají
vstup na další neurony a neprovádí žádný složitější výpočet, například u nich
není použita aktivační funkce, ovšem to již záleží na konkrétní konfiguraci
sítě. Dále stojí za povšimnutí, že neurony posílají svůj výstup neuronům na
nejbližší další vrstvě; nejsou zde tedy žádné zkratky, žádné zpětné vazby
atd.</p>

<p>Existují samozřejmě složitější typy sítí, těmi se teď ale nebudeme zabývat.
Dále tato síť propojuje neurony na sousedních vrstvách systémem &bdquo;každý
s&nbsp;každým&ldquo;. V&nbsp;našem konkrétním příkladu mají neurony na
prostřední vrstvě dva vstupy, protože předchozí vrstva má jen dva neurony.
Ovšem neurony na poslední vrstvě již musí mít tři vstupy.</p>

<p><div class="rs-tip-major">Poznámka: může se stát, že síť bude po naučení
obsahovat neurony, jejichž váhy na vstupu budou nulové. To vlastně značí, že ze
sítě některé spoje (šipky) zmizí, protože vynásobením jakéhokoli vstupu nulou
dostaneme zase jen nulu.</div></p>

<p>První vrstva s&nbsp;jednoduchými (&bdquo;hloupými&ldquo;) neurony se nazývá
<i>vstupní vrstva</i>, poslední vrstva je <i>vrstva výstupní</i>. Vrstvy mezi
vrstvou vstupní a výstupní, kterých může být teoreticky libovolné množství, se
nazývají <i>skryté vrstvy</i>.</p>



<p><a name="k08"></a></p>
<h2 id="k08">8. </h2>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu PyTorch lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td>tensor_constructor_scalar_1.py</td><td>konstrukce tenzoru nultého a prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py</a></td></tr>
<tr><td> 2</td><td>tensor_constructor_scalar_2.py</td><td>inicializace tenzoru prvního řádu s&nbsp;jedním prvkem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py</a></td></tr>
<tr><td> 3</td><td>tensor_constructor_vector_1.py</td><td>konstrukce tenzoru prvního řádu (tříprvkový vektor)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py</a></td></tr>
<tr><td> 4</td><td>tensor_constructor_vector_2.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;inicializací prvků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py</a></td></tr>
<tr><td> 5</td><td>tensor_constructor_vector_3.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;využitím generátoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py</a></td></tr>
<tr><td> 6</td><td>tensor_constructor_matrix_1.py</td><td>vytvoření a inicializace tenzoru druhého řádu, který může být reprezentován maticí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py</a></td></tr>
<tr><td> 7</td><td>tensor_constructor_matrix_2.py</td><td>inicializace prvků matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py</a></td></tr>
<tr><td> 8</td><td>tensor_constructor_3D_1.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py</a></td></tr>
<tr><td> 9</td><td>tensor_constructor_3D_2.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo; (jiná forma inicializace)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>10</td><td>tensor_constructor_scalar_zero.py</td><td>vynulování prvků tenzoru nultého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py</a></td></tr>
<tr><td>11</td><td>tensor_constructor_vector_zero.py</td><td>vynulování prvků tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py</a></td></tr>
<tr><td>12</td><td>tensor_constructor_matrix_zero.py</td><td>vynulování prvků tenzoru druhého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py</a></td></tr>
<tr><td>13</td><td>tensor_constructor_3D_zero.py</td><td>vynulování prvků tenzoru třetího řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>14</td><td>tensor_zeros_shape.py</td><td>použití konstruktoru <strong>zeros</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td>15</td><td>tensor_ones_shape.py</td><td>použití konstruktoru <strong>ones</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td>16</td><td>tensor_eye.py</td><td>konstrukce jednotkové matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>17</td><td>tensor_range.py</td><td>využití konstruktoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py</a></td></tr>
<tr><td>18</td><td>tensor_arange.py</td><td>využití konstruktoru <strong>arange</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>19</td><td>tensor_shape.py</td><td>zjištění tvaru tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_shape.py</a></td></tr>
<tr><td>20</td><td>tensor_zeros_shape.py</td><td>zjištění tvaru tenzoru vytvořeného konstruktorem <strong>zeros</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td>21</td><td>tensor_ones_shape.py</td><td>zjištění tvaru tenzoru vytvořeného konstruktorem <strong>ones</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td>22</td><td>tensor_read_dtype.py</td><td>zjištění, jakého typu jsou prvky tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_read_dtype.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_read_dtype.py</a></td></tr>
<tr><td>23</td><td>tensor_set_dtype.py</td><td>nastavení či změna typu prvků tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_set_dtype.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_set_dtype.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>24</td><td>tensor_storage_1.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_1.py</a></td></tr>
<tr><td>25</td><td>tensor_storage_2.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_2.py</a></td></tr>
<tr><td>26</td><td>tensor_storage_3.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_3.py</a></td></tr>
<tr><td>27</td><td>tensor_storage_casts.py</td><td>přetypování datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_casts.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_casts.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>28</td><td>tensor_slice_operation_1.py</td><td>konstrukce řezu z&nbsp;tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_1.py</a></td></tr>
<tr><td>29</td><td>tensor_slice_operation_2.py</td><td>konstrukce řezu z&nbsp;tenzoru druhého řádu (přes řádky a sloupce)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_2.py</a></td></tr>
<tr><td>30</td><td>tensor_slice_operation_3.py</td><td>konstrukce řezu s&nbsp;jeho následnou modifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_3.py</a></td></tr>
<tr><td>31</td><td>tensor_slice_operation_4.py</td><td>konstrukce řezu s&nbsp;jeho následnou modifikací (odlišné operace od předchozího příkladu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_4.py</a></td></tr>
<tr><td>32</td><td>tensor_is_slice.py</td><td>test základních vlastností řezů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_is_slice.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_is_slice.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>33</td><td>tensor_stride_1.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_1.py</a></td></tr>
<tr><td>34</td><td>tensor_stride_2.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_2.py</a></td></tr>
<tr><td>35</td><td>tensor_stride_3.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>36</td><td>tensor_reshape.py</td><td>změna tvaru tenzoru operací <strong>reshape</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape.py</a></td></tr>
<tr><td>37</td><td>tensor_reshape_2.py</td><td>změna tvaru tenzoru operací <strong>reshape</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>38</td><td>tensor_narrow_operation_1.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, první ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1.py</a></td></tr>
<tr><td>39</td><td>tensor_narrow_operation_1_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, první ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1_B.py</a></td></tr>
<tr><td>40</td><td>tensor_narrow_operation_2.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, druhá ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2.py</a></td></tr>
<tr><td>41</td><td>tensor_narrow_operation_2_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, druhá ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2_B.py</a></td></tr>
<tr><td>42</td><td>tensor_narrow_operation_3.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, třetí ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3.py</a></td></tr>
<tr><td>43</td><td>tensor_narrow_operation_3_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, třetí ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3_B.py</a></td></tr>
<tr><td>44</td><td>tensor_narrow_operation_4.py</td><td>přepis původní matice přes pohled na ni (<i>view</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_4.py</a></td></tr>
<tr><td>45</td><td>tensor_narrow_operation_5.py</td><td>přepis původní matice přes pohled na ni (<i>view</i>)<i>narrow</i>, třetí ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_5.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>46</td><td>tensor_operator_add.py</td><td>součet dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_add.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_add.py</a></td></tr>
<tr><td>47</td><td>tensor_operator_sub.py</td><td>rozdíl dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_sub.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_sub.py</a></td></tr>
<tr><td>48</td><td>tensor_operator_mul.py</td><td>součin dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_mul.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_mul.py</a></td></tr>
<tr><td>49</td><td>tensor_operator_div.py</td><td>podíl dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_div.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_div.py</a></td></tr>
<tr><td>50</td><td>tensor_dot_product.py</td><td>skalární součin dvou tenzorů prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_dot_product.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_dot_product.py</a></td></tr>
<tr><td>50</td><td>tensor_operator_matmul.py</td><td>maticové násobení (dvou tenzorů druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul.py</a></td></tr>
<tr><td>51</td><td>tensor_operator_matmul_2.py</td><td>maticové násobení (dvou tenzorů druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_2.py</a></td></tr>
<tr><td>52</td><td>tensor_operator_matmul_3.py</td><td>maticové násobení v&nbsp;případě nekompatibilních tvarů matic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_3.py</a></td></tr>
<tr><td>53</td><td>tensor_operator_matmul_4.py</td><td>maticové násobení s&nbsp;broadcastingem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_4.py</a></td></tr>
<tr><td>54</td><td>tensor_operator_matmul_5.py</td><td>násobení vektoru a matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_5.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>55</td><td>tensor_broadcast_1.py</td><td>operace <i>broadcast</i> (součin každého prvku tenzoru se skalárem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_1.py</a></td></tr>
<tr><td>56</td><td>tensor_broadcast_2.py</td><td>operace <i>broadcast</i> (součin tenzoru druhého řádu s vektorem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_2.py</a></td></tr>
<tr><td>57</td><td>tensor_broadcast_3.py</td><td>operace <i>broadcast</i> (součin vektoru s&nbsp;tenzorem druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_3.py</a></td></tr>
<tr><td>58</td><td>tensor_broadcast_4.py</td><td>operace <i>broadcast</i> (součet tenzorů druhého a třetího řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_4.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>59</td><td>tensor_sparse.py</td><td>konstrukce řídkého tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_sparse.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_sparse.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>60</td><td>activation_function_relu_numpy.py</td><td>aktivační funkce ReLU vypočtená knihovnou Numpy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_numpy.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_numpy.py</a></td></tr>
<tr><td>61</td><td>activation_function_relu_pytorch.py</td><td>aktivační funkce ReLU vypočtená knihovnou PyTorch</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_pytorch.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_pytorch.py</a></td></tr>
<tr><td>62</td><td>activation_function_sigmoid_numpy.py</td><td>aktivační funkce sigmoid vypočtená knihovnou Numpy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_numpy.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_numpy.py</a></td></tr>
<tr><td>63</td><td>activation_function_sigmoid_pytorch.py</td><td>aktivační funkce sigmoid vypočtená knihovnou PyTorch</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_pytorch.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_pytorch.py</a></td></tr>
<tr><td>64</td><td>activation_function_tanh_numpy.py</td><td>aktivační funkce tanh vypočtená knihovnou Numpy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_numpy.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_numpy.py</a></td></tr>
<tr><td>65</td><td>activation_function_tanh_pytorch.py</td><td>aktivační funkce tanh vypočtená knihovnou PyTorch</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_pytorch.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_pytorch.py</a></td></tr>
<tr><td>66</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Seriál Programovací jazyk Lua na Rootu:<br />
<a href="https://www.root.cz/serialy/programovaci-jazyk-lua/">https://www.root.cz/serialy/programovaci-jazyk-lua/</a>
</li>

<li>PDM: moderní správce balíčků a virtuálních prostředí Pythonu:<br />
<a href="https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/">https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/</a>
</li>

<li>PyTorch Tutorial: Building a Simple Neural Network From Scratch<br />
<a href="https://www.datacamp.com/tutorial/pytorch-tutorial-building-a-simple-neural-network-from-scratch">https://www.datacamp.com/tutorial/pytorch-tutorial-building-a-simple-neural-network-from-scratch</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008:<br />
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008 (dokončení):<br />
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/</a>
</li>

<li>Brain Floating Point &ndash; nový formát uložení čísel pro strojové učení a chytrá čidla:<br />
<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>
</li>

<li>Stránky projektu PyTorch:<br />
<a href="https://pytorch.org/">https://pytorch.org/</a>
</li>

<li>Informace o instalaci PyTorche:<br />
<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>
</li>

<li>Tenzor (Wikipedia):<br />
<a href="https://cs.wikipedia.org/wiki/Tenzor">https://cs.wikipedia.org/wiki/Tenzor</a>
</li>

<li>Introduction to Tensors:<br />
<a href="https://www.youtube.com/watch?v=uaQeXi4E7gA">https://www.youtube.com/watch?v=uaQeXi4E7gA</a>
</li>

<li>Introduction to Tensors: Transformation Rules:<br />
<a href="https://www.youtube.com/watch?v=j6DazQDbEhQ">https://www.youtube.com/watch?v=j6DazQDbEhQ</a>
</li>

<li>Tensor Attributes:<br />
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Tensors Explained Intuitively: Covariant, Contravariant, Rank :<br />
<a href="https://www.youtube.com/watch?v=CliW7kSxxWU">https://www.youtube.com/watch?v=CliW7kSxxWU</a>
</li>

<li>What is the relationship between PyTorch and Torch?:<br />
<a href="https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch">https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch</a>
</li>

<li>What is a tensor anyway?? (from a mathematician):<br />
<a href="https://www.youtube.com/watch?v=K7f2pCQ3p3U">https://www.youtube.com/watch?v=K7f2pCQ3p3U</a>
</li>

<li>Visualization of tensors - part 1 :<br />
<a href="https://www.youtube.com/watch?v=YxXyN2ifK8A">https://www.youtube.com/watch?v=YxXyN2ifK8A</a>
</li>

<li>Visualization of tensors - part 2A:<br />
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>Visualization of tensors - part 2B:<br />
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>What the HECK is a Tensor?!?:<br />
<a href="https://www.youtube.com/watch?v=bpG3gqDM80w">https://www.youtube.com/watch?v=bpG3gqDM80w</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>An Introduction to Tensors<br />
<a href="https://math.stackexchange.com/questions/10282/an-introduction-to-tensors">https://math.stackexchange.com/questions/10282/an-introduction-to-tensors</a>
</li>

<li>Differences between a matrix and a tensor<br />
<a href="https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor">https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor</a>
</li>

<li>Qualitatively, what is the difference between a matrix and a tensor?<br />
<a href="https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?">https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?</a>
</li>

<li>Tensors for Neural Networks, Clearly Explained!!!:<br />
<a href="https://www.youtube.com/watch?v=L35fFDpwIM4">https://www.youtube.com/watch?v=L35fFDpwIM4</a>
</li>

<li>Tensor Processing Unit:<br />
<a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit">https://en.wikipedia.org/wiki/Tensor_Processing_Unit</a>
</li>

<li>Třída Storage:<br />
<a href="http://docs.pytorch.wiki/en/storage.html">http://docs.pytorch.wiki/en/storage.html</a>
</li>

<li>Funkce torch.dot<br />
<a href="https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot">https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot</a>
</li>

<li>Funkce torch.narrow<br />
<a href="https://pytorch.org/docs/stable/generated/torch.narrow.html">https://pytorch.org/docs/stable/generated/torch.narrow.html</a>
</li>

<li>Funkce torch.matmul<br />
<a href="https://pytorch.org/docs/stable/generated/torch.matmul.html">https://pytorch.org/docs/stable/generated/torch.matmul.html</a>
</li>

<li>Funkce torch.reshape<br />
<a href="https://pytorch.org/docs/stable/generated/torch.reshape.html">https://pytorch.org/docs/stable/generated/torch.reshape.html</a>
</li>

<li>Funkce torch.arange<br />
<a href="https://pytorch.org/docs/stable/generated/torch.arange.html">https://pytorch.org/docs/stable/generated/torch.arange.html</a>
</li>

<li>Funkce torch.range<br />
<a href="https://pytorch.org/docs/stable/generated/torch.range.html">https://pytorch.org/docs/stable/generated/torch.range.html</a>
</li>

<li>Třída torch.Tensor<br />
<a href="https://pytorch.org/docs/stable/tensors.html">https://pytorch.org/docs/stable/tensors.html</a>
</li>

<li>Atributy tenzorů<br />
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Pohledy vytvořené nad tenzory<br />
<a href="https://pytorch.org/docs/stable/tensor_view.html">https://pytorch.org/docs/stable/tensor_view.html</a>
</li>

<li>Broadcasting v&nbsp;knihovně NumPy<br />
<a href="https://numpy.org/doc/stable/user/basics.broadcasting.html">https://numpy.org/doc/stable/user/basics.broadcasting.html</a>
</li>

<li>Broadcasting semantics (v&nbsp;knihovně PyTorch)<br />
<a href="https://pytorch.org/docs/stable/notes/broadcasting.html">https://pytorch.org/docs/stable/notes/broadcasting.html</a>
</li>

<li>Dot Product In Physics: What Is The Physical Meaning of It?<br />
<a href="https://profoundphysics.com/dot-product-in-physics-what-is-the-physical-meaning-of-it/">https://profoundphysics.com/dot-product-in-physics-what-is-the-physical-meaning-of-it/</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

