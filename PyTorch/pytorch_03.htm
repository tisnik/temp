<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Manipulace s tenzory v knihovně PyTorch (dokončení)</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Manipulace s tenzory v knihovně PyTorch (dokončení)</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>V dnešním článku dokončíme popis vlastností tenzorů. Ukážeme si, jaké operace je možné s tenzory provádět, ať již se jedná o operace prováděné prvek po prvku, o takzvaný broadcasting nebo o komplikovanější činnosti. Potom budeme mít znalosti nutné pro využití tenzorů pro konstrukci a trénink neuronových sítí.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Manipulace s&nbsp;tenzory v&nbsp;knihovně PyTorch (dokončení)</a></p>
<p><a href="#k02">2. Operace <strong>narrow</strong> aplikovaná na jednorozměrné vektory</a></p>
<p><a href="#k03">3. Operace <strong>narrow</strong> aplikovaná na matice a tenzory vyšších řádů</a></p>
<p><a href="#k04">4. Operace <strong>narrow</strong> nad dvourozměrnou maticí s&nbsp;výběrem druhé dimenze</a></p>
<p><a href="#k05">5. Vytvoření pohledu na pohled</a></p>
<p><a href="#k06">6. Operace <strong>narrow</strong> ve funkci zapisovatelných pohledů</a></p>
<p><a href="#k07">*** 7. Základní operace prováděné s&nbsp;dvojicí tenzorů metodou &bdquo;prvek po prvku&ldquo;</a></p>
<p><a href="#k08">8. Součet, rozdíl, součin a podíl provedený metodou prvek po prvku</a></p>
<p><a href="#k09">*** 9. Skalární součin</a></p>
<p><a href="#k10">*** 10. Maticový součin</a></p>
<p><a href="#k11">*** 11. Broadcasting</a></p>
<p><a href="#k12">*** 12. Násobení všech prvků tenzoru skalární hodnotou</a></p>
<p><a href="#k13">*** 13. Broadcasting vektoru vs.&nbsp;násobení matice a vektoru</a></p>
<p><a href="#k14">*** 14. Broadcasting celé matice</a></p>
<p><a href="#k15">*** 15. Maticový součin s&nbsp;broadcastingem</a></p>
<p><a href="#k16">*** 16. Řídké tenzory</a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. Obsah navazujícího článku</a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Manipulace s&nbsp;tenzory v&nbsp;knihovně PyTorch (dokončení)</h2>

<p>V&nbsp;dnešním článku dokončíme popis vlastností tenzorů implementovaných
v&nbsp;knihovně <i>PyTorch</i>. Se základními operacemi, které je možné
s&nbsp;tenzory provádět, jsme se již seznámili v&nbsp;úvodních dvou článcích
[<a
href="https://www.root.cz/clanky/od-projektu-scikit-learn-ke-knihovne-pytorch/">1</a>]
[<a
href="https://www.root.cz/clanky/manipulace-s-tenzory-v-knihovne-pytorch/">2</a>].
Dnes toto téma dokončíme. Ukážeme si totiž, jaké operace je možné
s&nbsp;tenzory provádět, ať již se jedná o operace prováděné prvek po prvku, o
takzvaný <i>broadcasting</i> nebo o komplikovanější činnosti. Potom budeme mít
k&nbsp;dispozici prakticky všechny potřebné základní znalosti nutné pro využití
tenzorů pro konstrukci a trénink neuronových sítí, což je ostatně primární
funkce celé knihovny <i>PyTorch</i>.</p>

<p><div class="rs-tip-major">Poznámka: připomeňme si, že knihovna
<i>PyTorch</i> umožňuje, aby výpočty probíhaly na CPU (a to v&nbsp;nativním
kódu, který Python pouze volá) nebo na GPU. A právě možnost velmi snadného
přenosu výpočtů z&nbsp;CPU na GPU je jednou z&nbsp;nejdůležitějších vlastností
knihovny PyTorch, protože nám to umožňuje provádět časově náročný trénink
neuronových sítí na specializovaném hardware, takže výsledku dosáhneme
několikanásobně rychleji v&nbsp;porovnání s&nbsp;výpočtem na CPU (a to i
přesto, že se zde využívají SIMD operace, například z&nbsp;instrukčních sad
AVX). Ostatně rozdíl poznáme již příště při konstrukci a tréninku jednoduché
neuronové sítě.</div></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Operace <strong>narrow</strong> aplikovaná na jednorozměrné vektory</h2>

<p>S&nbsp;některými operacemi, které vrací <i>pohled</i> (<i>view</i>) na
nějaký reálný tenzor (nebo též na jiný pohled), jsme se již setkali. Do této
kategorie velmi často používaných operací patří i operace nazvaná
<strong>narrow</strong>, která taktéž získá pohled na zvolený tenzor. Této
operaci se, pokud se volá formou funkce a nikoli metody, předávají čtyři
parametry: původní tenzor (nebo pohled), dimenze (resp.&nbsp;přesněji řečeno
její index), první prvek v&nbsp;dané dimenzi a celkový počet prvků, které má
pohled obsahovat. Při volání formou metody se pochopitelně vynechává první
parametr se zdrojovým tenzorem.</p>

<p>Podívejme se nyní na ten nejjednodušší (ale stále praktický) případ, tedy na
získání pohledu do jednorozměrného vektoru. Ten má pochopitelně jen jednu
dimenzi (=1) a budeme chtít získat pohled na osm prvků původního vektoru
začínajících druhým prvkem. Následně změníme hodnotu v&nbsp;novém vektoru, ale
kvůli tomu, že se jedná o <i>pohled</i> na vektor původní, bude tato hodnota
propsána i do původního vektoru. Pohled totiž neobsahuje vlastní data (prvky),
ale pouze reference na původní vektor:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru - vektoru s deseti prvky</i>
v1 = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
print(v1)
&nbsp;
print()
&nbsp;
<i># realizace operace narrow s výběrem dimenze číslo 0</i>
v2 = <strong>torch.narrow(v1, 0, 1, 8)</strong>
print(v2)
&nbsp;
print()
&nbsp;
<i># modifikace vektoru pres pohled na nej</i>
<strong>v2[0] = 99</strong>
print(v1)
print()
print(v2)
</pre>

<p>Výsledky, které získáme po spuštění tohoto skriptu, by měly vypadat
následovně:</p>

<pre>
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])
&nbsp;
tensor([2., 3., 4., 5., 6., 7., 8., 9.])
&nbsp;
tensor([ 1., 99.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.])
&nbsp;
tensor([99.,  3.,  4.,  5.,  6.,  7.,  8.,  9.])
</pre>

<p>Operaci <strong>narrow</strong> lze ovšem volat i formou metody. Výsledky
budou v&nbsp;obou případech totožné:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru - vektoru s deseti prvky</i>
v1 = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
print(v1)
&nbsp;
print()
&nbsp;
<i># realizace operace narrow s výběrem dimenze číslo 0</i>
v2 = <strong>v1.narrow(0, 1, 8)</strong>
print(v2)
&nbsp;
print()
&nbsp;
<i># modifikace vektoru pres pohled na nej</i>
<strong>v2[0] = 99</strong>
print(v1)
print()
print(v2)
</pre>

<p>Výsledky budou, jak již víme, shodné s&nbsp;předchozím demonstračním
příkladem.</p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Operace <strong>narrow</strong> aplikovaná na matice a tenzory vyšších řádů</h2>

<p>Varianta operace <strong>narrow</strong> představená <a
href="#k02">v&nbsp;předchozí kapitole</a> nebyla příliš praktická, protože u
jednorozměrných vektorů provádí jednoduchý řez (<i>slice</i>), který již dobře
známe a dokážeme ho provést i jednoduššími prostředky. Mnohem užitečnější je
použití operace <strong>narrow</strong> na matice a samozřejmě taktéž na
tenzory vyšších řádů. Vraťme se k&nbsp;naší matici 4&times;4 prvky použité
dříve. S&nbsp;využitím <strong>narrow</strong> získáme pohled na druhý a třetí
řádek matice (pohybujeme se tedy po řádcích, neboť jsme zvolili první dimenzi).
A opět je možné provést zápis do původní matice přes pohled na ni:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru (matice 4x4 prvky)</i>
m1 = torch.Tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
print(m1)
&nbsp;
print()
&nbsp;
<i># realizace operace narrow s výběrem dimenze číslo 0</i>
m2 = <strong>torch.narrow(m1, 0, 1, 2)</strong>
print(m2)
&nbsp;
print()
&nbsp;
<i># modifikace puvodni matice pres jeji pohled</i>
<strong>m2[0, 0] = 99</strong>
print(m1)
print()
print(m2)
</pre>

<p>Zobrazené výsledky představují původní matici, pohled na dva řádky
z&nbsp;této matice, modifikovanou variantu původní matice a modifikovaný
pohled:</p>

<pre>
tensor([[ 1.,  2.,  3.,  4.],
        [ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.],
        [13., 14., 15., 16.]])
&nbsp;
tensor([[ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.]])
&nbsp;
tensor([[ 1.,  2.,  3.,  4.],
        [99.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.],
        [13., 14., 15., 16.]])
&nbsp;
tensor([[99.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.]])
</pre>

<p>Opět platí, že operaci <strong>narrow</strong> můžeme volat jako funkci
<strong>pytorch.narrow</strong> i jako metodu
<i>muj_tenzor</i><strong>.narrow</strong>. To znamená, že předchozí příklad si
můžeme převést do podoby:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru (matice 4x4 prvky)</i>
m1 = torch.Tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
print(m1)
&nbsp;
print()
&nbsp;
<i># realizace operace narrow s výběrem dimenze číslo 0</i>
m2 = <strong>m1.narrow(0, 1, 2)</strong>
print(m2)
&nbsp;
print()
&nbsp;
<i># modifikace puvodni matice pres jeji pohled</i>
<strong>m2[0, 0] = 99</strong>
print(m1)
print()
print(m2)
</pre>

<p><div class="rs-tip-major">Poznámka: výsledky budou opět totožné
s&nbsp;předchozím demonstračním příkladem.</div></p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Operace <strong>narrow</strong> nad dvourozměrnou maticí s&nbsp;výběrem druhé dimenze</h2>

<p>V&nbsp;případě, že je první parametr metody <strong>narrow</strong>
resp.&nbsp;druhý parametr funkce <strong>pytorch.narrow</strong> roven jedné,
bude se provádět výběr z&nbsp;matice po sloupcích a nikoli po řádcích, protože
pracujeme s&nbsp;druhou a nikoli s&nbsp;první dimenzí. Opět si to pochopitelně
můžeme ukázat na nějakém jednoduchém příkladu, jenž jako zdroj dat využívá naši
matici 4&times;4 prvky. Nad touto maticí vytvoříme pohled na dva sloupce, tento
pohled následně zobrazíme a pokusíme se matici změnit <i>přes</i> tento
pohled:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru (matice 4x4 prvky)</i>
m1 = torch.Tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
print(m1)
&nbsp;
print()
&nbsp;
<i># realizace operace narrow s výběrem dimenze číslo 1</i>
m2 = <strong>torch.narrow(m1, 1, 1, 2)</strong>
print(m2)
&nbsp;
print()
&nbsp;
<i># modifikace puvodni matice pres jeji pohled</i>
<strong>m2[0, 0] = 99</strong>
print(m1)
print()
print(m2)
</pre>

<p>Výsledkem bude vytištěná původní matice, dále pohled na matici (dva
sloupce), modifikovaná matice a modifikovaný pohled:</p>

<pre>
tensor([[ 1.,  2.,  3.,  4.],
        [ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.],
        [13., 14., 15., 16.]])
&nbsp;
tensor([[ 2.,  3.],
        [ 6.,  7.],
        [10., 11.],
        [14., 15.]])
&nbsp;
tensor([[ 1., 99.,  3.,  4.],
        [ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.],
        [13., 14., 15., 16.]])
&nbsp;
tensor([[99.,  3.],
        [ 6.,  7.],
        [10., 11.],
        [14., 15.]])
</pre>

<p>Naprosto stejně můžeme namísto funkce <strong>pytorch.narrow</strong> použít
metodu se shodným jménem:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru (matice 4x4 prvky)</i>
m1 = torch.Tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
print(m1)
&nbsp;
print()
&nbsp;
<i># realizace operace narrow s výběrem dimenze číslo 1</i>
m2 = <strong>m1.narrow(1, 1, 2)</strong>
print(m2)
&nbsp;
print()
&nbsp;
<i># modifikace puvodni matice pres jeji pohled</i>
<strong>m2[0, 0] = 99</strong>
print(m1)
print()
print(m2)
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Vytvoření pohledu na pohled</h2>

<p>Nic nám samozřejmě nebrání v&nbsp;tom, abychom nad nějakým pohledem
vytvořili nový pohled. Tuto operaci lze provádět rekurzivně prakticky do
jakékoli hloubky a skutečně se často setkáme s&nbsp;tím, že se namísto tenzorů
pracuje s&nbsp;pohledy a taktéž pohledy na jiné pohledy. Ukažme si to na
jednoduchém příkladu, v&nbsp;němž z&nbsp;původní matice 4&times;4 prvky
vytvoříme pohled na dva sloupce a další pohled vybírající dva řádky
z&nbsp;prvního pohledu:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru (matice 4x4 prvky)</i>
m1 = torch.Tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
print(m1)
print()
&nbsp;
<i># pohled na původní matici</i>
m2 = <strong>torch.narrow(m1, 1, 1, 2)</strong>
print(m2)
print()
&nbsp;
<i># pohled na pohled</i>
m3 = <strong>torch.narrow(m2, 0, 1, 2)</strong>
print(m3)
print()
</pre>

<p>Alternativní způsob zápisu založený na metodě <strong>narrow</strong> a
nikoli na funkci <strong>pytorch.narrow</strong>:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru (matice 4x4 prvky)</i>
m1 = torch.Tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
print(m1)
print()
&nbsp;
<i># pohled na původní matici</i>
m2 = <strong>m1.narrow(1, 1, 2)</strong>
print(m2)
print()
&nbsp;
<i># pohled na pohled</i>
m3 = <strong>m2.narrow(0, 1, 2)</strong>
print(m3)
print()
</pre>

<p>V&nbsp;obou případech by se postupně měla zobrazit původní matice, pohled na
tuto matici (dva sloupce) a následně pohled na pohled (dva řádky):</p>

<pre>
tensor([[ 1.,  2.,  3.,  4.],
        [ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.],
        [13., 14., 15., 16.]])
&nbsp;
tensor([[ 2.,  3.],
        [ 6.,  7.],
        [10., 11.],
        [14., 15.]])
&nbsp;
tensor([[ 6.,  7.],
        [10., 11.]])
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. Operace <strong>narrow</strong> ve funkci zapisovatelných pohledů</h2>

<p>Již v&nbsp;předchozím textu jsme si ukázali, že tenzory jsou měnitelné jak
přímo, tak i přes své pohledy. Navíc jsou nad pohledy definovány všechny metody
měnící obsah tenzoru. To platí i pro operaci <strong>fill</strong>, kterou již
dobře známe, ovšem pro úplnost si ji ještě připomeňme. Zkonstruujeme matici o
rozměrech 4&times;4 prvky a přes dva pohledy získáme submatici 2&times;2 prvky
(což je ovšem pohled). Tuto podmatici vyplníme hodnotami 99 právě operací
<strong>fill</strong>. Tyto údaje se, jak již víme, propíšou do výchozí
matice:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru (matice 4x4 prvky)</i>
m1 = torch.Tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
print(m1)
print()
&nbsp;
<i># pohled na původní matici</i>
m2 = <strong>torch.narrow(m1, 1, 1, 2)</strong>
print(m2)
print()
&nbsp;
<i># pohled na pohled</i>
m3 = <strong>torch.narrow(m2, 0, 1, 2)</strong>
print(m3)
print()
&nbsp;
<i># změna všech prvků v pohledu</i>
m3.fill_(99)
print(m1)
</pre>

<p>Postupně prováděné kroky jsou vypisovány na standardní výstup:</p>

<pre>
tensor([[ 1.,  2.,  3.,  4.],
        [ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.],
        [13., 14., 15., 16.]])
&nbsp;
tensor([[ 2.,  3.],
        [ 6.,  7.],
        [10., 11.],
        [14., 15.]])
&nbsp;
tensor([[ 6.,  7.],
        [10., 11.]])
&nbsp;
tensor([[ 1.,  2.,  3.,  4.],
        [ 5., 99., 99.,  8.],
        [ 9., 99., 99., 12.],
        [13., 14., 15., 16.]])
</pre>

<p>Ještě se podívejme na složitější příklad, v&nbsp;němž operací
<strong>fill</strong> vyplníme zvolený řádek/řádky, zvolený sloupec/sloupce a
konečně vybranou podmatici:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru druheho radu</i>
<i># s vynulovanim vsech prvku</i>
m1 = torch.Tensor(5, 5).zero_()
print(m1)
print()
&nbsp;
<i># vyplneni radku matice</i>
<strong>m1.narrow(0, 2, 1).fill_(3)</strong>
print(m1)
print()
&nbsp;
<i># vyplneni sloupce matice</i>
<strong>m1.narrow(1, 2, 1).fill_(9)</strong>
print(m1)
print()
&nbsp;
<i># vyplneni strednich 3x3 prvku matice</i>
<strong>m1.narrow(1, 1, 3).narrow(0, 1, 3).fill_(1)</strong>
print(m1)
print()
</pre>

<p>Postupně měněná matice je vypsána na standardní výstup:</p>

<pre>
tensor([[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]])
&nbsp;
tensor([[0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.],
        [3., 3., 3., 3., 3.],
        [0., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0.]])
&nbsp;
tensor([[0., 0., 9., 0., 0.],
        [0., 0., 9., 0., 0.],
        [3., 3., 9., 3., 3.],
        [0., 0., 9., 0., 0.],
        [0., 0., 9., 0., 0.]])
&nbsp;
tensor([[0., 0., 9., 0., 0.],
        [0., 1., 1., 1., 0.],
        [3., 1., 1., 1., 3.],
        [0., 1., 1., 1., 0.],
        [0., 0., 9., 0., 0.]])
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. Základní operace prováděné s&nbsp;dvojicí tenzorů metodou &bdquo;prvek po prvku&ldquo;</h2>

<p></p>



<p><a name="k08"></a></p>
<h2 id="k08">8. Součet, rozdíl, součin a podíl provedený metodou prvek po prvku</h2>

<p>Otestování operace součtu, rozdílu, součinu a podílu dvou tenzorů si nejprve
ukážeme na dvojici matic stejného tvaru (<i>shape</i>). Následující čtyři
příklady pravděpodobně nevyžadují podrobnější popis:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.range(1, 12)
print(v1)
print()
&nbsp;
<i># konstrukce 2D matice z puvodniho vektoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()
&nbsp;
<i># vytvořeni druhe matice se stejnym tvarem</i>
m2 = torch.ones(4, 3)
print(m2)
print()
&nbsp;
<i># soucet metodou prvek po prvku</i>
m3 = <strong>m1 + m2</strong>
print(m3)
print()
</pre>

<p>Tento demonstrační příklad vypíše součet matic prvek po prvku:</p>

<pre>
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])
&nbsp;
tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.],
        [ 7.,  8.,  9.],
        [10., 11., 12.]])
&nbsp;
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])
&nbsp;
tensor([[ 2.,  3.,  4.],
        [ 5.,  6.,  7.],
        [ 8.,  9., 10.],
        [11., 12., 13.]])
</pre>

<p>Rozdíl dvou matic provedený prvek po prvku:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.range(1, 12)
print(v1)
print()
&nbsp;
<i># konstrukce 2D matice z puvodniho vektoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()
&nbsp;
<i># vytvořeni druhe matice se stejnym tvarem</i>
m2 = torch.ones(4, 3)
print(m2)
print()
&nbsp;
<i># rozdil metodou prvek po prvku</i>
m3 = <strong>m1 - m2</strong>
print(m3)
print()
</pre>

<p>Výsledky:</p>

<pre>
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])
&nbsp;
tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.],
        [ 7.,  8.,  9.],
        [10., 11., 12.]])
&nbsp;
tensor([[1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.],
        [1., 1., 1.]])
&nbsp;
tensor([[ 0.,  1.,  2.],
        [ 3.,  4.,  5.],
        [ 6.,  7.,  8.],
        [ 9., 10., 11.]])
</pre>

<p>Následuje součin provedený metodou prvek po prvku (pozor: v&nbsp;žádném
případě se nejedná o maticový součin):</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.range(1, 12)
print(v1)
print()
&nbsp;
<i># konstrukce 2D matice z puvodniho vektoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()
&nbsp;
<i># vytvořeni druhe matice se stejnym tvarem</i>
m2 = torch.ones(4, 3) + torch.ones(4, 3)
print(m2)
print()
&nbsp;
<i># soucin metodou prvek po prvku</i>
m3 = <strong>m1 * m2</strong>
print(m3)
print()
</pre>

<p>Výsledky:</p>

<pre>
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])
&nbsp;
tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.],
        [ 7.,  8.,  9.],
        [10., 11., 12.]])
&nbsp;
tensor([[2., 2., 2.],
        [2., 2., 2.],
        [2., 2., 2.],
        [2., 2., 2.]])
&nbsp;
tensor([[ 2.,  4.,  6.],
        [ 8., 10., 12.],
        [14., 16., 18.],
        [20., 22., 24.]])
</pre>

<p>A konečně podíl provedený metodou prvek po prvku:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.range(1, 12)
print(v1)
print()
&nbsp;
<i># konstrukce 2D matice z puvodniho vektoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()
&nbsp;
<i># vytvořeni druhe matice se stejnym tvarem</i>
m2 = torch.ones(4, 3) + torch.ones(4, 3)
print(m2)
print()
&nbsp;
<i># podil metodou prvek po prvku</i>
m3 = <strong>m1 / m2</strong>
print(m3)
print()
</pre>

<p>Výsledky:</p>

<pre>
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])
&nbsp;
tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.],
        [ 7.,  8.,  9.],
        [10., 11., 12.]])
&nbsp;
tensor([[2., 2., 2.],
        [2., 2., 2.],
        [2., 2., 2.],
        [2., 2., 2.]])
&nbsp;
tensor([[0.5000, 1.0000, 1.5000],
        [2.0000, 2.5000, 3.0000],
        [3.5000, 4.0000, 4.5000],
        [5.0000, 5.5000, 6.0000]])
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Skalární součin</h2>

<p></p>

<pre>
import torch
&nbsp;
<i># konstrukce 1D tenzoru</i>
v1 = torch.Tensor([2, 2, 3, 5])
print(v1)
print()
&nbsp;
<i># konstrukce druheho 2D tenzoru</i>
v2 = torch.Tensor([2, 2, 3, 5])
print(v2)
print()
&nbsp;
<i># skalarni soucin zapsany funkci</i>
s = torch.dot(v1, v2)
print(s)
print()
&nbsp;
<i># skalarni soucin zapsany operatorem</i>
s = v1 @ v2
print(s)
&nbsp;
<i># vysledkem je 42 - nahoda???</i>
</pre>

<pre>
tensor([2., 2., 3., 5.])
&nbsp;
tensor([2., 2., 3., 5.])
&nbsp;
tensor(42.)
&nbsp;
tensor(42.)
</pre>



<p><a name="k10"></a></p>
<h2 id="k10">10. Maticový součin</h2>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.range(1, 12)
print(v1)
print()
&nbsp;
<i># konstrukce prvni matice z puvodniho tenzoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()
&nbsp;
<i># konstrukce druhe matice z puvodniho tenzoru</i>
m2 = torch.reshape(v1, (3, 4))
print(m2)
print()
&nbsp;
<i># provedeni maticoveho soucinu</i>
m3 = m1 @ m2
print(m3)
</pre>

<pre>
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])
&nbsp;
tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.],
        [ 7.,  8.,  9.],
        [10., 11., 12.]])
&nbsp;
tensor([[ 1.,  2.,  3.,  4.],
        [ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.]])
&nbsp;
tensor([[ 38.,  44.,  50.,  56.],
        [ 83.,  98., 113., 128.],
        [128., 152., 176., 200.],
        [173., 206., 239., 272.]])
</pre>

<pre>
import torch

<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.range(1, 12)
print(v1)
print()

<i># konstrukce prvni matice z puvodniho tenzoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()

<i># konstrukce druhe matice z puvodniho tenzoru</i>
m2 = torch.reshape(v1, (3, 4))
print(m2)
print()

<i># provedeni maticoveho soucinu</i>
<i># v opacnem poradi</i>
m3 = m2 @ m1
print(m3)
</pre>

<pre>
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])

tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.],
        [ 7.,  8.,  9.],
        [10., 11., 12.]])

tensor([[ 1.,  2.,  3.,  4.],
        [ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.]])

tensor([[ 70.,  80.,  90.],
        [158., 184., 210.],
        [246., 288., 330.]])
</pre>

<pre>
import torch

<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.range(1, 12)
print(v1)
print()

<i># konstrukce prvni matice z puvodniho tenzoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()

<i># konstrukce druhe matice z puvodniho tenzoru</i>
m2 = torch.reshape(v1, (6, 2))
print(m2)
print()

<i># pokus o provedeni maticoveho soucinu</i>
m3 = m1 @ m2
print(m3)
</pre>

<pre>
  v1 = torch.range(1, 12)
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])

tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.],
        [ 7.,  8.,  9.],
        [10., 11., 12.]])

tensor([[ 1.,  2.],
        [ 3.,  4.],
        [ 5.,  6.],
        [ 7.,  8.],
        [ 9., 10.],
        [11., 12.]])

Traceback (most recent call last):
  File "/home/ptisnovs/xy/src/tensor_operator_matmul_3.py", line 19, in <module>
    m3 = m1 @ m2
         ~~~^~~~
RuntimeError: mat1 and mat2 shapes cannot be multiplied (4x3 and 6x2)
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. Broadcasting</h2>

<p></p>



<p><a name="k12"></a></p>
<h2 id="k12">12. Násobení všech prvků tenzoru skalární hodnotou</h2>

<pre>
import torch

<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.arange(1, 13)
print(v1)
print()

<i># vytvoreni matice z puvodniho vektoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()

<i># vynasobeni kazdeho prvku matice skalarem</i>
m2 = m1 * 10
print(m2)
print()
</pre>

<pre>
tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])

tensor([[ 1,  2,  3],
        [ 4,  5,  6],
        [ 7,  8,  9],
        [10, 11, 12]])

tensor([[ 10,  20,  30],
        [ 40,  50,  60],
        [ 70,  80,  90],
        [100, 110, 120]])
</pre>



<p><a name="k13"></a></p>
<h2 id="k13">13. Broadcasting vektoru vs.&nbsp;násobení matice a vektoru</h2>

<pre>
import torch

<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.arange(1, 13)
print(v1)
print()

<i># vytvoreni matice z puvodniho vektoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()

<i># jednorozmerny vektor</i>
v2 = torch.Tensor([1, 2, -1])
print(v2)
print()

<i># nasobeni matice a vektoru prvek po prvku</i>
m2 = m1 * v2
print(m2)
print()
</pre>

<pre>
tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])

tensor([[ 1,  2,  3],
        [ 4,  5,  6],
        [ 7,  8,  9],
        [10, 11, 12]])

tensor([ 1.,  2., -1.])

tensor([[  1.,   4.,  -3.],
        [  4.,  10.,  -6.],
        [  7.,  16.,  -9.],
        [ 10.,  22., -12.]])
</pre>

<pre>
import torch

<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.arange(1, 13)
print(v1)
print()

<i># vytvoreni matice z puvodniho vektoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()

<i># jednorozmerny vektor</i>
v2 = torch.Tensor([1, 2, -1])
print(v2)
print()

<i># nasobeni vektoru a matice prvek po prvku</i>
m2 = v2 * m1
print(m2)
print()
</pre>

<pre>
tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])

tensor([[ 1,  2,  3],
        [ 4,  5,  6],
        [ 7,  8,  9],
        [10, 11, 12]])

tensor([ 1.,  2., -1.])

tensor([[  1.,   4.,  -3.],
        [  4.,  10.,  -6.],
        [  7.,  16.,  -9.],
        [ 10.,  22., -12.]])
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Broadcasting celé matice</h2>

<pre>
import torch

<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.arange(1, 13)
print(v1)
print()

<i># tenzor druhého řádu</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()

<i># tenzor třetího řádu</i>
c1 = torch.ones(5, 4, 3)
print(c1)
print()

print(m1 + c1)
</pre>

<pre>
tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])

tensor([[ 1,  2,  3],
        [ 4,  5,  6],
        [ 7,  8,  9],
        [10, 11, 12]])

tensor([[[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.]],

        [[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.]],

        [[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.]],

        [[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.]],

        [[1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.],
         [1., 1., 1.]]])

tensor([[[ 2.,  3.,  4.],
         [ 5.,  6.,  7.],
         [ 8.,  9., 10.],
         [11., 12., 13.]],

        [[ 2.,  3.,  4.],
         [ 5.,  6.,  7.],
         [ 8.,  9., 10.],
         [11., 12., 13.]],

        [[ 2.,  3.,  4.],
         [ 5.,  6.,  7.],
         [ 8.,  9., 10.],
         [11., 12., 13.]],

        [[ 2.,  3.,  4.],
         [ 5.,  6.,  7.],
         [ 8.,  9., 10.],
         [11., 12., 13.]],

        [[ 2.,  3.,  4.],
         [ 5.,  6.,  7.],
         [ 8.,  9., 10.],
         [11., 12., 13.]]])
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. Maticový součin s&nbsp;broadcastingem</h2>

<pre>
import torch

<i># konstrukce tenzoru, vyplneni sekvenci</i>
v1 = torch.range(1, 12)
print(v1)
print()

<i># konstrukce prvni matice z puvodniho tenzoru</i>
m1 = torch.reshape(v1, (4, 3))
print(m1)
print()

<i># konstrukce druhe matice z puvodniho tenzoru</i>
m2 = torch.Tensor([[[ 1,  1], [ 1,  1], [ 1,  1]],
                   [[ 2,  2], [ 2,  2], [ 2,  2]],
                   [[-1, -1], [-1, -2], [-1, -1]]])
print(m2)
print()

<i># pokus o provedeni maticoveho soucinu s broadcastem</i>
m3 = m1 @ m2
print(m3)
</pre>

<pre>
tensor([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.])

tensor([[ 1.,  2.,  3.],
        [ 4.,  5.,  6.],
        [ 7.,  8.,  9.],
        [10., 11., 12.]])

tensor([[[ 1.,  1.],
         [ 1.,  1.],
         [ 1.,  1.]],

        [[ 2.,  2.],
         [ 2.,  2.],
         [ 2.,  2.]],

        [[-1., -1.],
         [-1., -2.],
         [-1., -1.]]])

tensor([[[  6.,   6.],
         [ 15.,  15.],
         [ 24.,  24.],
         [ 33.,  33.]],

        [[ 12.,  12.],
         [ 30.,  30.],
         [ 48.,  48.],
         [ 66.,  66.]],

        [[ -6.,  -8.],
         [-15., -20.],
         [-24., -32.],
         [-33., -44.]]])
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>

<pre>
import torch

m1 = torch.tensor([[0, 1, 0, 0], [1, 2, 0, 0], [0, 0, 1, 0]])
print(m1)
print()

sparse = m1.to_sparse()
print(sparse)
</pre>

<pre>
tensor([[0, 1, 0, 0],
        [1, 2, 0, 0],
        [0, 0, 1, 0]])

tensor(indices=tensor([[0, 1, 1, 2],
                       [1, 0, 1, 2]]),
       values=tensor([1, 1, 2, 1]),
       size=(3, 4), nnz=4, layout=torch.sparse_coo)
</pre>



<p><a name="k18"></a></p>
<h2 id="k18">18. Obsah navazujícího článku</h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu PyTorch lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td>tensor_constructor_scalar_1.py</td><td>konstrukce tenzoru nultého a prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py</a></td></tr>
<tr><td> 2</td><td>tensor_constructor_scalar_2.py</td><td>inicializace tenzoru prvního řádu s&nbsp;jedním prvkem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py</a></td></tr>
<tr><td> 3</td><td>tensor_constructor_vector_1.py</td><td>konstrukce tenzoru prvního řádu (tříprvkový vektor)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py</a></td></tr>
<tr><td> 4</td><td>tensor_constructor_vector_2.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;inicializací prvků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py</a></td></tr>
<tr><td> 5</td><td>tensor_constructor_vector_3.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;využitím generátoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py</a></td></tr>
<tr><td> 6</td><td>tensor_constructor_matrix_1.py</td><td>vytvoření a inicializace tenzoru druhého řádu, který může být reprezentován maticí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py</a></td></tr>
<tr><td> 7</td><td>tensor_constructor_matrix_2.py</td><td>inicializace prvků matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py</a></td></tr>
<tr><td> 8</td><td>tensor_constructor_3D_1.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py</a></td></tr>
<tr><td> 9</td><td>tensor_constructor_3D_2.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo; (jiná forma inicializace)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>10</td><td>tensor_constructor_scalar_zero.py</td><td>vynulování prvků tenzoru nultého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py</a></td></tr>
<tr><td>11</td><td>tensor_constructor_vector_zero.py</td><td>vynulování prvků tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py</a></td></tr>
<tr><td>12</td><td>tensor_constructor_matrix_zero.py</td><td>vynulování prvků tenzoru druhého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py</a></td></tr>
<tr><td>13</td><td>tensor_constructor_3D_zero.py</td><td>vynulování prvků tenzoru třetího řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>14</td><td>tensor_zeros_shape.py</td><td>použití konstruktoru <strong>zeros</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td>15</td><td>tensor_ones_shape.py</td><td>použití konstruktoru <strong>ones</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td>16</td><td>tensor_eye.py</td><td>konstrukce jednotkové matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>17</td><td>tensor_range.py</td><td>využití konstruktoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py</a></td></tr>
<tr><td>18</td><td>tensor_arange.py</td><td>využití konstruktoru <strong>arange</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>19</td><td>tensor_shape.py</td><td>zjištění tvaru tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_shape.py</a></td></tr>
<tr><td>20</td><td>tensor_zeros_shape.py</td><td>zjištění tvaru tenzoru vytvořeného konstruktorem <strong>zeros</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td>21</td><td>tensor_ones_shape.py</td><td>zjištění tvaru tenzoru vytvořeného konstruktorem <strong>ones</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td>22</td><td>tensor_read_dtype.py</td><td>zjištění, jakého typu jsou prvky tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_read_dtype.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_read_dtype.py</a></td></tr>
<tr><td>23</td><td>tensor_set_dtype.py</td><td>nastavení či změna typu prvků tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_set_dtype.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_set_dtype.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>24</td><td>tensor_storage_1.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_1.py</a></td></tr>
<tr><td>25</td><td>tensor_storage_2.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_2.py</a></td></tr>
<tr><td>26</td><td>tensor_storage_3.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_3.py</a></td></tr>
<tr><td>27</td><td>tensor_storage_casts.py</td><td>přetypování datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_casts.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_casts.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>28</td><td>tensor_slice_operation_1.py</td><td>konstrukce řezu z&nbsp;tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_1.py</a></td></tr>
<tr><td>29</td><td>tensor_slice_operation_2.py</td><td>konstrukce řezu z&nbsp;tenzoru druhého řádu (přes řádky a sloupce)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_2.py</a></td></tr>
<tr><td>30</td><td>tensor_slice_operation_3.py</td><td>konstrukce řezu s&nbsp;jeho následnou modifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_3.py</a></td></tr>
<tr><td>31</td><td>tensor_slice_operation_4.py</td><td>konstrukce řezu s&nbsp;jeho následnou modifikací (odlišné operace od předchozího příkladu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_4.py</a></td></tr>
<tr><td>32</td><td>tensor_is_slice.py</td><td>test základních vlastností řezů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_is_slice.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_is_slice.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>33</td><td>tensor_stride_1.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_1.py</a></td></tr>
<tr><td>34</td><td>tensor_stride_2.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_2.py</a></td></tr>
<tr><td>35</td><td>tensor_stride_3.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>36</td><td>tensor_reshape.py</td><td>změna tvaru tenzoru operací <strong>reshape</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape.py</a></td></tr>
<tr><td>37</td><td>tensor_reshape_2.py</td><td>změna tvaru tenzoru operací <strong>reshape</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>38</td><td>tensor_narrow_operation_1.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, první ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1.py</a></td></tr>
<tr><td>39</td><td>tensor_narrow_operation_1_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, první ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1_B.py</a></td></tr>
<tr><td>40</td><td>tensor_narrow_operation_2.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, druhá ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2.py</a></td></tr>
<tr><td>41</td><td>tensor_narrow_operation_2_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, druhá ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2_B.py</a></td></tr>
<tr><td>42</td><td>tensor_narrow_operation_3.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, třetí ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3.py</a></td></tr>
<tr><td>43</td><td>tensor_narrow_operation_3_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, třetí ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3_B.py</a></td></tr>
<tr><td>44</td><td>tensor_narrow_operation_4.py</td><td>přepis původní matice přes pohled na ni (<i>view</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_4.py</a></td></tr>
<tr><td>45</td><td>tensor_narrow_operation_5.py</td><td>přepis původní matice přes pohled na ni (<i>view</i>)<i>narrow</i>, třetí ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_5.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>46</td><td>tensor_operator_add.py</td><td>součet dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_add.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_add.py</a></td></tr>
<tr><td>47</td><td>tensor_operator_sub.py</td><td>rozdíl dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_sub.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_sub.py</a></td></tr>
<tr><td>48</td><td>tensor_operator_mul.py</td><td>součin dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_mul.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_mul.py</a></td></tr>
<tr><td>49</td><td>tensor_operator_div.py</td><td>podíl dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_div.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_div.py</a></td></tr>
<tr><td>50</td><td>tensor_dot_product.py</td><td>skalární součin dvou tenzorů prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_dot_product.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_dot_product.py</a></td></tr>
<tr><td>50</td><td>tensor_operator_matmul.py</td><td>maticové násobení (dvou tenzorů druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul.py</a></td></tr>
<tr><td>51</td><td>tensor_operator_matmul_2.py</td><td>maticové násobení (dvou tenzorů druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_2.py</a></td></tr>
<tr><td>52</td><td>tensor_operator_matmul_3.py</td><td>maticové násobení v&nbsp;případě nekompatibilních tvarů matic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_3.py</a></td></tr>
<tr><td>53</td><td>tensor_operator_matmul_4.py</td><td>maticové násobení s&nbsp;broadcastingem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_4.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>54</td><td>tensor_broadcast_1.py</td><td>operace <i>broadcast</i> (součin každého prvku tenzoru se skalárem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_1.py</a></td></tr>
<tr><td>55</td><td>tensor_broadcast_2.py</td><td>operace <i>broadcast</i> (součin tenzoru druhého řádu s vektorem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_2.py</a></td></tr>
<tr><td>56</td><td>tensor_broadcast_3.py</td><td>operace <i>broadcast</i> (součin vektoru s&nbsp;tenzorem druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_3.py</a></td></tr>
<tr><td>57</td><td>tensor_broadcast_4.py</td><td>operace <i>broadcast</i> (součet tenzorů druhého a třetího řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_4.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>58</td><td>tensor_sparse.py</td><td>konstrukce řídkého tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_sparse.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_sparse.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Seriál Programovací jazyk Lua na Rootu:<br />
<a href="https://www.root.cz/serialy/programovaci-jazyk-lua/">https://www.root.cz/serialy/programovaci-jazyk-lua/</a>
</li>

<li>PDM: moderní správce balíčků a virtuálních prostředí Pythonu:<br />
<a href="https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/">https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008:<br />
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008 (dokončení):<br />
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/</a>
</li>

<li>Brain Floating Point &ndash; nový formát uložení čísel pro strojové učení a chytrá čidla:<br />
<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>
</li>

<li>Stránky projektu PyTorch:<br />
<a href="https://pytorch.org/">https://pytorch.org/</a>
</li>

<li>Informace o instalaci PyTorche:<br />
<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>
</li>

<li>Tenzor (Wikipedia):<br />
<a href="https://cs.wikipedia.org/wiki/Tenzor">https://cs.wikipedia.org/wiki/Tenzor</a>
</li>

<li>Introduction to Tensors:<br />
<a href="https://www.youtube.com/watch?v=uaQeXi4E7gA">https://www.youtube.com/watch?v=uaQeXi4E7gA</a>
</li>

<li>Introduction to Tensors: Transformation Rules:<br />
<a href="https://www.youtube.com/watch?v=j6DazQDbEhQ">https://www.youtube.com/watch?v=j6DazQDbEhQ</a>
</li>

<li>Tensor Attributes:<br />
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Tensors Explained Intuitively: Covariant, Contravariant, Rank :<br />
<a href="https://www.youtube.com/watch?v=CliW7kSxxWU">https://www.youtube.com/watch?v=CliW7kSxxWU</a>
</li>

<li>What is the relationship between PyTorch and Torch?:<br />
<a href="https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch">https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch</a>
</li>

<li>What is a tensor anyway?? (from a mathematician):<br />
<a href="https://www.youtube.com/watch?v=K7f2pCQ3p3U">https://www.youtube.com/watch?v=K7f2pCQ3p3U</a>
</li>

<li>Visualization of tensors - part 1 :<br />
<a href="https://www.youtube.com/watch?v=YxXyN2ifK8A">https://www.youtube.com/watch?v=YxXyN2ifK8A</a>
</li>

<li>Visualization of tensors - part 2A:<br />
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>Visualization of tensors - part 2B:<br />
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>What the HECK is a Tensor?!?:<br />
<a href="https://www.youtube.com/watch?v=bpG3gqDM80w">https://www.youtube.com/watch?v=bpG3gqDM80w</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>An Introduction to Tensors<br />
<a href="https://math.stackexchange.com/questions/10282/an-introduction-to-tensors">https://math.stackexchange.com/questions/10282/an-introduction-to-tensors</a>
</li>

<li>Differences between a matrix and a tensor<br />
<a href="https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor">https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor</a>
</li>

<li>Qualitatively, what is the difference between a matrix and a tensor?<br />
<a href="https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?">https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?</a>
</li>

<li>Tensors for Neural Networks, Clearly Explained!!!:<br />
<a href="https://www.youtube.com/watch?v=L35fFDpwIM4">https://www.youtube.com/watch?v=L35fFDpwIM4</a>
</li>

<li>Tensor Processing Unit:<br />
<a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit">https://en.wikipedia.org/wiki/Tensor_Processing_Unit</a>
</li>

<li>Třída Storage:<br />
<a href="http://docs.pytorch.wiki/en/storage.html">http://docs.pytorch.wiki/en/storage.html</a>
</li>

<li>Funkce torch.dot<br />
<a href="https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot">https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot</a>
</li>

<li>Funkce torch.narrow<br />
<a href="https://pytorch.org/docs/stable/generated/torch.narrow.html">https://pytorch.org/docs/stable/generated/torch.narrow.html</a>
</li>

<li>Funkce torch.matmul<br />
<a href="https://pytorch.org/docs/stable/generated/torch.matmul.html">https://pytorch.org/docs/stable/generated/torch.matmul.html</a>
</li>

<li>Funkce torch.reshape<br />
<a href="https://pytorch.org/docs/stable/generated/torch.reshape.html">https://pytorch.org/docs/stable/generated/torch.reshape.html</a>
</li>

<li>Funkce torch.arange<br />
<a href="https://pytorch.org/docs/stable/generated/torch.arange.html">https://pytorch.org/docs/stable/generated/torch.arange.html</a>
</li>

<li>Funkce torch.range<br />
<a href="https://pytorch.org/docs/stable/generated/torch.range.html">https://pytorch.org/docs/stable/generated/torch.range.html</a>
</li>

<li>Třída torch.Tensor<br />
<a href="https://pytorch.org/docs/stable/tensors.html">https://pytorch.org/docs/stable/tensors.html</a>
</li>

<li>Atributy tenzorů<br />
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Pohledy vytvořené nad tenzory<br />
<a href="https://pytorch.org/docs/stable/tensor_view.html">https://pytorch.org/docs/stable/tensor_view.html</a>
</li>

<li>Broadcasting v&nbsp;knihovně NumPy<br />
<a href="https://numpy.org/doc/stable/user/basics.broadcasting.html">https://numpy.org/doc/stable/user/basics.broadcasting.html</a>
</li>

<li>Broadcasting semantics (v&nbsp;knihovně PyTorch)<br />
<a href="https://pytorch.org/docs/stable/notes/broadcasting.html">https://pytorch.org/docs/stable/notes/broadcasting.html</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

