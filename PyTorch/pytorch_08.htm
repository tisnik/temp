<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>PyTorch: problematika rozpoznávání a klasifikace obrázků (2. část)</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>PyTorch: problematika rozpoznávání a klasifikace obrázků (2. část)</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. PyTorch: problematika rozpoznávání a klasifikace obrázků (2. část)</a></p>
<p><a href="#k02">2. Klasifikace rastrových obrázků sítí běžnou neuronovou sítí s&nbsp;&bdquo;vektorovým&ldquo; vstupem a výstupem</a></p>
<p><a href="#k03">3. První skript: příprava datové sady pro trénink neuronové sítě s&nbsp;vektorovým vstupem a výstupem</a></p>
<p><a href="#k04">4. Příprava vstupních dat, která mohou být zašuměna popř.&nbsp;posunuta</a></p>
<p><a href="#k05">5. Druhý skript: příprava zašuměných a posunutých vstupních dat pro neuronovou síť</a></p>
<p><a href="#k06">6. Náhodné rozdělení datové sady funkcí <strong>train_test_split</strong></a></p>
<p><a href="#k07">7. Realizace rozdělení datové sady na trénovací a testovací data</a></p>
<p><a href="#k08">8. Třetí skript: rozdělení datové sady na trénovací a testovací data</a></p>
<p><a href="#k09">9. Konstrukce neuronové sítě s&nbsp;vektorovým vstupem i výstupem</a></p>
<p><a href="#k10">10. Trénink neuronové sítě</a></p>
<p><a href="#k11">11. Čtvrtý skript: trénink neuronové sítě pro rozpoznávání rastrových obrázků</a></p>
<p><a href="#k12">12. Zašuměné obrázky v&nbsp;trénovacích a testovacích datech</a></p>
<p><a href="#k13">13. Pátý skript: trénink neuronové sítě pro rozpoznávání rastrových obrázků s&nbsp;využitím zašuměných obrázků</a></p>
<p><a href="#k14">14. Posunuté obrázky v&nbsp;trénovacích a testovacích datech</a></p>
<p><a href="#k15">15. Šestý skript: trénink neuronové sítě pro rozpoznání posunutých obrázků</a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. PyTorch: problematika rozpoznávání a klasifikace obrázků (2. část)</h2>

<pre>
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
</pre>

<pre>
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
</pre>



<p><a name="k02"></a></p>
<h2 id="k02">2. Klasifikace rastrových obrázků sítí běžnou neuronovou sítí s&nbsp;&bdquo;vektorovým&ldquo; vstupem a výstupem</h2>

<p>Abychom zjistili limity klasických neuronových sítí pro klasifikaci
rastrových obrázků, pokusíme se je skutečně pro klasifikaci použít.
Zkonstruujeme tedy neuronovou síť, která bude jak na vstupu, tak i na výstupu
obsahovat vektorová data. Konkrétně bude vstupem sítě 64prvkový vektor
(s&nbsp;prvky typu <strong>float32</strong>), který obsahuje pixely původní
bitmapy 8&times;8 pixelů, ovšem v&nbsp;&bdquo;ploché&ldquo; podobě
(z&nbsp;matice vytvoříme vektor). A na výstupu sítě bude taktéž vektor. Ten
bude obsahovat deset prvků, přičemž pozice (<i>index</i>) největšího prvku určí
číslici, kterou síť nalezla ve vstupním obrázku. Ideálně bude tento vektor
vypadat například takto:</p>

<pre>
tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]))
</pre>

<p>což odpovídá číslici 2.</p>

<p>V&nbsp;praxi však síť může odpovědět i takto:</p>

<pre>
tensor([0.1872, 0.1687, 0.9529, 0.0941, 0.0442, 0.1684, 0.0257, 0.0000, 0.0612, 0.2341])
</pre>

<p>což stále poměrně přesně určuje číslici 2 (prvek 0,9529).</p>

<p>Trénovací a testovací data budou reprezentována instancí třídy
<strong>Data</strong>, která je odvozena od třídy
<strong>torch.utils.data.Dataset</strong>. Tuto třídu jsme již několikrát
použili, ovšem pro úplnost si ji ještě jednou ukažme:</p>

<pre>
<i># konverze původních dat z NumPy do tenzorů</i>
class <strong>Data</strong>(Dataset):
    def <strong>__init__</strong>(self, X, y):
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))
        self.len = self.X.shape[0]
&nbsp;
    def <strong>__getitem__</strong>(self, index):
        return self.X[index], self.y[index]
&nbsp;
    def <strong>__len__</strong>(self):
        return self.len
</pre>

<p>Podívejme se nyní na pomocnou funkci, která trénovací a/nebo testovací data
připraví. Tato funkce využívá jak vstupní matici 8&times;8 pixelů
<strong>digits</strong>, tak i funkci nazvanou <strong>digit_to_array</strong>
a popsanou minule. Povšimněte si způsobu tvorby vektorů
<strong>x_vector</strong> a <strong>y_vector</strong>, jejichž délka i hodnoty
prvků odpovídají popisu uvedeném výše:</p>

<pre>
def <strong>prepare_data</strong>(digits, length):
    <i># příprava dat pro trénink a testování</i>
    X = []
    y = []
&nbsp;
    for i in range(length):
        <i># cislice</i>
        digit = i % 10
        <i># vstupy</i>
        array = digit_to_array(digits, digit)
        <i># prevod na vektor</i>
        x_vector = array.flatten()
        X.append(x_vector)
        <i># očekávané výstupy</i>
        y_vector = [0.0] * 10
        y_vector[digit] = 1.0
        y.append(y_vector)
&nbsp;
    return Data(np.array(X), np.array(y))
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. První skript: příprava datové sady pro trénink neuronové sítě s&nbsp;vektorovým vstupem a výstupem</h2>

<p>Postup popsaný <a href="#k02">v&nbsp;předchozí kapitole</a> nyní použijeme
ve skriptu, jehož úkolem je příprava datové sady (což je instance třídy
<strong>Data</strong> odvozené od třídy
<strong>torch.utils.data.Dataset</strong>), která bude z&nbsp;vnějšího pohledu
obsahovat sekvenci dvojic tenzorů. První tenzor z&nbsp;těchto dvojic bude
jednorozměrným vektorem se 64 prvky typu <strong>float32</strong>, jejichž
hodnoty odpovídají intenzitě pixelů původní bitmapy. A druhý tenzor bude taktéž
jednorozměrným vektorem, nyní ovšem s&nbsp;deseti prvky typu
<strong>float32</strong>. Takový vektor bude mít devět prvků nulových a jeden
z&nbsp;prvků nastavený na jedničku &ndash; pozice jedničky odpovídá číslici 0
až 9:</p>

<pre>
import torch
from torch.utils.data import Dataset
import numpy as np
&nbsp;
&nbsp;
<i># konverze původních dat z NumPy do tenzorů</i>
class <strong>Data</strong>(Dataset):
    def <strong>__init__</strong>(self, X, y):
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))
        self.len = self.X.shape[0]
&nbsp;
    def <strong>__getitem__</strong>(self, index):
        return self.X[index], self.y[index]
&nbsp;
    def <strong>__len__</strong>(self):
        return self.len
&nbsp;
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>prepare_data</strong>(digits, length):
    <i># příprava dat pro trénink a testování</i>
    X = []
    y = []
&nbsp;
    for i in range(length):
        <i># cislice</i>
        digit = i % 10
        <i># vstupy</i>
        array = digit_to_array(digits, digit)
        <i># prevod na vektor</i>
        x_vector = array.flatten()
        X.append(x_vector)
        <i># očekávané výstupy</i>
        y_vector = [0.0] * 10
        y_vector[digit] = 1.0
        y.append(y_vector)
&nbsp;
    return Data(np.array(X), np.array(y))
&nbsp;
&nbsp;
data = prepare_data(digits, 1000)
print(len(data))
&nbsp;
for i in range(10):
    print(data[i])
</pre>

<p>Skript po svém spuštění připraví data pro neuronovou síť, poté vytiskne
jejich počet a nakonec i obsah prvních deseti dvojic. Povšimněte si, jak se ve
druhém tenzoru &bdquo;posunuje&ldquo; jednička, která určuje cifru na
obrázku:</p>

<pre>
1000
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 0., 0., 1., 1., 1.,
        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1.,
        1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]))
        ...
        ...
        ...
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0.,
        0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]))
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 0., 1.,
        1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 1., 1., 1., 0.,
        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]))
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. Příprava vstupních dat, která mohou být zašuměna popř.&nbsp;posunuta</h2>

<p>V&nbsp;praxi však nebudou vstupní obrázky pro neuronovou síť ideální.
Ostatně kdyby byly, stačilo by nám naprogramovat jednoduché mapování
přesný_vstup&rarr;přesný_výstup. Na vstupní data tedy budeme aplikovat šum a
popř.&nbsp;i operaci posunu obrázku ve směru horizontální a/nebo vertikální
osy. Všechny potřebné pomocné funkce jsme si již vysvětlili v&nbsp;předchozím
článku, takže jen ve stručnosti:</p>

<pre>
def <strong>add_noise</strong>(array, level):
    return (1.0 - level) * array + level * np.random.rand(8, 8)
</pre>

<p>a:</p>

<pre>
def <strong>shift</strong>(arr, x_shift, y_shift):
    <i># horizontální posun</i>
    arr = np.roll(arr, x_shift, axis=1)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if x_shift &lt; 0:
        arr[:, x_shift:] = 0.0
    elif x_shift &gt; 0:
        arr[:, :x_shift] = 0.0
&nbsp;
    <i># vertikální posun</i>
    arr = np.roll(arr, y_shift, axis=0)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if y_shift &lt; 0:
        arr[y_shift:] = 0.0
    elif y_shift &gt; 0:
        arr[:y_shift] = 0.0
    return arr
</pre>

<p>Funkci pro přípravu dat upravíme takovým způsobem, že bude tyto dvě funkce
volat a předávat jim vstupní parametry nastavené uživatelem &ndash; tedy úroveň
šumu a maximální posun obrázků uvedený v&nbsp;pixelech:</p>

<pre>
def <strong>prepare_data</strong>(digits, length, noise_level=0.0, x_shift_amount=0, y_shift_amount=0):
    <i># příprava dat pro trénink a testování</i>
    X = []
    y = []
&nbsp;
    for i in range(length):
        <i># cislice</i>
        digit = i % 10
        <i># vstupy</i>
        array = digit_to_array(digits, digit)
        <i># zasumeni</i>
        array = add_noise(array, noise_level)
        <i># posuny</i>
        x_shift = random.randint(-x_shift_amount, x_shift_amount)
        y_shift = random.randint(-y_shift_amount, y_shift_amount)
        array = shift(array, x_shift, y_shift)
        <i># prevod na vektor</i>
        x_vector = array.flatten()
        X.append(x_vector)
        <i># očekávané výstupy</i>
        y_vector = [0.0] * 10
        y_vector[digit] = 1.0
        y.append(y_vector)
&nbsp;
    return Data(np.array(X), np.array(y))
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Druhý skript: příprava zašuměných a posunutých vstupních dat pro neuronovou síť</h2>

<p>Opět se podívejme, jak by mohl vypadat skript, který připraví data pro
trénink a testování klasické neuronové sítě s&nbsp;64prvkovými vektory na
vstupu a desetiprvkovými vektory na výstupu. Tentokrát však budou vstupní
vektory obsahovat hodnoty, které jsou zašuměné, nebo mohou být obrázky posunuté
v&nbsp;libovolném směru. Asi správně odhadnete, že právě posun bude kritický,
protože jsme ztratili informaci o dvou rozměrech a vstupem je jen jednorozměrný
vektor. Ukažme si zdrojový kód upraveného skriptu:</p>

<pre>
import random
import torch
from torch.utils.data import Dataset
import numpy as np
&nbsp;
&nbsp;
<i># konverze původních dat z NumPy do tenzorů</i>
class <strong>Data</strong>(Dataset):
    def <strong>__init__</strong>(self, X, y):
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))
        self.len = self.X.shape[0]
&nbsp;
    def <strong>__getitem__</strong>(self, index):
        return self.X[index], self.y[index]
&nbsp;
    def <strong>__len__</strong>(self):
        return self.len
&nbsp;
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>add_noise</strong>(array, level):
    return (1.0 - level) * array + level * np.random.rand(8, 8)
&nbsp;
&nbsp;
def <strong>shift</strong>(arr, x_shift, y_shift):
    <i># horizontální posun</i>
    arr = np.roll(arr, x_shift, axis=1)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if x_shift &lt; 0:
        arr[:, x_shift:] = 0.0
    elif x_shift &gt; 0:
        arr[:, :x_shift] = 0.0
&nbsp;
    <i># vertikální posun</i>
    arr = np.roll(arr, y_shift, axis=0)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if y_shift &lt; 0:
        arr[y_shift:] = 0.0
    elif y_shift &gt; 0:
        arr[:y_shift] = 0.0
    return arr
&nbsp;
&nbsp;
def <strong>prepare_data</strong>(digits, length, noise_level=0.0, x_shift_amount=0, y_shift_amount=0):
    <i># příprava dat pro trénink a testování</i>
    X = []
    y = []
&nbsp;
    for i in range(length):
        <i># cislice</i>
        digit = i % 10
        <i># vstupy</i>
        array = digit_to_array(digits, digit)
        <i># zasumeni</i>
        array = add_noise(array, noise_level)
        <i># posuny</i>
        x_shift = random.randint(-x_shift_amount, x_shift_amount)
        y_shift = random.randint(-y_shift_amount, y_shift_amount)
        array = shift(array, x_shift, y_shift)
        <i># prevod na vektor</i>
        x_vector = array.flatten()
        X.append(x_vector)
        <i># očekávané výstupy</i>
        y_vector = [0.0] * 10
        y_vector[digit] = 1.0
        y.append(y_vector)
&nbsp;
    return Data(np.array(X), np.array(y))
&nbsp;
&nbsp;
data = prepare_data(digits, 1000, noise_level=0.0, x_shift_amount=2, y_shift_amount=2)
print(len(data))
&nbsp;
for i in range(10):
    print(data[i])
</pre>

<p>Po spuštění skriptu se opět zobrazí počet prvků v&nbsp;trénovací/testovací
sadě a posléze hodnoty prvních deseti prvků. Nyní je patrné, že první vektor už
neobsahuje pouze hodnoty 0,0 a 1,0, ale více či méně odlišné hodnoty:</p>

<pre>
1000
(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0991, 0.1470,
        0.0453, 0.1430, 0.0893, 0.0821, 0.0000, 0.0000, 0.9793, 0.8072, 0.9616,
        0.8820, 0.0053, 0.0436, 0.0000, 0.0000, 0.9762, 0.0246, 0.0278, 0.8587,
        0.9291, 0.0374, 0.0000, 0.0000, 0.9698, 0.0695, 0.8725, 0.8903, 0.9781,
        0.0564, 0.0000, 0.0000, 0.9405, 0.9431, 0.1012, 0.9844, 0.9339, 0.1723,
        0.0000, 0.0000, 0.8720, 0.1137, 0.1474, 0.8364, 0.8673, 0.0288, 0.0000,
        0.0000]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))
(tensor([0.1282, 0.1286, 0.9159, 0.9999, 0.0604, 0.0830, 0.1627, 0.0000, 0.0997,
        0.8669, 0.8799, 0.9667, 0.1710, 0.0166, 0.1434, 0.0000, 0.1858, 0.0872,
        0.9059, 0.8710, 0.1191, 0.1385, 0.0505, 0.0000, 0.0617, 0.0100, 0.9928,
        0.9849, 0.1692, 0.1496, 0.0553, 0.0000, 0.0863, 0.0691, 0.9267, 0.8241,
        0.1422, 0.1098, 0.0381, 0.0000, 0.8753, 0.8869, 0.9612, 0.8800, 0.9099,
        0.8483, 0.0810, 0.0000, 0.1768, 0.1332, 0.1881, 0.1756, 0.0358, 0.1965,
        0.1333, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000]), tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]))
        ...
        ...
        ...
(tensor([0.0000, 0.0000, 0.0733, 0.1337, 0.9931, 0.9026, 0.8485, 0.9472, 0.0000,
        0.0000, 0.1810, 0.8931, 0.8541, 0.0940, 0.1297, 0.1427, 0.0000, 0.0000,
        0.1165, 0.9050, 0.8881, 0.8289, 0.9612, 0.9271, 0.0000, 0.0000, 0.0582,
        0.8934, 0.9511, 0.1421, 0.0801, 0.8987, 0.0000, 0.0000, 0.1779, 0.8515,
        0.8020, 0.1619, 0.0649, 0.8573, 0.0000, 0.0000, 0.1445, 0.1342, 0.9168,
        0.8039, 0.9018, 0.9114, 0.0000, 0.0000, 0.1518, 0.0960, 0.0952, 0.0685,
        0.1568, 0.1162, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000]), tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]))
(tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0170,
        0.1181, 0.1175, 0.0079, 0.0321, 0.1954, 0.0000, 0.0000, 0.8095, 0.9161,
        0.9373, 0.9020, 0.1813, 0.1592, 0.0000, 0.0000, 0.9597, 0.1631, 0.1652,
        0.8400, 0.9894, 0.1514, 0.0000, 0.0000, 0.8719, 0.8249, 0.9083, 0.8364,
        0.1119, 0.0627, 0.0000, 0.0000, 0.8413, 0.0157, 0.0148, 0.8373, 0.9239,
        0.1173, 0.0000, 0.0000, 0.9013, 0.0727, 0.0251, 0.8195, 0.8519, 0.0888,
        0.0000, 0.0000, 0.8526, 0.8314, 0.8749, 0.9900, 0.1544, 0.1514, 0.0000,
        0.0000]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]))
(tensor([0.0936, 0.9051, 0.9126, 0.1106, 0.0446, 0.8483, 0.9484, 0.1938, 0.1982,
        0.0617, 0.9297, 0.8475, 0.8500, 0.9321, 0.9868, 0.1909, 0.1818, 0.0986,
        0.0904, 0.1327, 0.0302, 0.8697, 0.8073, 0.0833, 0.0850, 0.1306, 0.0666,
        0.1750, 0.8532, 0.8485, 0.0680, 0.0881, 0.0256, 0.0323, 0.9974, 0.9051,
        0.9478, 0.1259, 0.0662, 0.0194, 0.0463, 0.1651, 0.0389, 0.0865, 0.0547,
        0.1028, 0.0711, 0.1404, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,
        0.0000]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]))
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. Náhodné rozdělení datové sady funkcí <strong>train_test_split</strong></h2>

<p>Pro rozdělení dat, která byla získána postupem popsaným v&nbsp;předchozích
kapitolách (dvojice 64prvkový vektor+desetiprvkový vektor) na data trénovací a
validační (resp.&nbsp;testovací), použijeme funkci
<strong>train_test_split</strong>. Tato funkce ve svém prvním parametru
akceptuje přímo datovou sadu (nemusíme se tedy snažit o ruční získání
naměřených dat a očekávaných výsledků), dále velikost testovacích a trénovacích
dat (buď jako celé číslo, což je počet záznamů nebo hodnotu typu float, což
bude zlomek od 0 do 1, nepovinnou hodnotu, která zamezí různým výsledkům pro
několik volání této funkce a dále parametr povolující zamíchání dat (ve
výchozím nastavení je povolen, což nám opět vyhovuje):</p>

<pre>
train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)
    Split arrays or matrices into random train and test subsets.
&nbsp;
    Quick utility that wraps input validation,
    ``next(ShuffleSplit().split(X, y))``, and application to input data
    into a single call for splitting (and optionally subsampling) data into a
    one-liner.
&nbsp;
    Read more in the :ref:`User Guide &lt;cross_validation&gt;`.
&nbsp;
    Parameters
    ----------
    *arrays : sequence of indexables with same length / shape[0]
        Allowed inputs are lists, numpy arrays, scipy-sparse
        matrices or pandas dataframes.
&nbsp;
    test_size : float or int, default=None
        If float, should be between 0.0 and 1.0 and represent the proportion
        of the dataset to include in the test split. If int, represents the
        absolute number of test samples. If None, the value is set to the
        complement of the train size. If ``train_size`` is also None, it will
        be set to 0.25.
&nbsp;
    train_size : float or int, default=None
        If float, should be between 0.0 and 1.0 and represent the
        proportion of the dataset to include in the train split. If
        int, represents the absolute number of train samples. If None,
        the value is automatically set to the complement of the test size.
&nbsp;
    random_state : int, RandomState instance or None, default=None
        Controls the shuffling applied to the data before applying the split.
        Pass an int for reproducible output across multiple function calls.
        See :term:`Glossary &lt;random_state&gt;`.
&nbsp;
    shuffle : bool, default=True
        Whether or not to shuffle the data before splitting. If shuffle=False
        then stratify must be None.
&nbsp;
    stratify : array-like, default=None
        If not None, data is split in a stratified fashion, using this as
        the class labels.
        Read more in the :ref:`User Guide &lt;stratification&gt;`.
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. Realizace rozdělení datové sady na trénovací a testovací data</h2>

<p>Nyní si funkci pro přípravu dat, s&nbsp;nimiž budeme při konstrukci,
tréninku a validaci neuronové sítě pracovat, rozšíříme o volání funkce
<strong>train_test_split</strong>. Vstupem této funkce jsou hodnoty
<strong>X</strong> a <strong>y</strong> převedené ze seznamů na n-rozměrná pole
typu <strong>np.array</strong> (ale vlastně už nyní by bylo možné použít
tenzory). Výsledkem je čtveřice n-rozměrných polí <strong>X_train</strong>,
<strong>X_test</strong>, <strong>y_train</strong> a <strong>y_test</strong>,
která jsou použita pro konstrukci dvou objektů typu <strong>Data</strong>. Tím
máme přípravné práce za sebou:</p>

<pre>
def <strong>prepare_data</strong>(digits, length, noise_level=0.0, x_shift_amount=0, y_shift_amount=0, test_size=1/2):
    <i># příprava dat pro trénink a testování</i>
    X = []
    y = []
&nbsp;
    for i in range(length):
        <i># cislice</i>
        digit = i % 10
        <i># vstupy</i>
        array = digit_to_array(digits, digit)
        <i># zasumeni</i>
        array = add_noise(array, noise_level)
        <i># posuny</i>
        x_shift = random.randint(-x_shift_amount, x_shift_amount)
        y_shift = random.randint(-y_shift_amount, y_shift_amount)
        array = shift(array, x_shift, y_shift)
        <i># prevod na vektor</i>
        x_vector = array.flatten()
        X.append(x_vector)
        <i># očekávané výstupy</i>
        y_vector = [0.0] * 10
        y_vector[digit] = 1.0
        y.append(y_vector)
&nbsp;
    X_train, X_test, y_train, y_test = train_test_split(
        np.array(X), np.array(y),
        test_size=test_size, random_state=26
    )
&nbsp;
    <i># trénovací sada</i>
    train_data = Data(X_train, y_train)
&nbsp;
    <i># testovací sada</i>
    test_data = Data(X_test, y_test)
&nbsp;
    return train_data, test_data
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. Třetí skript: rozdělení datové sady na trénovací a testovací data</h2>

<p>Celý skript, který připraví data pro neuronovou síť na základě bitmap
s&nbsp;číslicemi, se &bdquo;natáhl&ldquo; na délku přibližně tří kilobajtů,
ovšem stále by mělo být zřejmé, jaké operace se v&nbsp;něm provádí a proč:</p>

<pre>
import random
from sklearn.model_selection import train_test_split
import torch
from torch.utils.data import Dataset
import numpy as np
&nbsp;
&nbsp;
<i># konverze původních dat z NumPy do tenzorů</i>
class <strong>Data</strong>(Dataset):
    def <strong>__init__</strong>(self, X, y):
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))
        self.len = self.X.shape[0]
&nbsp;
    def <strong>__getitem__</strong>(self, index):
        return self.X[index], self.y[index]
&nbsp;
    def <strong>__len__</strong>(self):
        return self.len
&nbsp;
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>add_noise</strong>(array, level):
    return (1.0 - level) * array + level * np.random.rand(8, 8)
&nbsp;
&nbsp;
def <strong>shift</strong>(arr, x_shift, y_shift):
    <i># horizontální posun</i>
    arr = np.roll(arr, x_shift, axis=1)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if x_shift &lt; 0:
        arr[:, x_shift:] = 0.0
    elif x_shift &gt; 0:
        arr[:, :x_shift] = 0.0
&nbsp;
    <i># vertikální posun</i>
    arr = np.roll(arr, y_shift, axis=0)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if y_shift &lt; 0:
        arr[y_shift:] = 0.0
    elif y_shift &gt; 0:
        arr[:y_shift] = 0.0
    return arr
&nbsp;
&nbsp;
def <strong>prepare_data</strong>(digits, length, noise_level=0.0, x_shift_amount=0, y_shift_amount=0, test_size=1/2):
    <i># příprava dat pro trénink a testování</i>
    X = []
    y = []
&nbsp;
    for i in range(length):
        <i># cislice</i>
        digit = i % 10
        <i># vstupy</i>
        array = digit_to_array(digits, digit)
        <i># zasumeni</i>
        array = add_noise(array, noise_level)
        <i># posuny</i>
        x_shift = random.randint(-x_shift_amount, x_shift_amount)
        y_shift = random.randint(-y_shift_amount, y_shift_amount)
        array = shift(array, x_shift, y_shift)
        <i># prevod na vektor</i>
        x_vector = array.flatten()
        X.append(x_vector)
        <i># očekávané výstupy</i>
        y_vector = [0.0] * 10
        y_vector[digit] = 1.0
        y.append(y_vector)
&nbsp;
    X_train, X_test, y_train, y_test = train_test_split(
        np.array(X), np.array(y),
        test_size=test_size, random_state=26
    )
&nbsp;
    <i># trénovací sada</i>
    train_data = Data(X_train, y_train)
&nbsp;
    <i># testovací sada</i>
    test_data = Data(X_test, y_test)
&nbsp;
    return train_data, test_data
&nbsp;
&nbsp;
train, test = prepare_data(digits, 1000, noise_level=0.0, x_shift_amount=2, y_shift_amount=2)
print(len(train))
print(len(test))
&nbsp;
for i in range(10):
    print(train[i])
</pre>

<p>Z&nbsp;prvních dvou vypsaných řádků je patrné, že jak trénovací data, tak i
data pro otestování, mají shodně 500 prvků. Ovšem tyto prvky se pochopitelně od
sebe odlišují:</p>

<pre>
500
500
</pre>

<p>Skript navíc vypíše prvních deset prvků trénovacích dat:</p>

<pre>
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]))
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]))
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1.,
        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1.,
        1., 0., 0., 0., 0., 1., 1., 1., 0., 0.]), tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]))
...
...
...
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,
        0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0.,
        0., 0., 0., 0., 1., 1., 1., 1., 1., 1.]), tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]))
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        0., 1., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1., 1.,
        0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0.]), tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))
(tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
        1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0.,
        1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 0.,
        1., 1., 0., 0., 0., 1., 1., 1., 1., 0.]), tensor([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]))
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Konstrukce neuronové sítě s&nbsp;vektorovým vstupem i výstupem</h2>

<p>V&nbsp;dalším kroku (konečně) zkonstruujeme neuronovou síť, na jejíž vstup
budeme posílat 64prvkové vektory s&nbsp;hodnotami zašuměných a posunutých
obrázků s&nbsp;číslicemi a na jejímž výstupu bude desetiprvkový vektor, jehož
nejvyšší prvek určí index číslice rozeznané touto sítí. Pro jednoduchost a pro
rychlé učení bude síť obsahovat pouze jednu skrytou vrstvu. Jako aktivační
funkci mezi vstupy a skrytou vrstvou vybereme ReLU a pro dvojici vrstev naopak
sigmoid (později tento výběr můžeme kdykoli modifikovat):</p>

<pre>
class <strong>NeuralNetwork</strong>(nn.Module):
    <i>"""Třída reprezentující neuronovou síť."""</i>
&nbsp;
    def <strong>__init__</strong>(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        <i># vrstvy neuronové sítě</i>
        self.layer_1 = nn.Linear(input_dim, hidden_dim)
        self.layer_2 = nn.Linear(hidden_dim, output_dim)
&nbsp;
    def <strong>forward</strong>(self, x):
        <i># propagace hodnot přes neuronovou síť</i>
        x = torch.nn.functional.relu(self.layer_1(x))
        x = torch.nn.functional.sigmoid(self.layer_2(x))
        return x
</pre>

<p>Vstupem jsou 64prvkové vektory, výstupem desetiprvkový vektor. Tím jsou
přímo určeny počty neuronů na vstupu i neuronů ve výstupní vrstvě. Skrytá
vrstva může mít libovolný počet neuronů. Zvolme hodnotu 10. Ta není ani velká
(problém nedoučení) ani malá (problém &bdquo;hloupé&ldquo; sítě s&nbsp;malým
množstvím stavů):</p>

<pre>
<i># konfigurace vrstev neuronové sítě</i>
input_dim = 64
hidden_dim = 10
output_dim = 10
&nbsp;
nn_64_10_10 = NeuralNetwork(input_dim, hidden_dim, output_dim)
&nbsp;
<i># výpis základních informací o neuronové síti</i>
print("Neural network:")
print(nn_64_10_10)
</pre>

<p>Skript v&nbsp;této zkrácené podobě by měl vypsat strukturu neuronové
sítě:</p>

<pre>
Neural network:
NeuralNetwork(
  (layer_1): Linear(in_features=64, out_features=10, bias=True)
  (layer_2): Linear(in_features=10, out_features=10, bias=True)
)
</pre>

<p>Pokud vás mate, že skrytá vrstva má stejný počet neuronů, jako vrstva
výstupní, můžeme skrytou vrstvu rozšířit na 99 neuronů:</p>

<pre>
Neural network:
NeuralNetwork(
  (layer_1): Linear(in_features=64, out_features=99, bias=True)
  (layer_2): Linear(in_features=99, out_features=10, bias=True)
)
</pre>



<p><a name="k10"></a></p>
<h2 id="k10">10. Trénink neuronové sítě</h2>

<p>Neuronovou síť máme nyní zkonstruovanou, ovšem váhy na vstupech neuronů jsou
prozatím nastaveny na náhodnou hodnotu. Síť je tedy nutné natrénovat. Pro tento
účel si necháme vygenerovat trénovací a testovací data, což není nic nového,
protože jsme se s&nbsp;tímto konceptem seznámili <a
href="#k06">v&nbsp;šesté</a> a <a href="#k07">sedmé kapitole</a>:</p>

<pre>
train_data, test_data = prepare_data(digits, 1000, noise_level=0.0, x_shift_amount=0, y_shift_amount=0)
print("Train data:")
print(len(train_data))
print("Test data:")
print(len(test_data))
</pre>

<p>Povšimněte si, že si sice necháme vygenerovat 1000 záznamů, ale vzhledem
k&nbsp;tomu, že úroveň šumu je nulová a obrázky se neposunují, vlastně bude
datová sada obsahovat každý záznam ve 100 identických kopiích:</p>

<pre>
Train data:
666
Test data:
334
</pre>

<p>Samotný trénink neuronové sítě taktéž není nová metoda. Na vstup sítě
předáme jeden vektor vybraný z&nbsp;trénovacích dat, na výstup očekávaný výstup
(taktéž vektor) a zpětným šířením chyby se poupraví váhy na vstupech
jednotlivých neuronů:</p>

<pre>
<i># příprava na trénink neuronové sítě</i>
learning_rate = 0.1
loss_fn = nn.BCELoss()
&nbsp;
optimizer = optim.SGD(nn_64_10_10.parameters(), lr=learning_rate)
&nbsp;
<i># zpracovat trénovací data</i>
batch_size = 64
train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
print("Batches: ", len(train_dataloader))
&nbsp;
<i># vlastní trénink</i>
print("Training started")
num_epochs = 100
loss_values = []
for epoch in range(num_epochs):
    print(f"    Epoch {epoch}: ", end="")
    last_lost_value = None
    for X, y in train_dataloader:
        optimizer.zero_grad()
&nbsp;
        <i># dopředný tok + zpětný tok + optimalizace</i>
        pred = nn_64_10_10(X)
&nbsp;
        <i># výpočet účelové funkce</i>
        loss = loss_fn(pred, y)
&nbsp;
        <i>#loss = loss_fn(pred, y.unsqueeze(-1))</i>
        loss_values.append(loss.item())
        loss.backward()
        optimizer.step()
        last_lost_value = loss.item()
        print(".", end="")
    print(last_lost_value)
&nbsp;
print("Training completed")
</pre>

<p>V&nbsp;průběhu učení by se postupně měla snižovat hodnota vypočtená účelovou
funkcí. V&nbsp;ideálním případě by měla klesnout k&nbsp;nule:</p>

<pre>
Batches:  11
Training started
    Epoch 0: ...........0.6447266936302185
    Epoch 1: ...........0.6193460822105408
    Epoch 2: ...........0.587082028388977
    Epoch 3: ...........0.5465092658996582
    Epoch 4: ...........0.4956221878528595
    Epoch 5: ...........0.44743767380714417
    Epoch 6: ...........0.38974180817604065
    Epoch 7: ...........0.3594760000705719
    Epoch 8: ...........0.3338333070278168
    Epoch 9: ...........0.3175426423549652
    Epoch 10: ...........0.32316410541534424
    Epoch 11: ...........0.32127857208251953
    Epoch 12: ...........0.3148137927055359
    Epoch 13: ...........0.3114672899246216
    Epoch 14: ...........0.316869854927063
    Epoch 15: ...........0.3137578070163727
    Epoch 16: ...........0.3157559633255005
    Epoch 17: ...........0.3102682828903198
    Epoch 18: ...........0.3075677454471588
    Epoch 19: ...........0.30908656120300293
    Epoch 20: ...........0.3039756715297699
    Epoch 21: ...........0.3026908338069916
    Epoch 22: ...........0.30455878376960754
    Epoch 23: ...........0.30317121744155884
    Epoch 24: ...........0.29968011379241943
    Epoch 25: ...........0.2984805703163147
    Epoch 26: ...........0.2998690903186798
    Epoch 27: ...........0.2988283932209015
    Epoch 28: ...........0.28817668557167053
    Epoch 29: ...........0.2917144298553467
    Epoch 30: ...........0.2874159812927246
    Epoch 31: ...........0.2909078598022461
    Epoch 32: ...........0.27771422266960144
    Epoch 33: ...........0.2821337580680847
    Epoch 34: ...........0.28642821311950684
    Epoch 35: ...........0.276723176240921
    Epoch 36: ...........0.2759454548358917
    Epoch 37: ...........0.27059292793273926
    Epoch 38: ...........0.2683849036693573
    Epoch 39: ...........0.268013060092926
    Epoch 40: ...........0.2737174928188324
    Epoch 41: ...........0.2644055187702179
    Epoch 42: ...........0.26093563437461853
    Epoch 43: ...........0.2565652132034302
    Epoch 44: ...........0.25182580947875977
    Epoch 45: ...........0.2551380693912506
    Epoch 46: ...........0.2450740933418274
    Epoch 47: ...........0.24896760284900665
    Epoch 48: ...........0.24437251687049866
    Epoch 49: ...........0.24140697717666626
    Epoch 50: ...........0.23914998769760132
    Epoch 51: ...........0.23454098403453827
    Epoch 52: ...........0.23361629247665405
    Epoch 53: ...........0.23802918195724487
    Epoch 54: ...........0.223032146692276
    Epoch 55: ...........0.2397080361843109
    Epoch 56: ...........0.21921715140342712
    Epoch 57: ...........0.21958164870738983
    Epoch 58: ...........0.22020205855369568
    Epoch 59: ...........0.2035556137561798
    Epoch 60: ...........0.21375465393066406
    Epoch 61: ...........0.1982254534959793
    Epoch 62: ...........0.19214391708374023
    Epoch 63: ...........0.2059931755065918
    Epoch 64: ...........0.1918933093547821
    Epoch 65: ...........0.20608077943325043
    Epoch 66: ...........0.19234557449817657
    Epoch 67: ...........0.1903819739818573
    Epoch 68: ...........0.1945323795080185
    Epoch 69: ...........0.1832999587059021
    Epoch 70: ...........0.18331988155841827
    Epoch 71: ...........0.1699090152978897
    Epoch 72: ...........0.1823926419019699
    Epoch 73: ...........0.17585024237632751
    Epoch 74: ...........0.16324113309383392
    Epoch 75: ...........0.17733824253082275
    Epoch 76: ...........0.17202644050121307
    Epoch 77: ...........0.16952469944953918
    Epoch 78: ...........0.15982866287231445
    Epoch 79: ...........0.16450724005699158
    Epoch 80: ...........0.15805110335350037
    Epoch 81: ...........0.16729946434497833
    Epoch 82: ...........0.14237038791179657
    Epoch 83: ...........0.16939890384674072
    Epoch 84: ...........0.15275999903678894
    Epoch 85: ...........0.14588870108127594
    Epoch 86: ...........0.15782424807548523
    Epoch 87: ...........0.15238074958324432
</pre>

*** image ***
<p><i>Obrázek 1: Postupně klesající hodnoty vypočítané účelovou funkcí
naznačují korektní učení sítě.</i></p>



<p><a name="k11"></a></p>
<h2 id="k11">11. Čtvrtý skript: trénink neuronové sítě pro rozpoznávání rastrových obrázků</h2>

<p>Postup popsaný v&nbsp;předchozích pěti kapitolách byl použit v&nbsp;dnešním
čtvrtém skriptu, který vypadá takto:</p>

<pre>
import random
from sklearn.model_selection import train_test_split
import torch
from torch import nn
from torch import optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
&nbsp;
class <strong>NeuralNetwork</strong>(nn.Module):
    <i>"""Třída reprezentující neuronovou síť."""</i>
&nbsp;
    def <strong>__init__</strong>(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        <i># vrstvy neuronové sítě</i>
        self.layer_1 = nn.Linear(input_dim, hidden_dim)
        self.layer_2 = nn.Linear(hidden_dim, output_dim)
&nbsp;
    def <strong>forward</strong>(self, x):
        <i># propagace hodnot přes neuronovou síť</i>
        x = torch.nn.functional.relu(self.layer_1(x))
        x = torch.nn.functional.sigmoid(self.layer_2(x))
        return x
&nbsp;
&nbsp;
<i># konfigurace vrstev neuronové sítě</i>
input_dim = 64
hidden_dim = 10
output_dim = 10
&nbsp;
nn_64_10_10 = NeuralNetwork(input_dim, hidden_dim, output_dim)
&nbsp;
<i># výpis základních informací o neuronové síti</i>
print("Neural network:")
print(nn_64_10_10)
&nbsp;
&nbsp;
<i># konverze původních dat z NumPy do tenzorů</i>
class <strong>Data</strong>(Dataset):
    def <strong>__init__</strong>(self, X, y):
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))
        self.len = self.X.shape[0]
&nbsp;
    def <strong>__getitem__</strong>(self, index):
        return self.X[index], self.y[index]
&nbsp;
    def <strong>__len__</strong>(self):
        return self.len
&nbsp;
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>add_noise</strong>(array, level):
    return (1.0 - level) * array + level * np.random.rand(8, 8)
&nbsp;
&nbsp;
def <strong>shift</strong>(arr, x_shift, y_shift):
    <i># horizontální posun</i>
    arr = np.roll(arr, x_shift, axis=1)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if x_shift &lt; 0:
        arr[:, x_shift:] = 0.0
    elif x_shift &gt; 0:
        arr[:, :x_shift] = 0.0
&nbsp;
    <i># vertikální posun</i>
    arr = np.roll(arr, y_shift, axis=0)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if y_shift &lt; 0:
        arr[y_shift:] = 0.0
    elif y_shift &gt; 0:
        arr[:y_shift] = 0.0
    return arr
&nbsp;
&nbsp;
def <strong>prepare_data</strong>(digits, length, noise_level=0.0, x_shift_amount=0, y_shift_amount=0, test_size=1/3):
    <i># příprava dat pro trénink a testování</i>
    X = []
    y = []
&nbsp;
    for i in range(length):
        <i># cislice</i>
        digit = i % 10
        <i># vstupy</i>
        array = digit_to_array(digits, digit)
        <i># zasumeni</i>
        array = add_noise(array, noise_level)
        <i># posuny</i>
        x_shift = random.randint(-x_shift_amount, x_shift_amount)
        y_shift = random.randint(-y_shift_amount, y_shift_amount)
        array = shift(array, x_shift, y_shift)
        <i># prevod na vektor</i>
        x_vector = array.flatten()
        X.append(x_vector)
        <i># očekávané výstupy</i>
        y_vector = [0.0] * 10
        y_vector[digit] = 1.0
        y.append(y_vector)
&nbsp;
    X_train, X_test, y_train, y_test = train_test_split(
        np.array(X), np.array(y),
        test_size=test_size, random_state=26
    )
&nbsp;
    <i># trénovací sada</i>
    train_data = Data(X_train, y_train)
&nbsp;
    <i># testovací sada</i>
    test_data = Data(X_test, y_test)
&nbsp;
    return train_data, test_data
&nbsp;
&nbsp;
train_data, test_data = prepare_data(digits, 1000, noise_level=0.0, x_shift_amount=0, y_shift_amount=0)
print("Train data:")
print(len(train_data))
print("Test data:")
print(len(test_data))
&nbsp;
<i># příprava na trénink neuronové sítě</i>
learning_rate = 0.1
loss_fn = nn.BCELoss()
&nbsp;
optimizer = optim.SGD(nn_64_10_10.parameters(), lr=learning_rate)
&nbsp;
<i># zpracovat trénovací data</i>
batch_size = 64
train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
print("Batches: ", len(train_dataloader))
&nbsp;
<i># vlastní trénink</i>
print("Training started")
num_epochs = 100
loss_values = []
for epoch in range(num_epochs):
    print(f"    Epoch {epoch}: ", end="")
    last_lost_value = None
    for X, y in train_dataloader:
        optimizer.zero_grad()
&nbsp;
        <i># dopředný tok + zpětný tok + optimalizace</i>
        pred = nn_64_10_10(X)
&nbsp;
        <i># výpočet účelové funkce</i>
        loss = loss_fn(pred, y)
&nbsp;
        <i>#loss = loss_fn(pred, y.unsqueeze(-1))</i>
        loss_values.append(loss.item())
        loss.backward()
        optimizer.step()
        last_lost_value = loss.item()
        print(".", end="")
    print(last_lost_value)
&nbsp;
print("Training completed")
&nbsp;
step = range(len(loss_values))
&nbsp;
<i># příprava na vykreslení grafu</i>
fig, ax = plt.subplots(figsize=(6.4, 4.8))
plt.plot(step, np.array(loss_values))
plt.title("Průběh tréninku neuronové sítě")
plt.xlabel("Epocha")
plt.ylabel("Chyba")
&nbsp;
<i># uložení do souboru</i>
plt.savefig("nn_16.png")
&nbsp;
<i># vykreslení grafu</i>
plt.show()
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Zašuměné obrázky v&nbsp;trénovacích a testovacích datech</h2>

<p>Naprosto stejnou neuronovou síť nyní natrénujeme s&nbsp;využitím zašuměných
obrázků. A nutno říci, že úroveň šumu je nastavena poměrně vysoko &ndash; na
50%. To může v&nbsp;některých případech znamenat, že obrázky nebudou dobře
rozeznatelné ani tou nejlepší neuronovou sítí pro rozpoznání obrazu &ndash;
lidským mozkem:</p>

<pre>
train_data, test_data = prepare_data(digits, 1000, noise_level=0.5, x_shift_amount=0, y_shift_amount=0)
</pre>

<p>Průběh učení naznačuje, že hodnoty účelové funkce již neklesnou na hodnotu
0,15 tak, jako v&nbsp;příkladu předchozím:</p>

<pre>
Batches:  11
Training started
    Epoch 0: ...........0.6567670106887817
    Epoch 1: ...........0.6100022792816162
    Epoch 2: ...........0.5560295581817627
    Epoch 3: ...........0.491263747215271
    Epoch 4: ...........0.4276190996170044
    Epoch 5: ...........0.39090630412101746
    Epoch 6: ...........0.3492359519004822
    Epoch 7: ...........0.34494543075561523
    Epoch 8: ...........0.3371904492378235
    Epoch 9: ...........0.3227657973766327
    Epoch 10: ...........0.32668638229370117
    ...
    ...
    ...
    Epoch 90: ...........0.28734317421913147
    Epoch 91: ...........0.28829020261764526
    Epoch 92: ...........0.29428786039352417
    Epoch 93: ...........0.27999159693717957
    Epoch 94: ...........0.27175065875053406
    Epoch 95: ...........0.2788369059562683
    Epoch 96: ...........0.2692151367664337
    Epoch 97: ...........0.28449100255966187
    Epoch 98: ...........0.27109402418136597
    Epoch 99: ...........0.28655123710632324
Training completed
</pre>

<p>Totéž je ostatně velmi dobře patrné i ve vizualizovaném průběhu účelové
funkce:</p>

*** image ***
<p><i>Obrázek 2: Postupně klesající hodnoty vypočítané účelovou funkcí
naznačují korektní učení sítě. Nyní je ovšem učení pomalejší a model bude
obsahovat chyby v&nbsp;predikci.</i></p>

<p>Vliv větší úrovně šumu (70%):</p>

*** image ***
<p><i>Obrázek 3: Postupně klesající hodnoty vypočítané účelovou funkcí
naznačují korektní učení sítě.</i></p>



<p><a name="k13"></a></p>
<h2 id="k13">13. Pátý skript: trénink neuronové sítě pro rozpoznávání rastrových obrázků s&nbsp;využitím zašuměných obrázků</h2>

<p>Jen pro úplnost si ukažme celý skript, po jehož spuštění se neuronová síť
natrénuje a následně i otestuje s&nbsp;využitím zašuměných obrázků:</p>

<pre>
import random
from sklearn.model_selection import train_test_split
import torch
from torch import nn
from torch import optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
&nbsp;
class <strong>NeuralNetwork</strong>(nn.Module):
    <i>"""Třída reprezentující neuronovou síť."""</i>
&nbsp;
    def <strong>__init__</strong>(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        <i># vrstvy neuronové sítě</i>
        self.layer_1 = nn.Linear(input_dim, hidden_dim)
        self.layer_2 = nn.Linear(hidden_dim, output_dim)
&nbsp;
    def <strong>forward</strong>(self, x):
        <i># propagace hodnot přes neuronovou síť</i>
        x = torch.nn.functional.relu(self.layer_1(x))
        x = torch.nn.functional.sigmoid(self.layer_2(x))
        return x
&nbsp;
&nbsp;
<i># konfigurace vrstev neuronové sítě</i>
input_dim = 64
hidden_dim = 10
output_dim = 10
&nbsp;
nn_64_10_10 = NeuralNetwork(input_dim, hidden_dim, output_dim)
&nbsp;
<i># výpis základních informací o neuronové síti</i>
print("Neural network:")
print(nn_64_10_10)
&nbsp;
&nbsp;
<i># konverze původních dat z NumPy do tenzorů</i>
class <strong>Data</strong>(Dataset):
    def <strong>__init__</strong>(self, X, y):
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))
        self.len = self.X.shape[0]
&nbsp;
    def <strong>__getitem__</strong>(self, index):
        return self.X[index], self.y[index]
&nbsp;
    def <strong>__len__</strong>(self):
        return self.len
&nbsp;
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>add_noise</strong>(array, level):
    return (1.0 - level) * array + level * np.random.rand(8, 8)
&nbsp;
&nbsp;
def <strong>shift</strong>(arr, x_shift, y_shift):
    <i># horizontální posun</i>
    arr = np.roll(arr, x_shift, axis=1)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if x_shift &lt; 0:
        arr[:, x_shift:] = 0.0
    elif x_shift &gt; 0:
        arr[:, :x_shift] = 0.0
&nbsp;
    <i># vertikální posun</i>
    arr = np.roll(arr, y_shift, axis=0)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if y_shift &lt; 0:
        arr[y_shift:] = 0.0
    elif y_shift &gt; 0:
        arr[:y_shift] = 0.0
    return arr
&nbsp;
&nbsp;
def <strong>prepare_data</strong>(digits, length, noise_level=0.0, x_shift_amount=0, y_shift_amount=0, test_size=1/3):
    <i># příprava dat pro trénink a testování</i>
    X = []
    y = []
&nbsp;
    for i in range(length):
        <i># cislice</i>
        digit = i % 10
        <i># vstupy</i>
        array = digit_to_array(digits, digit)
        <i># zasumeni</i>
        array = add_noise(array, noise_level)
        <i># posuny</i>
        x_shift = random.randint(-x_shift_amount, x_shift_amount)
        y_shift = random.randint(-y_shift_amount, y_shift_amount)
        array = shift(array, x_shift, y_shift)
        <i># prevod na vektor</i>
        x_vector = array.flatten()
        X.append(x_vector)
        <i># očekávané výstupy</i>
        y_vector = [0.0] * 10
        y_vector[digit] = 1.0
        y.append(y_vector)
&nbsp;
    X_train, X_test, y_train, y_test = train_test_split(
        np.array(X), np.array(y),
        test_size=test_size, random_state=26
    )
&nbsp;
    <i># trénovací sada</i>
    train_data = Data(X_train, y_train)
&nbsp;
    <i># testovací sada</i>
    test_data = Data(X_test, y_test)
&nbsp;
    return train_data, test_data
&nbsp;
&nbsp;
train_data, test_data = prepare_data(digits, 1000, noise_level=0.5, x_shift_amount=0, y_shift_amount=0)
print("Train data:")
print(len(train_data))
print("Test data:")
print(len(test_data))
&nbsp;
<i># příprava na trénink neuronové sítě</i>
learning_rate = 0.1
loss_fn = nn.BCELoss()
&nbsp;
optimizer = optim.SGD(nn_64_10_10.parameters(), lr=learning_rate)
&nbsp;
<i># zpracovat trénovací data</i>
batch_size = 64
train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
print("Batches: ", len(train_dataloader))
&nbsp;
<i># vlastní trénink</i>
print("Training started")
num_epochs = 100
loss_values = []
for epoch in range(num_epochs):
    print(f"    Epoch {epoch}: ", end="")
    last_lost_value = None
    for X, y in train_dataloader:
        optimizer.zero_grad()
&nbsp;
        <i># dopředný tok + zpětný tok + optimalizace</i>
        pred = nn_64_10_10(X)
&nbsp;
        <i># výpočet účelové funkce</i>
        loss = loss_fn(pred, y)
&nbsp;
        <i>#loss = loss_fn(pred, y.unsqueeze(-1))</i>
        loss_values.append(loss.item())
        loss.backward()
        optimizer.step()
        last_lost_value = loss.item()
        print(".", end="")
    print(last_lost_value)
&nbsp;
print("Training completed")
&nbsp;
step = range(len(loss_values))
&nbsp;
<i># příprava na vykreslení grafu</i>
fig, ax = plt.subplots(figsize=(6.4, 4.8))
plt.plot(step, np.array(loss_values))
plt.title("Průběh tréninku neuronové sítě")
plt.xlabel("Epocha")
plt.ylabel("Chyba")
&nbsp;
<i># uložení do souboru</i>
plt.savefig("nn_17.png")
&nbsp;
<i># vykreslení grafu</i>
plt.show()
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Posunuté obrázky v&nbsp;trénovacích a testovacích datech</h2>

<p>Ověřme si, jak dobře či špatně se neuronová síť dokáže naučit a predikovat
posunuté obrázky. Úroveň šumu vynulujeme a povolíme posun obrázků v&nbsp;obou
směrech, ovšem maximálně o dva pixely:</p>

<pre>
train_data, test_data = prepare_data(digits, 1000, noise_level=0.0, x_shift_amount=2, y_shift_amount=2)
</pre>

<p>Průběh učení sítě:</p>

<pre>
Training started
    Epoch 0: ...........0.662143349647522
    Epoch 1: ...........0.6225242018699646
    Epoch 2: ...........0.5437997579574585
    Epoch 3: ...........0.47505685687065125
    Epoch 4: ...........0.4151655435562134
    Epoch 5: ...........0.3567219078540802
    Epoch 6: ...........0.35883376002311707
    Epoch 7: ...........0.3546479344367981
    Epoch 8: ...........0.33377087116241455
    Epoch 9: ...........0.33360761404037476
    Epoch 10: ...........0.32562145590782166
    ...
    ...
    ...
    Epoch 70: ...........0.31016451120376587
    Epoch 71: ...........0.32512548565864563
    Epoch 72: ...........0.3208373486995697
    Epoch 73: ...........0.320453405380249
    Epoch 74: ...........0.3224222660064697
    Epoch 75: ...........0.30925461649894714
    Epoch 76: ...........0.3184351325035095
    Epoch 77: ...........0.3149249255657196
    Epoch 78: ...........0.3213757276535034
</pre>

<p>Predikce sítě se pravděpodobně ještě více zhorší:</p>

*** image ***
<p><i>Obrázek 4: Postupně klesající hodnoty vypočítané účelovou funkcí
naznačují korektní učení sítě. Nyní je učení ještě pomalejší a model bude
obsahovat větší chyby v&nbsp;predikci.</i></p>

<p>Výsledky pro náhodný posun o &plusmn; tři pixely:</p>

*** image ***
<p><i>Obrázek 5: Postupně klesající hodnoty vypočítané účelovou funkcí
naznačují korektní učení sítě.</i></p>



<p><a name="k15"></a></p>
<h2 id="k15">15. Šestý skript: trénink neuronové sítě pro rozpoznání posunutých obrázků</h2>

<p>Opět si, podobně jako <a href="#k13">ve třinácté kapitole</a>, pro úplnost
ukažme celý skript, po jehož spuštění se neuronová síť natrénuje a následně i
otestuje s&nbsp;využitím zašuměných obrázků:</p>

<pre>
import random
from sklearn.model_selection import train_test_split
import torch
from torch import nn
from torch import optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
&nbsp;
class <strong>NeuralNetwork</strong>(nn.Module):
    <i>"""Třída reprezentující neuronovou síť."""</i>
&nbsp;
    def <strong>__init__</strong>(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        <i># vrstvy neuronové sítě</i>
        self.layer_1 = nn.Linear(input_dim, hidden_dim)
        self.layer_2 = nn.Linear(hidden_dim, output_dim)
&nbsp;
    def <strong>forward</strong>(self, x):
        <i># propagace hodnot přes neuronovou síť</i>
        x = torch.nn.functional.relu(self.layer_1(x))
        x = torch.nn.functional.sigmoid(self.layer_2(x))
        return x
&nbsp;
&nbsp;
<i># konfigurace vrstev neuronové sítě</i>
input_dim = 64
hidden_dim = 10
output_dim = 10
&nbsp;
nn_64_10_10 = NeuralNetwork(input_dim, hidden_dim, output_dim)
&nbsp;
<i># výpis základních informací o neuronové síti</i>
print("Neural network:")
print(nn_64_10_10)
&nbsp;
&nbsp;
<i># konverze původních dat z NumPy do tenzorů</i>
class <strong>Data</strong>(Dataset):
    def <strong>__init__</strong>(self, X, y):
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))
        self.len = self.X.shape[0]
&nbsp;
    def <strong>__getitem__</strong>(self, index):
        return self.X[index], self.y[index]
&nbsp;
    def <strong>__len__</strong>(self):
        return self.len
&nbsp;
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>add_noise</strong>(array, level):
    return (1.0 - level) * array + level * np.random.rand(8, 8)
&nbsp;
&nbsp;
def <strong>shift</strong>(arr, x_shift, y_shift):
    <i># horizontální posun</i>
    arr = np.roll(arr, x_shift, axis=1)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if x_shift &lt; 0:
        arr[:, x_shift:] = 0.0
    elif x_shift &gt; 0:
        arr[:, :x_shift] = 0.0
&nbsp;
    <i># vertikální posun</i>
    arr = np.roll(arr, y_shift, axis=0)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if y_shift &lt; 0:
        arr[y_shift:] = 0.0
    elif y_shift &gt; 0:
        arr[:y_shift] = 0.0
    return arr
&nbsp;
&nbsp;
def <strong>prepare_data</strong>(digits, length, noise_level=0.0, x_shift_amount=0, y_shift_amount=0, test_size=1/3):
    <i># příprava dat pro trénink a testování</i>
    X = []
    y = []
&nbsp;
    for i in range(length):
        <i># cislice</i>
        digit = i % 10
        <i># vstupy</i>
        array = digit_to_array(digits, digit)
        <i># zasumeni</i>
        array = add_noise(array, noise_level)
        <i># posuny</i>
        x_shift = random.randint(-x_shift_amount, x_shift_amount)
        y_shift = random.randint(-y_shift_amount, y_shift_amount)
        array = shift(array, x_shift, y_shift)
        <i># prevod na vektor</i>
        x_vector = array.flatten()
        X.append(x_vector)
        <i># očekávané výstupy</i>
        y_vector = [0.0] * 10
        y_vector[digit] = 1.0
        y.append(y_vector)
&nbsp;
    X_train, X_test, y_train, y_test = train_test_split(
        np.array(X), np.array(y),
        test_size=test_size, random_state=26
    )
&nbsp;
    <i># trénovací sada</i>
    train_data = Data(X_train, y_train)
&nbsp;
    <i># testovací sada</i>
    test_data = Data(X_test, y_test)
&nbsp;
    return train_data, test_data
&nbsp;
&nbsp;
train_data, test_data = prepare_data(digits, 1000, noise_level=0.0, x_shift_amount=2, y_shift_amount=2)
print("Train data:")
print(len(train_data))
print("Test data:")
print(len(test_data))
&nbsp;
<i># příprava na trénink neuronové sítě</i>
learning_rate = 0.1
loss_fn = nn.BCELoss()
&nbsp;
optimizer = optim.SGD(nn_64_10_10.parameters(), lr=learning_rate)
&nbsp;
<i># zpracovat trénovací data</i>
batch_size = 64
train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
print("Batches: ", len(train_dataloader))
&nbsp;
<i># vlastní trénink</i>
print("Training started")
num_epochs = 100
loss_values = []
for epoch in range(num_epochs):
    print(f"    Epoch {epoch}: ", end="")
    last_lost_value = None
    for X, y in train_dataloader:
        optimizer.zero_grad()
&nbsp;
        <i># dopředný tok + zpětný tok + optimalizace</i>
        pred = nn_64_10_10(X)
&nbsp;
        <i># výpočet účelové funkce</i>
        loss = loss_fn(pred, y)
&nbsp;
        <i>#loss = loss_fn(pred, y.unsqueeze(-1))</i>
        loss_values.append(loss.item())
        loss.backward()
        optimizer.step()
        last_lost_value = loss.item()
        print(".", end="")
    print(last_lost_value)
&nbsp;
print("Training completed")
&nbsp;
step = range(len(loss_values))
&nbsp;
<i># příprava na vykreslení grafu</i>
fig, ax = plt.subplots(figsize=(6.4, 4.8))
plt.plot(step, np.array(loss_values))
plt.title("Průběh tréninku neuronové sítě")
plt.xlabel("Epocha")
plt.ylabel("Chyba")
&nbsp;
<i># uložení do souboru</i>
plt.savefig("nn_18.png")
&nbsp;
<i># vykreslení grafu</i>
plt.show()
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k17"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu PyTorch lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td>  1</td><td>tensor_constructor_scalar_1.py</td><td>konstrukce tenzoru nultého a prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py</a></td></tr>
<tr><td>  2</td><td>tensor_constructor_scalar_2.py</td><td>inicializace tenzoru prvního řádu s&nbsp;jedním prvkem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py</a></td></tr>
<tr><td>  3</td><td>tensor_constructor_vector_1.py</td><td>konstrukce tenzoru prvního řádu (tříprvkový vektor)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py</a></td></tr>
<tr><td>  4</td><td>tensor_constructor_vector_2.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;inicializací prvků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py</a></td></tr>
<tr><td>  5</td><td>tensor_constructor_vector_3.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;využitím generátoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py</a></td></tr>
<tr><td>  6</td><td>tensor_constructor_matrix_1.py</td><td>vytvoření a inicializace tenzoru druhého řádu, který může být reprezentován maticí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py</a></td></tr>
<tr><td>  7</td><td>tensor_constructor_matrix_2.py</td><td>inicializace prvků matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py</a></td></tr>
<tr><td>  8</td><td>tensor_constructor_3D_1.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py</a></td></tr>
<tr><td>  9</td><td>tensor_constructor_3D_2.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo; (jiná forma inicializace)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 10</td><td>tensor_constructor_scalar_zero.py</td><td>vynulování prvků tenzoru nultého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py</a></td></tr>
<tr><td> 11</td><td>tensor_constructor_vector_zero.py</td><td>vynulování prvků tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py</a></td></tr>
<tr><td> 12</td><td>tensor_constructor_matrix_zero.py</td><td>vynulování prvků tenzoru druhého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py</a></td></tr>
<tr><td> 13</td><td>tensor_constructor_3D_zero.py</td><td>vynulování prvků tenzoru třetího řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 14</td><td>tensor_zeros_shape.py</td><td>použití konstruktoru <strong>zeros</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td> 15</td><td>tensor_ones_shape.py</td><td>použití konstruktoru <strong>ones</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td> 16</td><td>tensor_eye.py</td><td>konstrukce jednotkové matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 17</td><td>tensor_range.py</td><td>využití konstruktoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py</a></td></tr>
<tr><td> 18</td><td>tensor_arange.py</td><td>využití konstruktoru <strong>arange</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 19</td><td>tensor_shape.py</td><td>zjištění tvaru tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_shape.py</a></td></tr>
<tr><td> 20</td><td>tensor_zeros_shape.py</td><td>zjištění tvaru tenzoru vytvořeného konstruktorem <strong>zeros</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td> 21</td><td>tensor_ones_shape.py</td><td>zjištění tvaru tenzoru vytvořeného konstruktorem <strong>ones</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td> 22</td><td>tensor_read_dtype.py</td><td>zjištění, jakého typu jsou prvky tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_read_dtype.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_read_dtype.py</a></td></tr>
<tr><td> 23</td><td>tensor_set_dtype.py</td><td>nastavení či změna typu prvků tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_set_dtype.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_set_dtype.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 24</td><td>tensor_storage_1.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_1.py</a></td></tr>
<tr><td> 25</td><td>tensor_storage_2.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_2.py</a></td></tr>
<tr><td> 26</td><td>tensor_storage_3.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_3.py</a></td></tr>
<tr><td> 27</td><td>tensor_storage_casts.py</td><td>přetypování datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_casts.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_casts.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 28</td><td>tensor_slice_operation_1.py</td><td>konstrukce řezu z&nbsp;tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_1.py</a></td></tr>
<tr><td> 29</td><td>tensor_slice_operation_2.py</td><td>konstrukce řezu z&nbsp;tenzoru druhého řádu (přes řádky a sloupce)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_2.py</a></td></tr>
<tr><td> 30</td><td>tensor_slice_operation_3.py</td><td>konstrukce řezu s&nbsp;jeho následnou modifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_3.py</a></td></tr>
<tr><td> 31</td><td>tensor_slice_operation_4.py</td><td>konstrukce řezu s&nbsp;jeho následnou modifikací (odlišné operace od předchozího příkladu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_4.py</a></td></tr>
<tr><td> 32</td><td>tensor_is_slice.py</td><td>test základních vlastností řezů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_is_slice.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_is_slice.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 33</td><td>tensor_stride_1.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_1.py</a></td></tr>
<tr><td> 34</td><td>tensor_stride_2.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_2.py</a></td></tr>
<tr><td> 35</td><td>tensor_stride_3.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 36</td><td>tensor_reshape.py</td><td>změna tvaru tenzoru operací <strong>reshape</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape.py</a></td></tr>
<tr><td> 37</td><td>tensor_reshape_2.py</td><td>změna tvaru tenzoru operací <strong>reshape</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 38</td><td>tensor_narrow_operation_1.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, první ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1.py</a></td></tr>
<tr><td> 39</td><td>tensor_narrow_operation_1_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, první ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1_B.py</a></td></tr>
<tr><td> 40</td><td>tensor_narrow_operation_2.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, druhá ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2.py</a></td></tr>
<tr><td> 41</td><td>tensor_narrow_operation_2_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, druhá ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2_B.py</a></td></tr>
<tr><td> 42</td><td>tensor_narrow_operation_3.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, třetí ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3.py</a></td></tr>
<tr><td> 43</td><td>tensor_narrow_operation_3_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, třetí ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3_B.py</a></td></tr>
<tr><td> 44</td><td>tensor_narrow_operation_4.py</td><td>přepis původní matice přes pohled na ni (<i>view</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_4.py</a></td></tr>
<tr><td> 45</td><td>tensor_narrow_operation_5.py</td><td>přepis původní matice přes pohled na ni (<i>view</i>)<i>narrow</i>, třetí ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_5.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 46</td><td>tensor_operator_add.py</td><td>součet dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_add.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_add.py</a></td></tr>
<tr><td> 47</td><td>tensor_operator_sub.py</td><td>rozdíl dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_sub.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_sub.py</a></td></tr>
<tr><td> 48</td><td>tensor_operator_mul.py</td><td>součin dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_mul.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_mul.py</a></td></tr>
<tr><td> 49</td><td>tensor_operator_div.py</td><td>podíl dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_div.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_div.py</a></td></tr>
<tr><td> 50</td><td>tensor_dot_product.py</td><td>skalární součin dvou tenzorů prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_dot_product.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_dot_product.py</a></td></tr>
<tr><td> 50</td><td>tensor_operator_matmul.py</td><td>maticové násobení (dvou tenzorů druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul.py</a></td></tr>
<tr><td> 51</td><td>tensor_operator_matmul_2.py</td><td>maticové násobení (dvou tenzorů druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_2.py</a></td></tr>
<tr><td> 52</td><td>tensor_operator_matmul_3.py</td><td>maticové násobení v&nbsp;případě nekompatibilních tvarů matic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_3.py</a></td></tr>
<tr><td> 53</td><td>tensor_operator_matmul_4.py</td><td>maticové násobení s&nbsp;broadcastingem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_4.py</a></td></tr>
<tr><td> 54</td><td>tensor_operator_matmul_5.py</td><td>násobení vektoru a matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_5.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 55</td><td>tensor_broadcast_1.py</td><td>operace <i>broadcast</i> (součin každého prvku tenzoru se skalárem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_1.py</a></td></tr>
<tr><td> 56</td><td>tensor_broadcast_2.py</td><td>operace <i>broadcast</i> (součin tenzoru druhého řádu s vektorem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_2.py</a></td></tr>
<tr><td> 57</td><td>tensor_broadcast_3.py</td><td>operace <i>broadcast</i> (součin vektoru s&nbsp;tenzorem druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_3.py</a></td></tr>
<tr><td> 58</td><td>tensor_broadcast_4.py</td><td>operace <i>broadcast</i> (součet tenzorů druhého a třetího řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_4.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 59</td><td>tensor_sparse.py</td><td>konstrukce řídkého tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_sparse.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_sparse.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 60</td><td>activation_function_relu_.py</td><td>aktivační funkce ReLU vypočtená knihovnou NumPy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_numpy.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_numpy.py</a></td></tr>
<tr><td> 61</td><td>activation_function_relu_pytorch.py</td><td>aktivační funkce ReLU vypočtená knihovnou PyTorch</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_pytorch.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_pytorch.py</a></td></tr>
<tr><td> 62</td><td>activation_function_sigmoid_.py</td><td>aktivační funkce sigmoid vypočtená knihovnou NumPy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_numpy.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_numpy.py</a></td></tr>
<tr><td> 63</td><td>activation_function_sigmoid_pytorch.py</td><td>aktivační funkce sigmoid vypočtená knihovnou PyTorch</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_pytorch.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_pytorch.py</a></td></tr>
<tr><td> 64</td><td>activation_function_tanh_.py</td><td>aktivační funkce tanh vypočtená knihovnou NumPy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_numpy.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_numpy.py</a></td></tr>
<tr><td> 65</td><td>activation_function_tanh_pytorch.py</td><td>aktivační funkce tanh vypočtená knihovnou PyTorch</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_pytorch.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_pytorch.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 66</td><td>make_circles.py</td><td>vygenerování dat pro neuronovou síť funkcí <strong>make_circles</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_circles.py</a></td></tr>
<tr><td> 67</td><td>make_circles_labels.py</td><td>vizualizace dat společně s&nbsp;jejich skupinou (ohodnocením)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_circles_labels.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_circles_labels.py</a></td></tr>
<tr><td> 68</td><td>make_more_noise_circles.py</td><td>získání náhodnějších dat funkcí <strong>make_circles</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_more_noise_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_more_noise_circles.py</a></td></tr>
<tr><td> 69</td><td>make_data_set.py</td><td>náhodné rozdělení datové sady funkcí <strong>train_test_split</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_data_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_data_set.py</a></td></tr>
<tr><td> 70</td><td>prepare_for_training.py</td><td>konverze původních dat z&nbsp;n-dimenzionálních polí do tenzorů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/prepare_for_training.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/prepare_for_training.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 71</td><td>compute_train_and_test_data.py</td><td>výpočet trénovacích a testovacích dat pro neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/compute_train_and_test_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/compute_train_and_test_data.py</a></td></tr>
<tr><td> 72</td><td>print_train_and_test_data.py</td><td>tisk dat získaných předchozím skriptem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/print_train_and_test_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/print_train_and_test_data.py</a></td></tr>
<tr><td> 73</td><td>nn_01.py</td><td>deklarace třídy představující neuronovou síť</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_01.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_01.py</a></td></tr>
<tr><td> 74</td><td>nn_02.py</td><td>definice vrstev neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_02.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_02.py</a></td></tr>
<tr><td> 75</td><td>nn_03.py</td><td>trénink neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_03.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_03.py</a></td></tr>
<tr><td> 76</td><td>nn_04.py</td><td>trénink neuronové sítě se zobrazením kvality tréninku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_04.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_04.py</a></td></tr>
<tr><td> 77</td><td>nn_05.py</td><td>neuronová síť s&nbsp;jednou skrytou vrstvou</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_05.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_05.py</a></td></tr>
<tr><td> 78</td><td>nn_06.py</td><td>neuronová síť s&nbsp;více skrytými vrstvami, která nebude dotrénována</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_06.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_06.py</a></td></tr>
<tr><td> 79</td><td>nn_07.py</td><td>vliv parametru <strong>learning_rate</strong> na rychlosti naučení sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_07.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_07.py</a></td></tr>
<tr><td> 80</td><td>nn_08.py</td><td>výpočet kvality neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_08.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_08.py</a></td></tr>
<tr><td> 81</td><td>nn_09.py</td><td>vizualizace predikce neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_09.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_09.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 82</td><td>nn_linear_help.py</td><td>zobrazení nápovědy ke třídě <strong>torch.nn.Linear</strong> i k&nbsp;parametrům konstruktorů této třídy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_help.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_help.py</a></td></tr>
<tr><td> 83</td><td>nn_linear_1.py</td><td>konstrukce objektu typu <strong>torch.nn.Linear</strong> s&nbsp;biasem (transformace s&nbsp;jedním vstupem a jedním výstupem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_1.py</a></td></tr>
<tr><td> 84</td><td>nn_linear_2.py</td><td>konstrukce objektu typu <strong>torch.nn.Linear</strong> bez biasu (transformace s&nbsp;jedním vstupem a jedním výstupem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_2.py</a></td></tr>
<tr><td> 85</td><td>nn_linear_3.py</td><td>specifikace vah a biasu po konstrukci objektu typu <strong>torch.nn.Linear</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_3.py</a></td></tr>
<tr><td> 86</td><td>nn_linear_4.py</td><td>aplikace lineární transformace reprezentované objektem typu <strong>torch.nn.Linear</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_4.py</a></td></tr>
<tr><td> 87</td><td>nn_linear_5.py</td><td>aplikace lineární transformace na větší soubor vstupních tenzorů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_5.py</a></td></tr>
<tr><td> 88</td><td>nn_linear_6.py</td><td>2D transformace prováděná objektem typu <strong>torch.nn.Linear</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_6.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_6.py</a></td></tr>
<tr><td> 89</td><td>nn_linear_7.py</td><td>2D transformace &ndash; otočení bodů v&nbsp;rovině</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_7.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_7.py</a></td></tr>
<tr><td> 90</td><td>nn_linear_zeros.py</td><td>konstrukce objektu typu <strong>torch.nn.Linear</strong> pro nulový počet vstupů a/nebo výstupů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_zeros.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_zeros.py</a></td></tr>
<tr><td> 91</td><td>nn_forward_1.py</td><td>neuronová síť s&nbsp;jedním vstupem a jedním výstupem, bez aktivační funkce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_1.py</a></td></tr>
<tr><td> 92</td><td>nn_forward_2.py</td><td>neuronová síť s&nbsp;jedním vstupem a dvěma výstupy, bez aktivační funkce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_2.py</a></td></tr>
<tr><td> 93</td><td>nn_forward_3.py</td><td>neuronová síť se dvěma vstupy a jedním výstupem, bez aktivační funkce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_3.py</a></td></tr>
<tr><td> 94</td><td>nn_forward_4.py</td><td>přidání aktivační funkce do neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_4.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 95</td><td>conv_nn_01_digits.py</td><td>první verze generátoru trénovacích obrázků číslic od 0 do 9</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_01_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_01_digits.py</a></td></tr>
<tr><td> 96</td><td>conv_nn_02_digits_as_bitmaps.py</td><td>konstrukce dvourozměrné matice 8&times;8 bodů pro vybranou číslici</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_02_digits_as_bitmaps.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_02_digits_as_bitmaps.py</a></td></tr>
<tr><td> 97</td><td>conv_nn_03_show_digits.py</td><td>vizualizace matic s&nbsp;obrazy číslic v&nbsp;rastru 8&times;8 v&nbsp;nepravých barvách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_03_show_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_03_show_digits.py</a></td></tr>
<tr><td> 98</td><td>conv_nn_04_show_digits.py</td><td>vizualizace matic s&nbsp;obrazy číslic v&nbsp;rastru 8&times;8 ve stupních šedi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_04_show_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_04_show_digits.py</a></td></tr>
<tr><td> 99</td><td>conv_nn_05_show_all_digits.py</td><td>vizualizace všech deseti matic s&nbsp;číslicemi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_05_show_all_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_05_show_all_digits.py</a></td></tr>
<tr><td>100</td><td>conv_nn_06_noise.py</td><td>přidání šumu do obrázků s&nbsp;číslicemi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_06_noise.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_06_noise.py</a></td></tr>
<tr><td>101</td><td>conv_nn_07_noise_levels.py</td><td>šum se sílou od 0% do 100%</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_07_noise_levels.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_07_noise_levels.py</a></td></tr>
<tr><td>102</td><td>conv_nn_08_5_6_or_8.py</td><td>rozdíl mezi číslicemi 5, 6 a 8</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_08_5_6_or_8.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_08_5_6_or_8.py</a></td></tr>
<tr><td>103</td><td>conv_nn_09_shift.py</td><td>posun obrazu číslice v&nbsp;rámci matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_09_shift.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_09_shift.py</a></td></tr>
<tr><td>104</td><td>conv_nn_10_shifts.py</td><td>různé posuny obrazu číslice v&nbsp;rámci matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_10_shifts.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_10_shifts.py</a></td></tr>
<tr><td>105</td><td>conv_nn_11_classification_report.py</td><td>numerická podoba ověření sítě provádějící klasifikaci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_11_classification_report.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_11_classification_report.py</a></td></tr>
<tr><td>106</td><td>conv_nn_12_confusion_matrix.py</td><td>výpočet a vizualizace matice záměn (<i>confusion matrix</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_12_confusion_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_12_confusion_matrix.py</a></td></tr>
<tr><td>107</td><td>nn_10.py</td><td>jednoduchá neuronová síť provádějící klasifikaci (nikoli regresi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_10.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_10.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>108</td><td>conv_nn_13_input_data.py</td><td>příprava datové sady pro trénink neuronové sítě s&nbsp;vektorovým vstupem a výstupem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_13_input_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_13_input_data.py</a></td></tr>
<tr><td>109</td><td>conv_nn_14_real_input_data.py</td><td>příprava zašuměných a posunutých vstupních dat pro neuronovou síť</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_14_real_input_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_14_real_input_data.py</a></td></tr>
<tr><td>110</td><td>conv_nn_15_train_test_data.py</td><td>rozdělení datové sady na trénovací a testovací data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_15_train_test_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_15_train_test_data.py</a></td></tr>
<tr><td>111</td><td>conv_nn_16_simple_nn.py</td><td>trénink neuronové sítě pro rozpoznávání rastrových obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_16_simple_nn.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_16_simple_nn.py</a></td></tr>
<tr><td>112</td><td>conv_nn_17_noise_nn.py</td><td>trénink neuronové sítě pro rozpoznávání rastrových obrázků s&nbsp;využitím zašuměných obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_17_noise_nn.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_17_noise_nn.py</a></td></tr>
<tr><td>113</td><td>conv_nn_18_shift_nn.py</td><td>trénink neuronové sítě pro rozpoznání posunutých obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_18_shift_nn.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_18_shift_nn.py</a></td></tr>
<tr><td>114</td><td>conv_nn_19_noise_and_shift_nn.py</td><td>trénink neuronové sítě pro rozpoznání posunutých obrázků a současně i zašuměných obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_19_noise_and_shift_nn.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_19_noise_and_shift_nn.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Seriál Programovací jazyk Lua na Rootu:<br />
<a href="https://www.root.cz/serialy/programovaci-jazyk-lua/">https://www.root.cz/serialy/programovaci-jazyk-lua/</a>
</li>

<li>PDM: moderní správce balíčků a virtuálních prostředí Pythonu:<br />
<a href="https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/">https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/</a>
</li>

<li>PyTorch Tutorial: Building a Simple Neural Network From Scratch<br />
<a href="https://www.datacamp.com/tutorial/pytorch-tutorial-building-a-simple-neural-network-from-scratch">https://www.datacamp.com/tutorial/pytorch-tutorial-building-a-simple-neural-network-from-scratch</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008:<br />
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008 (dokončení):<br />
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/</a>
</li>

<li>Brain Floating Point &ndash; nový formát uložení čísel pro strojové učení a chytrá čidla:<br />
<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>
</li>

<li>Stránky projektu PyTorch:<br />
<a href="https://pytorch.org/">https://pytorch.org/</a>
</li>

<li>Informace o instalaci PyTorche:<br />
<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>
</li>

<li>Tenzor (Wikipedia):<br />
<a href="https://cs.wikipedia.org/wiki/Tenzor">https://cs.wikipedia.org/wiki/Tenzor</a>
</li>

<li>Introduction to Tensors:<br />
<a href="https://www.youtube.com/watch?v=uaQeXi4E7gA">https://www.youtube.com/watch?v=uaQeXi4E7gA</a>
</li>

<li>Introduction to Tensors: Transformation Rules:<br />
<a href="https://www.youtube.com/watch?v=j6DazQDbEhQ">https://www.youtube.com/watch?v=j6DazQDbEhQ</a>
</li>

<li>Tensor Attributes:<br />
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Tensors Explained Intuitively: Covariant, Contravariant, Rank :<br />
<a href="https://www.youtube.com/watch?v=CliW7kSxxWU">https://www.youtube.com/watch?v=CliW7kSxxWU</a>
</li>

<li>What is the relationship between PyTorch and Torch?:<br />
<a href="https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch">https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch</a>
</li>

<li>What is a tensor anyway?? (from a mathematician):<br />
<a href="https://www.youtube.com/watch?v=K7f2pCQ3p3U">https://www.youtube.com/watch?v=K7f2pCQ3p3U</a>
</li>

<li>Visualization of tensors - part 1 :<br />
<a href="https://www.youtube.com/watch?v=YxXyN2ifK8A">https://www.youtube.com/watch?v=YxXyN2ifK8A</a>
</li>

<li>Visualization of tensors - part 2A:<br />
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>Visualization of tensors - part 2B:<br />
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>What the HECK is a Tensor?!?:<br />
<a href="https://www.youtube.com/watch?v=bpG3gqDM80w">https://www.youtube.com/watch?v=bpG3gqDM80w</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>An Introduction to Tensors<br />
<a href="https://math.stackexchange.com/questions/10282/an-introduction-to-tensors">https://math.stackexchange.com/questions/10282/an-introduction-to-tensors</a>
</li>

<li>Differences between a matrix and a tensor<br />
<a href="https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor">https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor</a>
</li>

<li>Qualitatively, what is the difference between a matrix and a tensor?<br />
<a href="https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?">https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?</a>
</li>

<li>Tensors for Neural Networks, Clearly Explained!!!:<br />
<a href="https://www.youtube.com/watch?v=L35fFDpwIM4">https://www.youtube.com/watch?v=L35fFDpwIM4</a>
</li>

<li>Tensor Processing Unit:<br />
<a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit">https://en.wikipedia.org/wiki/Tensor_Processing_Unit</a>
</li>

<li>Třída Storage:<br />
<a href="http://docs.pytorch.wiki/en/storage.html">http://docs.pytorch.wiki/en/storage.html</a>
</li>

<li>Funkce torch.dot<br />
<a href="https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot">https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot</a>
</li>

<li>Funkce torch.narrow<br />
<a href="https://pytorch.org/docs/stable/generated/torch.narrow.html">https://pytorch.org/docs/stable/generated/torch.narrow.html</a>
</li>

<li>Funkce torch.matmul<br />
<a href="https://pytorch.org/docs/stable/generated/torch.matmul.html">https://pytorch.org/docs/stable/generated/torch.matmul.html</a>
</li>

<li>Funkce torch.reshape<br />
<a href="https://pytorch.org/docs/stable/generated/torch.reshape.html">https://pytorch.org/docs/stable/generated/torch.reshape.html</a>
</li>

<li>Funkce torch.arange<br />
<a href="https://pytorch.org/docs/stable/generated/torch.arange.html">https://pytorch.org/docs/stable/generated/torch.arange.html</a>
</li>

<li>Funkce torch.range<br />
<a href="https://pytorch.org/docs/stable/generated/torch.range.html">https://pytorch.org/docs/stable/generated/torch.range.html</a>
</li>

<li>Třída torch.Tensor<br />
<a href="https://pytorch.org/docs/stable/tensors.html">https://pytorch.org/docs/stable/tensors.html</a>
</li>

<li>Atributy tenzorů<br />
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Pohledy vytvořené nad tenzory<br />
<a href="https://pytorch.org/docs/stable/tensor_view.html">https://pytorch.org/docs/stable/tensor_view.html</a>
</li>

<li>Broadcasting v&nbsp;knihovně <br />
<a href="https://.org/doc/stable/user/basics.broadcasting.html">https://numpy.org/doc/stable/user/basics.broadcasting.html</a>
</li>

<li>Broadcasting semantics (v&nbsp;knihovně PyTorch)<br />
<a href="https://pytorch.org/docs/stable/notes/broadcasting.html">https://pytorch.org/docs/stable/notes/broadcasting.html</a>
</li>

<li>Dot Product In Physics: What Is The Physical Meaning of It?<br />
<a href="https://profoundphysics.com/dot-product-in-physics-what-is-the-physical-meaning-of-it/">https://profoundphysics.com/dot-product-in-physics-what-is-the-physical-meaning-of-it/</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

<li>Třída torch.nn.Linear<br />
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">https://pytorch.org/docs/stable/generated/torch.nn.Linear.html</a>
</li>

<li>Třída torch.nn.Parameter<br />
<a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html">https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html</a>
</li>

<li>Třída torch.nn.Sigmoid<br />
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html">https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

