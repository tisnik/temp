<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>PyTorch: problematika rozpoznávání a klasifikace obrázků</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>PyTorch: problematika rozpoznávání a klasifikace obrázků</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>Dnešním článkem se začneme zabývat dalším problémem, který je poměrně dobře řešitelný s využitím knihovny PyTorch. Jedná se o rozpoznávání a klasifikaci rastrových obrázků. Řešení (většinou) spočívá ve využití konvolučních neuronových sítí.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. PyTorch: problematika rozpoznávání a klasifikace obrázků</a></p>
<p><a href="#k02">2. První verze generátoru trénovacích obrázků číslic od 0 do 9</a></p>
<p><a href="#k03">3. Konstrukce dvourozměrné matice 8&times;8 bodů pro vybranou číslici</a></p>
<p><a href="#k04">4. Kooperace mezi knihovnami Matplotlib a NumPy: vizualizace obsahu 2D matice</a></p>
<p><a href="#k05">5. Vizualizace matic s&nbsp;obrazy číslic v&nbsp;rastru 8&times;8</a></p>
<p><a href="#k06">6. Vizualizace všech deseti matic s&nbsp;číslicemi</a></p>
<p><a href="#k07">7. Problém rozpoznávání číslic na reálných obrázcích</a></p>
<p><a href="#k08">8. Vliv šumu na kvalitu predikcí neuronové sítě</a></p>
<p><a href="#k09">9. Vizualizace matice reprezentující zašuměnou číslici</a></p>
<p><a href="#k10">10. Vizualizace vlivu parametru <strong>level</strong> na způsob zašumění matice s&nbsp;číslicí</a></p>
<p><a href="#k11">11. Rozeznání číslic 5, 6 a 8</a></p>
<p><a href="#k12">12. Posun číslic v&nbsp;matici pro přípravu trénovacích dat</a></p>
<p><a href="#k13">13. Zobrazení všech variant posunů matice s&nbsp;číslicí 2 o &plusm; jeden nebo dva pixely</a></p>
<p><a href="#k14">14. Numerické ohodnocení klasifikační neuronové sítě pro rozpoznávání obrázků</a></p>
<p><a href="#k15">15. Matice záměn</a></p>
<p><a href="#k16">16. Příklad klasifikační neuronové sítě se dvěma výstupy</a></p>
<p><a href="#k17">17. Konvoluční neuronové sítě</a></p>
<p><a href="#k18">18. Vrstvy v&nbsp;konvolučních neuronových sítích</a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. PyTorch: problematika rozpoznávání a klasifikace obrázků</h2>

<p>Na předchozí tři části [<a
href="https://www.root.cz/clanky/realizace-neuronovych-siti-s-vyuzitim-knihovny-pytorch/">1</a>]
[<a
href="https://www.root.cz/clanky/realizace-neuronovych-siti-s-vyuzitim-knihovny-pytorch-2-cast/">2</a>]
[<a
href="https://www.root.cz/clanky/realizace-neuronovych-siti-s-vyuzitim-knihovny-pytorch-3-cast/">3</a>]
<a
href="https://www.root.cz/serialy/datova-analyza-s-vyuzitim-jazyka-python/">seriálu
o knihovně PyTorch</a>, v&nbsp;nichž jsme se seznámili se základními postupy,
které se používají při tvorbě umělých neuronových sítí s&nbsp;pravidelnou
strukturou tvořenou jednotlivými vrstvami, u nichž učení probíhá
s&nbsp;využitím takzvaného <i>backpropagation</i> algoritmu (algoritmu zpětného
šíření), dnes navážeme. Začneme se totiž zabývat problematikou rozpoznávání a
klasifikace rastrových obrázků. Ty sice budou zpočátku velmi malé a budou
obsahovat poměrně dobře predikovatelná data, ovšem i takto malé obrázky nám
umožní ukázat některé nevýhody klasických obecných neuronových sítí při jejich
aplikaci na rastrová data.</p>

<p>Ve druhé části dnešního článku se ve stručnosti seznámíme s&nbsp;neuronovými
sítěmi provádějícími <i>klasifikaci</i> (a nikoli <i>regresi</i>). Právě tento
typ neuronových sítí nám umožní realizovat rozpoznávání obrázků stylem
&bdquo;zde je pes&ldquo; nebo &bdquo;tady jsou tři stromy&ldquo;. S&nbsp;tímto
tématem souvisí i problematika vyjádření kvality sítě s&nbsp;využitím matice
záměn (<i>confusion matrix</i>).</p>

<p>V&nbsp;závěru článku se navíc seznámíme s&nbsp;principy, na nichž jsou
postaveny takzvané <i>konvoluční neuronové sítě</i>. Ty jsou v&nbsp;současnosti
velmi populární, a to hned z&nbsp;několika důvodů &ndash; po jejich natrénování
sítě (to je sice časově náročné, ovšem s&nbsp;moderními GPU již většinou
uspokojivě řešitelné) jsou již konvoluční sítě poměrně rychlé a především se
rozšiřují možnosti, kde je možné tyto sítě prakticky použít (doprava, tedy
například automatické řízení vozidel, průmysl atd.).</p>

<p>Tím získáme všechny dílky potřebné k&nbsp;tomu, abychom příště vytvořili
skutečnou konvoluční síť, natrénovali ji a nakonec ověřili její kvalitu
s&nbsp;využitím matice záměn.</p>



<p><a name="k02"></a></p>
<h2 id="k02">2. První verze generátoru trénovacích obrázků číslic od 0 do 9</h2>

<p>Jak jsme si již řekli <a href="#k01">v&nbsp;úvodní kapitole</a>, budeme se
snažit s&nbsp;využitím jednoduchých neuronových sítí rozpoznávat objekty na
velmi malých obrázcích. Konkrétně se bude zpočátku jednat o vstupní obrázky
s&nbsp;pevným rozlišením pouhých 8&times;8 pixelů, což nám mj.&nbsp;umožní
velmi rychlý tréning sítě a samozřejmě i její následnou validaci (a to bez
nutnosti zdlouhavého tréninku s&nbsp;využitím GPU; prozatím si vystačíme
s&nbsp;výpočty na CPU).</p>

<p>Rastrové obrázky budou reprezentovány ve stupních šedi a úkolem postupně
vytvářené neuronové sítě bude na těchto obrázcích rozpoznat číslice 0 až 9
zapsané pro jednoduchost předem známým fontem (příště už budeme mít horší úkol,
protože číslice budou napsány rukou, navíc mnoha autory). Abychom získali
představu, jak tyto číslice vypadají, necháme si vygenerovat testovací obrázky,
a to z&nbsp;následujících vstupních dat:</p>

<pre>
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
<i># triviální výpis</i>
print(digits)
</pre>

<p>Každá číslice, jejíž tvar je zakódován v&nbsp;n-tici
<strong>digits</strong>, je reprezentována osmicí bajtů, protože každý bajt
reprezentuje osm sousedních pixelů. Celkem tedy vstupní data obsahují osmdesát
bajtů, protože máme deset číslic, každou uloženou v&nbsp;osmi bajtech:</p>

<pre>
((0, 60, 102, 118, 110, 102, 60, 0), (0, 24, 28, 24, 24, 24, 126, 0), (0, 60, 102, 48, 24, 12, 126, 0),
(0, 126, 48, 24, 48, 102, 60, 0), (0, 48, 56, 60, 54, 126, 48, 0), (0, 126, 6, 62, 96, 102, 60, 0),
(0, 60, 6, 62, 102, 102, 60, 0), (0, 126, 96, 48, 24, 12, 12, 0), (0, 60, 102, 60, 102, 102, 60, 0),
(0, 60, 102, 124, 96, 48, 28, 0))
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. Konstrukce dvourozměrné matice 8&times;8 bodů pro vybranou číslici</h2>

<p>Výše uvedený způsob uložení bitových map s&nbsp;číslicemi je sice velmi
úsporný, ovšem příliš se nehodí pro trénink neuronových sítí (minimálně ne
v&nbsp;takové formě, jakou nám nabízí knihovna <i>PyTorch</i>). Proto musíme
mít k&nbsp;dispozici pomocnou funkci, která pro zadanou číslici 0-9 vrátí
matici o rozměrech 8&times;8 prvků obsahující hodnoty 0,0 nebo 1,0,
v&nbsp;závislosti na tom, zda příslušný prvek odpovídá černému pixelu nebo
naopak pixelu bílému. Povšimněte si, že i když by bylo možné vytvořit matici
s&nbsp;pravdivostními hodnotami True/False nebo celočíselnými hodnotami 0/1,
použijeme hodnoty s&nbsp;plovoucí řádovou čárkou. To nám později umožní nejenom
simulovat šum, ale i přímo takové matice použít pro vstup do neuronových
sítí.</p>

<p>Převodní funkce může vypadat následovně:</p>

<pre>
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
</pre>

<p><div class="rs-tip-major">Poznámka: tuto funkci lze zapsat i úspornějším a
idiomatičtějším způsobem, který ovšem není příliš čitelný.</div></p>

<p>Ověřme si, jak například bude vypadat výsledná dvourozměrná matice
s&nbsp;reprezentací číslice 2 (ta je nesymetrická, takže si ověříme korektnost
převodu):</p>

<pre>
import numpy as np
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
<i># vytvoření matice, kterou budeme vizualizovat</i>
array = digit_to_array(digits, 2)
&nbsp;
<i># výpis pole s reprezentací číslice 2</i>
print(array)
</pre>

<p>Výsledná matice by měla vypadat následovně:</p>

<pre>
[[0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 1. 1. 1. 1. 0. 0.]
 [0. 1. 1. 0. 0. 1. 1. 0.]
 [0. 0. 0. 0. 1. 1. 0. 0.]
 [0. 0. 0. 1. 1. 0. 0. 0.]
 [0. 0. 1. 1. 0. 0. 0. 0.]
 [0. 1. 1. 1. 1. 1. 1. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0.]]
</pre>

<p>Pro zajímavost si můžeme doplnit krátký kód, který matici převede do
tisknutelné podoby a navíc výslednou &bdquo;bitmapu&ldquo; orámuje:</p>

<pre>
<i># převod na tisknutelnou podobu</i>
print("+--------+")
for row in array:
    print("|", end="")
    for item in row:
        print(" "  if item==0.0 else "*", end="")
    print("|")
print("+--------+")
</pre>

<p>Nyní bude výsledek vypadat následovně:</p>

<pre>
+--------+
|        |
|  ****  |
| **  ** |
|    **  |
|   **   |
|  **    |
| ****** |
|        |
+--------+
</pre>

<p><div class="rs-tip-major">Poznámka: většina fontů není určena pro tento typ
výstupu, protože obdélníky okolo znaků nejsou čtvercové, ale mají typicky poměr
1:2. To znamená, že výsledná podoba číslice 2 je mnohem vyšší, než by tomu mělo
být ve skutečném rastrovém obrázku se čtvercovými pixely.</div></p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Kooperace mezi knihovnami Matplotlib a NumPy: vizualizace obsahu 2D matice</h2>

<p>V&nbsp;praxi, když začneme pracovat s&nbsp;obrázky ve stupních šedi, se
zašuměnými obrázky atd., již není zobrazení obrázku na konzoli ideální. Pokusme
se tedy využitím kooperace mezi knihovnami Matplotlib a NumPy. Konkrétně si
ukážeme vizualizaci obsahu dvourozměrné matice (NumPy podporuje obecná
n-rozměrná pole a matice jsou tedy pouze podtypem). Vytvoříme si matici o
rozměrech 10&times;10 prvků a naplníme ji náhodnými hodnotami. Výsledek si
necháme zobrazit na grafu a tento graf taktéž uložíme do souboru (formát
PNG):</p>

<pre>
<i>#!/usr/bin/env python</i>
&nbsp;
<i># budeme provádět vykreslování de facto standardní knihovnou Matplotlib</i>
import matplotlib.pyplot as plt
&nbsp;
import numpy as np
&nbsp;
<i># vytvoření matice, kterou budeme vizualizovat</i>
array = np.random.rand(10, 10)
&nbsp;
<i># vykreslení</i>
plt.matshow(array)
&nbsp;
<i># uložení vizualizované matice</i>
plt.savefig("random.png")
&nbsp;
<i># vizualizace na obrazovku</i>
plt.show()
&nbsp;
<i># finito</i>
</pre>

<p>Výsledek bude vypadat následovně:</p>

<img src="https://i.iinfo.cz/images/542/scikit-learn-1-6.webp" class="image-1110848" width="480" height="480" alt="&#160;" title="Autor: Tisnik+MNiST authors, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 1: Vizualizace pole s&nbsp;náhodným obsahem.</i></p>

<p>Povšimněte si, že se při vizualizaci použily nepravé barvy. Těch se později
zbavíme, protože nás budou spíše mást. Prozatím jsou však užitečné.</p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Vizualizace matic s&nbsp;obrazy číslic v&nbsp;rastru 8&times;8</h2>

<p>Podívejme se nyní na způsob vizualizace matic s&nbsp;rozměry 8&times;8,
jejichž prvky mají hodnoty 0,0 nebo 1,0. Tyto matice mohou obsahovat bitmapy
číslic v&nbsp;rastru 8&times;8 pixelů. Nejdříve při vizualizaci použijeme
nepravé barvy, přesněji řečeno barvovou paletu, která provádí mapování mezi
hodnotami uloženými v&nbsp;matici na barvovou škálu. Algoritmus nejdříve zjistí
minimální a maximální hodnoty prvků (což jsou v&nbsp;našem případě hodnoty 0,0
a 1,0) a následně určí měřítko použité při hledání barev:</p>

<pre>
import matplotlib.pyplot as plt
import numpy as np
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
<i># vytvoření matice, kterou budeme vizualizovat</i>
array = digit_to_array(digits, 2)
&nbsp;
<i># vykreslení matice</i>
plt.matshow(array)
&nbsp;
<i># uložení vizualizované matice</i>
plt.savefig("conv_nn_03.png")
&nbsp;
<i># vizualizace matice na obrazovce</i>
plt.show()
</pre>

<p>Opět jsme si nechali zobrazit matici odpovídající číslici 2:</p>

*** image ***
<p><i>Obrázek 2: Matice číslice 2 zobrazená v&nbsp;nepravých barvách.</i></p>

<p>Alternativně je možné zavoláním <strong>plt.gray()</strong> dosáhnout
převodu na stupně šedi, což může být v&nbsp;tomto případě výhodnější způsob
vizualizace matice s&nbsp;de facto černobílým obrázkem. Opět si to ukažme:</p>

<pre>
import matplotlib.pyplot as plt
import numpy as np
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
<i># vytvoření matice, kterou budeme vizualizovat</i>
array = digit_to_array(digits, 2)
&nbsp;
<i># vykreslení matice</i>
plt.matshow(array)
&nbsp;
<i># převod na stupně šedi</i>
plt.gray()
&nbsp;
<i># uložení vizualizované matice</i>
plt.savefig("conv_nn_04.png")
&nbsp;
<i># vizualizace matice na obrazovce</i>
plt.show()
</pre>

<p>Výsledek:</p>

*** image ***
<p><i>Obrázek 3: Matice číslice 2 zobrazená ve stupních šedi.</i></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Vizualizace všech deseti matic s&nbsp;číslicemi</h2>

<p>V&nbsp;navazujícím článku budeme zobrazovat velké množství číslic,
resp.&nbsp;přesněji řečeno vizualizaci jejich matic. Pravděpodobně by nebylo
praktické každou číslici vykreslit do samostatného grafu. Můžeme však využít
další vlastností Matplotlibu &ndash; jeho schopnosti do jediné plochy grafu
přidat více menších grafů. Plocha je rozdělena na pomyslnou mřížku, jejíž
rozměry zadáváme při přidávání menšího grafu do jednotlivých políček:</p>

<pre>
ax = plt.subplot(počet řádků, počet sloupců, pozice/index v rámci mřížky)
</pre>

<p>Snadno tak můžeme zobrazit všech deset číslic do mřížky se třemi sloupci a
čtyřmi řádky. Dvě políčka nebudou obsazena, což nám umožňuje simulovat
rozložení numerických kláves na číselníku telefonu:</p>

<pre>
import matplotlib.pyplot as plt
import numpy as np
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
<i># velikost obrázku s grafem</i>
plt.subplots(figsize=(6.4, 6.4))
plt.axis("off")
&nbsp;
<i># vykreslení číslic 1-9</i>
for digit in range(1, 10):
    array = digit_to_array(digits, digit)
    ax = plt.subplot(4, 3, digit)
    plt.gray()
    ax.matshow(array)
&nbsp;
<i># dokreslení číslice 0</i>
array = digit_to_array(digits, 0)
ax = plt.subplot(4, 3, 11)
plt.gray()
ax.matshow(array)
&nbsp;
<i># uložení vizualizované matice</i>
plt.savefig("conv_nn_05.png")
&nbsp;
<i># vizualizace matice na obrazovce</i>
plt.show()
</pre>

<p>Výsledky:</p>

*** image ***
<p><i>Obrázek 4: Vizualizace matic všech deseti číslic.</i></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Problém rozpoznávání číslic na reálných obrázcích</h2>

<p>Mohlo by se zdát, že pro rozpoznání obrázků nám stačí si natrénovat běžnou
neuronovou síť se 64 vstupy a deseti výstupy. Jednalo by se o klasifikační síť,
na jejíž vstup by se přivedly hodnoty všech 64 pixelů a na výstupu by se
(ideálně) měla objevit hodnota 1,0 na jednom z&nbsp;výstupů a naopak hodnoty
0,0 na ostatních devíti výstupech. Ve skutečnosti je však nutné přiznat, že je
to v&nbsp;praxi mnohem složitější, a to minimálně ze tří důvodů:</p>

<ol>

<li>Takto natrénovaná neuronová síť dokáže rozpoznat pouze jeden font, což
obecně bude vadit, například ve chvíli, kdy namísto námi připravených
trénovacích dat použijeme například ručně psané číslice z&nbsp;již zmíněné
databáze MNIST. A raději ji vůbec nepouštějte na obrázky získané ze systémů
CAPTCHA :-)</li>

<li>Klasickou neuronovou síť je možné velmi snadno zmást i při použití stále
stejného fontu. Postačuje pouze obraz číslice posunout o jeden jediný pixel
(jakýmkoli směrem)!</li>

<li>Síť nemusí být dobře připravena na klasifikaci zašuměných obrázků, tedy
například obrázků číslic získaných z&nbsp;fotografií, po naskenování číslic
z&nbsp;papíru, ale například číslic uložených do formátů se ztrátovou
komprimací (JPEG) atd.</li>

</ol>



<p><a name="k08"></a></p>
<h2 id="k08">8. Vliv šumu na kvalitu predikcí neuronové sítě</h2>

<p>Po natrénování neuronové sítě s&nbsp;využitím pouhých deseti vstupních
obrázků by se mohlo stát, že by síť prakticky vůbec nebyla schopna rozeznat i
nepatrně změněná vstupní data. Proto funkci pro vytvoření trénovacích obrázků
vhodně pozměníme takovým způsobem, že se do obrázků zanese šum. Pro vytvoření
šumu používám pro jednoduchost funkci <strong>np.random.rand</strong>, ovšem
v&nbsp;případě potřeby samozřejmě můžete využít i funkci pro generování
náhodných hodnot s&nbsp;normálním rozložením atd.:</p>

<pre>
def <strong>add_noise</strong>(array, level):
    return (1.0 - level) * array + level * np.random.rand(8, 8)
</pre>

<p>Povšimněte si dále, že i zašuměné obrázky mají přesně stanovenou hranici
mezi pixely, které tvoří číslici a pixely tvořícími pozadí (záleží na hodnotě
<strong>level</strong> v&nbsp;rozsahu od 0,0 do 1,0). Tuto část si samozřejmě
můžete upravit, a to i takovým způsobem, aby tato hranice byla z&nbsp;obou
stran překračována. Ovšem takto obecně naučená síť nebude dávat jednoznačné
výsledky &ndash; ostatně si to vyzkoušíme příště.</p>



<p><a name="k09"></a></p>
<h2 id="k09">9. Vizualizace matice reprezentující zašuměnou číslici</h2>

<p>Skript, po jehož spuštění se provede &bdquo;zašumění&ldquo; matice
s&nbsp;reprezentací číslice 2 a následné vykreslení takto upravené matice,
vypadá takto:</p>

<pre>
import matplotlib.pyplot as plt
import numpy as np
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>add_noise</strong>(array, level):
    return (1.0 - level) * array + level * np.random.rand(8, 8)
&nbsp;
&nbsp;
<i># vytvoření matice, kterou budeme vizualizovat</i>
array = digit_to_array(digits, 2)
array = add_noise(array, 0.2)
&nbsp;
<i># vykreslení matice</i>
plt.matshow(array)
&nbsp;
<i># převod na stupně šedi</i>
plt.gray()
&nbsp;
<i># uložení vizualizované matice</i>
plt.savefig("conv_nn_06.png")
&nbsp;
<i># vizualizace matice na obrazovce</i>
plt.show()
</pre>

<p>Zašuměný obraz číslice 2 nyní vypadá následovně:</p>

*** image ***
<p><i>Obrázek 5: Vizualizace matice se zašuměnou číslicí 2.</i></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Vizualizace vlivu parametru <strong>level</strong> na způsob zašumění matice s&nbsp;číslicí</h2>

<p>Jak jsme si již řekli v&nbsp;předchozím textu, může parametr
<strong>level</strong>, který ovlivňuje výpočet šumu, nabývat hodnot od 0,0 do
1,0. Vyzkoušejme si tedy, jak budou vypadat matice číslic v&nbsp;případě, kdy
postupně úroveň šumu zvyšujeme v&nbsp;tomto rozsahu. Opět využijeme možnost
vykreslení více grafů do jedné plochy:</p>

<pre>
import matplotlib.pyplot as plt
import numpy as np
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>add_noise</strong>(array, level):
    return (1.0 - level) * array + level * np.random.rand(8, 8)
&nbsp;
&nbsp;
<i># velikost obrázku s grafem</i>
plt.subplots(figsize=(6.4, 6.4))
plt.axis("off")
&nbsp;
for i in range(1, 17):
    array = digit_to_array(digits, 2)
    level = (i - 1.0) / 16.0
    array = add_noise(array, level)
    ax = plt.subplot(4, 4, i)
    <i># plt.gray()</i>
    ax.matshow(array)
&nbsp;
&nbsp;
<i># uložení vizualizované matice</i>
plt.savefig("conv_nn_07.png")
&nbsp;
<i># vizualizace matice na obrazovce</i>
plt.show()
</pre>

<p>Z&nbsp;vizualizace je patrné, že pro úrovně vyšší než 0,5 je výsledná
číslice prakticky nerozeznatelná (ovšem to je logický důsledek):</p>

*** image ***
<p><i>Obrázek 6: Vizualizace matice se zašuměnou číslicí 2, úroveň šumu se
postupně zvyšuje.</i></p>



<p><a name="k11"></a></p>
<h2 id="k11">11. Rozeznání číslic 5, 6 a 8</h2>

<p>Font s&nbsp;číslicemi, který používáme, má jednu zajímavou vlastnost &ndash;
rozdíly mezi číslicemi 5, 6 a 8 jsou pouze několika pixelové (a to existují i
fonty, ve kterých je rozdíl jen jednopixelový). Bude tedy zajímavé zjistit, jak
dobře budeme moci rozlišit tyto tři číslice v&nbsp;případě, že se postupně bude
zvyšovat úroveň zašumění. Další demonstrační příklad zobrazí tři sloupce
s&nbsp;vizualizovanými maticemi s&nbsp;číslicemi 5, 6 a 8. Úroveň šumu postupně
roste od 0,0 do 1,0:</p>

<pre>
import matplotlib.pyplot as plt
import numpy as np
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>add_noise</strong>(array, level):
    return (1.0 - level) * array + level * np.random.rand(8, 8)
&nbsp;
&nbsp;
<i># velikost obrázku s grafem</i>
plt.subplots(figsize=(3.2, 9.8))
plt.axis("off")
&nbsp;
for j, digit in enumerate([5, 6, 8]):
    for i in range(1, 12):
        level = (i - 1.0) / 12.0
        array = digit_to_array(digits, digit)
        array = add_noise(array, level)
        ax = plt.subplot(12, 3, j + 1 + i * 3)
        ax.matshow(array)
        ax.axis("off")
&nbsp;
&nbsp;
<i># uložení vizualizované matice</i>
plt.savefig("conv_nn_08.png")
&nbsp;
<i># vizualizace matice na obrazovce</i>
plt.show()
</pre>

<p>Schválně si sami vyzkoušejte, jak dobře dokážete číslice rozeznat. Vaše
vlastní neuronová síť je přitom mnohem výkonnější, než budou konvoluční umělé
sítě, které si otestujeme příště:</p>

*** image ***
<p><i>Obrázek 7: Matice číslic 5, 6 a 8 s&nbsp;postupně rostoucí úrovní
šumu.</i></p>



<p><a name="k12"></a></p>
<h2 id="k12">12. Posun číslic v&nbsp;matici pro přípravu trénovacích dat</h2>

<p>Neuronovou síť je nutné natrénovat i na takových číslicích, které jsou
v&nbsp;libovolném směru posunuty. Vzhledem k&nbsp;tomu, že možnosti posunu
číslic v&nbsp;rastru 8&times;8 pixelů jsou velmi malé, bude mít v&nbsp;našem
případě význam pouze posun o &plusmn;2 pixely v&nbsp;libovolném směru:
horizontálním, vertikálním a/nebo šikmém. Pro posun v&nbsp;rámci matice
kupodivu v&nbsp;knihovně NumPy neexistuje specializovaná funkce, ale to nevadí,
protože posun lze nasimulovat rotací realizovanou funkcí
<strong>numpy.roll</strong> zkombinovanou s&nbsp;výplní těch částí matice,
které byly orotovány na její druhou stranu. Implementace funkce pro posun může
vypadat takto (posun může být jak kladný, tak i záporný):</p>

<pre>
def <strong>shift</strong>(arr, x_shift, y_shift):
    <i># horizontální posun</i>
    arr = np.roll(arr, x_shift, axis=1)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if x_shift &lt; 0:
        arr[:, x_shift:] = 0.0
    elif x_shift &gt; 0:
        arr[:, :x_shift] = 0.0
&nbsp;
    <i># vertikální posun</i>
    arr = np.roll(arr, y_shift, axis=0)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if y_shift &lt; 0:
        arr[y_shift:] = 0.0
    elif y_shift &gt; 0:
        arr[:y_shift] = 0.0
    return arr
</pre>

<p>Začlenění této funkce do skriptu, který vykreslí matici posunuté číslice 2,
vypadá takto:</p>

<pre>
import matplotlib.pyplot as plt
import numpy as np
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>shift</strong>(arr, x_shift, y_shift):
    <i># horizontální posun</i>
    arr = np.roll(arr, x_shift, axis=1)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if x_shift &lt; 0:
        arr[:, x_shift:] = 0.0
    elif x_shift &gt; 0:
        arr[:, :x_shift] = 0.0
&nbsp;
    <i># vertikální posun</i>
    arr = np.roll(arr, y_shift, axis=0)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if y_shift &lt; 0:
        arr[y_shift:] = 0.0
    elif y_shift &gt; 0:
        arr[:y_shift] = 0.0
    return arr
&nbsp;
&nbsp;
<i># vytvoření matice, kterou budeme vizualizovat</i>
array = digit_to_array(digits, 2)
array = shift(array, 1, 1)
&nbsp;
<i># vykreslení matice</i>
plt.matshow(array)
&nbsp;
<i># převod na stupně šedi</i>
<i># plt.gray()</i>
&nbsp;
<i># uložení vizualizované matice</i>
plt.savefig("conv_nn_09.png")
&nbsp;
<i># vizualizace matice na obrazovce</i>
plt.show()
</pre>

*** image ***
<p><i>Obrázek 8: Vizualizovaná matice s&nbsp;posunutou číslicí 2.</i></p>



<p><a name="k13"></a></p>
<h2 id="k13">13. Zobrazení všech variant posunů matice s&nbsp;číslicí 2 o &plusm; jeden nebo dva pixely</h2>

<p>Nyní si vizuálně ověříme, jak vypadá matice s&nbsp;číslicí 2, která je
posunutá o jeden či dva pixely v&nbsp;libovolném směru. Spuštěním skriptu,
jehož zdrojový kód je zobrazen pod tímto odstavcem, získáme celkem 24 obrázků
(dvacátý pátý je obrázek původní číslice), které jsou vloženy do jediného
grafu:</p>

<pre>
import matplotlib.pyplot as plt
import numpy as np
&nbsp;
<i># číslice reprezentované v masce 8x8 pixelů</i>
digits = (
    (0x00, 0x3C, 0x66, 0x76, 0x6E, 0x66, 0x3C, 0x00),
    (0x00, 0x18, 0x1C, 0x18, 0x18, 0x18, 0x7E, 0x00),
    (0x00, 0x3C, 0x66, 0x30, 0x18, 0x0C, 0x7E, 0x00),
    (0x00, 0x7E, 0x30, 0x18, 0x30, 0x66, 0x3C, 0x00),
    (0x00, 0x30, 0x38, 0x3C, 0x36, 0x7E, 0x30, 0x00),
    (0x00, 0x7E, 0x06, 0x3E, 0x60, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x06, 0x3E, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x7E, 0x60, 0x30, 0x18, 0x0C, 0x0C, 0x00),
    (0x00, 0x3C, 0x66, 0x3C, 0x66, 0x66, 0x3C, 0x00),
    (0x00, 0x3C, 0x66, 0x7C, 0x60, 0x30, 0x1C, 0x00),
)
&nbsp;
&nbsp;
def <strong>digit_to_array</strong>(digits, n):
    digit = digits[n]
    rows = []
    <i># převod jednotlivých řádků na osmici bitů</i>
    for scanline in digit:
        row = []
        <i># převod bitmapy představující řádek na osmici bitů</i>
        for _ in range(8):
            bit = scanline &amp; 0x01
            row.append(float(bit))
            scanline &gt;&gt;= 1
        rows.append(row)
    <i># transformace na n-dimenzionální pole</i>
    return np.array(rows)
&nbsp;
&nbsp;
def <strong>shift</strong>(arr, x_shift, y_shift):
    <i># horizontální posun</i>
    arr = np.roll(arr, x_shift, axis=1)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if x_shift &lt; 0:
        arr[:, x_shift:] = 0.0
    elif x_shift &gt; 0:
        arr[:, :x_shift] = 0.0
&nbsp;
    <i># vertikální posun</i>
    arr = np.roll(arr, y_shift, axis=0)
&nbsp;
    <i># výplně těch částí, které byly orotovány na druhou stranu</i>
    if y_shift &lt; 0:
        arr[y_shift:] = 0.0
    elif y_shift &gt; 0:
        arr[:y_shift] = 0.0
    return arr
&nbsp;
&nbsp;
<i># velikost obrázku s grafem</i>
plt.subplots(figsize=(6.4, 6.4))
plt.axis("off")
&nbsp;
i = 1
for y_shift in range(-2, 3):
    for x_shift in range(-2, 3):
        array = digit_to_array(digits, 2)
        array = shift(array, x_shift, y_shift)
        ax = plt.subplot(5, 5, i)
        i += 1
        ax.matshow(array)
&nbsp;
<i># převod na stupně šedi</i>
plt.gray()
&nbsp;
<i># uložení vizualizované matice</i>
plt.savefig("conv_nn_10.png")
&nbsp;
<i># vizualizace matice na obrazovce</i>
plt.show()
</pre>

<p>Takto by měly vypadat výsledky:</p>

*** image ***
<p><i>Obrázek 9: Číslice 2, která je posunutá o jeden až dva pixely
v&nbsp;libovolném směru.</i></p>



<p><a name="k14"></a></p>
<h2 id="k14">14. Numerické ohodnocení klasifikační neuronové sítě pro rozpoznávání obrázků</h2>

<p>Pro klasifikační neuronové sítě si nevystačíme s&nbsp;výpočtem absolutní či
relativní odchylky výsledku od korektní hodnoty. Typicky se pro tyto účely
používá matice záměn zmíněná v&nbsp;následující kapitole. Ovšem pomoci nám může
i funkce <strong>classification_report</strong> z&nbsp;knihovny
<i>Scikit-learn</i> (již jsme se s&nbsp;ní setkali). Vyzkoušejme tedy, jaké
výsledky získáme pro simulované odpovědi (prozatím neexistující) neuronové sítě
pro rozpoznávání číslic s&nbsp;odpověďmi očekávanými. Tyto hodnoty jsou uloženy
v&nbsp;seznamech <strong>y_pred</strong> a <strong>y_test</strong>:</p>

<pre>
from sklearn.metrics import classification_report
&nbsp;
&nbsp;
y_pred = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
y_test = [0, 1, 2, 8, 4, 5, 6, 7, 6, 9, 0, 1, 2, 2, 4, 5, 8, 7, 8, 9]
&nbsp;
<i># tisk zprávy o výsledcích klasifikace</i>
print(classification_report(y_test, y_pred))
</pre>

<p>Z&nbsp;výsledků získáme informace o tom, které číslice jsou z&nbsp;pohledu
predikce sítě nejvíce problematické. Jedná se o číslici 3 a dále o dvojici 6 a
8, které se zaměňují:</p>

<pre>
              precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2
           2       1.00      0.67      0.80         3
           3       0.00      0.00      0.00         0
           4       1.00      1.00      1.00         2
           5       1.00      1.00      1.00         2
           6       0.50      0.50      0.50         2
           7       1.00      1.00      1.00         2
           8       0.50      0.33      0.40         3
           9       1.00      1.00      1.00         2
&nbsp;
    accuracy                           0.80        20
   macro avg       0.80      0.75      0.77        20
weighted avg       0.88      0.80      0.83        20
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. Matice záměn</h2>

<p>Při zjišťování kvality modelů, které provádí klasifikaci, se s&nbsp;úspěchem
používá takzvaná <i>matice záměn</i> neboli <i>confusion matrix</i>. Jedná se o
matici, která ve sloupcích obsahuje očekávané hodnoty a v&nbsp;řádcích pak
předpovědi/odpovědi modelu (popř.&nbsp;je matice transponovaná, to však
nevadí). Pokud model odpoví ve všech případech správně, bude matice obsahovat
nenulové hodnoty pouze na hlavní diagonále a tyto hodnoty budou znamenat
&bdquo;očekávalo se X odpovědí A a model takto odpověděl skutečně
X-krát&ldquo;. Ovšem ve chvíli, kdy se model splete, vypíše se tato hodnota
mimo hlavní diagonálu; tj.&nbsp;hodnoty mimo hlavní diagonálu znamenají chyby a
navíc můžeme zjistit, které odpovědi způsobují modelu největší problémy
(tj.&nbsp;například které číslice se nejčastěji zaměňují).</p>

<p>Podívejme se na příklad modelu, který vždy odpoví korektně:</p>

<pre>
  | A    B   C
--+------------
A | 10   0   0
B |  0  20   0
C |  0   0  30
</pre>

<p>Model pro 10 očekávaných odpovědí A skutečně desetkrát odpověděl
&bdquo;A&ldquo; atd. Celkem se provedlo 10+20+30 testů.</p>

<p>Naopak může model nesprávně rozlišovat mezi odpověďmi A a B. Potom může
matice vypadat například takto:</p>

<pre>
  | A    B   C
--+------------
A |  7   3   0
B |  0  20   0
C |  0   0  30
</pre>

<p>Nebo takto:</p>

<pre>
  | A    B   C
--+------------
A | 10   0   0
B | 10  10   0
C |  0   0  30
</pre>

<p>Zkoumáním obsahu matice záměn můžeme zjistit nejenom <i>citlivost
modelu</i>, ale i <i>specificitu modelu</i> (což je mnohdy důležitější atribut
&ndash; ještě se k&nbsp;němu vrátíme).</p>

<p>Matice záměn může obsahovat i relativní hodnoty, které jsou nezávislé na
počtu měření. Maximální hodnota prvku v&nbsp;takové matici je rovna 1.0 a
minimální pochopitelně 0.0.</p>

<p>Ukažme si nyní využití matice záměn pro vizualizaci kvality (prozatím
neexistující) neuronové sítě rozpoznávající číslice. Správné odpovědi jsou
uloženy v&nbsp;seznamu <strong>y_test</strong>, odpovědi sítě pak
v&nbsp;seznamu <strong>y_pred</strong>. Skript po svém spuštění vypočítá a
zobrazí matici záměn:</p>

<pre>
import matplotlib.pyplot as plt
from sklearn.metrics import ConfusionMatrixDisplay
&nbsp;
&nbsp;
y_pred = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
y_test = [0, 1, 2, 8, 4, 5, 6, 7, 6, 9, 0, 1, 2, 2, 4, 5, 8, 7, 8, 9]
&nbsp;
<i># výpočet matice záměn</i>
disp = ConfusionMatrixDisplay.from_predictions(
    y_test, y_pred,
    cmap=plt.cm.Blues,
    normalize=None,
)
&nbsp;
<i># zobrazení matice záměn</i>
print(disp.confusion_matrix)
&nbsp;
<i># uložení výsledků</i>
plt.savefig("confusion_matrix.png")
&nbsp;
<i># vykreslení matice záměn</i>
plt.show()
</pre>

<p>Výsledky, které získáme po spuštění tohoto skriptu:</p>

<pre>
[[2 0 0 0 0 0 0 0 0 0]
 [0 2 0 0 0 0 0 0 0 0]
 [0 0 2 1 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 1 0 1 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 0 1 0 0 1 0 1 0]
 [0 0 0 0 0 0 0 0 0 2]]
</pre>

*** image ***
<p><i>Obrázek 10: Vizualizovaná matice záměn.</i></p>

<p>Nejvíce problémů tedy způsobuje záměna číslic 6 a 8.</p>



<p><a name="k16"></a></p>
<h2 id="k16">16. Příklad klasifikační neuronové sítě se dvěma výstupy</h2>

<p>V&nbsp;dnešním posledním demonstračním příkladu je ukázána velmi jednoduchá
klasifikační neuronová síť, která pro dvě vstupní hodnoty v&nbsp;rozsahu 0,0 až
1,0 vrátí informaci o tom, jaký je vztah mezi těmito hodnotami. Síť se naučí do
jisté míry rozpoznávat relaci &bdquo;menší než&ldquo; a
&bdquo;rovnost&ldquo; (rozšíření na číslice bude snadné):</p>

<pre>
import torch
from torch import nn
from torch import optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
&nbsp;
&nbsp;
&nbsp;
class <strong>NeuralNetwork</strong>(nn.Module):
    <i>"""Třída reprezentující neuronovou síť."""</i>
&nbsp;
    def <strong>__init__</strong>(self, input_dim, hidden_dim, output_dim):
        super().__init__()
        <i># vrstvy neuronové sítě</i>
        self.layer_1 = nn.Linear(input_dim, hidden_dim)
        self.layer_2 = nn.Linear(hidden_dim, hidden_dim)
        self.layer_3 = nn.Linear(hidden_dim, output_dim)
&nbsp;
    def <strong>forward</strong>(self, x):
        <i># propagace hodnot přes neuronovou síť</i>
        x = torch.nn.functional.sigmoid(self.layer_1(x))
        x = torch.nn.functional.sigmoid(self.layer_2(x))
        x = torch.nn.functional.sigmoid(self.layer_3(x))
        return x
&nbsp;
&nbsp;
<i># konfigurace vrstev neuronové sítě</i>
input_dim = 2
hidden_dim = 4
output_dim = 2
&nbsp;
<i># konstrukce neuronové sítě</i>
nn1 = NeuralNetwork(input_dim, hidden_dim, output_dim)
&nbsp;
<i># výpis základních informací o neuronové síti</i>
print(nn1)
&nbsp;
&nbsp;
<i># příprava na trénink neuronové sítě</i>
learning_rate = 0.1
loss_fn = nn.BCELoss()
&nbsp;
optimizer = optim.SGD(nn1.parameters(), lr=learning_rate)
&nbsp;
&nbsp;
<i># konverze původních dat z NumPy do tenzorů</i>
class <strong>Data</strong>(Dataset):
    def <strong>__init__</strong>(self, X, y):
        self.X = torch.from_numpy(X.astype(np.float32))
        self.y = torch.from_numpy(y.astype(np.float32))
        self.len = self.X.shape[0]
&nbsp;
    def <strong>__getitem__</strong>(self, index):
        return self.X[index], self.y[index]
&nbsp;
    def <strong>__len__</strong>(self):
        return self.len
&nbsp;
&nbsp;
<i># příprava trénovacích dat</i>
X_train = []
y_train = []
&nbsp;
for a in np.linspace(0, 1.0, 101):
    for b in np.linspace(0, 1.0, 101):
        <i># vstupy</i>
        X_train.append([a, b])
        <i># očekávané výstupy</i>
        y_train.append([1.0 if a&gt;b else 0.0, 1.0 if abs(a-b)&lt;0.2 else 0.0])
&nbsp;
train_data = Data(np.array(X_train), np.array(y_train))
&nbsp;
<i># zpracovat trénovací data</i>
batch_size = 64
train_dataloader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)
print("Batches: ", len(train_dataloader))
&nbsp;
<i># vlastní trénink</i>
print("Training started")
num_epochs = 100
loss_values = []
for epoch in range(num_epochs):
    print(f"    Epoch {epoch}: ", end="")
    last_lost_value = None
    for X, y in train_dataloader:
        optimizer.zero_grad()
&nbsp;
        <i># dopředný tok + zpětný tok + optimalizace</i>
        pred = nn1(X)
&nbsp;
        <i># výpočet účelové funkce</i>
        loss = loss_fn(pred, y)#.unsqueeze(-1))
        loss_values.append(loss.item())
        loss.backward()
        optimizer.step()
        last_lost_value = loss.item()
        print(".", end="")
    print(last_lost_value)
&nbsp;
print("Training completed")
&nbsp;
<i># naivní otestování neuronové sítě</i>
for x in np.linspace(0, 1, 11):
    X = torch.tensor([float(x), 1.0-float(x)])
    y = nn1(X)
    gt = y[0] &gt;= 0.5
    eq = y[1] &gt;= 0.5
    relation = "?"
    if eq:
        relation = "=="
    elif gt:
        relation = "&gt; "
    else:
        relation = "&lt; "
    print(f"{x:4.3} {relation} {1.0-x:4.3}")
</pre>

<p>Výsledky po natrénování této sítě:</p>

<pre>
 0.0 &lt;   1.0
 0.1 &lt;   0.9
 0.2 &lt;   0.8
 0.3 &lt;   0.7
 0.4 &lt;   0.6
 0.5 ==  0.5
 0.6 &gt;   0.4
 0.7 &gt;   0.3
 0.8 &gt;   0.2
 0.9 &gt;   0.1
 1.0 &gt;   0.0
</pre>



<p><a name="k17"></a></p>
<h2 id="k17">17. Konvoluční neuronové sítě</h2>

<p>Jak je tedy možné zlepšit odhad sítě i v&nbsp;případě, že očekáváme, že
obrázky posílané na její vstup budou posunuty, nepatrně otočeny, zkoseny atd.?
Máme k&nbsp;dispozici více řešení. Buď udělat síť mnohem víc robustní, což
znamená <i>výrazně</i> zvětšit počet skrytých vrstev, zvětšit počet neuronů
v&nbsp;těchto vrstvách a o několik řádů zvětšit i množství trénovacích dat
(různé formy offsetu, posun jen některých pixelů atd.). To je sice skutečně
možné zařídit (ostatně zaplatíme za to &bdquo;jen&ldquo; strojovým časem),
ovšem stále zde narážíme na principiální omezení klasických vrstvených
neuronových sítí &ndash; jednotlivé neurony se učí izolovaně od ostatních
neuronů, zatímco na vstupu máme &bdquo;plovoucí&ldquo; obrázek. Bylo by tedy
výhodnější se zaměřit na vylepšení samotné architektury neuronové sítě
specializované právě na to, že na vstupu bude mít bitmapy a tudíž by sousední
neurony měly nějakým způsobem sdílet své váhy na vstupech. Taková architektura
již ve skutečnosti byla dávno vymyšlena a jmenuje se <i>konvoluční neuronová
sít</i>.</p>

<p><div class="rs-tip-major">Poznámka: stále musíme mít na paměti, že i
konvoluční neuronové sítě jsou založené na klasických dopředných sítích, které
navíc bývají tzv.&nbsp;hluboké.</div></p>



<p><a name="k18"></a></p>
<h2 id="k18">18. Vrstvy v&nbsp;konvolučních neuronových sítích</h2>

<p>V&nbsp;konvolučních neuronových sítích se používají vrstvy se speciálním
významem i chováním. Jedná se především o takzvané <i>konvoluční vrstvy</i>,
které jsou napojeny přímo na vstupní vrstvu popř.&nbsp;na <i>subsamplingové
vrstvy</i>. Konvoluční vrstvy se skládají z&nbsp;obecně libovolného množství
příznakových map, podle toho, jaké objekty nebo vlastnosti vlastně
v&nbsp;obrázku rozpoznáváme. Zpracovávaná bitmapa se zde rozděluje na
podoblasti, které se vzájemně překrývají. Neurony přitom mohou sdílet své váhy
přiřazené vstupům. Jak přesně to funguje si řekneme příště. Mezi jednotlivé
konvoluční vrstvy se vkládají subsamplingové vrstvy, které jsou
z&nbsp;výpočetního hlediska jednodušší, protože neurony zde obsahují jen dvě
váhy (součet vstupů+práh). Tyto vrstvy získaly svoje jméno podle toho, že
umožňují provádět podvzorkování založené většinou na velmi jednoduchých
funkcích aplikovaných na okolí každého pixelu (maximální hodnota, střední
hodnota...).</p>

<p>Typicky se vrstvy střídají takto:</p>

<ol>
<li>Vstupní vrstva</li>
<li>Konvoluční vrstva #1</li>
<li>Subsamplingová vrstva #1</li>
<li>Konvoluční vrstva #2</li>
<li>Subsamplingová vrstva #2</li>
<li>...</li>
<li>...</li>
<li>Klasická skrytá vrstva</li>
<li>Výstupní vrstva</li>
</ol>

<p>Existují ovšem i další možnosti, opět se o nich zmíníme příště.</p>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu PyTorch lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td>  1</td><td>tensor_constructor_scalar_1.py</td><td>konstrukce tenzoru nultého a prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py</a></td></tr>
<tr><td>  2</td><td>tensor_constructor_scalar_2.py</td><td>inicializace tenzoru prvního řádu s&nbsp;jedním prvkem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py</a></td></tr>
<tr><td>  3</td><td>tensor_constructor_vector_1.py</td><td>konstrukce tenzoru prvního řádu (tříprvkový vektor)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py</a></td></tr>
<tr><td>  4</td><td>tensor_constructor_vector_2.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;inicializací prvků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py</a></td></tr>
<tr><td>  5</td><td>tensor_constructor_vector_3.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;využitím generátoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py</a></td></tr>
<tr><td>  6</td><td>tensor_constructor_matrix_1.py</td><td>vytvoření a inicializace tenzoru druhého řádu, který může být reprezentován maticí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py</a></td></tr>
<tr><td>  7</td><td>tensor_constructor_matrix_2.py</td><td>inicializace prvků matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py</a></td></tr>
<tr><td>  8</td><td>tensor_constructor_3D_1.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py</a></td></tr>
<tr><td>  9</td><td>tensor_constructor_3D_2.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo; (jiná forma inicializace)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 10</td><td>tensor_constructor_scalar_zero.py</td><td>vynulování prvků tenzoru nultého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py</a></td></tr>
<tr><td> 11</td><td>tensor_constructor_vector_zero.py</td><td>vynulování prvků tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py</a></td></tr>
<tr><td> 12</td><td>tensor_constructor_matrix_zero.py</td><td>vynulování prvků tenzoru druhého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py</a></td></tr>
<tr><td> 13</td><td>tensor_constructor_3D_zero.py</td><td>vynulování prvků tenzoru třetího řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 14</td><td>tensor_zeros_shape.py</td><td>použití konstruktoru <strong>zeros</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td> 15</td><td>tensor_ones_shape.py</td><td>použití konstruktoru <strong>ones</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td> 16</td><td>tensor_eye.py</td><td>konstrukce jednotkové matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 17</td><td>tensor_range.py</td><td>využití konstruktoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py</a></td></tr>
<tr><td> 18</td><td>tensor_arange.py</td><td>využití konstruktoru <strong>arange</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 19</td><td>tensor_shape.py</td><td>zjištění tvaru tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_shape.py</a></td></tr>
<tr><td> 20</td><td>tensor_zeros_shape.py</td><td>zjištění tvaru tenzoru vytvořeného konstruktorem <strong>zeros</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td> 21</td><td>tensor_ones_shape.py</td><td>zjištění tvaru tenzoru vytvořeného konstruktorem <strong>ones</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td> 22</td><td>tensor_read_dtype.py</td><td>zjištění, jakého typu jsou prvky tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_read_dtype.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_read_dtype.py</a></td></tr>
<tr><td> 23</td><td>tensor_set_dtype.py</td><td>nastavení či změna typu prvků tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_set_dtype.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_set_dtype.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 24</td><td>tensor_storage_1.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_1.py</a></td></tr>
<tr><td> 25</td><td>tensor_storage_2.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_2.py</a></td></tr>
<tr><td> 26</td><td>tensor_storage_3.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_3.py</a></td></tr>
<tr><td> 27</td><td>tensor_storage_casts.py</td><td>přetypování datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_casts.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_casts.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 28</td><td>tensor_slice_operation_1.py</td><td>konstrukce řezu z&nbsp;tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_1.py</a></td></tr>
<tr><td> 29</td><td>tensor_slice_operation_2.py</td><td>konstrukce řezu z&nbsp;tenzoru druhého řádu (přes řádky a sloupce)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_2.py</a></td></tr>
<tr><td> 30</td><td>tensor_slice_operation_3.py</td><td>konstrukce řezu s&nbsp;jeho následnou modifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_3.py</a></td></tr>
<tr><td> 31</td><td>tensor_slice_operation_4.py</td><td>konstrukce řezu s&nbsp;jeho následnou modifikací (odlišné operace od předchozího příkladu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_4.py</a></td></tr>
<tr><td> 32</td><td>tensor_is_slice.py</td><td>test základních vlastností řezů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_is_slice.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_is_slice.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 33</td><td>tensor_stride_1.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_1.py</a></td></tr>
<tr><td> 34</td><td>tensor_stride_2.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_2.py</a></td></tr>
<tr><td> 35</td><td>tensor_stride_3.py</td><td>význam atributů <strong>stride</strong> a <strong>storage_offset</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_stride_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 36</td><td>tensor_reshape.py</td><td>změna tvaru tenzoru operací <strong>reshape</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape.py</a></td></tr>
<tr><td> 37</td><td>tensor_reshape_2.py</td><td>změna tvaru tenzoru operací <strong>reshape</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_reshape_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 38</td><td>tensor_narrow_operation_1.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, první ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1.py</a></td></tr>
<tr><td> 39</td><td>tensor_narrow_operation_1_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, první ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_1_B.py</a></td></tr>
<tr><td> 40</td><td>tensor_narrow_operation_2.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, druhá ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2.py</a></td></tr>
<tr><td> 41</td><td>tensor_narrow_operation_2_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, druhá ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_2_B.py</a></td></tr>
<tr><td> 42</td><td>tensor_narrow_operation_3.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, třetí ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3.py</a></td></tr>
<tr><td> 43</td><td>tensor_narrow_operation_3_B.py</td><td>operace nad celým tenzorem typu <i>narrow</i>, třetí ukázka přepsaná do volání metody</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3_B.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_3_B.py</a></td></tr>
<tr><td> 44</td><td>tensor_narrow_operation_4.py</td><td>přepis původní matice přes pohled na ni (<i>view</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_4.py</a></td></tr>
<tr><td> 45</td><td>tensor_narrow_operation_5.py</td><td>přepis původní matice přes pohled na ni (<i>view</i>)<i>narrow</i>, třetí ukázka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_narrow_operation_5.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 46</td><td>tensor_operator_add.py</td><td>součet dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_add.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_add.py</a></td></tr>
<tr><td> 47</td><td>tensor_operator_sub.py</td><td>rozdíl dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_sub.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_sub.py</a></td></tr>
<tr><td> 48</td><td>tensor_operator_mul.py</td><td>součin dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_mul.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_mul.py</a></td></tr>
<tr><td> 49</td><td>tensor_operator_div.py</td><td>podíl dvou tenzorů prvek po prvku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_div.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_div.py</a></td></tr>
<tr><td> 50</td><td>tensor_dot_product.py</td><td>skalární součin dvou tenzorů prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_dot_product.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_dot_product.py</a></td></tr>
<tr><td> 50</td><td>tensor_operator_matmul.py</td><td>maticové násobení (dvou tenzorů druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul.py</a></td></tr>
<tr><td> 51</td><td>tensor_operator_matmul_2.py</td><td>maticové násobení (dvou tenzorů druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_2.py</a></td></tr>
<tr><td> 52</td><td>tensor_operator_matmul_3.py</td><td>maticové násobení v&nbsp;případě nekompatibilních tvarů matic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_3.py</a></td></tr>
<tr><td> 53</td><td>tensor_operator_matmul_4.py</td><td>maticové násobení s&nbsp;broadcastingem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_4.py</a></td></tr>
<tr><td> 54</td><td>tensor_operator_matmul_5.py</td><td>násobení vektoru a matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_operator_matmul_5.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 55</td><td>tensor_broadcast_1.py</td><td>operace <i>broadcast</i> (součin každého prvku tenzoru se skalárem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_1.py</a></td></tr>
<tr><td> 56</td><td>tensor_broadcast_2.py</td><td>operace <i>broadcast</i> (součin tenzoru druhého řádu s vektorem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_2.py</a></td></tr>
<tr><td> 57</td><td>tensor_broadcast_3.py</td><td>operace <i>broadcast</i> (součin vektoru s&nbsp;tenzorem druhého řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_3.py</a></td></tr>
<tr><td> 58</td><td>tensor_broadcast_4.py</td><td>operace <i>broadcast</i> (součet tenzorů druhého a třetího řádu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_broadcast_4.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 59</td><td>tensor_sparse.py</td><td>konstrukce řídkého tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_sparse.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_sparse.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 60</td><td>activation_function_relu_.py</td><td>aktivační funkce ReLU vypočtená knihovnou NumPy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_numpy.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_numpy.py</a></td></tr>
<tr><td> 61</td><td>activation_function_relu_pytorch.py</td><td>aktivační funkce ReLU vypočtená knihovnou PyTorch</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_pytorch.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_relu_pytorch.py</a></td></tr>
<tr><td> 62</td><td>activation_function_sigmoid_.py</td><td>aktivační funkce sigmoid vypočtená knihovnou NumPy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_numpy.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_numpy.py</a></td></tr>
<tr><td> 63</td><td>activation_function_sigmoid_pytorch.py</td><td>aktivační funkce sigmoid vypočtená knihovnou PyTorch</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_pytorch.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_sigmoid_pytorch.py</a></td></tr>
<tr><td> 64</td><td>activation_function_tanh_.py</td><td>aktivační funkce tanh vypočtená knihovnou NumPy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_numpy.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_numpy.py</a></td></tr>
<tr><td> 65</td><td>activation_function_tanh_pytorch.py</td><td>aktivační funkce tanh vypočtená knihovnou PyTorch</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_pytorch.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/activation_function_tanh_pytorch.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 66</td><td>make_circles.py</td><td>vygenerování dat pro neuronovou síť funkcí <strong>make_circles</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_circles.py</a></td></tr>
<tr><td> 67</td><td>make_circles_labels.py</td><td>vizualizace dat společně s&nbsp;jejich skupinou (ohodnocením)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_circles_labels.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_circles_labels.py</a></td></tr>
<tr><td> 68</td><td>make_more_noise_circles.py</td><td>získání náhodnějších dat funkcí <strong>make_circles</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_more_noise_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_more_noise_circles.py</a></td></tr>
<tr><td> 69</td><td>make_data_set.py</td><td>náhodné rozdělení datové sady funkcí <strong>train_test_split</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_data_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/make_data_set.py</a></td></tr>
<tr><td> 70</td><td>prepare_for_training.py</td><td>konverze původních dat z&nbsp;n-dimenzionálních polí do tenzorů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/prepare_for_training.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/prepare_for_training.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 71</td><td>compute_train_and_test_data.py</td><td>výpočet trénovacích a testovacích dat pro neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/compute_train_and_test_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/compute_train_and_test_data.py</a></td></tr>
<tr><td> 72</td><td>print_train_and_test_data.py</td><td>tisk dat získaných předchozím skriptem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/print_train_and_test_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/print_train_and_test_data.py</a></td></tr>
<tr><td> 73</td><td>nn_01.py</td><td>deklarace třídy představující neuronovou síť</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_01.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_01.py</a></td></tr>
<tr><td> 74</td><td>nn_02.py</td><td>definice vrstev neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_02.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_02.py</a></td></tr>
<tr><td> 75</td><td>nn_03.py</td><td>trénink neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_03.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_03.py</a></td></tr>
<tr><td> 76</td><td>nn_04.py</td><td>trénink neuronové sítě se zobrazením kvality tréninku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_04.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_04.py</a></td></tr>
<tr><td> 77</td><td>nn_05.py</td><td>neuronová síť s&nbsp;jednou skrytou vrstvou</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_05.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_05.py</a></td></tr>
<tr><td> 78</td><td>nn_06.py</td><td>neuronová síť s&nbsp;více skrytými vrstvami, která nebude dotrénována</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_06.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_06.py</a></td></tr>
<tr><td> 79</td><td>nn_07.py</td><td>vliv parametru <strong>learning_rate</strong> na rychlosti naučení sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_07.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_07.py</a></td></tr>
<tr><td> 80</td><td>nn_08.py</td><td>výpočet kvality neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_08.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_08.py</a></td></tr>
<tr><td> 81</td><td>nn_09.py</td><td>vizualizace predikce neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_09.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_09.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 82</td><td>nn_linear_help.py</td><td>zobrazení nápovědy ke třídě <strong>torch.nn.Linear</strong> i k&nbsp;parametrům konstruktorů této třídy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_help.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_help.py</a></td></tr>
<tr><td> 83</td><td>nn_linear_1.py</td><td>konstrukce objektu typu <strong>torch.nn.Linear</strong> s&nbsp;biasem (transformace s&nbsp;jedním vstupem a jedním výstupem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_1.py</a></td></tr>
<tr><td> 84</td><td>nn_linear_2.py</td><td>konstrukce objektu typu <strong>torch.nn.Linear</strong> bez biasu (transformace s&nbsp;jedním vstupem a jedním výstupem)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_2.py</a></td></tr>
<tr><td> 85</td><td>nn_linear_3.py</td><td>specifikace vah a biasu po konstrukci objektu typu <strong>torch.nn.Linear</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_3.py</a></td></tr>
<tr><td> 86</td><td>nn_linear_4.py</td><td>aplikace lineární transformace reprezentované objektem typu <strong>torch.nn.Linear</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_4.py</a></td></tr>
<tr><td> 87</td><td>nn_linear_5.py</td><td>aplikace lineární transformace na větší soubor vstupních tenzorů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_5.py</a></td></tr>
<tr><td> 88</td><td>nn_linear_6.py</td><td>2D transformace prováděná objektem typu <strong>torch.nn.Linear</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_6.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_6.py</a></td></tr>
<tr><td> 89</td><td>nn_linear_7.py</td><td>2D transformace &ndash; otočení bodů v&nbsp;rovině</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_7.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_7.py</a></td></tr>
<tr><td> 90</td><td>nn_linear_zeros.py</td><td>konstrukce objektu typu <strong>torch.nn.Linear</strong> pro nulový počet vstupů a/nebo výstupů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_zeros.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_linear_zeros.py</a></td></tr>
<tr><td> 91</td><td>nn_forward_1.py</td><td>neuronová síť s&nbsp;jedním vstupem a jedním výstupem, bez aktivační funkce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_1.py</a></td></tr>
<tr><td> 92</td><td>nn_forward_2.py</td><td>neuronová síť s&nbsp;jedním vstupem a dvěma výstupy, bez aktivační funkce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_2.py</a></td></tr>
<tr><td> 93</td><td>nn_forward_3.py</td><td>neuronová síť se dvěma vstupy a jedním výstupem, bez aktivační funkce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_3.py</a></td></tr>
<tr><td> 94</td><td>nn_forward_4.py</td><td>přidání aktivační funkce do neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_forward_4.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 95</td><td>conv_nn_01_digits.py</td><td>první verze generátoru trénovacích obrázků číslic od 0 do 9</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_01_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_01_digits.py</a></td></tr>
<tr><td> 96</td><td>conv_nn_02_digits_as_bitmaps.py</td><td>konstrukce dvourozměrné matice 8&times;8 bodů pro vybranou číslici</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_02_digits_as_bitmaps.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_02_digits_as_bitmaps.py</a></td></tr>
<tr><td> 97</td><td>conv_nn_03_show_digits.py</td><td>vizualizace matic s&nbsp;obrazy číslic v&nbsp;rastru 8&times;8 v&nbsp;nepravých barvách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_03_show_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_03_show_digits.py</a></td></tr>
<tr><td> 98</td><td>conv_nn_04_show_digits.py</td><td>vizualizace matic s&nbsp;obrazy číslic v&nbsp;rastru 8&times;8 ve stupních šedi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_04_show_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_04_show_digits.py</a></td></tr>
<tr><td> 99</td><td>conv_nn_05_show_all_digits.py</td><td>vizualizace všech deseti matic s&nbsp;číslicemi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_05_show_all_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_05_show_all_digits.py</a></td></tr>
<tr><td>100</td><td>conv_nn_06_noise.py</td><td>přidání šumu do obrázků s&nbsp;číslicemi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_06_noise.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_06_noise.py</a></td></tr>
<tr><td>101</td><td>conv_nn_07_noise_levels.py</td><td>šum se sílou od 0% do 100%</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_07_noise_levels.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_07_noise_levels.py</a></td></tr>
<tr><td>102</td><td>conv_nn_08_5_6_or_8.py</td><td>rozdíl mezi číslicemi 5, 6 a 8</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_08_5_6_or_8.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_08_5_6_or_8.py</a></td></tr>
<tr><td>103</td><td>conv_nn_09_shift.py</td><td>posun obrazu číslice v&nbsp;rámci matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_09_shift.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_09_shift.py</a></td></tr>
<tr><td>104</td><td>conv_nn_10_shifts.py</td><td>různé posuny obrazu číslice v&nbsp;rámci matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_10_shifts.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_10_shifts.py</a></td></tr>
<tr><td>105</td><td>conv_nn_11_classification_report.py</td><td>numerická podoba ověření sítě provádějící klasifikaci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_11_classification_report.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_11_classification_report.py</a></td></tr>
<tr><td>106</td><td>conv_nn_12_confusion_matrix.py</td><td>výpočet a vizualizace matice záměn (<i>confusion matrix</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_12_confusion_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/conv_nn_12_confusion_matrix.py</a></td></tr>
<tr><td>107</td><td>nn_10.py</td><td>jednoduchá neuronová síť provádějící klasifikaci (nikoli regresi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_10.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/nn_10.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Seriál Programovací jazyk Lua na Rootu:<br />
<a href="https://www.root.cz/serialy/programovaci-jazyk-lua/">https://www.root.cz/serialy/programovaci-jazyk-lua/</a>
</li>

<li>PDM: moderní správce balíčků a virtuálních prostředí Pythonu:<br />
<a href="https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/">https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/</a>
</li>

<li>PyTorch Tutorial: Building a Simple Neural Network From Scratch<br />
<a href="https://www.datacamp.com/tutorial/pytorch-tutorial-building-a-simple-neural-network-from-scratch">https://www.datacamp.com/tutorial/pytorch-tutorial-building-a-simple-neural-network-from-scratch</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008:<br />
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008 (dokončení):<br />
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/</a>
</li>

<li>Brain Floating Point &ndash; nový formát uložení čísel pro strojové učení a chytrá čidla:<br />
<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>
</li>

<li>Stránky projektu PyTorch:<br />
<a href="https://pytorch.org/">https://pytorch.org/</a>
</li>

<li>Informace o instalaci PyTorche:<br />
<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>
</li>

<li>Tenzor (Wikipedia):<br />
<a href="https://cs.wikipedia.org/wiki/Tenzor">https://cs.wikipedia.org/wiki/Tenzor</a>
</li>

<li>Introduction to Tensors:<br />
<a href="https://www.youtube.com/watch?v=uaQeXi4E7gA">https://www.youtube.com/watch?v=uaQeXi4E7gA</a>
</li>

<li>Introduction to Tensors: Transformation Rules:<br />
<a href="https://www.youtube.com/watch?v=j6DazQDbEhQ">https://www.youtube.com/watch?v=j6DazQDbEhQ</a>
</li>

<li>Tensor Attributes:<br />
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Tensors Explained Intuitively: Covariant, Contravariant, Rank :<br />
<a href="https://www.youtube.com/watch?v=CliW7kSxxWU">https://www.youtube.com/watch?v=CliW7kSxxWU</a>
</li>

<li>What is the relationship between PyTorch and Torch?:<br />
<a href="https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch">https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch</a>
</li>

<li>What is a tensor anyway?? (from a mathematician):<br />
<a href="https://www.youtube.com/watch?v=K7f2pCQ3p3U">https://www.youtube.com/watch?v=K7f2pCQ3p3U</a>
</li>

<li>Visualization of tensors - part 1 :<br />
<a href="https://www.youtube.com/watch?v=YxXyN2ifK8A">https://www.youtube.com/watch?v=YxXyN2ifK8A</a>
</li>

<li>Visualization of tensors - part 2A:<br />
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>Visualization of tensors - part 2B:<br />
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>What the HECK is a Tensor?!?:<br />
<a href="https://www.youtube.com/watch?v=bpG3gqDM80w">https://www.youtube.com/watch?v=bpG3gqDM80w</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>An Introduction to Tensors<br />
<a href="https://math.stackexchange.com/questions/10282/an-introduction-to-tensors">https://math.stackexchange.com/questions/10282/an-introduction-to-tensors</a>
</li>

<li>Differences between a matrix and a tensor<br />
<a href="https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor">https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor</a>
</li>

<li>Qualitatively, what is the difference between a matrix and a tensor?<br />
<a href="https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?">https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?</a>
</li>

<li>Tensors for Neural Networks, Clearly Explained!!!:<br />
<a href="https://www.youtube.com/watch?v=L35fFDpwIM4">https://www.youtube.com/watch?v=L35fFDpwIM4</a>
</li>

<li>Tensor Processing Unit:<br />
<a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit">https://en.wikipedia.org/wiki/Tensor_Processing_Unit</a>
</li>

<li>Třída Storage:<br />
<a href="http://docs.pytorch.wiki/en/storage.html">http://docs.pytorch.wiki/en/storage.html</a>
</li>

<li>Funkce torch.dot<br />
<a href="https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot">https://pytorch.org/docs/stable/generated/torch.dot.html#torch.dot</a>
</li>

<li>Funkce torch.narrow<br />
<a href="https://pytorch.org/docs/stable/generated/torch.narrow.html">https://pytorch.org/docs/stable/generated/torch.narrow.html</a>
</li>

<li>Funkce torch.matmul<br />
<a href="https://pytorch.org/docs/stable/generated/torch.matmul.html">https://pytorch.org/docs/stable/generated/torch.matmul.html</a>
</li>

<li>Funkce torch.reshape<br />
<a href="https://pytorch.org/docs/stable/generated/torch.reshape.html">https://pytorch.org/docs/stable/generated/torch.reshape.html</a>
</li>

<li>Funkce torch.arange<br />
<a href="https://pytorch.org/docs/stable/generated/torch.arange.html">https://pytorch.org/docs/stable/generated/torch.arange.html</a>
</li>

<li>Funkce torch.range<br />
<a href="https://pytorch.org/docs/stable/generated/torch.range.html">https://pytorch.org/docs/stable/generated/torch.range.html</a>
</li>

<li>Třída torch.Tensor<br />
<a href="https://pytorch.org/docs/stable/tensors.html">https://pytorch.org/docs/stable/tensors.html</a>
</li>

<li>Atributy tenzorů<br />
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Pohledy vytvořené nad tenzory<br />
<a href="https://pytorch.org/docs/stable/tensor_view.html">https://pytorch.org/docs/stable/tensor_view.html</a>
</li>

<li>Broadcasting v&nbsp;knihovně <br />
<a href="https://.org/doc/stable/user/basics.broadcasting.html">https://numpy.org/doc/stable/user/basics.broadcasting.html</a>
</li>

<li>Broadcasting semantics (v&nbsp;knihovně PyTorch)<br />
<a href="https://pytorch.org/docs/stable/notes/broadcasting.html">https://pytorch.org/docs/stable/notes/broadcasting.html</a>
</li>

<li>Dot Product In Physics: What Is The Physical Meaning of It?<br />
<a href="https://profoundphysics.com/dot-product-in-physics-what-is-the-physical-meaning-of-it/">https://profoundphysics.com/dot-product-in-physics-what-is-the-physical-meaning-of-it/</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

<li>Třída torch.nn.Linear<br />
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">https://pytorch.org/docs/stable/generated/torch.nn.Linear.html</a>
</li>

<li>Třída torch.nn.Parameter<br />
<a href="https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html">https://pytorch.org/docs/stable/generated/torch.nn.parameter.Parameter.html</a>
</li>

<li>Třída torch.nn.Sigmoid<br />
<a href="https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html">https://pytorch.org/docs/stable/generated/torch.nn.Sigmoid.html</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

