<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. </a></p>
<p><a href="#k02">2. Získání tvaru tenzoru (<i>shape</i>)</a></p>
<p><a href="#k03">3. Způsob uložení tenzorů v&nbsp;paměti počítače nebo TPU</a></p>
<p><a href="#k04">4. Získání typu prvků tenzoru</a></p>
<p><a href="#k05">5. Specifikace či změna typu prvků tenzoru</a></p>
<p><a href="#k06">6. Manipulace s&nbsp;objektem typu <i>Storage</i></a></p>
<p><a href="#k07">7. Způsob uložení prvků tenzoru druhého a třetího řádu</a></p>
<p><a href="#k08">8. Konstrukce řezu (<i>slice</i>)</a></p>
<p><a href="#k09">9. Specifikace záporných indexů a záporného kroku při provádění řezu</a></p>
<p><a href="#k10">10. Operace řezu aplikovaná na matice (tenzory druhého řádu)</a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. </h2>



<p><a name="k02"></a></p>
<h2 id="k02">2. Získání tvaru tenzoru (<i>shape</i>)</h2>

<p>Tvar tenzoru neboli <i>shape</i> je popsán n-ticí obsahující počet prvků
v&nbsp;jednotlivých dimenzích (ovšem pokud se tvar tenzoru čte, získáme hodnotu
typu <strong>torch.Size</strong>, v&nbsp;níž je n-tice zabalená). Poněkud
speciálním případem je skalár (vektor nultého řádu), který je popsán prázdnou
n-ticí. Vektor je popsán n-ticí s&nbsp;jednou hodnotou &ndash; délkou vektoru,
matice n-ticí se dvěma hodnotami atd. atd. Můžeme si to velmi snadno
otestovat:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru + zjisteni jejich tvaru</i>
&nbsp;
<i># tenzor nulteho radu - skalar</i>
s1 = torch.tensor(100)
print(s1.shape)
&nbsp;
<i># tenzor prvniho radu - vektor</i>
v1 = torch.Tensor(1)
print(v1.shape)
&nbsp;
v2 = torch.Tensor(3)
print(v2.shape)
&nbsp;
<i># tenzor druheho radu - matice</i>
m1 = torch.Tensor(3, 4)
print(m1.shape)
&nbsp;
<i># tenzor tretiho radu - 3D pole</i>
c1 = torch.Tensor(3, 4, 5)
print(c1.shape)
</pre>

<p>Po spuštění tohoto demonstračního příkladu by se měly zobrazit následující
tvary:</p>

<pre>
torch.Size([])
torch.Size([1])
torch.Size([3])
torch.Size([3, 4])
torch.Size([3, 4, 5])
</pre>

<p>Specifikaci tvaru tenzoru založenou na sekvenci celých čísel jsme využili
například v&nbsp;konstruktoru <strong>zeros</strong>:</p>

<pre>
<i># konstrukce tenzoru prvniho radu, vyplneni nulami </i>
v1 = torch.zeros(1)
print(v1)
print()
&nbsp;
<i># konstrukce tenzoru prvniho radu, vyplneni nulami </i>
v2 = torch.zeros(10)
print(v2)
print()
&nbsp;
<i># konstrukce tenzoru druheho radu, vyplneni nulami </i>
m1 = torch.zeros(3, 4)
print(m1)
print()
&nbsp;
<i># konstrukce tenzoru tretiho radu, vyplneni nulami </i>
c1 = torch.zeros(3, 4, 5)
print(c1)
print()
</pre>

<p>Výsledky:</p>

<pre>
tensor([0.])
&nbsp;
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])
&nbsp;
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]])
&nbsp;
tensor([[[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]],
&nbsp;
        [[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]],
&nbsp;
        [[0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.],
         [0., 0., 0., 0., 0.]]])
</pre>

<p>Dtto pro konstruktor <strong>ones</strong>:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru, vyplneni jednickami</i>
v1 = torch.ones(1)
print(v1)
print()
&nbsp;
<i># konstrukce tenzoru prvniho radu, vyplneni jednickami </i>
v2 = torch.ones(10)
print(v2)
print()
&nbsp;
<i># konstrukce tenzoru druheho radu, vyplneni jednickami </i>
m1 = torch.ones(3, 4)
print(m1)
print()
&nbsp;
<i># konstrukce tenzoru tretiho radu, vyplneni jednickami </i>
c1 = torch.ones(3, 4, 5)
print(c1)
print()
</pre>

<p>Výsledky:</p>

<pre>
tensor([1.])
&nbsp;
tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])
&nbsp;
tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]])
&nbsp;
tensor([[[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]],
&nbsp;
        [[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]],
&nbsp;
        [[1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.],
         [1., 1., 1., 1., 1.]]])
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. Způsob uložení tenzorů v&nbsp;paměti počítače nebo TPU</h2>

<p>V&nbsp;úvodním článku jsme si řekli, že objekty typu <strong>Tensor</strong>
pro uložení svých komponent (prvků) interně používají jednorozměrná pole. To,
že se tenzory uživateli jeví jako 1D, 2D, 3D atd. struktury je ve skutečnosti
záležitostí pohledů (<i>views</i>) na zmíněná jednorozměrná pole (jedná se
vlastně o běžná céčková pole). Pro některé nízkoúrovňové operace může být
výhodné přistupovat přímo k&nbsp;internímu poli, což nám knihovna
<i>PyTorch</i> umožňuje, protože nabízí objekty typu <i>Storage</i>. Existuje
přitom několik konkrétních typů Storage, protože interní (céčková) pole taktéž
mohou obsahovat prvky různých typů. Implicitně se používá
<strong>FloatStorage</strong>, pokud není z&nbsp;typu prvků tenzorů zřejmé, že
se má jednat o jiný typ (v&nbsp;budoucnu ovšem takto nízkoúrovňový přístup již
nebude možný, o čemž se ještě zmíníme v&nbsp;dalších článcích):</p>

<table>
<tr><th>Typ Storage</th><th>Význam</th></tr>
<tr><td>torch.BoolStorage</td><td>pole s&nbsp;prvky typu <i>boolean</i></td></tr>
<tr><td>torch.CharStorage</td><td>pole s&nbsp;prvky typu <i>char</i></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.ByteStorage</td><td>pole s&nbsp;prvky typu <i>unsigned char</i></td></tr>
<tr><td>torch.ShortStorage</td><td>pole s&nbsp;prvky typu <i>short</i> (16bitové celé číslo)</td></tr>
<tr><td>torch.IntStorage</td><td>pole s&nbsp;prvky typu <i>int</i> (32bitové celé číslo)</td></tr>
<tr><td>torch.LongStorage</td><td>pole s&nbsp;prvky typu <i>long</i> (64bitové celé číslo)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.BFloat16Storage</td><td>pole s&nbsp;prvky typu <i>brain floating point/Bfloat16</i></td></tr>
<tr><td>torch.HalfStorage</td><td>pole s&nbsp;prvky typu <i>half</i> dle IEEE 754</td></tr>
<tr><td>torch.FloatStorage</td><td>pole s&nbsp;prvky typu <i>float</i> dle IEEE 754</td></tr>
<tr><td>torch.DoubleStorage</td><td>pole s&nbsp;prvky typu <i>double</i> dle IEEE 754</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.ComplexFloatStorage</td><td>komplexní hodnoty založené na typu <i>float</i></td></tr>
<tr><td>torch.ComplexDoubleStorage</td><td>komplexní hodnoty založené na typu <i>double</i></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.QUInt8Storage</td><td>kvantované hodnoty interně uložené do bajtu</td></tr>
<tr><td>torch.QInt8Storage</td><td>kvantované hodnoty interně uložené do bajtu</td></tr>
<tr><td>torch.QUInt2x4Storage</td><td>kvantované hodnoty interně uložené do bajtu</td></tr>
<tr><td>torch.QUInt4x2Storage</td><td>kvantované hodnoty interně uložené do bajtu</td></tr>
<tr><td>torch.QInt32Storage</td><td>kvantované hodnoty interně uložené do 32bitového slova</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>torch.UntypedStorage</td><td>bez specifikace typu (jen s&nbsp;tímto typem se setkáme v&nbsp;budoucnu)</td></tr>
</table>



<p><a name="k04"></a></p>
<h2 id="k04">4. Získání typu prvků tenzoru</h2>

<p>Ještě než se podíváme na to, jakým způsobem je možné zjistit interní pole,
které reprezentuje tenzor v&nbsp;paměti, si ukažme způsob zjištění typů prvku
tenzoru. Bude se tedy jednat o informaci důležitou při
&bdquo;vysokoúrovňovém&ldquo; pohledu na tenzor, kdy nás nezajímají
implementační detaily. Pro získání, jakého typu je každý prvek tenzoru, stačí
přečíst atribut nazvaný <strong>dtype</strong>:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru s inicializaci prvku</i>
v1 = torch.tensor(10)
print(v1)
print(type(v1))
print(v1.dtype)
&nbsp;
print()
&nbsp;
<i># konstrukce tenzoru bez inicializace prvku</i>
m1 = torch.Tensor(3, 4)
print(m1)
print(type(m1))
print(m1.dtype)
</pre>

<p>V&nbsp;prvním případě (jedná se o tenzor prvního řádu s&nbsp;jedním prvkem)
je typ tohoto prvku nastaven na <strong>int64</strong>, což odpovídá předané
hodnotě.  Na druhou stranu by možná bylo možné použít i typ s&nbsp;menší
bitovou šířkou:</p>

<pre>
tensor(10)
&lt;class 'torch.Tensor'&gt;
torch.int64
</pre>

<p>Ve druhém případě (tenzor druhého řádu, neboli v&nbsp;našem podání běžná 2D
matice) je, možná poněkud překvapivě, použit typ <strong>float32</strong>
resp.&nbsp;přesněji řečeno <strong>torch.float32</strong> (a prvky tenzoru
nejsou inicializovány, takže mohou obsahovat náhodné hodnoty):</p>

<pre>
tensor([[-2.4020e-35,  4.5600e-41, -2.4020e-35,  4.5600e-41],
        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],
        [ 1.5520e-33,  2.2060e-38, -2.2407e+29,  4.8069e-07]])
&lt;class 'torch.Tensor'&gt;
torch.float32
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Specifikace či změna typu prvků tenzoru</h2>

<p>Typy, které mají mít všechny prvky tenzoru, lze specifikovat již při jeho
konstrukci. Ukažme si to na jednoduchém příkladu s&nbsp;tenzorem nultého řádu
neboli skalárem. Budeme chtít, aby prvek byl typu <i>bfloat16</i> (viz též <a
href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">tento
článek</a>):</p>

<pre>
<i># konstrukce tenzoru nulteho radu (skalaru)</i>
v1 = torch.tensor(10, dtype=torch.bfloat16)
print(v1)
print(type(v1))
print(v1.dtype)
</pre>

<p>Výsledný tenzor, který získáme, by měl vypadat následovně:</p>

<pre>
tensor(10., dtype=torch.bfloat16)
<class 'torch.Tensor'>
torch.bfloat16
</pre>

<p>Ovšem v&nbsp;případě, že již máme k&nbsp;dispozici zkonstruovaný tenzor,
znamená změna typu jeho prvků vlastně vytvoření nového tenzoru (opět &ndash;
buď v&nbsp;paměti počítače nebo TPU). Tato konverze tenzorů se provádí metodou
<strong>type</strong>, které předáme požadovaný typ prvků nově vytvořeného
tenzoru:</p>

<pre>
<i># konstrukce tenzoru prvniho radu</i>
v2 = torch.arange(10, 20).type(torch.bfloat16)
print(v2)
print(type(v2))
print(v2.dtype)
&nbsp;
print()
&nbsp;
<i># konstrukce tenzoru druheho radu se zmenou typu prvku</i>
m1 = torch.Tensor(3, 4).type(torch.bfloat16)
print(m1)
print(type(m1))
print(m1.dtype)
</pre>

<p>Z&nbsp;výsledků je patrné, že se konverze skutečně podařila a že
v&nbsp;prvním případě došlo ke konverzi hodnot (ve druhém případě taktéž, ovšem
tenzor nebyl naplněn žádnými daty):</p>

<pre>
tensor([10., 11., 12., 13., 14., 15., 16., 17., 18., 19.],
       dtype=torch.bfloat16)
&lt;class 'torch.Tensor'&gt;
torch.bfloat16
&nbsp;
tensor([[ 1.6213e+19,  0.0000e+00,  1.6213e+19,  0.0000e+00],
        [ 1.7090e-02,  8.0889e-32,  1.1581e-22, -1.0402e+10],
        [ 8.3200e-32,  1.8529e-21,  3.8738e+20,  1.6941e-20]],
       dtype=torch.bfloat16)
&lt;class 'torch.Tensor'&gt;
torch.bfloat16
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. Manipulace s&nbsp;objektem typu <i>Storage</i></h2>

<p>Ukažme si nyní, jak je možné pro existující tenzor získat objekt typu
<strong>Storage</strong> a jak se dá tento objekt využít pro změnu hodnot
komponent tenzoru. Nejprve vytvoříme běžný vektor s&nbsp;deseti prvky:</p>

<pre>
v1 = torch.tensor([1, 255, 65535, 65536])
print(v1)
print(type(v1))
print(v1.dtype)
</pre>

<p>Vypíše se:</p>

<pre>
tensor([    1,   255, 65535, 65536])
&lt;class 'torch.Tensor'&gt;
torch.int64
</pre>

<p>Následně pro tento vektor získáme objekt typu <strong>Storage</strong> a
vypíšeme si jeho obsah (tedy data tvořící zdroj pro samotný tenzor):</p>

<pre>
<i># informace o typu Storage</i>
storage = v1.untyped_storage()
&nbsp;
print(storage)
print(type(storage))
</pre>

<p>Z&nbsp;vypsaných informací je patrné (resp.&nbsp;můžeme relativně snadno
odvodit), že je tenzor uložen v&nbsp;paměti počítače (a ne TPU) i způsob
uložení jeho čtyř prvků:</p>

<pre>
 1
 0
 0
 0
 0
 0
 0
 0
 255
 0
 0
 0
 0
 0
 0
 0
 255
 255
 0
 0
 0
 0
 0
 0
 0
 0
 1
 0
 0
 0
 0
 0
[torch.storage.UntypedStorage(device=cpu) of size 32]
&lt;class 'torch.storage.UntypedStorage'&gt;
</pre>

<p>Jednotlivé prvky (rozepsané na bajty) jsou tedy uloženy takto:</p>

<pre>
   1   0   0   0   0   0   0   0 = 1
 255   0   0   0   0   0   0   0 = 255
 255 255   0   0   0   0   0   0 = 255*256 + 255 = 65535
   0   0   1   0   0   0   0   0 = 1*256*256 = 65536
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. Způsob uložení prvků tenzoru druhého a třetího řádu</h2>

<p>Zajímavé (a později i užitečné) bude zjištění, jakým způsobem jsou interně
uloženy prvky tenzorů druhého a třetího řádu. Nejprve si ukažme tenzory druhého
řádu, které můžeme pro naše potřeby považovat za běžné matice. Zde se nabízí
dva možné způsoby uložení &ndash; po řádcích nebo po sloupcích. Vytvořme si
tedy jednoduchý tenzor pouze se šesti prvky. Navíc budeme ukládat pouze celá
osmibitová čísla, což nám čtení výsledků ještě více zjednoduší:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru druheho radu</i>
m2 = torch.tensor([[1,2,3], [4,5,6]]).type(torch.uint8)
print(m2)
print(type(m2))
print(m2.dtype)
&nbsp;
print()
&nbsp;
<i># informace o typu Storage</i>
storage = m2.untyped_storage()
&nbsp;
print(storage)
print(type(storage))
</pre>

<p>Tenzor je nejdříve vypsán ve své původní podobě:</p>

<pre>
tensor([[1, 2, 3],
        [4, 5, 6]], dtype=torch.uint8)
&lt;class 'torch.Tensor'&gt;
torch.uint8
</pre>

<p>Na dalších řádcích výstupu se zobrazí interní pohled na <i>storage</i>, ze
kterého je vidět uspořádání po řádcích (tedy &bdquo;podle céčka&ldquo;, nikoli
&bdquo;podle Fortanu&ldquo;):</p>

<pre>
&nbsp;
 1
 2
 3
 4
 5
 6
[torch.storage.UntypedStorage(device=cpu) of size 6]
&lt;class 'torch.storage.UntypedStorage'&gt;
</pre>

<p>Podobně můžeme postupovat pro tenzory třetího řádu, tedy z&nbsp;našeho
pohledu pro 3D pole:</p>

<pre>
import torch
&nbsp;
<i># konstrukce tenzoru tretiho radu</i>
c1 = torch.tensor([[[1,2,3], [4,5,6]], [[7,8,9], [10,11,12]]]).type(torch.int16)
print(c1)
print(type(c1))
print(c1.dtype)
&nbsp;
print()
&nbsp;
<i># informace o typu Storage</i>
storage = c1.untyped_storage()
&nbsp;
print(storage)
print(type(storage))
</pre>

<p>Výpis obsahu tenzoru:</p>

<pre>
tensor([[[ 1,  2,  3],
         [ 4,  5,  6]],
&nbsp;
        [[ 7,  8,  9],
         [10, 11, 12]]], dtype=torch.int16)
&lt;class 'torch.Tensor'&gt;
torch.int16
</pre>

<p>Interní uložení prvků tenzoru:</p>

<pre>
 1
 0
 2
 0
 3
 0
 4
 0
 5
 0
 6
 0
 7
 0
 8
 0
 9
 0
 10
 0
 11
 0
 12
 0
[torch.storage.UntypedStorage(device=cpu) of size 24]
&lt;class 'torch.storage.UntypedStorage'&gt;
</pre>

<p>Každý prvek je v&nbsp;tomto případě uložen v&nbsp;šestnácti bitech
(tj.&nbsp;na osmi bajtech), takže se vlastně jedná o následující pole:</p>

<pre>
 1 0
 2 0
 3 0
 4 0
 5 0
 6 0
 7 0
 8 0
 9 0
 10 0
 11 0
 12 0
</pre>

<p>Z&nbsp;výše uvedeného je patrné, že jsou prvky ukládány v&nbsp;pořadí od
nejnižší dimenze k&nbsp;dimenzi nejvyšší. Tomu je nutné přizpůsobit i
algoritmy.</p>



<p><a name="k08"></a></p>
<h2 id="k08">8. Konstrukce řezu (<i>slice</i>)</h2>

<p>Další zajímavou a velmi užitečnou operací, která produkuje pohled
(<i>view</i>) nad tenzorem, je operace nazvaná <strong>slice</strong> (původně
<strong>sub</strong>. Ta umožňuje z&nbsp;tenzoru získat určitou část,
s&nbsp;níž bude možné pracovat jako s&nbsp;dalším tenzorem. Nejprve se podíváme
na nejjednodušší použití této operace při práci s&nbsp;vektory. Vytvoříme si
vektor s&nbsp;deseti prvky od 1/1 do 1/10:</p>

<pre>
<i># konstrukce tenzoru</i>
v1 = torch.range(10, 20)
print(v1)
</pre>

<p>Vektor skutečně obsahuje deset prvků:</p>

<pre>
tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19])
</pre>

<p>Pomocí operace <strong>slice</strong> můžeme získat pohled na prvky ležícími
mezi specifikovaným dolním a horním indexem. Třetí až osmý prvek se tedy přečte
takto:</p>

<pre>
<i># konstrukce rezu z tenzoru prvniho radu</i>
v2 = v1[2:8]
print(v2)
</pre>

<p>Povšimněte si, že výsledkem operace <strong>slice</strong> je opět
plnohodnotný tenzor.</p>

<pre>
tensor([12, 13, 14, 15, 16, 17])
</pre>

<p><div class="rs-tip-major">Poznámka: prvek s&nbsp;nejvyšším specifikovaným
indexem není do výsledného tenzoru zahrnut.</div></p>

<p>Můžeme specifikovat i krok, tedy vlastně rozdíl v&nbsp;indexech prvků
z&nbsp;původního tenzoru:</p>

<pre>
<i># konstrukce rezu z tenzoru prvniho radu</i>
v3 = v1[2:8:2]
print(v3)
</pre>

<p>S&nbsp;výsledkem:</p>

<pre>
tensor([12, 14, 16])
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Specifikace záporných indexů a záporného kroku při provádění řezu</h2>

<p>Při zadávání indexů prvků je možné použít i záporné hodnoty. Jak je zvykem,
jsou tyto hodnoty chápány jako indexy od konce vektoru. Další příklad nám tedy
dá stejný výsledek, jako příklad předchozí (druhý prvek od začátku až druhý
prvek od konce; povšimněte si, proč by v&nbsp;praxi bylo více konzistentní
pracovat s&nbsp;indexy začínajícími od 1 a nikoli od 0):</p>

<pre>
<i># konstrukce rezu z tenzoru prvniho radu</i>
v4 = v1[-8:-2]
print(v4)
</pre>

<p>Výsledek:</p>

<pre>
tensor([12, 13, 14, 15, 16, 17])
</pre>

<p>Horní nebo dolní index lze vynechat. Za dolní index se v&nbsp;tomto případě
dosadí nula a za horní index počet prvků tenzoru:</p>

<pre>
<i># konstrukce rezu z tenzoru prvniho radu</i>
v5 = v1[:-2]
print(v5)
&nbsp;
<i># konstrukce rezu z tenzoru prvniho radu</i>
v6 = v1[-3:]
print(v6)
</pre>

<p>Nyní budou výsledky vypadat následovně:</p>

<pre>
tensor([10, 11, 12, 13, 14, 15, 16, 17])
tensor([17, 18, 19])
</pre>

<p>V&nbsp;případě, že je dolní index větší než index horní, vrátí se prázdný
tenzor (což je zcela legitimní datová struktura):</p>

<pre>
<i># konstrukce rezu z tenzoru prvniho radu</i>
v7 = v1[10:0]
print(v7)
</pre>

<p>Výsledný tenzor:</p>

<pre>
tensor([], dtype=torch.int64)
</pre>

<p>Mohlo by se zdát, že se <i>PyTorch</i> v&nbsp;případě řezů chová stejně,
jako knihovna <i>NumPy</i>. Ovšem v&nbsp;případě záporného kroku tomu tak
není:</p>

<pre>
<i># konstrukce rezu z tenzoru prvniho radu</i>
v8 = v1[10:1:-1]
print(v8)
</pre>

<p>Nyní dojde k&nbsp;vyhození výjimky:</p>

<pre>
Traceback (most recent call last):
  File "/home/ptisnovs/xy/src/tensor_slice_operation_1.py", line 32, in &lt;module&lt;
    v8 = v1[10:1:-1]
         ~~^^^^^^^^^
ValueError: step must be greater than zero
</pre>

<p>Proč tomu tak je, si vysvětlíme v&nbsp;navazujícím textu.</p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Operace řezu aplikovaná na matice (tenzory druhého řádu)</h2>

<p>Operaci <strong>slice</strong> je samozřejmě možné aplikovat i na matice a
tenzory vyšších řádů; výsledkem je vždy opět tenzor. Nejprve si pro ukázku
vytvoříme 2D matici a naplníme ji prvky s&nbsp;hodnotami 1 až 16:</p>

<pre>
<i># konstrukce tenzoru</i>
m1 = torch.Tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]])
print(m1)
</pre>

<p>Matice se skutečně vytvořila:</p>

<pre>
tensor([[ 1.,  2.,  3.,  4.],
        [ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.],
        [13., 14., 15., 16.]])
</pre>

<p>Pokusme se nyní vytvořit řez obsahující řádky 1 a 2 (vyšší index není do
výsledku zahrnut):</p>

<pre>
<i># konstrukce rezu - pres radky</i>
m2 = m1[1:3]
print(m2)
</pre>

<p>Výsledný tenzor by měl vypadat následovně:</p>

<pre>
tensor([[ 5.,  6.,  7.,  8.],
        [ 9., 10., 11., 12.]])
</pre>

<p>To ovšem není zdaleka vše, protože je možné specifikovat indexy i ve druhé
dimenzi. Následující příkaz tedy získá tenzor tvořený původním sloupcem číslo 1
a 2 (indexuje se od nuly):</p>

<pre>
<i># konstrukce rezu - pres sloupce</i>
m3 = m1[:,1:3]
print(m3)
</pre>

<p>Přesvědčme se, že tomu tak skutečně je:</p>

<pre>
tensor([[ 2.,  3.],
        [ 6.,  7.],
        [10., 11.],
        [14., 15.]])
</pre>

<p><div class="rs-tip-major">Poznámka: i v&nbsp;tomto případě lze použít
záporné indexy:</div></p>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu PyTorch lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td>tensor_constructor_scalar_1.py</td><td>konstrukce tenzoru nultého a prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_1.py</a></td></tr>
<tr><td> 2</td><td>tensor_constructor_scalar_2.py</td><td>inicializace tenzoru prvního řádu s&nbsp;jedním prvkem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_2.py</a></td></tr>
<tr><td> 3</td><td>tensor_constructor_vector_1.py</td><td>konstrukce tenzoru prvního řádu (tříprvkový vektor)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_1.py</a></td></tr>
<tr><td> 4</td><td>tensor_constructor_vector_2.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;inicializací prvků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_2.py</a></td></tr>
<tr><td> 5</td><td>tensor_constructor_vector_3.py</td><td>konstrukce tenzoru prvního řádu s&nbsp;využitím generátoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_3.py</a></td></tr>
<tr><td> 6</td><td>tensor_constructor_matrix_1.py</td><td>vytvoření a inicializace tenzoru druhého řádu, který může být reprezentován maticí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_1.py</a></td></tr>
<tr><td> 7</td><td>tensor_constructor_matrix_2.py</td><td>inicializace prvků matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_2.py</a></td></tr>
<tr><td> 8</td><td>tensor_constructor_3D_1.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_1.py</a></td></tr>
<tr><td> 9</td><td>tensor_constructor_3D_2.py</td><td>tenzor třetího řádu reprezentovaný &bdquo;3D maticí&ldquo; (jiná forma inicializace)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_2.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>10</td><td>tensor_constructor_scalar_zero.py</td><td>vynulování prvků tenzoru nultého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_scalar_zero.py</a></td></tr>
<tr><td>11</td><td>tensor_constructor_vector_zero.py</td><td>vynulování prvků tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_vector_zero.py</a></td></tr>
<tr><td>12</td><td>tensor_constructor_matrix_zero.py</td><td>vynulování prvků tenzoru druhého řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_matrix_zero.py</a></td></tr>
<tr><td>13</td><td>tensor_constructor_3D_zero.py</td><td>vynulování prvků tenzoru třetího řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_constructor_3D_zero.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>14</td><td>tensor_zeros_shape.py</td><td>použití konstruktoru <strong>zeros</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td>15</td><td>tensor_ones_shape.py</td><td>použití konstruktoru <strong>ones</strong> pro tenzory různých řádů a tvarů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td>16</td><td>tensor_eye.py</td><td>konstrukce jednotkové matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_eye.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>17</td><td>tensor_range.py</td><td>využití konstruktoru <strong>range</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_range.py</a></td></tr>
<tr><td>18</td><td>tensor_arange.py</td><td>využití konstruktoru <strong>arange</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_arange.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>19</td><td>tensor_shape.py</td><td>zjištění tvaru tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_shape.py</a></td></tr>
<tr><td>20</td><td>tensor_zeros_shape.py</td><td>zjištění tvaru tenzoru vytvořeného konstruktorem <strong>zeros</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_zeros_shape.py</a></td></tr>
<tr><td>21</td><td>tensor_ones_shape.py</td><td>zjištění tvaru tenzoru vytvořeného konstruktorem <strong>ones</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_ones_shape.py</a></td></tr>
<tr><td>22</td><td>tensor_read_dtype.py</td><td>zjištění, jakého typu jsou prvky tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_read_dtype.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_read_dtype.py</a></td></tr>
<tr><td>23</td><td>tensor_set_dtype.py</td><td>nastavení či změna typu prvků tenzoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_set_dtype.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_set_dtype.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>24</td><td>tensor_storage_1.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_1.py</a></td></tr>
<tr><td>25</td><td>tensor_storage_2.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_2.py</a></td></tr>
<tr><td>26</td><td>tensor_storage_3.py</td><td>získání datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_3.py</a></td></tr>
<tr><td>27</td><td>tensor_storage_casts.py</td><td>přetypování datové struktury se zdrojem dat pro tenzor</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_casts.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_storage_casts.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>28</td><td>tensor_slice_operation_1.py</td><td>konstrukce řezu z&nbsp;tenzoru prvního řádu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_1.py</a></td></tr>
<tr><td>29</td><td>tensor_slice_operation_2.py</td><td>konstrukce řezu z&nbsp;tenzoru druhého řádu (přes řádky a sloupce)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_2.py</a></td></tr>
<tr><td>30</td><td>tensor_slice_operation_3.py</td><td>konstrukce řezu s&nbsp;jeho následnou modifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_3.py</a></td></tr>
<tr><td>31</td><td>tensor_slice_operation_4.py</td><td>konstrukce řezu s&nbsp;jeho následnou modifikací (odlišné operace od předchozího příkladu)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_slice_operation_4.py</a></td></tr>
<tr><td>32</td><td>tensor_is_slice.py</td><td>test základních vlastností řezů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_is_slice.py">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/tensor_is_slice.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>33</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/">https://github.com/tisnik/most-popular-python-libs/blob/master/PyTorch/</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Seriál Programovací jazyk Lua na Rootu</ br>
<a href="https://www.root.cz/serialy/programovaci-jazyk-lua/">https://www.root.cz/serialy/programovaci-jazyk-lua/</a>
</li>

<li>PDM: moderní správce balíčků a virtuálních prostředí Pythonu</ br>
<a href="https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/">https://www.root.cz/clanky/pdm-moderni-spravce-balicku-a-virtualnich-prostredi-pythonu/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008</ br>
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008/</a>
</li>

<li>Interní reprezentace numerických hodnot: od skutečného počítačového pravěku po IEEE 754–2008 (dokončení)</ br>
<a href="https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/">https://www.root.cz/clanky/interni-reprezentace-numerickych-hodnot-od-skutecneho-pocitacoveho-praveku-po-ieee-754-2008-dokonceni/</a>
</li>

<li>Brain Floating Point &ndash; nový formát uložení čísel pro strojové učení a chytrá čidla</ br>
<a href="https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/">https://www.root.cz/clanky/brain-floating-point-ndash-novy-format-ulozeni-cisel-pro-strojove-uceni-a-chytra-cidla/</a>
</li>

<li>Stránky projektu PyTorch</ br>
<a href="https://pytorch.org/">https://pytorch.org/</a>
</li>

<li>Informace o instalaci PyTorche</ br>
<a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a>
</li>

<li>Tenzor (Wikipedia)</ br>
<a href="https://cs.wikipedia.org/wiki/Tenzor">https://cs.wikipedia.org/wiki/Tenzor</a>
</li>

<li>Introduction to Tensors</ br>
<a href="https://www.youtube.com/watch?v=uaQeXi4E7gA">https://www.youtube.com/watch?v=uaQeXi4E7gA</a>
</li>

<li>Introduction to Tensors: Transformation Rules</ br>
<a href="https://www.youtube.com/watch?v=j6DazQDbEhQ">https://www.youtube.com/watch?v=j6DazQDbEhQ</a>
</li>

<li>Tensor Attributes</ br>
<a href="https://pytorch.org/docs/stable/tensor_attributes.html">https://pytorch.org/docs/stable/tensor_attributes.html</a>
</li>

<li>Tensors Explained Intuitively: Covariant, Contravariant, Rank </ br>
<a href="https://www.youtube.com/watch?v=CliW7kSxxWU">https://www.youtube.com/watch?v=CliW7kSxxWU</a>
</li>

<li>What is the relationship between PyTorch and Torch?</ br>
<a href="https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch">https://stackoverflow.com/questions/44371560/what-is-the-relationship-between-pytorch-and-torch</a>
</li>

<li>What is a tensor anyway?? (from a mathematician)</ br>
<a href="https://www.youtube.com/watch?v=K7f2pCQ3p3U">https://www.youtube.com/watch?v=K7f2pCQ3p3U</a>
</li>

<li>Visualization of tensors - part 1 </ br>
<a href="https://www.youtube.com/watch?v=YxXyN2ifK8A">https://www.youtube.com/watch?v=YxXyN2ifK8A</a>
</li>

<li>Visualization of tensors - part 2A</ br>
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>Visualization of tensors - part 2B</ br>
<a href="https://www.youtube.com/watch?v=A95jdIuUUW0">https://www.youtube.com/watch?v=A95jdIuUUW0</a>
</li>

<li>What the HECK is a Tensor?!?</ br>
<a href="https://www.youtube.com/watch?v=bpG3gqDM80w">https://www.youtube.com/watch?v=bpG3gqDM80w</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>An Introduction to Tensors<br />
<a href="https://math.stackexchange.com/questions/10282/an-introduction-to-tensors">https://math.stackexchange.com/questions/10282/an-introduction-to-tensors</a>
</li>

<li>Differences between a matrix and a tensor<br />
<a href="https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor">https://math.stackexchange.com/questions/412423/differences-between-a-matrix-and-a-tensor</a>
</li>

<li>Qualitatively, what is the difference between a matrix and a tensor?<br />
<a href="https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?">https://math.stackexchange.com/questions/1444412/qualitatively-what-is-the-difference-between-a-matrix-and-a-tensor?</a>
</li>

<li>Tensors for Neural Networks, Clearly Explained!!!</ br>
<a href="https://www.youtube.com/watch?v=L35fFDpwIM4">https://www.youtube.com/watch?v=L35fFDpwIM4</a>
</li>

<li>Tensor Processing Unit</ br>
<a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit">https://en.wikipedia.org/wiki/Tensor_Processing_Unit</a>
</li>

<li>Třída Storage</ br>
<a href="http://docs.pytorch.wiki/en/storage.html">http://docs.pytorch.wiki/en/storage.html</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

