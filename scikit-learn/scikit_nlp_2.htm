<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">1. Využití knihovny scikit-learn pro zpracování a analýzu přirozeného jazyka (NLP), 2.část</a></p>
<p><a href="#k02">2. Vektorizace sady textů (korpusu) s&nbsp;využitím třídy <strong>CountVectorizer</strong></a></p>
<p><a href="#k03">3. Zkonstruovaná tabulka (slovník) pro zpětný převod indexů na slova</a></p>
<p><a href="#k04">4. Význam parametru <i>cut off</i> pro vektorizaci</a></p>
<p><a href="#k05">5. Význam parametru <i>max_df</i> pro vektorizaci</a></p>
<p><a href="#k06">6. Zpětný převod matice s&nbsp;frekvencí slov na slova</a></p>
<p><a href="#k07">7. Odstranění stopslov v&nbsp;průběhu vektorizace</a></p>
<p><a href="#k08">8. Korektně provedený zpětný převod vektorů na dokumenty</a></p>
<p><a href="#k09">9. Tf-idf: relevance a specifičnost jednotlivých slov vztažená k&nbsp;aktuálnímu dokumentu i k&nbsp;celému korpusu</a></p>
<p><a href="#k10">10. Základní vlastnosti výpočtu relevance slov</a></p>
<p><a href="#k11">11. Další příklady výpočtu <i>tf-idf</i></a></p>
<p><a href="#k12">12. Realizace výpočtu matice s&nbsp;relevancí jednotlivých slov</a></p>
<p><a href="#k13">13. Vliv většího množství dokumentů se stejnými slovy v&nbsp;korpusu na vypočtenou relevanci slov</a></p>
<p><a href="#k14">14. Přímé využití třídy <strong>TfidfVectorizer</strong></a></p>
<p><a href="#k15">15. Nalezení textu, který se nejvíce blíží hledanému vzorku</a></p>
<p><a href="#k16">16. Realizace algoritmu pro nalezení nejpodobnější věty</a></p>
<p><a href="#k17">17. Úskalí algoritmu pro hledání podobných textů</a></p>
<p><a href="#k18">18. Vektorizovaný text a neuronové sítě</a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Využití knihovny scikit-learn pro zpracování a analýzu přirozeného jazyka (NLP), 2.část</h2>

<p>Na <a href="https://www.root.cz/clanky/vyuziti-knihovny-scikit-learn-pro-zpracovani-a-analyzu-prirozeneho-jazyka-nlp/">úvodní
článek</a> o využití knihovny <i>scikit-learn</i> pro zpracování přirozeného
jazyka (<i>Natural Language Processing</i> &ndash; <i>NLP</i>) dnes navážeme.
Vysvětlíme si algoritmy pro <i>vektorizaci</i> jazykového korpusu, což je
proces, při němž se z&nbsp;jednotlivých textových dokumentů (každý dokument je
představován řetězcem) konstruuje matice s&nbsp;numerickými hodnotami. Tyto
hodnoty nějakým způsobem reprezentují původní korpus, resp.&nbsp;přesněji řečeno
jeho vybrané typické znaky. Navíc tato matice může v&nbsp;sobě mít zakódovány i
další vlastnosti, například specifičnost jednotlivých slov v&nbsp;kontextu
celého korpusu atd. Tato matice se používá jak pro trénink a validaci modelů
(včetně modelů založených na neuronové síti), tak i pro jednodušší operace
&ndash; nalezení nejbližšího textu (<i>text similarity</i>). I s&nbsp;tímto
algoritmem se dnes ve stručnosti seznámíme.</p>




<p><a name="k02"></a></p>
<h2 id="k02">2. Vektorizace sady textů (korpusu) s&nbsp;využitím třídy <strong>CountVectorizer</strong></h2>

<p>Prvním úkolem, který je nutné provést ještě předtím, než (nějakým způsobem)
natrénujeme a následně zvalidujeme model, je převod sady textů (ty označujeme
jako <i>korpus</i>) do numerické podoby, konkrétně do 2D matice. Nejjednodušším
postupem, který se v&nbsp;této oblasti používá, je konstrukce 2D matice, která
má počet řádků odpovídající počtu vstupních dokumentů a počet sloupců odpovídá
počtu všech unikátních slov ze všech vstupních dokumentů (tedy z&nbsp;celého
korpusu). Do takové matice můžeme zapsat počty jednotlivých slov ve vstupních
dokumentech &ndash; což ovšem znamená, že ztratíme kontextovou informaci o tom,
jaká je sekvence slov v&nbsp;původních dokumentech. Výše uvedený algoritmus je
v&nbsp;knihovně <i>scikit-learn</i> realizován třídou
<strong>CountVectorizer</strong>. Ukažme si její použití při vektorizaci
korpusu, v&nbsp;němž je pouze šest vět:</p>

<pre>
<i># Vektorizace sady textů (korpusu)</i>
&nbsp;
from sklearn.feature_extraction.text import CountVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = CountVectorizer(min_df=1)
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># výsledek vektorizace - řídká matice</i>
print(vectorized)
print()
&nbsp;
<i># převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
print(as_array)
&nbsp;
<i># získat vektor z 2D pole</i>
flattened = as_array.flatten()
&nbsp;
<i># unikátní prvky a jejich frekvence</i>
unique, counts = np.unique(flattened, return_counts=True)
&nbsp;
print("Word count statistic:")
print(np.asarray((unique, counts)).T)
</pre>

<p>Samotná vektorizace je realizována následovně:</p>

<pre>
<i># provedení vektorizace korpusu</i>
vectorizer = CountVectorizer(min_df=1)
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># výsledek vektorizace - řídká matice</i>
print(vectorized)
</pre>

<p>Výsledkem vektorizace je řídká matice (<i>sparse matrix</i>), která by měla
vypadat takto:</p>

<pre>
  (0, 13)       1
  (0, 0)        2
  (0, 2)        2
  (0, 17)       1
  (0, 19)       1
  (1, 0)        1
  (1, 2)        1
  (1, 8)        1
  (1, 11)       1
  (1, 22)       1
  (1, 10)       1
  (1, 4)        1
  (2, 0)        2
  (2, 2)        1
  (2, 15)       1
  (2, 7)        1
  (2, 23)       1
  (2, 18)       1
  (3, 23)       1
  (3, 18)       1
  (3, 20)       1
  (3, 21)       1
  (3, 12)       1
  (4, 22)       1
  (4, 18)       1
  (4, 21)       1
  (4, 12)       1
  (4, 9)        1
  (4, 3)        1
  (4, 1)        1
  (4, 6)        1
  (5, 2)        1
  (5, 18)       1
  (5, 1)        1
  (5, 6)        1
  (5, 16)       1
  (5, 14)       1
  (5, 24)       1
  (5, 5)        1
</pre>

<p>Řídkou matici si můžeme nechat převést na běžnou matici pomocí metody
<strong>toarray</strong>:</p>

<pre>
<i># převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
print(as_array)
</pre>

<p>Výsledná matice:</p>

<pre>
[[2 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0]
 [1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0]
 [2 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0]
 [0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0]
 [0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1]]
</pre>

<p>Taktéž si můžeme nechat zobrazit statistické informace &ndash; frekvence
jednotlivých prvků v&nbsp;celé matici, která obsahuje 25&times;6=150 prvků:</p>

<pre>
<i># získat vektor z 2D pole</i>
flattened = as_array.flatten()
&nbsp;
<i># unikátní prvky a jejich frekvence</i>
unique, counts = np.unique(flattened, return_counts=True)
&nbsp;
print("Word count statistic:")
print(np.asarray((unique, counts)).T)
</pre>

<p>Ze statistiky je patrné, že matice skutečně obsahuje mnoho nulových prvků a
proto je její reprezentace řídkou maticí užitečná (první sloupec zobrazuje
hodnotu prvku, druhý počet prvků s&nbsp;touto hodnotou):</p>

<pre>
Word count statistic:
[[  0 111]
 [  1  36]
 [  2   3]]
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. Zkonstruovaná tabulka (slovník) pro zpětný převod indexů na slova</h2>

<p>Ve skutečnosti není výsledkem vektorizace pouze tabulka s&nbsp;četnostmi
jednotlivých slov, protože pouze z&nbsp;této informace bychom nezjistili, o
jaká konkrétní slova se jedná. Musíme mít k&nbsp;dispozici i slovník,
z&nbsp;něhož bude patrné, že slovo na první pozici (první sloupec matice) je
například &bdquo;ahoj&ldquo; a druhé slovo (druhý sloupec matice) je
&bdquo;zeď&ldquo;. I k&nbsp;těmto údajům ve skutečnosti máme přístup, protože
z&nbsp;objektu představujícího výsledek vektorizace lze metodou
<strong>get_feature_names_out</strong> přečíst jména takzvaných atributů
(<i>features</i>), což je onen požadovaný slovník:</p>

<pre>
<i># Tabulka pro zpětný převod indexů na slova</i>
&nbsp;
from sklearn.feature_extraction.text import CountVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = CountVectorizer(min_df=1)
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># výsledek vektorizace - řídká matice</i>
print(vectorized)
print()
&nbsp;
<i># slova pro dekódování vah</i>
feature_names = <strong>vectorizer.get_feature_names_out()</strong>
print("Feature names count:", len(feature_names))
print()
&nbsp;
<i># tabulka indexů slov a vlastních slov</i>
print("Index Feature")
for i, feature_name in enumerate(feature_names):
    print(f"{i:2}    {feature_name}")
&nbsp;
print()
&nbsp;
<i># převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
print(as_array)
</pre>

<p>V&nbsp;našem konkrétním případě bude slovník obsahovat 25 slov získaných ze
všech šesti dokumentů (vět) korpusu:</p>

<pre>
Feature names count: 25
&nbsp;
Index Feature
 0    an
 1    and
 2    apple
 3    are
 4    away
 5    be
 6    blue
 7    compare
 8    day
 9    docs
10    doctor
11    keeps
12    learn
13    like
14    logo
15    never
16    new
17    or
18    orange
19    pie
20    prefer
21    scikit
22    the
23    to
24    will
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. Význam parametru <i>cut off</i> pro vektorizaci</h2>

<p>Připomeňme si, že při vektorizaci se konstruktoru
<strong>CountVectorizer</strong> předával i parametr <strong>min_df</strong>,
které je ovšem znám spíše pod označením <i>cut off</i>:</p>

<pre>
<i># provedení vektorizace korpusu</i>
vectorizer = CountVectorizer(min_df=1)
vectorized = vectorizer.fit_transform(corpus)
</pre>

<p>Tímto parametrem se určuje, jaký minimální počet výskytů musí nějaké slovo
mít, aby se uložilo do slovníku. Výchozí hodnotou je 1, tj.&nbsp;do slovníku je
uloženo jakékoli nalezené slovo. Ovšem pokud například nastavíme tento parametr
na 3, bude slovník menší &ndash; bude totiž obsahovat pouze slova, která byla
nalezena minimálně třikrát atd. Ukažme si vliv tohoto parametru jak na velikost
slovníku, tak i na rozměry matice vytvořené vektorizací:</p>

<pre>
<i># Tabulka pro zpětný převod indexů na slova, role parametru cut off.</i>
&nbsp;
from sklearn.feature_extraction.text import CountVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
for cut_off in range(1, 7):
    print("Cut off set to:", cut_off)
    print()
    <i># provedení vektorizace korpusu</i>
    vectorizer = <strong>CountVectorizer(min_df=cut_off)</strong>
    vectorized = vectorizer.fit_transform(corpus)
&nbsp;
    <i># slova pro dekódování vah</i>
    feature_names = vectorizer.get_feature_names_out()
    print("Feature names count:", len(feature_names))
    print()
&nbsp;
    <i># tabulka indexů slov a vlastních slov</i>
    print("Index Feature")
    for i, feature_name in enumerate(feature_names):
        print(f"{i:2}    {feature_name}")
&nbsp;
    print()
&nbsp;
    <i># převod na běžnou matici</i>
    as_array = vectorized.toarray()
&nbsp;
    <i># zobrazení výsledku v novém formátu</i>
    print(as_array)
    print("-" * 100)
</pre>

<p>Povšimněte si, jak se slovník i matice zmenšuje společně s&nbsp;rostoucí hodnotou <i>cut off</i>:</p>

<pre>
Cut off set to: 1
&nbsp;
Feature names count: 25
&nbsp;
Index Feature
 0    an
 1    and
 2    apple
 3    are
 4    away
 5    be
 6    blue
 7    compare
 8    day
 9    docs
10    doctor
11    keeps
12    learn
13    like
14    logo
15    never
16    new
17    or
18    orange
19    pie
20    prefer
21    scikit
22    the
23    to
24    will
&nbsp;
[[2 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0]
 [1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0]
 [2 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0]
 [0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0]
 [0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1]]
----------------------------------------------------------------------------------------------------
Cut off set to: 2
&nbsp;
Feature names count: 9
&nbsp;
Index Feature
 0    an
 1    and
 2    apple
 3    blue
 4    learn
 5    orange
 6    scikit
 7    the
 8    to
&nbsp;
[[2 0 2 0 0 0 0 0 0]
 [1 0 1 0 0 0 0 1 0]
 [2 0 1 0 0 1 0 0 1]
 [0 0 0 0 1 1 1 0 1]
 [0 1 0 1 1 1 1 1 0]
 [0 1 1 1 0 1 0 0 0]]
----------------------------------------------------------------------------------------------------
Cut off set to: 3
&nbsp;
Feature names count: 3
&nbsp;
Index Feature
 0    an
 1    apple
 2    orange
&nbsp;
[[2 2 0]
 [1 1 0]
 [2 1 1]
 [0 0 1]
 [0 0 1]
 [0 1 1]]
----------------------------------------------------------------------------------------------------
Cut off set to: 4
&nbsp;
Feature names count: 2
&nbsp;
Index Feature
 0    apple
 1    orange
&nbsp;
[[2 0]
 [1 0]
 [1 1]
 [0 1]
 [0 1]
 [1 1]]
</pre>

<p>Pro větší hodnoty <i>cut off</i> se již vyhodí výjimka, protože by slovník
byl prázdný a matice tudíž měla 0 sloupců:</p>

<pre>
----------------------------------------------------------------------------------------------------
Cut off set to: 5
&nbsp;
Traceback (most recent call last):
  File "/home/ptisnovs/xy/199_cut_off.py", line 20, in &lt;module&gt;
    vectorized = vectorizer.fit_transform(corpus)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ptisnovs/.local/lib/python3.11/site-packages/sklearn/base.py", line 1473, in wrapper
    return fit_method(estimator, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ptisnovs/.local/lib/python3.11/site-packages/sklearn/feature_extraction/text.py", line 1385, in fit_transform
    X = self._limit_features(
        ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ptisnovs/.local/lib/python3.11/site-packages/sklearn/feature_extraction/text.py", line 1237, in _limit_features
    raise ValueError(
ValueError: After pruning, no terms remain. Try a lower min_df or a higher max_df.
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Význam parametru <i>max_df</i> pro vektorizaci</h2>

<p>Průběh vektorizace lze ovlivnit i parametrem <i>max df</i>, který má opačný
význam, než <i>cut off</i>. Umožňuje nám totiž odstranit ze slovníku ta slova,
která mají příliš vysoký výskyt. Taková slova (pravděpodobně) nebudou mít vliv
na přesnost naučeného modelu a naopak jejich odstraněním můžeme významně
zmenšit velikost výsledné matice. Ukažme si nejdříve, jak se tento parametr
předává konstruktoru <strong>CountVectorizer</strong>:</p>

<pre>
<i># Tabulka pro zpětný převod indexů na slova role parametru max_df</i>
&nbsp;
from sklearn.feature_extraction.text import CountVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
for max_df in range(1, 4):
    print("max_df set to:", max_df)
    print()
    <i># provedení vektorizace korpusu</i>
    vectorizer = <strong>CountVectorizer(min_df=1, max_df=max_df)</strong>
    vectorized = vectorizer.fit_transform(corpus)
&nbsp;
    <i># slova pro dekódování vah</i>
    feature_names = vectorizer.get_feature_names_out()
    print("Feature names count:", len(feature_names))
    print()
&nbsp;
    <i># tabulka indexů slov a vlastních slov</i>
    print("Index Feature")
    for i, feature_name in enumerate(feature_names):
        print(f"{i:2}    {feature_name}")
&nbsp;
    print()
&nbsp;
    <i># převod na běžnou matici</i>
    as_array = vectorized.toarray()
&nbsp;
    <i># zobrazení výsledku v novém formátu</i>
    print(as_array)
    print("-" * 100)
</pre>

<p>První slovník bude obsahovat pouze šestnáct slov:</p>

<pre>
----------------------------------------------------------------------------------------------------
max_df set to: 1
&nbsp;
Feature names count: 16
&nbsp;
Index Feature
 0    are
 1    away
 2    be
 3    compare
 4    day
 5    docs
 6    doctor
 7    keeps
 8    like
 9    logo
10    never
11    new
12    or
13    pie
14    prefer
15    will
&nbsp;
[[0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0]
 [0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0]
 [0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]
 [1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1]]
</pre>

<p>Druhý slovník již bude mít 22 slov (přidáno bylo například frekventované
slovo &bdquo;and&ldquo; a taktéž &bdquo;the&ldquo; atd.):</p>

<pre>
----------------------------------------------------------------------------------------------------
max_df set to: 2
&nbsp;
Feature names count: 22
&nbsp;
Index Feature
 0    and
 1    are
 2    away
 3    be
 4    blue
 5    compare
 6    day
 7    docs
 8    doctor
 9    keeps
10    learn
11    like
12    logo
13    never
14    new
15    or
16    pie
17    prefer
18    scikit
19    the
20    to
21    will
&nbsp;
[[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0]
 [0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0]
 [0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0]
 [1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0]
 [1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1]]
</pre>

<p>A konečně třetí slovník bude mít 23 slov, a to včetně členu &bdquo;an&ldquo;:</p>

<pre>
----------------------------------------------------------------------------------------------------
max_df set to: 3
&nbsp;
Feature names count: 23
&nbsp;
Index Feature
 0    an
 1    and
 2    are
 3    away
 4    be
 5    blue
 6    compare
 7    day
 8    docs
 9    doctor
10    keeps
11    learn
12    like
13    logo
14    never
15    new
16    or
17    pie
18    prefer
19    scikit
20    the
21    to
22    will
&nbsp;
[[2 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0]
 [1 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0]
 [2 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0]
 [0 1 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1 1 0 0]
 [0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1]]
----------------------------------------------------------------------------------------------------
</pre>

<p><div class="rs-tip-major">Poznámka: oba parametry ovlivňující vektorizaci
lze pochopitelně kombinovat.</div></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Zpětný převod matice s&nbsp;frekvencí slov na slova</h2>

<p>V&nbsp;případě, že máme k&nbsp;dispozici matici s&nbsp;frekvencí slov (řádky
přitom odpovídají původním dokumentům, sloupce pak odpovídají pořadí slova ve
slovníku), můžeme se pokusit o realizaci zpětného převodu matice na původní
dokumenty. Již nyní ovšem víme, že nezískáme původní věty (dokumenty), ale
pouze skupinu slov tvořících původní větu. To by však mohlo pro mnoho účelů
dostačovat. Samotný převod je jednoduchý a je založen na detekci těch prvků
v&nbsp;matici, které mají nenulovou hodnotu:</p>

<pre>
<i># Realizace zpětného převodu na slova</i>
&nbsp;
from sklearn.feature_extraction.text import CountVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = CountVectorizer(min_df=1)
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># výsledek vektorizace - řídká matice</i>
print(vectorized)
print()
&nbsp;
<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
print("Feature names count:", len(feature_names))
print()
&nbsp;
<i># tabulka indexů slov a vlastních slov</i>
print("Index Feature")
for i, feature_name in enumerate(feature_names):
    print(f"{i:2}    {feature_name}")
&nbsp;
print()
&nbsp;
<i># převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
print(as_array)
print()
&nbsp;
&nbsp;
def <strong>array_to_words</strong>(feature_names, as_array):
    <i>"""Převod matice s frekvencemi slov zpět na slova."""</i>
    return list(
        feature_names[index]
        for index, included in enumerate(as_array[i])
        if included == 1
    )
&nbsp;
&nbsp;
<i># zpětný převod vět</i>
for i in range(len(corpus)):
    print("Original: ", corpus[i])
    print("Vectors:  ", as_array[i])
    print("As words: ", array_to_words(feature_names, as_array))
    print()
</pre>

<p>Výše uvedená funkce <strong>array_to_words</strong> sice není napsána
korektně (a pokuste se sami zjistit, proč tomu tak je &ndash; vysvětlení podáme
později), ovšem dokáže z&nbsp;vektoru 25 hodnot, tedy z&nbsp;jednoho řádku
tabulky, částečně &bdquo;zrekonstruovat&ldquo; původní věty, resp.&nbsp;slova
použitá v&nbsp;těchto větách:</p>

<pre>
Original:  I'd like an apple or an apple pie
Vectors:   [2 0 2 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0]
As words:  ['like', 'or', 'pie']
&nbsp;
Original:  An apple a day keeps the doctor away
Vectors:   [1 0 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 1 0 0]
As words:  ['an', 'apple', 'away', 'day', 'doctor', 'keeps', 'the']
&nbsp;
Original:  Never compare an apple to an orange
Vectors:   [2 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 1 0]
As words:  ['apple', 'compare', 'never', 'orange', 'to']
&nbsp;
Original:  I prefer scikit-learn to orange
Vectors:   [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 1 0]
As words:  ['learn', 'orange', 'prefer', 'scikit', 'to']
&nbsp;
Original:  The scikit-learn docs are orange and blue
Vectors:   [0 1 0 1 0 0 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 1 1 0 0]
As words:  ['and', 'are', 'blue', 'docs', 'learn', 'orange', 'scikit', 'the']
&nbsp;
Original:  New apple logo will be orange and blue
Vectors:   [0 1 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 0 0 0 0 0 1]
As words:  ['and', 'apple', 'be', 'blue', 'logo', 'new', 'orange', 'will']
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. Odstranění stopslov v&nbsp;průběhu vektorizace</h2>

<p>Již minule jsme se v&nbsp;rychlosti zmínili o takzvaných <i>stopslovech</i>
neboli anglicky <i>stopwords</i>. Jedná se většinou o slova, která ve větách
mají spíše jen gramatický význam, ovšem nenesou příliš mnoho dalších informací.
V&nbsp;angličtině se v&nbsp;první řadě jedná o členy, ale může se jednat i o
předložky atd. Taková slova <i>většinou</i> můžeme ze slovníku odstranit
(resp.&nbsp;je vůbec do slovníku nepřidávat), aniž by to změnilo kvalitu
výsledného modelu. Pokusme se tedy tuto operaci provést při vektorizaci našeho
malého korpusu složeného ze šesti vět:</p>

<pre>
<i># provedení vektorizace korpusu</i>
vectorizer = <strong>CountVectorizer(min_df=1, stop_words="english")</strong>
vectorized = vectorizer.fit_transform(corpus)
</pre>

<p>Upravený skript bude vypadat následovně:</p>

<pre>
<i># Realizace zpětného převodu na slova, odstranění stopslov</i>
&nbsp;
from sklearn.feature_extraction.text import CountVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = <strong>CountVectorizer(min_df=1, stop_words="english")</strong>
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># výsledek vektorizace - řídká matice</i>
print(vectorized)
print()
&nbsp;
<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
print("Feature names count:", len(feature_names))
print()
&nbsp;
<i># tabulka indexů slov a vlastních slov</i>
print("Index Feature")
for i, feature_name in enumerate(feature_names):
    print(f"{i:2}    {feature_name}")
&nbsp;
print()
&nbsp;
<i># převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
print(as_array)
print()
&nbsp;
&nbsp;
def <strong>array_to_words</strong>(feature_names, as_array):
    <i>"""Převod matice s frekvencemi slov zpět na slova."""</i>
    return list(
        feature_names[index]
        for index, included in enumerate(as_array[i])
        if included == 1
    )
&nbsp;
&nbsp;
<i># zpětný převod vět</i>
for i in range(len(corpus)):
    print("Original: ", corpus[i])
    print("Vectors:  ", as_array[i])
    print("As words: ", array_to_words(feature_names, as_array))
    print()
</pre>

<p>Nyní bude slovník menší, protože namísto 25 slov bude obsahovat jen slov
šestnáct:</p>

<pre>
Feature names count: 16
&nbsp;
Index Feature
 0    apple
 1    away
 2    blue
 3    compare
 4    day
 5    docs
 6    doctor
 7    keeps
 8    learn
 9    like
10    logo
11    new
12    orange
13    pie
14    prefer
15    scikit
</pre>

<p>Stejně tak se zmenší matice získaná vektorizací:</p>

<pre>
[[2 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]
 [1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0]
 [1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]
 [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1]
 [0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1]
 [1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0]]
</pre>

<p>Při obnově původních vět nyní budou pochopitelně všechna stopslova chybět
&ndash; tuto informaci jsme ztratili při vektorizaci:</p>

<pre>
Original:  I'd like an apple or an apple pie
Vectors:   [2 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]
As words:  ['like', 'pie']
&nbsp;
Original:  An apple a day keeps the doctor away
Vectors:   [1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0]
As words:  ['apple', 'away', 'day', 'doctor', 'keeps']
&nbsp;
Original:  Never compare an apple to an orange
Vectors:   [1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]
As words:  ['apple', 'compare', 'orange']
&nbsp;
Original:  I prefer scikit-learn to orange
Vectors:   [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1]
As words:  ['learn', 'orange', 'prefer', 'scikit']
&nbsp;
Original:  The scikit-learn docs are orange and blue
Vectors:   [0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1]
As words:  ['blue', 'docs', 'learn', 'orange', 'scikit']
&nbsp;
Original:  New apple logo will be orange and blue
Vectors:   [1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0]
As words:  ['apple', 'blue', 'logo', 'new', 'orange']
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. Korektně provedený zpětný převod vektorů na dokumenty</h2>

<p>Předchozí dva demonstrační příklady vypisovaly pouze ta slova, která se
v&nbsp;daném dokumentu (v&nbsp;našem případě v&nbsp;jedné větě) vyskytovaly
pouze (přesně) jedenkrát. Ovšem pochopitelně není možné ignorovat opakující se
slova, takže funkci <strong>array_to_words</strong> je nutné nepatrně
modifikovat do následující podoby:</p>

<pre>
def <strong>array_to_words</strong>(feature_names, as_array):
    <i>"""Převod matice s frekvencemi slov zpět na slova."""</i>
    return list(
        feature_names[index]
        for index, included in enumerate(as_array[i])
        if included &gt;= 1
    )
</pre>

<p>Upravený skript:</p>

<pre>
<i># Realizace zpětného převodu na slova (korektní práce s opakujícími se slovy)</i>
&nbsp;
from sklearn.feature_extraction.text import CountVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = CountVectorizer(min_df=1, stop_words="english")
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># výsledek vektorizace - řídká matice</i>
print(vectorized)
print()
&nbsp;
<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
print("Feature names count:", len(feature_names))
print()
&nbsp;
<i># tabulka indexů slov a vlastních slov</i>
print("Index Feature")
for i, feature_name in enumerate(feature_names):
    print(f"{i:2}    {feature_name}")
&nbsp;
print()
&nbsp;
<i># převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
print(as_array)
print()
&nbsp;
&nbsp;
def <strong>array_to_words</strong>(feature_names, as_array):
    <i>"""Převod matice s frekvencemi slov zpět na slova."""</i>
    return list(
        feature_names[index]
        for index, included in enumerate(as_array[i])
        if included &gt;= 1
    )
&nbsp;
&nbsp;
<i># zpětný převod vět</i>
for i in range(len(corpus)):
    print("Original: ", corpus[i])
    print("Vectors:  ", as_array[i])
    print("As words: ", array_to_words(feature_names, as_array))
    print()
</pre>

<p>Nyní jsou již výsledky korektní &ndash; zpětně zrekonstruované věty bez
stopslov a bez správného pořadí slov:</p>

<pre>
Original:  I'd like an apple or an apple pie
Vectors:   [2 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]
As words:  ['apple', 'like', 'pie']
&nbsp;
Original:  An apple a day keeps the doctor away
Vectors:   [1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0]
As words:  ['apple', 'away', 'day', 'doctor', 'keeps']
&nbsp;
Original:  Never compare an apple to an orange
Vectors:   [1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]
As words:  ['apple', 'compare', 'orange']
&nbsp;
Original:  I prefer scikit-learn to orange
Vectors:   [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1]
As words:  ['learn', 'orange', 'prefer', 'scikit']
&nbsp;
Original:  The scikit-learn docs are orange and blue
Vectors:   [0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1]
As words:  ['blue', 'docs', 'learn', 'orange', 'scikit']
&nbsp;
Original:  New apple logo will be orange and blue
Vectors:   [1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0]
As words:  ['apple', 'blue', 'logo', 'new', 'orange']
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Tf-idf: relevance a specifičnost jednotlivých slov vztažená k&nbsp;aktuálnímu dokumentu i k&nbsp;celému korpusu</h2>

<p>Již minule jsme se zmínili o algoritmu pro výpočet relevance jednotlivých
slov. Zjednodušeně řečeno se jedná o numerickou hodnotu určující, do jaké míry
je nějaké slovo specifické pro určitý dokument. Slova s&nbsp;nízkým ohodnocením
jsou příliš obecná a vyskytují se v&nbsp;mnoha dokumentech. A naopak slova
s&nbsp;vysokým ohodnocením jsou specifická pro menší počet dokumentů (či
dokonce pro jediný dokument). A právě taková slova mají význam jak pro hledání
nejbližšího dokumentu, tak i pro trénink modelů.</p>

<p>Můžeme si to ukázat na příkladu. Mějme jazykový korpus, ve kterém budou
uloženy texty 1000 knih v&nbsp;angličtině. Slovo &bdquo;the&ldquo; bude mít
velmi nízkou specifičnost, protože se vyskytuje v&nbsp;každém dokumentu
(knize). Naopak slovo &bdquo;newspeak&ldquo; bude mít vysokou specifičnost
v&nbsp;knize &bdquo;1984&ldquo; (vyskytuje se zde mnohokrát) a naopak nízkou
nebo nulovou specifičnost v&nbsp;dalších knihách. To například znamená, že
model může rozpoznat část textu a říci &bdquo;toto patří do knihy 1984&ldquo;
apod. Podobně to může fungovat u algoritmu pro vyhledání podobných textů
(vět).</p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Základní vlastnosti výpočtu relevance slov</h2>

<p>V&nbsp;následujícím skriptu vektorizujeme korpus obsahující pouze trojici
dokumentů (řetězců), přičemž každý řetězec obsahuje pouze tři slova. Všechna
slova jsou v&nbsp;tomto případě striktně unikátní &ndash; neopakují se:</p>

<pre>
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "foo bar baz",
    "apple pear orange",
    "Go Python Clojure",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = TfidfVectorizer(min_df=1)
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
for index, feature in enumerate(feature_names):
    print(index, feature)
print()
&nbsp;
<i># výsledek vektorizace - řídká matice: převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
np.set_printoptions(precision=2)
print(as_array)
</pre>

<p>Skript nejprve zobrazí vytvořený slovník:</p>
<pre>
0 apple
1 bar
2 baz
3 clojure
4 foo
5 go
6 orange
7 pear
8 python
</pre>

<p>Následně se zobrazí vektorizovaná podoba matice:</p>

<pre>
[[0.   0.58 0.58 0.   0.58 0.   0.   0.   0.  ]
 [0.58 0.   0.   0.   0.   0.   0.58 0.58 0.  ]
 [0.   0.   0.   0.58 0.   0.58 0.   0.   0.58]]
</pre>

<p>Otázkou je, jakým způsobem se došlo k&nbsp;hodnotám 0,58 (naproti tomu nula
je zřejmá &ndash; slovo se v&nbsp;daném dokumentu vůbec nevyskytuje).</p>

<p>Provádí se tento výpočet:</p>

<pre>
idf = log((1+n) / (1 + df(t))) + 1
</pre>

<p>Dosadíme tedy <i>n=3</i> (počet dokumentů) a <i>df(t)=1</i> (počet dokumentů
s&nbsp;výskytem slova &ndash; to je v&nbsp;našem případě vždy rovno jedné):</p>

<pre>
idf = log((1+3) / (1 + 1)) + 1 = log(4/2) + 1 = 1,301
</pre>

<p>Vektory obsahující tyto hodnoty se ovšem ještě normalizují a vzhledem
k&nbsp;tomu, že každý vektor obsahuje trojici stejných hodnot, je výpočet
poměrně triviální (uvádím ho pro jeden prvek, ale rozšířit se musí na všech
šest prvků):</p>

<pre>
v[1] = 1,301 ÷ sqrt(1,3^2+1,3^2+1,3^2) = 0,577
</pre>

<p>tedy po zaokrouhlení získáme vektory s&nbsp;prvky 0.58.</p>



<p><a name="k11"></a></p>
<h2 id="k11">11. Další příklady výpočtu <i>tf-idf</i></h2>

<p>Podívejme se nyní na další příklady výpočtu <i>tf-idf</i>. Začneme
příkladem, který opět obsahuje tři dokumenty v&nbsp;korpusu, ovšem druhý
dokument má jen dvě slova a nikoli slova tři:</p>

<pre>
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "foo bar baz",
    "apple orange",
    "Go Python Clojure",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = TfidfVectorizer(min_df=1)
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
for index, feature in enumerate(feature_names):
    print(index, feature)
print()
&nbsp;
<i># výsledek vektorizace - řídká matice: převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
np.set_printoptions(precision=2)
print(as_array)
</pre>

<p>Kvůli odlišně provedené normalizaci budou ve druhém řádku odlišné hodnoty:</p>

<pre>
v[1] = 1,301 ÷ sqrt(1,3^2+1,3^2) = 0,707 ≈ 0,71
</pre>

<p>Což si lze snadno ověřit:</p>

<pre>
0 apple
1 bar
2 baz
3 clojure
4 foo
5 go
6 orange
7 python
&nbsp;
[[0.   0.58 0.58 0.   0.58 0.   0.   0.  ]
 [0.71 0.   0.   0.   0.   0.   0.71 0.  ]
 [0.   0.   0.   0.58 0.   0.58 0.   0.58]]
</pre>

<p>Pojďme ještě dále a upravme poslední dokument tak, že bude obsahovat jen jediné slovo:</p>

<pre>
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "foo bar baz",
    "apple orange",
    "Go",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = TfidfVectorizer(min_df=1)
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
for index, feature in enumerate(feature_names):
    print(index, feature)
print()
&nbsp;
<i># výsledek vektorizace - řídká matice: převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
np.set_printoptions(precision=2)
print(as_array)
</pre>

<p>Zde normalizace výsledek nijak &bdquo;nespraví&ldquo;:</p>

<pre>
v[1] = 1,301 ÷ sqrt(1,3^2) = 1,301/1,301 = 1
</pre>

<p>To je ostatně patrné i na posledním řádku matice, který obsahuje jedinou
hodnotu rovnou jedničce:</p>

<pre>
0 apple
1 bar
2 baz
3 foo
4 go
5 orange
&nbsp;
[[0.   0.58 0.58 0.58 0.   0.  ]
 [0.71 0.   0.   0.   0.   0.71]
 [0.   0.   0.   0.   1.   0.  ]]
</pre>

<p>A konečně si ukažme případ, v&nbsp;němž se jedno slovo &bdquo;foo&ldquo;
opakuje ve dvou dokumentech &ndash; v&nbsp;dokumentu prvním a třetím:</p>

<pre>
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "foo bar baz",
    "apple orange",
    "Go foo",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = TfidfVectorizer(min_df=1)
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
for index, feature in enumerate(feature_names):
    print(index, feature)
print()
&nbsp;
<i># výsledek vektorizace - řídká matice: převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
np.set_printoptions(precision=2)
print(as_array)
</pre>

<p>Výsledky nyní budou odlišné:</p>

<pre>
0 apple
1 bar
2 baz
3 foo
4 go
5 orange
&nbsp;
[[0.   0.62 0.62 0.47 0.   0.  ]
 [0.71 0.   0.   0.   0.   0.71]
 [0.   0.   0.   0.61 0.8  0.  ]]
</pre>

<p>Proč tomu tak je? Změní se výpočet <i>idf</i> pro slovo &bdquo;foo&ldquo;.
Zatímco u slov, které se neopakovaly, stále platí:</p>

<pre>
idf = log((1+3) / (1 + 1)) + 1 = log(4/2) + 1 = 1,301
</pre>

<p>tak u slova &bdquo;foo&ldquo; jsou hodnoty odlišné:</p>

<pre>
idf = log((1 + 3) / (2 + 1)) + 1 = log(4/3) + 1 = 1,12
</pre>

<p>Tato menší hodnota (pochopitelně po normalizaci) ovlivní právě čtvrtý
sloupec v&nbsp;tabulce.</p>



<p><a name="k12"></a></p>
<h2 id="k12">12. Realizace výpočtu matice s&nbsp;relevancí jednotlivých slov</h2>

<p>V&nbsp;dalším kroku se pokusme o realizaci jednoduché
&bdquo;pipeline&ldquo;, ve které se nejprve vypočtou frekvence slov
s&nbsp;využitím nám již známé třídy <strong>CountVectorizer</strong> a následně
se provede transformace na hodnoty odpovídající <i>tf-idf</i>. Tato druhá
transformace je založena na třídě <strong>TfidfTransformer</strong>. Postup je
stále totožný a odpovídá ustálenému vzoru &ndash; konstrukce instance objektu
následovaná voláním metody <strong>fit</strong>, přičemž instanci třídy
<strong>TfidfTransformer</strong> se předává výsledek vektorizace:</p>

<pre>
vectorizer = CountVectorizer(min_df=1, stop_words="english")
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># výpočet IDF - převrácené četnosti slov</i>
transformer = TfidfTransformer(smooth_idf=True, use_idf=True)
transformer.fit(vectorized)
</pre>

<p>Tento postup je ukázán v&nbsp;následujícím skriptu:</p>

<pre>
<i># Výpočet relevance jednotlivých slov</i>
&nbsp;
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = CountVectorizer(min_df=1, stop_words="english")
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
&nbsp;
<i># převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># výpočet IDF - převrácené četnosti slov</i>
transformer = TfidfTransformer(smooth_idf=True, use_idf=True)
transformer.fit(vectorized)
&nbsp;
<i># zobrazení tabulky s převrácenými četnostmi jednotlivých slov</i>
for feature_name, idf in zip(feature_names, transformer.idf_):
    print(f"{feature_name:9} {idf:5.2}")
</pre>

<p>Tento skript nejdříve zobrazí matici s&nbsp;frekvencemi slov:</p>

<pre>
[[2 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]
 [1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0]
 [1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]
 [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1]
 [0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1]
 [1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0]]
</pre>

<p>Následně se zobrazí slovník i s&nbsp;vypočtenými hodnotami
<i>tf-idf</i>:</p>

<pre>
apple       1.3
away        2.3
blue        1.8
compare     2.3
day         2.3
docs        2.3
doctor      2.3
keeps       2.3
learn       1.8
like        2.3
logo        2.3
new         2.3
orange      1.3
pie         2.3
prefer      2.3
scikit      1.8
</pre>



<p><a name="k13"></a></p>
<h2 id="k13">13. Vliv většího množství dokumentů se stejnými slovy v&nbsp;korpusu na vypočtenou relevanci slov</h2>

<p>Pokusme se nyní do zpracovávaného korpusu přidat větší množství dalších
&bdquo;dokumentů&ldquo;, které budou obsahovat stejná slova. To provedeme
docela snadno:</p>

<pre>
<i># věty pro vyšší četnosti vybraných slov</i>
for i in range(20):
    corpus.append("blue day")
</pre>

<p>Skript by po svém spuštění měl zobrazit odlišné hodnoty <i>tf-idf</i> u slov
&bdquo;blue&ldquo; a &bdquo;day&ldquo;, konkrétně by se měly hodnoty u těchto
slov snížit. A kvůli způsobu výpočtu se naopak zvýší hodnoty u ostatních
slov:</p>

<pre>
<i># Výpočet relevance jednotlivých slov</i>
&nbsp;
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
<i># věty pro vyšší četnosti vybraných slov</i>
for i in range(20):
    corpus.append("blue day")
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = CountVectorizer(min_df=1, stop_words="english")
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
&nbsp;
<i># převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># výpočet IDF - převrácené četnosti slov</i>
transformer = TfidfTransformer(smooth_idf=True, use_idf=True)
transformer.fit(vectorized)
&nbsp;
<i># zobrazení tabulky s převrácenými četnostmi jednotlivých slov</i>
for feature_name, idf in zip(feature_names, transformer.idf_):
    print(f"{feature_name:9} {idf:5.2}")
</pre>

<p>Původní vypočtená matice s&nbsp;frekvencemi slov:</p>

<pre>
[[2 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0]
 [1 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0]
 [1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0]
 [0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1]
 [0 0 1 0 0 1 0 0 1 0 0 0 1 0 0 1]
 [1 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]
 [0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0]]
</pre>

<p>Hodnoty <i>tf-idf</i> vypočtené u jednotlivých slov:</p>

<pre>
apple       2.7
away        3.6
blue        1.2
compare     3.6
day         1.2
docs        3.6
doctor      3.6
keeps       3.6
learn       3.2
like        3.6
logo        3.6
new         3.6
orange      2.7
pie         3.6
prefer      3.6
scikit      3.2
</pre>

<p>Zajímavé bude porovnání hodnot z&nbsp;předchozí kapitoly a této kapitoly:</p>

<pre>
apple       1.3     2.7
away        2.3     3.6
blue        1.8     1.2   (menší)
compare     2.3     3.6
day         2.3     1.2  (menší)
docs        2.3     3.6
doctor      2.3     3.6
keeps       2.3     3.6
learn       1.8     3.2
like        2.3     3.6
logo        2.3     3.6
new         2.3     3.6
orange      1.3     2.7
pie         2.3     3.6
prefer      2.3     3.6
scikit      1.8     3.2
</pre>

<p><div class="rs-tip-major">Poznámka: u ostatních slov se jejich hodnota
naopak <i>zvýšila</i>, protože jsou nyní méně častá a tím pádem i specifičtější
(konkrétně &ndash; tato ostatní slova chybí v&nbsp;posledních dvaceti
dokumentech).</div></p>



<p><a name="k14"></a></p>
<h2 id="k14">14. Přímé využití třídy <strong>TfidfVectorizer</strong></h2>

<p>V&nbsp;předchozím textu jsme si ukázali, jakým způsobem je možné zkombinovat
třídu <strong>CountVectorizer</strong> společně se třídou
<strong>TfidfTransformer</strong> do jednoduché &bdquo;pipeline&ldquo;, jejímž
výsledkem bude ohodnocení slov v&nbsp;jazykovém korpusu. Ovšem v&nbsp;praxi se
setkáme spíše se třídou <strong>TfidfVectorizer</strong>, která provádí
(poněkud zjednodušeně řečeno) obě operace současně. Výsledkem takového výpočtu
je matice s&nbsp;váhami slov podle jejich specifičnosti v&nbsp;kontextu
<i>jednoho dokumentu</i> (řádek matice) i <i>celého korpusu</i> (sloupec
matice). Vlastnosti takových matic i způsob výpočtu jsme si již ukázali <a href="#k10">v&nbsp;desáté</a> a <a href="#k11">jedenácté kapitole</a>.</p>

<p>Pokusme se tedy upravit demonstrační příklad z&nbsp;předchozí kapitoly tak,
aby se při vektorizaci přímo používala třída <strong>TfidfVectorizer</strong>.
Je to ve skutečnosti velmi snadné:</p>

<pre>
<i># Přímý výpočet relevance jednotlivých slov</i>
&nbsp;
from sklearn.feature_extraction.text import TfidfVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = TfidfVectorizer(min_df=1, stop_words="english")
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># výsledek vektorizace - řídká matice</i>
print(vectorized)
print()
&nbsp;
<i># převod na běžnou matici</i>
as_array = vectorized.toarray()
&nbsp;
<i># zobrazení výsledku v novém formátu</i>
print(as_array)
</pre>

<p>Výsledek ve formě řídké matice (zobrazují se tedy prvky s&nbsp;nenulovou
hodnotou):</p>

<pre>
  (0, 9)        0.5417030933272916
  (0, 0)        0.642740629927257
  (0, 13)       0.5417030933272916
  (1, 0)        0.2843820458449716
  (1, 4)        0.47935551837885115
  (1, 7)        0.47935551837885115
  (1, 6)        0.47935551837885115
  (1, 1)        0.47935551837885115
  (2, 0)        0.45448625796567665
  (2, 3)        0.7660838613629144
  (2, 12)       0.45448625796567665
  (3, 12)       0.3612599391251273
  (3, 14)       0.6089412039859956
  (3, 15)       0.49934049829319643
  (3, 8)        0.49934049829319643
  (4, 12)       0.32320592952117017
  (4, 15)       0.44674150776102867
  (4, 8)        0.44674150776102867
  (4, 5)        0.5447972125961776
  (4, 2)        0.44674150776102867
  (5, 0)        0.32286546559023394
  (5, 12)       0.32286546559023394
  (5, 2)        0.4462709119088114
  (5, 11)       0.5442233252270988
  (5, 10)       0.5442233252270988
</pre>

<p>Následuje výsledek ve formě běžné matice. Čím vyšší je nějaká hodnota, tím
specifičtější slovo bylo použito (a současně i tím kratší je dokument):</p>

<pre>
[[0.64 0.   0.   0.   0.   0.   0.   0.   0.   0.54 0.   0.   0.   0.54 0.   0.  ]
 [0.28 0.48 0.   0.   0.48 0.   0.48 0.48 0.   0.   0.   0.   0.   0.   0.   0.  ]
 [0.45 0.   0.   0.77 0.   0.   0.   0.   0.   0.   0.   0.   0.45 0.   0.   0.  ]
 [0.   0.   0.   0.   0.   0.   0.   0.   0.5  0.   0.   0.   0.36 0.   0.61 0.5 ]
 [0.   0.   0.45 0.   0.   0.54 0.   0.   0.45 0.   0.   0.   0.32 0.   0.   0.45]
 [0.32 0.   0.45 0.   0.   0.   0.   0.   0.   0.   0.54 0.54 0.32 0.   0.   0.  ]]
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. Nalezení textu, který se nejvíce blíží hledanému vzorku</h2>

<p>Ukažme si nyní jedno praktické použití matic s&nbsp;hodnotami <i>tf-idf</i>.
Naimplementujeme si algoritmus, která se v&nbsp;korpusu pokusí najít větu
(dokument), který se nejvíce blíží hledanému vzorku. Existuje hned několik
metod, jak toho dosáhnout, ovšem nejjednodušší a vlastně i nejrychlejší metoda
je založena právě na použití matice s&nbsp;hodnotami <i>tf-idf</i>.</p>

<p>Vstupem bude matice získaná vektorizací korpusu. Ta bude obsahovat například
následujících sedm vektorů pro sedm dokumentů (řetězců):</p>

<pre>
[[0.6427 0.     0.     0.     0.     0.     0.     0.     0.     0.5417 0.     0.     0.     0.5417 0.     0.    ]
 [0.2844 0.4794 0.     0.     0.4794 0.     0.4794 0.4794 0.     0.     0.     0.     0.     0.     0.     0.    ]
 [0.4545 0.     0.     0.7661 0.     0.     0.     0.     0.     0.     0.     0.     0.4545 0.     0.     0.    ]
 [0.     0.     0.     0.     0.     0.     0.     0.     0.4993 0.     0.     0.     0.3613 0.     0.6089 0.4993]
 [0.     0.     0.4467 0.     0.     0.5448 0.     0.     0.4467 0.     0.     0.     0.3232 0.     0.     0.4467]
 [0.3229 0.     0.4463 0.     0.     0.     0.     0.     0.     0.     0.5442 0.5442 0.3229 0.     0.     0.    ]]
</pre>

<p>Jak však zjistit, které dokumenty se nejvíce podobají? Můžeme využít toho,
že podobné dokumenty budou pravděpodobně obsahovat podobná slova a největší
váhu mají mít slova s&nbsp;vyšší hodnotou v&nbsp;matici, protože tato slova
jsou více specifická. Takže vlastně můžeme využít skalárních součinů vektorů
získaných z&nbsp;jazykového korpusu, který bude obsahovat jak hledanou větu,
tak i vzorek. Skalární součin dvou vektorů můžeme vypočítat snadno, ovšem
všechny skalární součiny jsou de facto realizovány maticovým součinem,
konkrétně součinem výše uvedené matice se stejnou maticí, která je však
nejdříve transponována. Výsledkem by měla být matice 7×7 prvků:</p>

<pre>
[[1.     0.1828 0.2921 0.     0.     0.2075]
 [0.1828 1.     0.1292 0.     0.     0.0918]
 [0.2921 0.1292 1.     0.1642 0.1469 0.2935]
 [0.     0.     0.1642 1.     0.5629 0.1166]
 [0.     0.     0.1469 0.5629 1.     0.3037]
 [0.2075 0.0918 0.2935 0.1166 0.3037 1.    ]]
</pre>

<p>V&nbsp;této nové matici prvek A[i,j] říká, jak moc se podobají dokumenty
s&nbsp;indexy <i>i</i> a <i>j</i>, přičemž pochopitelně platí, že dokument se
nejvíce podobá sobě samotnému (hlavní diagonála). Z&nbsp;tohoto důvodu nejdříve
z&nbsp;hlavní diagonály hodnoty vymažeme (nahradíme je za
&bdquo;nečísla&ldquo;). Dostaneme následující matici:</p>

<pre>
[[   nan 0.1828 0.2921 0.     0.     0.2075]
 [0.1828    nan 0.1292 0.     0.     0.0918]
 [0.2921 0.1292    nan 0.1642 0.1469 0.2935]
 [0.     0.     0.1642    nan 0.5629 0.1166]
 [0.     0.     0.1469 0.5629    nan 0.3037]
 [0.2075 0.0918 0.2935 0.1166 0.3037    nan]]
</pre>

<p>Lze tedy relativně snadno zjistit, že nejvíce se podobají dokumenty číslo 3
a 4 (číslováno od nuly) a nejméně například dokument 0 a 3. A poslední dokument
je nejvíce podobný dokumentu číslo 4.</p>

<div class="rs-tip-major">Poznámka: zde je situace triviální, protože máme
k&nbsp;dispozici pouze šest dokumentů a šestnáct slov ve slovníku, ale
v&nbsp;praxi budou rozměry matice mnohem větší.</div>




<p><a name="k16"></a></p>
<h2 id="k16">16. Realizace algoritmu pro nalezení nejpodobnější věty</h2>

<p>Vyzkoušejme si nyní konkrétní realizaci algoritmu, s&nbsp;nímž jsme se právě
seznámili. Je zde provedena transpozice matice s&nbsp;výpočtem součinu matice
představující původní vektorizovaný korpus s&nbsp;transponovanou maticí. Navíc
jsou z&nbsp;výsledné matice odstraněny prvky na hlavní diagonále a následně je
tato nová matice použita pro nalezení, která další věta z&nbsp;korpusu je
nejbližší větě &bdquo;New apple logo will be orange and blue&ldquo;:</p>

<pre>
<i># Nalezení textu, který se nejvíce blíží hledanému vzorku</i>
&nbsp;
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
&nbsp;
<i># sada textů (korpus)</i>
corpus = [
    "I'd like an apple or an apple pie",
    "An apple a day keeps the doctor away",
    "Never compare an apple to an orange",
    "I prefer scikit-learn to orange",
    "The scikit-learn docs are orange and blue",
    "New apple logo will be orange and blue",
]
&nbsp;
<i># provedení vektorizace korpusu</i>
vectorizer = TfidfVectorizer(min_df=1, stop_words="english")
vectorized = vectorizer.fit_transform(corpus)
&nbsp;
<i># výsledek vektorizace - řídká matice</i>
print(vectorized)
print()
&nbsp;
<i># matice s převrácenými četnostmi</i>
pairwise_similarity = vectorized * vectorized.T
&nbsp;
print(pairwise_similarity)
print()
&nbsp;
print(pairwise_similarity.toarray())
print()
&nbsp;
arr = pairwise_similarity.toarray()
&nbsp;
<i># odstranění jedniček na hlavní diagonále</i>
np.fill_diagonal(arr, np.nan)
print(arr)
print()
&nbsp;
<i># hledaná věta</i>
input_doc = "New apple logo will be orange and blue"
input_idx = corpus.index(input_doc)
print(input_idx, input_doc)
&nbsp;
result_idx = np.nanargmax(arr[input_idx])
print(result_idx, corpus[result_idx])
</pre>

<p>Tento skript nejdříve vypíše použité matice (ty jsme si však již uvedli
v&nbsp;předchozím textu, takže je zde nebudu opakovat) a nakonec určí, která
věta je nejbližší větě zadané. Je to věta číslo 4 z&nbsp;našeho jazykového
korpusu:</p>

<pre>
4 The scikit-learn docs are orange and blue
</pre>



<p><a name="k17"></a></p>
<h2 id="k17">17. Úskalí algoritmu pro hledání podobných textů</h2>

<p>Algoritmus určený pro vyhledávání podobných textů v&nbsp;realizaci,
v&nbsp;jaké byl právě představen, trpí jednou zásadní vadou &ndash; nedokáže
totiž korektně rozlišit pořadí slov a navíc (většinou) jsou
z&nbsp;vektorizovaného textu odstraněna stopslova, která v&nbsp;některých
případech mohou měnit smysl textu. To například může znamenat, že dvě věty
(nebo delší sekvence textu), které mají zcela opačný význam kvůli použití slov
jako &bdquo;no&ldquo;, &bdquo;not&ldquo; atd., budou ve skutečnosti považovány
za věty velmi si podobné.</p>

<p>Oba zmíněné nedostatky je možné do značné míry odstranit takovým způsobem,
že při vektorizaci jazykového korpusu budeme do slovníku ukládat nikoli
samostatná slova, ale například dvojice slov. Celý slovník se pochopitelně
zvětší a tím pádem se zvětší i matice s&nbsp;vektorizovaným textem, ovšem
v&nbsp;některých situacích je to jedno z&nbsp;mála praktických řešení, které je
navíc možné velmi snadno implementovat. Základy tohoto postupu si vysvětlíme
v&nbsp;navazujícím článku.</p>




<p><a name="k18"></a></p>
<h2 id="k18">18. Vektorizovaný text a neuronové sítě</h2>

<p>Vraťme se ještě na chvíli k&nbsp;minulému článku, v&nbsp;němž jsme se
pokusili natrénovat model určený pro rozeznávání pozitivně, negativně nebo
neutrálně naladěných tweetů o dopravcích. Samozřejmě nám nic nebrání
v&nbsp;tom, abychom pro model využili neuronovou síť a (možná?) tak zlepšili
jeho predikční schopnosti. Ukažme si, jak by celý postup mohl vypadat.
Neuronovou síť prozatím ponecháme v&nbsp;původní podobě &ndash; nebudeme ji
tedy nijak &bdquo;dolaďovat&ldquo;:</p>

<pre>
# Trénink a predikce modelu nad vektorizovanými daty

import pandas as pd
import re
import matplotlib.pyplot as plt
from nltk.corpus import stopwords
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# model zalozeny na neuronove siti
from sklearn.neural_network import MLPClassifier



# načtení tabulky do datového rámce s předzpracováním numerických dat
airline_tweets = pd.read_csv("Tweets_airlines.csv")

# hodnocení (pozitivní, negativní, neutrální)
labels = airline_tweets["airline_sentiment"].values

# vlastní text hodnocení
features = airline_tweets["text"].values


def process_feature(feature):
    """Preprocesing textových dat."""
    # odstranění speciálních znaků a dalšího smetí
    processed_feature = re.sub(r"\W", " ", feature)

    # odstranění samostatných znaků (oddělených bílými znaky)
    processed_feature = re.sub(r"\s+[a-zA-Z]\s+", " ", processed_feature)

    # odstranění samostatných znaků na začátku vět
    processed_feature = re.sub(r"\^[a-zA-Z]\s+", " ", processed_feature)

    # náhrada více mezer (nebo jiných bílých znaků) za jedinou mezeru
    processed_feature = re.sub(r"\s+", " ", processed_feature, flags=re.I)

    # odstranění prefixů ^b
    processed_feature = re.sub(r"^b\s+", "", processed_feature)

    # konverze výsledku na malá písmena
    return processed_feature.lower()


# preprocesing všech hodnocení
processed_features = [process_feature(feature) for feature in features]

# hodnoty použité později pro trénink modelu
print("Labels:")
print(labels)
print("Number of labels:", len(labels))
print()

print("Features:")
print(processed_features)
print("Number of features:", len(processed_features))
print()

# vektorizace textu
vectorizer = TfidfVectorizer(
    max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words("english")
)
vectorized_features = vectorizer.fit_transform(processed_features).toarray()

# klasické rozdělení datové sady na trénovací a testovací část
trainX, testX, trainY, testY = train_test_split(
    vectorized_features, labels, test_size=0.2, random_state=0
)

# konstrukce vybraného modelu s předáním hyperparametrů
classifier =  MLPClassifier(max_iter=5000)

# trénink modelu
classifier.fit(trainX, trainY)

# predikce modelu pro testovací vstupy (ne pro trénovací data)
predictions = classifier.predict(testX)

# vyhodnocení kvality modelu
print(classification_report(testY, predictions))
print(accuracy_score(testY, predictions))

# matice záměn - absolutní hodnoty
disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    testX,
    testY,
    cmap=plt.cm.Blues,
    normalize=None,
)

# zobrazení matice v textové podobě
print(disp.confusion_matrix)

# uložení výsledků ve formě rastrového obrázku
plt.savefig("189_1.png")

# vizualizace matice
plt.show()

# matice záměn - relativní hodnoty
disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    testX,
    testY,
    cmap=plt.cm.Blues,
    normalize="true",
)

# zobrazení matice v textové podobě
print(disp.confusion_matrix)

# uložení výsledků ve formě rastrového obrázku
plt.savefig("189_2.png")

# vizualizace matice
plt.show()
</pre>

<p>Matice záměn budou vypadat takto:</p>

<img src="https://i.iinfo.cz/images/31/scikit-learn-nlp-2-1.webp" class="image-1154958" width="640" height="480" alt="&nbsp;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 1: Matice záměn s&nbsp;absolutními hodnotami.</i></p>

<img src="https://i.iinfo.cz/images/31/scikit-learn-nlp-2-2.webp" class="image-1154961" width="640" height="480" alt="&nbsp;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 2: Matice záměn s&nbsp;relativními hodnotami.</i></p>

<div class="rs-tip-major">Poznámka: z&nbsp;těchto obrázků je patrný fakt (o
němž jsme se zmínili už minule), že nejvíce hodnocení je negativních. A dále je
patrné, že model stále nedokáže přesně rozhodnout, jaké hodnocení jednotlivé
tweety obsahují, protože míra špatného odhadu je relativně vysoká. I přesto
jsou nejvyšší relativní hodnoty stále na hlavní diagonále, takže model
neodpovídá zcela náhodně.</div>




<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu Scikit-learn lze nalézt
v&nbsp;repositáři <a href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady i na (Jupyter) diáře s&nbsp;postupem
výpočtů a analýz:</p>

<table>
<tr><th>#</th><th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr>
<tr><td> 1</td><td>01_show_matrix.py</td><td>kooperace mezi knihovnami Matplotlib a NumPy: vizualizace obsahu 2D matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py</a></td></tr>
<tr><td> 2</td><td>02_get_digits.py</td><td>datová množina obsahující naskenované ručně napsané číslice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py</a></td></tr>
<tr><td> 3</td><td>03_get_features.py</td><td>další atributy datové množiny, které použijeme při trénování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py</a></td></tr>
<tr><td> 4</td><td>04_get_images.py</td><td>přečtení a následné vykreslení jednotlivých ručně nakreslených číslic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py</a></td></tr>
<tr><td> 5</td><td>05_show_grayscale_matrix.py</td><td>odstranění umělé aplikované barvové palety (obrázky ve stupních šedi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py</a></td></tr>
<tr><td> 6</td><td>06_grayscale_images.py</td><td>vykreslení ručně nakreslených číslic ve formě obrázků ve stupních šedi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py</a></td></tr>
<tr><td> 7</td><td>07_multiplot.py</td><td>rozdělení plochy grafu do oblastí; vykreslení více obrázků do jediného grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py</a></td></tr>
<tr><td> 8</td><td>08_model_preperation_1.py</td><td>obrázky s&nbsp;jejich ohodnocením</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py</a></td></tr>
<tr><td> 9</td><td>09_training_set.py</td><td>příprava dat pro trénink</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py</a></td></tr>
<tr><td>10</td><td>10_classification.py</td><td>klasifikace obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py</a></td></tr>
<tr><td>11</td><td>11_results.py</td><td>vykreslení obrázků společně s&nbsp;jejich klasifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py</a></td></tr>
<tr><td>12</td><td>12_change_training_set.py</td><td>změna poměru rozdělení dat na tréninkovou a testovací množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>13</td><td>13_blobs.py</td><td>použití funkce <strong>make_blobs</strong> pro vygenerování sady bodů v&nbsp;rovině sdružených do oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py</a></td></tr>
<tr><td>14</td><td>14_swap_coords.py</td><td>úprava předchozího příkladu: prohození souřadnic na osách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py</a></td></tr>
<tr><td>15</td><td>15_blobs_scatter_plot.py</td><td>základní podoba bodového diagramu (<i>scatter plot</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py</a></td></tr>
<tr><td>16</td><td>16_blobs_scatter_plot.py</td><td>úprava bodového diagramu při zobrazení většího množství bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py</a></td></tr>
<tr><td>17</td><td>17_colorized_blobs.py</td><td>obarvení bodů podle oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py</a></td></tr>
<tr><td>18</td><td>18_k-means.py</td><td>základní použití algoritmu K-means pro clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py</a></td></tr>
<tr><td>19</td><td>19_combination.py</td><td>zobrazení centroidů společně s&nbsp;původními body</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py</a></td></tr>
<tr><td>20</td><td>20_combinations.py</td><td>vizualizace clusteringu původní množiny bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py</a></td></tr>
<tr><td>21</td><td>21_other_settings.py</td><td>vizualizace clusteringu původní množiny bodů pro odlišnou množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py</a></td></tr>
<tr><td>22</td><td>22_random_points.py</td><td>clustering pro náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>23</td><td>23_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, menší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py</a></td></tr>
<tr><td>24</td><td>24_more_noise_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, větší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py</a></td></tr>
<tr><td>25</td><td>25_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, menší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py</a></td></tr>
<tr><td>26</td><td>26_more_noisy_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, větší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py</a></td></tr>
<tr><td>27</td><td>27_circles_kmeans.py</td><td>výsledek clusteringu provedeného algoritmem K-means na &bdquo;kružnice&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/27_circles_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/27_circles_kmeans.py</a></td></tr>
<tr><td>28</td><td>28_moons_kmeans.py</td><td>výsledek clusteringu provedeného algoritmem K-means na &bdquo;půlměsíce&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/28_moons_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/28_moons_kmeans.py</a></td></tr>
<tr><td>29</td><td>29_blobs_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné pomocí <strong>make_blobs</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/29_blobs_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/29_blobs_spectral_clustering.py</a></td></tr>
<tr><td>30</td><td>30_circles_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné do kružnic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/30_circles_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/30_circles_spectral_clustering.py</a></td></tr>
<tr><td>31</td><td>31_moons_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné do půlměsíců </td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/31_moons_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/31_moons_spectral_clustering.py</a></td></tr>
<tr><td>32</td><td>32_moons_spectral_clustering_limits.py</td><td>vyhledání limitů algoritmu spectral clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/32_moons_spectral_clustering_limits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/32_moons_spectral_clustering_limits.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>33</td><td>33_particles_load.py</td><td>načtení souřadnic částic uložených v&nbsp;souboru formátu CSV</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/33_particles_load.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/33_particles_load.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>34</td><td>34_lorenz_attractor.py</td><td>zobrazení Lorenzova atraktoru formou bodů propojených úsečkami</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/34_lorenz_attractor.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/34_lorenz_attractor.py</a></td></tr>
<tr><td>35</td><td>35_lorenz_attractor_points.py</td><td>Lorenzův atraktor vykreslený formou jednotlivých bodů s&nbsp;definovaným stylem zobrazení a velikostí stopy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/35_lorenz_attractor_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/35_lorenz_attractor_points.py</a></td></tr>
<tr><td>36</td><td>36_blobs_3d.py</td><td>vygenerování a zobrazení sady bodů v&nbsp;3D prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/36_blobs_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/36_blobs_3d.py</a></td></tr>
<tr><td>37</td><td>37_spread_blobs_3d.py</td><td>vygenerování a zobrazení sady bodů v&nbsp;3D prostoru, odlišné parametry při generování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/37_spread_blobs_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/37_spread_blobs_3d.py</a></td></tr>
<tr><td>38</td><td>38_views.py</td><td>různé pohledy na 3D graf</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/38_views.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/38_views.py</a></td></tr>
<tr><td>39</td><td>39_colorized_3d_blobs.py</td><td>obarvení bodů v&nbsp;prostoru na základě vstupních dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/39_colorized_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/39_colorized_3d_blobs.py</a></td></tr>
<tr><td>40</td><td>40_kmeans_3d_blobs.py</td><td>shluková analýza v&nbsp;3D prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/40_kmeans_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/40_kmeans_3d_blobs.py</a></td></tr>
<tr><td>41</td><td>41_kmeans_spread_3d_blobs.py</td><td>shluková analýza v&nbsp;3D prostoru pro odlišnou množinu bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/41_kmeans_spread_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/41_kmeans_spread_3d_blobs.py</a></td></tr>
<tr><td>42</td><td>42_kmeans_random_3d.py</td><td>shluková analýza pro body rozmístěné zcela náhodně v&nbsp;omezeném prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/42_kmeans_random_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/42_kmeans_random_3d.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>43</td><td>43_speed_measurements.py</td><td>benchmark pro postupně rostoucí počet bodů tvořících shluky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/43_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/43_speed_measurements.py</a></td></tr>
<tr><td>44</td><td>44_speed_measurements.py</td><td>benchmark pro postupně rostoucí počet bodů rozmístěných náhodně</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/44_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/44_speed_measurements.py</a></td></tr>
<tr><td>45</td><td>45_speed_measurements.py</td><td>benchmark pro stále stejný počet bodů, u jejichž rozmístění v&nbsp;prostoru se používá stále větší směrodatná odchylka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/45_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/45_speed_measurements.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>46</td><td>46_iris_dataset.py</td><td>načtení datové kolekce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/46_iris_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/46_iris_dataset.py</a></td></tr>
<tr><td>47</td><td>47_iris_description.py</td><td>metadata o datové kolekci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/47_iris_description.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/47_iris_description.py</a></td></tr>
<tr><td>48</td><td>48_iris_data.py</td><td>tvar dat &ndash; počet záznamů a počet proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/48_iris_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/48_iris_data.py</a></td></tr>
<tr><td>49</td><td>49_iris_targets.py</td><td>jména atributů, vztah mezi numerickou hodnotou atributu a jeho jménem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/49_iris_targets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/49_iris_targets.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>50</td><td>50_iris_scatter_plot_1.py</td><td>korelační diagram pro dvojici vybraných proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/50_iris_scatter_plot_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/50_iris_scatter_plot_1.py</a></td></tr>
<tr><td>51</td><td>51_iris_scatter_plot_2.py</td><td>příprava pro tvorbu složitějších grafů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/51_iris_scatter_plot_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/51_iris_scatter_plot_2.py</a></td></tr>
<tr><td>52</td><td>52_iris_mutliplot.py</td><td>mřížka obsahující více korelačních diagramů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/52_iris_mutliplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/52_iris_mutliplot.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>53</td><td>53_iris_histograms.py</td><td>zobrazení základního histogramu pro data v&nbsp;sadě Iris</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/53_iris_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/53_iris_histograms.py</a></td></tr>
<tr><td>54</td><td>54_iris_histograms.py</td><td>úprava histogramu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/54_iris_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/54_iris_histograms.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>55</td><td>55_pca.py</td><td>analýza hlavních komponent (PCA), výsledek zobrazený v&nbsp;2D grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/55_pca.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/55_pca.py</a></td></tr>
<tr><td>56</td><td>56_pca_3d.py</td><td>analýza hlavních komponent (PCA), výsledek zobrazený v&nbsp;3D grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/56_pca_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/56_pca_3d.py</a></td></tr>
<tr><td>57</td><td>57_kmeans.py</td><td>základní shluková analýza</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/57_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/57_kmeans.py</a></td></tr>
<tr><td>58</td><td>58_multiple_kmeans.py</td><td>větší množství výsledků shlukové analýzy pro různé atributy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/58_multiple_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/58_multiple_kmeans.py</a></td></tr>
<tr><td>59</td><td>59_kmeans_errors.py</td><td>korektní a nekorektní výsledky základní shlukové analýzy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/59_kmeans_errors.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/59_kmeans_errors.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>60</td><td>60_basic_classifier.py</td><td>aplikace jednoduchého modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/60_basic_classifier.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/60_basic_classifier.py</a></td></tr>
<tr><td>61</td><td>61_changed_model_parameters.py</td><td>změna parametrů modelu pro zjištění druhů rostil</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/61_changed_model_parameters.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/61_changed_model_parameters.py</a></td></tr>
<tr><td>62</td><td>62_different_model.py</td><td>použití odlišného modelu pro zjištění druhů rostlin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/62_different_model.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/62_different_model.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>63</td><td>63_verify_on_whole_data_1.py</td><td>otestování naučeného modelu s&nbsp;využitím tréninkových dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/63_verify_on_whole_data_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/63_verify_on_whole_data_1.py</a></td></tr>
<tr><td>64</td><td>64_verify_on_whole_data_2.py</td><td>využití funkce <strong>metrics.accuracy_score</strong> pro zjištění kvality modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/64_verify_on_whole_data_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/64_verify_on_whole_data_2.py</a></td></tr>
<tr><td>65</td><td>65_basic_comparison.py</td><td>porovnání vlastností různých modelů (prozatím nekorektní řešení)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/65_basic_comparison.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/65_basic_comparison.py</a></td></tr>
<tr><td>66</td><td>66_training_testing_split_1.py</td><td>rozdělení datové sady na trénovací data a testovací data (základní varianta)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/66_training_testing_split_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/66_training_testing_split_1.py</a></td></tr>
<tr><td>67</td><td>67_training_testing_split_2.py</td><td>rozdělení datové sady na trénovací data a testovací data (náhodné rozdělení sady)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/67_training_testing_split_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/67_training_testing_split_2.py</a></td></tr>
<tr><td>68</td><td>68_training_testing_split_3.py</td><td>rozdělení datové sady na trénovací data a testovací data (využití vestavěné funkce)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/68_training_testing_split_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/68_training_testing_split_3.py</a></td></tr>
<tr><td>69</td><td>69_better_comparison.py</td><td>vylepšené porovnání vlastností různých modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/69_better_comparison.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/69_better_comparison.py</a></td></tr>
<tr><td>70</td><td>70_multiple_runs.py</td><td>vliv generátoru náhodných čísel na změřené výsledky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/70_multiple_runs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/70_multiple_runs.py</a></td></tr>
<tr><td>71</td><td>71_stable_multiple_runs.py</td><td>generátor náhodných čísel a použití hodnoty <strong>random_state</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/71_stable_multiple_runs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/71_stable_multiple_runs.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>72</td><td>72_housings_dataset.py</td><td>načtení datové sady <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/72_housings_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/72_housings_dataset.py</a></td></tr>
<tr><td>73</td><td>73_housings_dataset_description.py</td><td>metainformace o datové sadě <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/73_housings_dataset_description.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/73_housings_dataset_description.py</a></td></tr>
<tr><td>74</td><td>74_housings_data.py</td><td>n-rozměrné pole s&nbsp;atributy jednotlivých domů/bloků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/74_housings_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/74_housings_data.py</a></td></tr>
<tr><td>75</td><td>75_housings_targets.py</td><td>jména atributů, ceny domů atd.</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/75_housings_targets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/75_housings_targets.py</a></td></tr>
<tr><td>76</td><td>76_housings_scatter_plot.py</td><td>korelační diagram pro dvojici vybraných proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/76_housings_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/76_housings_scatter_plot.py</a></td></tr>
<tr><td>77</td><td>77_housings_mutliplot.py</td><td>korelační diagram pro všechny kombinace dvojic proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/77_housings_mutliplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/77_housings_mutliplot.py</a></td></tr>
<tr><td>78</td><td>78_scatter.py</td><td>dvourozměrné hodnoty reprezentované jako dvojice atributů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/78_scatter.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/78_scatter.py</a></td></tr>
<tr><td>79</td><td>79_linear_regression_gen_data.py</td><td>model <i>LinearRegression</i> nad uměle vytvořenými daty</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/79_linear_regression_gen_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/79_linear_regression_gen_data.py</a></td></tr>
<tr><td>80</td><td>80_linear_regression_predictions.py</td><td>predikce modelu provádějícího lineární regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/80_linear_regression_predictions.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/80_linear_regression_predictions.py</a></td></tr>
<tr><td>81</td><td>81_linear_regression_random_data.py</td><td>chování modelu pro zcela náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/81_linear_regression_random_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/81_linear_regression_random_data.py</a></td></tr>
<tr><td>82</td><td>82_linear_regression_housings.py</td><td>model <i>LinearRegression</i> pro datovou sadu <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/82_linear_regression_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/82_linear_regression_housings.py</a></td></tr>
<tr><td>83</td><td>83_polynomial_regression_gen_data.py</td><td>polynomiální regrese (základní příklad)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/83_polynomial_regression_gen_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/83_polynomial_regression_gen_data.py</a></td></tr>
<tr><td>84</td><td>84_polynomial_regression_housings.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, první příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/84_polynomial_regression_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/84_polynomial_regression_housings.py</a></td></tr>
<tr><td>85</td><td>85_polynomial_regression_housings_2.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, druhý příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/85_polynomial_regression_housings_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/85_polynomial_regression_housings_2.py</a></td></tr>
<tr><td>86</td><td>86_polynomial_regression_housings_3.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, třetí příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/86_polynomial_regression_housings_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/86_polynomial_regression_housings_3.py</a></td></tr>
<tr><td>87</td><td>87_linear_regression_errors.py</td><td>výpočet chyby a skóre modelu lineární regrese</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/87_linear_regression_errors.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/87_linear_regression_errors.py</a></td></tr>
<tr><td>88</td><td>88_linear_regression_non_linear_data.py</td><td>lineární regrese nad nelineárními daty</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/88_linear_regression_non_linear_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/88_linear_regression_non_linear_data.py</a></td></tr>
<tr><td>89</td><td>89_polynomial_regression_error.py</td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/89_polynomial_regression_error.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/89_polynomial_regression_error.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>90</td><td>90_housings_prediction_1.py</td><td>regresní analýza nad daty <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/90_housings_prediction_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/90_housings_prediction_1.py</a></td></tr>
<tr><td>91</td><td>91_housings_prediction_2.py</td><td>korektní natrénování modelu pro regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/91_housings_prediction_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/91_housings_prediction_2.py</a></td></tr>
<tr><td>92</td><td>92_housings_prediction_3.py</td><td>omezení množství atributů (proměnných), na kterých je model natrénován</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/92_housings_prediction_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/92_housings_prediction_3.py</a></td></tr>
<tr><td>93</td><td>93_housings_prediction_errors_1.py</td><td>chybně natrénovaný model při náhodné volbě dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/93_housings_prediction_errors_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/93_housings_prediction_errors_1.py</a></td></tr>
<tr><td>94</td><td>94_housings_prediction_errors_2.py</td><td>omezení atributů + chybně natrénovaný model</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/94_housings_prediction_errors_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/94_housings_prediction_errors_2.py</a></td></tr>
<tr><td>95</td><td>95_housings_histograms.py</td><td>histogramy pro jednotlivé atributy (proměnné)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/95_housings_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/95_housings_histograms.py</a></td></tr>
<tr><td>96</td><td>96_housings_statistic.py</td><td>statistické údaje pro jednotlivé atributy (proměnné)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/96_housings_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/96_housings_statistic.py</a></td></tr>
<tr><td>97</td><td>97_housings_statistic_normalized.py</td><td>statistické údaje získané po normalizaci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/97_housings_statistic_normalized.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/97_housings_statistic_normalized.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 98</td><td>98_k_fold_help.py</td><td>zobrazení nápovědy ke třídě s&nbsp;realizací k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/98_k_fold_help.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/98_k_fold_help.py</a></td></tr>
<tr><td> 99</td><td>99_k_fold_old.py</td><td>původní (nepodporovaná) varianta provedení k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/99_k_fold_old.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/99_k_fold_old.py</a></td></tr>
<tr><td>100</td><td>100_k_fold_1.py</td><td>interní chování algoritmu k-foldingu (základní parametry)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/100_k_fold_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/100_k_fold_1.py</a></td></tr>
<tr><td>101</td><td>101_k_fold_2.py</td><td>interní chování algoritmu k-foldingu (odlišné parametry)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/101_k_fold_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/101_k_fold_2.py</a></td></tr>
<tr><td>102</td><td>102_k_fold_selection.py</td><td>k-folding a výběr dat pro otestování modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/102_k_fold_selection.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/102_k_fold_selection.py</a></td></tr>
<tr><td>103</td><td>103_average_score.py</td><td>realizace výpočtu průměrného skóre pro otestování modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/103_average_score.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/103_average_score.py</a></td></tr>
<tr><td>104</td><td>104_hyperparams_score.py</td><td>změna hyperparametrů s&nbsp;výpočtem průměrného skóre (tabulka)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/104_hyperparams_score.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/104_hyperparams_score.py</a></td></tr>
<tr><td>105</td><td>105_hyperparams_score_plot.py</td><td>změna hyperparametrů s&nbsp;výpočtem průměrného skóre (graf)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/105_hyperparams_score_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/105_hyperparams_score_plot.py</a></td></tr>
<tr><td>106</td><td>106_model_selection.py</td><td>výběr nejlepšího modelu s&nbsp;využitím k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/106_model_selection.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/106_model_selection.py</a></td></tr>
<tr><td>107</td><td>107_features_selection_basic.py</td><td>výběr atributů (proměnných) pro trénink modelu (základní varianta)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/107_features_selection_basic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/107_features_selection_basic.py</a></td></tr>
<tr><td>108</td><td>108_features_selection_iris.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada Iris)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/108_features_selection_iris.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/108_features_selection_iris.py</a></td></tr>
<tr><td>109</td><td>109_features_selection_houses.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada California Housings)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/109_features_selection_houses.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/109_features_selection_houses.py</a></td></tr>
<tr><td>110</td><td>110_best_features_selection_houses.py</td><td>získání nejlepší sady atributů (proměnných)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/110_best_features_selection_houses.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/110_best_features_selection_houses.py</a></td></tr>
<tr><td>111</td><td>111_features_selection_graphical.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada Iris), grafický výstup</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/111_features_selection_graphical.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/111_features_selection_graphical.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>112</td><td>112_simplest_linear_regression.py</td><td>lineární regrese bodů ležících v&nbsp;rovině</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/112_simplest_linear_regression.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/112_simplest_linear_regression.py</a></td></tr>
<tr><td>113</td><td>113_linear_regression_no_intercept.py</td><td>lineární regrese při vynucení <i>w<sub>0</sub>=0</i> pro obecná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/113_linear_regression_no_intercept.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/113_linear_regression_no_intercept.py</a></td></tr>
<tr><td>114</td><td>114_linear_regression_from_0_0.py</td><td>lineární regrese při vynucení <i>w<sub>0</sub>=0</i> v&nbsp;případě, že vstupní body obsahují počátek souřadného systému</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/114_linear_regression_from_0_0.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/114_linear_regression_from_0_0.py</a></td></tr>
<tr><td>115</td><td>115_linear_regression_multiple_y.py</td><td>model předpovídající pro každou vstupní hodnotu dvě výstupní hodnoty (odpovědi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/115_linear_regression_multiple_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/115_linear_regression_multiple_y.py</a></td></tr>
<tr><td>116</td><td>116_grid_operations.py</td><td>konstrukce matice obsahující souřadnice bodů v&nbsp;mřížce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/116_grid_operations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/116_grid_operations.py</a></td></tr>
<tr><td>117</td><td>117_linear_regression_multiple_x.py</td><td>proložení bodů v&nbsp;prostoru rovinou</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/117_linear_regression_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/117_linear_regression_multiple_x.py</a></td></tr>
<tr><td>118</td><td>118_linear_regression_multiple_x.py</td><td>proložení bodů s&nbsp;náhodnou výškou rovinou</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/118_linear_regression_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/118_linear_regression_multiple_x.py</a></td></tr>
<tr><td>119</td><td>119_linear_regression_multiple_x_and_y.py</td><td>proložení dvou sad bodů dvojicí rovin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/119_linear_regression_multiple_x_and_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/119_linear_regression_multiple_x_and_y.py</a></td></tr>
<tr><td>120</td><td>120_linear_regression_multiple_x_and_y.py</td><td>proložení dvou sad bodů dvojicí rovin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/120_linear_regression_multiple_x_and_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/120_linear_regression_multiple_x_and_y.py</a></td></tr>
<tr><td>121</td><td>121_linear_regression_poly.py</td><td>základní polynomická regrese</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/121_linear_regression_poly.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/121_linear_regression_poly.py</a></td></tr>
<tr><td>122</td><td>122_linear_regression_poly_multiple_x.py</td><td>polynomická regrese a body v&nbsp;prostoru, první příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/122_linear_regression_poly_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/122_linear_regression_poly_multiple_x.py</a></td></tr>
<tr><td>123</td><td>123_linear_regression_poly_multiple_x.py</td><td>polynomická regrese a body v&nbsp;prostoru, druhý příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/123_linear_regression_poly_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/123_linear_regression_poly_multiple_x.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>124</td><td>124_iris_set_statistic.py</td><td>získání statistických informací o datové sadě <i>Iris</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/124_iris_set_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/124_iris_set_statistic.py</a></td></tr>
<tr><td>125</td><td>125_california_housings_statistic.py</td><td>získání statistických informací o datové sadě <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/125_california_housings_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/125_california_housings_statistic.py</a></td></tr>
<tr><td>126</td><td>126_variance_threshold_1.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/126_variance_threshold_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/126_variance_threshold_1.py</a></td></tr>
<tr><td>127</td><td>127_variance_threshold_2.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/127_variance_threshold_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/127_variance_threshold_2.py</a></td></tr>
<tr><td>128</td><td>128_variance_threshold_3.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/128_variance_threshold_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/128_variance_threshold_3.py</a></td></tr>
<tr><td>129</td><td>129_select_best_iris.py</td><td>výběr nejvhodnějších atributů pro datovou sadu <i>Iris</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/129_select_best_iris.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/129_select_best_iris.py</a></td></tr>
<tr><td>130</td><td>130_select_best_housings.py</td><td>výběr nejvhodnějších atributů pro datovou sadu <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/130_select_best_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/130_select_best_housings.py</a></td></tr>
<tr><td>131</td><td>131_select_k_best_housings.py</td><td>výběr K nejvhodnějších atributů pro datovou sadu <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/131_select_k_best_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/131_select_k_best_housings.py</a></td></tr>
<tr><td>132</td><td>132_select_from_model.py</td><td>výběr atributů na základě k&nbsp;tomu určeného modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/132_select_from_model.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/132_select_from_model.py</a></td></tr>
<tr><td>133</td><td>133_cross_validation_1.py</td><td>křížová validace po výběru (filtraci) modelů (datová sada <i>Iris</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/133_cross_validation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/133_cross_validation_1.py</a></td></tr>
<tr><td>134</td><td>134_cross_validation_2.py</td><td>křížová validace po výběru (filtraci) modelů (datová sada <i>California Housings</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/134_cross_validation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/134_cross_validation_2.py</a></td></tr>
<tr><td>135</td><td>135_cross_validation_3.py</td><td>křížová validace po výběru (filtraci) modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/135_cross_validation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/135_cross_validation_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>136</td><td>136_mlp_classifier_01.py</td><td>použití neuronové sítě pro klasifikaci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/136_mlp_classifier_01.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/136_mlp_classifier_01.py</a></td></tr>
<tr><td>137</td><td>137_mlp_classifier_02.py</td><td>výpočet úspěšnosti modelu založeného na neuronové síti</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/137_mlp_classifier_02.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/137_mlp_classifier_02.py</a></td></tr>
<tr><td>138</td><td>138_mlp_classifier_03.py</td><td>konfigurace vrstev neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/138_mlp_classifier_03.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/138_mlp_classifier_03.py</a></td></tr>
<tr><td>139</td><td>139_mlp_classifier_04.py</td><td>proměnný počet neuronů ve vrstvách neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/139_mlp_classifier_04.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/139_mlp_classifier_04.py</a></td></tr>
<tr><td>140</td><td>140_mlp_classifier_05.py</td><td>proměnný počet neuronů ve více vrstvách neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/140_mlp_classifier_05.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/140_mlp_classifier_05.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>141</td><td>141_mlp_regression_1.py</td><td>použití neuronové sítě pro regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/141_mlp_regression_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/141_mlp_regression_1.py</a></td></tr>
<tr><td>142</td><td>142_mlp_regression_2.py</td><td>modifikace parametrů neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/142_mlp_regression_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/142_mlp_regression_2.py</a></td></tr>
<tr><td>143</td><td>143_mlp_regression_2.py</td><td>další modifikace parametrů neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/143_mlp_regression_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/143_mlp_regression_2.py</a></td></tr>
<tr><td>144</td><td>144_mlp_regression_3.py</td><td>postupná změna počtu neuronů v&nbsp;jedné skryté vrstvě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/144_mlp_regression_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/144_mlp_regression_3.py</a></td></tr>
<tr><td>145</td><td>145_mlp_regression_4.py</td><td>postupná změna počtu neuronů ve třech skrytých vrstvách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/145_mlp_regression_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/145_mlp_regression_4.py</a></td></tr>
<tr><td>146</td><td>146_mlp_regression_5.py</td><td>postupná změna počtu neuronů v&nbsp;pěti skrytých vrstvách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/146_mlp_regression_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/146_mlp_regression_5.py</a></td></tr>
<tr><td>147</td><td>147_mlp_regression_6.py</td><td>postupná změna počtu skrytých vrstev při zachování počtu neuronů v&nbsp;každé vrstvě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/147_mlp_regression_6.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/147_mlp_regression_6.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>148</td><td>148_confusion_matrix_1.py</td><td>zjištění kvality modelu s&nbsp;využitím matice záměn (<i>confusion matrix</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/148_confusion_matrix_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/148_confusion_matrix_1.py</a></td></tr>
<tr><td>149</td><td>149_confusion_matrix_2.py</td><td>zjištění kvality modelu hledajícího K nejbližších sousedů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/149_confusion_matrix_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/149_confusion_matrix_2.py</a></td></tr>
<tr><td>150</td><td>150_confusion_matrix_3.py</td><td>zjištění kvality modelu tvořeného neuronovou sítí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/150_confusion_matrix_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/150_confusion_matrix_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>151</td><td>151_multiplication_table.py</td><td>využití neuronové sítě pro odhad výsledků součinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/151_multiplication_table.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/151_multiplication_table.py</a></td></tr>
<tr><td>152</td><td>152_multiplication_table.py</td><td>odhad/vygenerování celé matice malé násobilky neuronovou sítí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/152_multiplication_table.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/152_multiplication_table.py</a></td></tr>
<tr><td>153</td><td>153_multiplication_table.py</td><td>rozšíření výpočtu součinu na rozsah 20×20 (při zachování původní sítě)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/153_multiplication_table.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/153_multiplication_table.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>154</td><td>154_images_1.py</td><td>rozpoznání číslic modelem provádějícím logistickou regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/154_images_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/154_images_1.py</a></td></tr>
<tr><td>155</td><td>155_images_2.py</td><td>rozpoznání číslic: využití modelu SVM (metoda podpůrných vektorů) pro klasifikaci obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/155_images_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/155_images_2.py</a></td></tr>
<tr><td>156</td><td>156_images_3.py</td><td>rozpoznání číslic: využití modelu pro hledání K nejbližších sousedů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/156_images_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/156_images_3.py</a></td></tr>
<tr><td>157</td><td>157_images_4.py</td><td>rozpoznání rastrových obrázků neuronovou sítí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/157_images_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/157_images_4.py</a></td></tr>
<tr><td>158</td><td>158_all_predictions.py</td><td>zobrazení původních obrázků i predikovaných výsledků ve vizuální podobě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/158_all_predictions.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/158_all_predictions.py</a></td></tr>
<tr><td>159</td><td>159_wrong_predictions.py</td><td>zobrazení 25 nekorektních odhadů modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/159_wrong_predictions.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/159_wrong_predictions.py</a></td></tr>
<tr><td>160</td><td>160_nn_wrong_predictions.py</td><td>zobrazení 25 nekorektních odhadů neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/160_nn_wrong_predictions.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/160_nn_wrong_predictions.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>161</td><td>161_activation_function.py</td><td>specifikace aktivační funkce neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/161_activation_function.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/161_activation_function.py</a></td></tr>
<tr><td>162</td><td>162_solver.py</td><td>specifikace trénovacího a učícího algoritmu neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/162_solver.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/162_solver.py</a></td></tr>
<tr><td>163</td><td>163_best_combination.py</td><td>kombinace nejlepší aktivační funkce a nejlepšího trénovacího algoritmu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/163_best_combination.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/163_best_combination.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>164</td><td>164_simplest_nn.py</td><td>neuronová síť s&nbsp;pouhými třemi neurony</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/164_simplest_nn.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/164_simplest_nn.py</a></td></tr>
<tr><td>165</td><td>165_no_randomization.py</td><td>odstranění náhody z&nbsp;procesu tréninku a testování neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/165_no_randomization.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/165_no_randomization.py</a></td></tr>
<tr><td>166</td><td>166_step_by_step.py</td><td>postupné zvětšování počtu vzorků použitých pro trénink neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/166_step_by_step.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/166_step_by_step.py</a></td></tr>
<tr><td>167</td><td>167_weights_biases.py</td><td>grafické znázornění závislosti MSE, vah neuronů a biasu na počtu vzorků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/167_weights_biases.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/167_weights_biases.py</a></td></tr>
<tr><td>168</td><td>168_maxiter.py</td><td>zrychlení tréninku neuronové sítě snížením počtu iterací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/168_maxiter.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/168_maxiter.py</a></td></tr>
<tr><td>169</td><td>169_learning_rate.py</td><td>vyšší míra změny vah na vstupu neuronů při tréninku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/169_learning_rate.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/169_learning_rate.py</a></td></tr>
<tr><td>170</td><td>170_too_fast_rate.py</td><td>riziko příliš vysoké hodnoty <strong>learning_rate_init</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/170_too_fast_rate.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/170_too_fast_rate.py</a></td></tr>
<tr><td>171</td><td>171_too_slow_rate.py</td><td>opačný extrém &ndash; příliš malá hodnota <strong>learning_rate_init</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/171_too_slow_rate.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/171_too_slow_rate.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>172</td><td>172_download_dataset.py</td><td>získání datové sady s&nbsp;tweety o dopravcích</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/172_download_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/172_download_dataset.py</a></td></tr>
<tr><td>173</td><td>173_download_stopwords.py</td><td>získání slovníku se stopslovy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/173_download_stopwords.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/173_download_stopwords.py</a></td></tr>
<tr><td>174</td><td>174_read_airline_tweets.py</td><td>načtení datové sady s&nbsp;tweety o dopravcích</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/174_read_airline_tweets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/174_read_airline_tweets.py</a></td></tr>
<tr><td>175</td><td>175_airline_tweets_info.py</td><td>informace o načtené datové sadě s&nbsp;tweety o dopravcích</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/175_airline_tweets_info.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/175_airline_tweets_info.py</a></td></tr>
<tr><td>176</td><td>176_airline_tweets_statistic.py</td><td>základní statistické údaje o datové sadě s&nbsp;tweety o dopravcích</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/176_airline_tweets_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/176_airline_tweets_statistic.py</a></td></tr>
<tr><td>177</td><td>177_tweets_per_airline.py</td><td>statistika: počet tweetů o jednotlivých dopravcích</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/177_tweets_per_airline.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/177_tweets_per_airline.py</a></td></tr>
<tr><td>178</td><td>178_tweets_bar_chart.py</td><td>vizualizace počtu tweetů o jednotlivých dopravcích na sloupcovém diagramu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/178_tweets_bar_chart.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/178_tweets_bar_chart.py</a></td></tr>
<tr><td>179</td><td>179_tweets_pie_chart.py</td><td>vizualizace počtu tweetů o jednotlivých dopravcích na koláčovém diagram</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/179_tweets_pie_chart.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/179_tweets_pie_chart.py</a></td></tr>
<tr><td>180</td><td>180_sentiments.py</td><td>výpočet hodnocení jednotlivých dopravců</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/180_sentiments.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/180_sentiments.py</a></td></tr>
<tr><td>181</td><td>181_sentiments_piechart.py</td><td>vizualizace hodnocení jednotlivých dopravců</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/181_sentiments_piechart.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/181_sentiments_piechart.py</a></td></tr>
<tr><td>182</td><td>182_sentiment_per_airline.py</td><td>výpočet hodnocení vztažených k&nbsp;jednotlivým dopravcům</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/182_sentiment_per_airline.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/182_sentiment_per_airline.py</a></td></tr>
<tr><td>183</td><td>183_sentiment_per_airline.py</td><td>výpočet hodnocení vztažených k&nbsp;jednotlivým dopravcům</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/183_sentiment_per_airline.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/183_sentiment_per_airline.py</a></td></tr>
<tr><td>184</td><td>184_features.py</td><td>přečtení potřebných atributů z&nbsp;datové sady pro trénink modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/184_features.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/184_features.py</a></td></tr>
<tr><td>185</td><td>185_processing.py</td><td>předzpracování textových dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/185_processing.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/185_processing.py</a></td></tr>
<tr><td>186</td><td>186_vectorization.py</td><td>vektorizace textových dat pomocí třídy <strong>CountVectorizer</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/186_vectorization.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/186_vectorization.py</a></td></tr>
<tr><td>187</td><td>187_vectorization.py</td><td>vektorizace textových dat pomocí třídy <strong>TfidfVectorizer</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/187_vectorization.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/187_vectorization.py</a></td></tr>
<tr><td>188</td><td>188_vectorization_and_training.py</td><td>trénink modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/188_vectorization_and_training.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/188_vectorization_and_training.py</a></td></tr>
<tr><td>189</td><td>189_vectorization_and_nn.py</td><td>trénink modelu s&nbsp;využitím neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/189_vectorization_and_nn.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/189_vectorization_and_nn.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>190</td><td>190_count_vectorizer.py</td><td>základní vektorizace s&nbsp;využitím třídy <strong>CountVectorizer</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/190_count_vectorizer.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/190_count_vectorizer.py</a></td></tr>
<tr><td>191</td><td>191_words_to_vec.py</td><td>převod sekvence slov do vektorové podoby</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/191_words_to_vec.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/191_words_to_vec.py</a></td></tr>
<tr><td>192</td><td>192_vec_to_words.py</td><td>zpětný převod z&nbsp;vektorové podoby na sekvenci slov</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/192_vec_to_words.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/192_vec_to_words.py</a></td></tr>
</table>

<p>V&nbsp;repositáři nalezneme taktéž projektový soubor a Jupyter Notebook
s&nbsp;vysvětlením, jak lze modely využít pro rozpoznávání obsahu rastrových
obrázků:</p>

<table>
<tr><th>#</th><th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr>
<tr><td>1</td><td>pyproject.toml</td><td>projektový soubor (pro PDM) se všemi závislostmi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>2</td><td>pdm.lock</td><td>lock soubor s&nbsp;konkrétními verzemi všech přímých i tranzitivních závislostí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>3</td><td>Rozpoznání_obrazu_scikit-learn.ipynb</td><td>Jupyter notebook s&nbsp;celým postupem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>4</td><td>particle_life.py</td><td>emergence: příklad vzniku struktury</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py">https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Python for NLP: Sentiment Analysis with Scikit-Learn<br />
<a href="https://stackabuse.com/python-for-nlp-sentiment-analysis-with-scikit-learn/">https://stackabuse.com/python-for-nlp-sentiment-analysis-with-scikit-learn/</a>
</li>

<li>Datová sada - hodnocení leteckých dopravců<br />
<a href="https://raw.githubusercontent.com/satyajeetkrjha/kaggle-Twitter-US-Airline-Sentiment-/refs/heads/master/Tweets.csv">https://raw.githubusercontent.com/satyajeetkrjha/kaggle-Twitter-US-Airline-Sentiment-/refs/heads/master/Tweets.csv</a>
</li>

<li>Twitter_US_Airline_Sentiment_Analysis <br />
<a href="https://github.com/rustagijanvi/Twitter_US_Airline_Sentiment_Analysis/tree/main">https://github.com/rustagijanvi/Twitter_US_Airline_Sentiment_Analysis/tree/main</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

<li>Rozpoznávání obrázků knihovnou Scikit-learn: první kroky<br />
<a href="https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/">https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/</a>
</li>

<li>scikit-learn: Machine Learning in Python<br />
<a href="https://scikit-learn.org/stable/index.html">https://scikit-learn.org/stable/index.html</a>
</li>

<li>Sklearn-pandas<br />
<a href="https://github.com/scikit-learn-contrib/sklearn-pandas">https://github.com/scikit-learn-contrib/sklearn-pandas</a>
</li>

<li>sklearn-xarray<br />
<a href="https://github.com/phausamann/sklearn-xarray/">https://github.com/phausamann/sklearn-xarray/</a>
</li>

<li>Clustering<br />
<a href="https://scikit-learn.org/stable/modules/clustering.html">https://scikit-learn.org/stable/modules/clustering.html</a>
</li>

<li>Cluster analysis (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Cluster_analysis">https://en.wikipedia.org/wiki/Cluster_analysis</a>
</li>

<li>Shluková analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza">https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza</a>
</li>

<li>K-means<br />
<a href="https://cs.wikipedia.org/wiki/K-means">https://cs.wikipedia.org/wiki/K-means</a>
</li>

<li>k-means clustering<br />
<a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a>
</li>

<li>Spectral clustering<br />
<a href="https://en.wikipedia.org/wiki/Spectral_clustering">https://en.wikipedia.org/wiki/Spectral_clustering</a>
</li>

<li>Emergence<br />
<a href="https://cs.wikipedia.org/wiki/Emergence">https://cs.wikipedia.org/wiki/Emergence</a>
</li>

<li>Particle Life: Vivid structures from rudimentary rules<br />
<a href="https://particle-life.com/">https://particle-life.com/</a>
</li>

<li>Hertzsprungův–Russellův diagram<br />
<a href="https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram">https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram</a>
</li>

<li>Using Machine Learning in an HR Diagram<br />
<a href="https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f">https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f</a>
</li>

<li>Gaia H-R diagrams: Querying Gaia data for one million nearby stars<br />
<a href="https://vlas.dev/post/gaia-dr2-hrd/">https://vlas.dev/post/gaia-dr2-hrd/</a>
</li>

<li>The Hertzsprung–Russell diagram<br />
<a href="https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/">https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/</a>
</li>

<li>Animated Hertzsprung-Russell Diagram with 119,614 datapoints<br />
<a href="https://github.com/zonination/h-r-diagram">https://github.com/zonination/h-r-diagram</a>
</li>

<li>Neuraxle Pipelines<br />
<a href="https://github.com/Neuraxio/Neuraxle">https://github.com/Neuraxio/Neuraxle</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Natural-language processing<br />
<a href="https://en.wikipedia.org/wiki/Natural-language_processing">https://en.wikipedia.org/wiki/Natural-language_processing</a>
</li>

<li>THE MNIST DATABASE of handwritten digits<br />
<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>
</li>

<li>MNIST database (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/MNIST_database">https://en.wikipedia.org/wiki/MNIST_database</a>
</li>

<li>MNIST For ML Beginners<br />
<a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch: Serialization<br />
<a href="https://github.com/torch/torch7/blob/master/doc/serialization.md">https://github.com/torch/torch7/blob/master/doc/serialization.md</a>
</li>

<li>Torch: modul image<br />
<a href="https://github.com/torch/image/blob/master/README.md">https://github.com/torch/image/blob/master/README.md</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>Neural network containres (Torch)<br />
<a href="https://github.com/torch/nn/blob/master/doc/containers.md">https://github.com/torch/nn/blob/master/doc/containers.md</a>
</li>

<li>Simple layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear">https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear</a>
</li>

<li>Transfer Function Layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok">https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>PyTorch<br />
<a href="http://pytorch.org/">http://pytorch.org/</a>
</li>

<li>JupyterLite na PyPi<br />
<a href="https://pypi.org/project/jupyterlite/">https://pypi.org/project/jupyterlite/</a>
</li>

<li>JupyterLite na GitHubu<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Dokumentace k&nbsp;projektu JupyterLite<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Matplotlib Home Page<br />
<a href="http://matplotlib.org/">http://matplotlib.org/</a>
</li>

<li>Matplotlib (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Matplotlib">https://en.wikipedia.org/wiki/Matplotlib</a>
</li>

<li>Popis barvových map modulu matplotlib.cm<br />
<a href="https://gist.github.com/endolith/2719900#id7">https://gist.github.com/endolith/2719900#id7</a>
</li>

<li>Ukázky (palety) barvových map modulu matplotlib.cm<br />
<a href="http://matplotlib.org/examples/color/colormaps_reference.html">http://matplotlib.org/examples/color/colormaps_reference.html</a>
</li>

<li>Galerie grafů vytvořených v&nbsp;Matplotlibu<br />
<a href="https://matplotlib.org/3.2.1/gallery/">https://matplotlib.org/3.2.1/gallery/</a>
</li>

<li>3D rendering<br />
<a href="https://en.wikipedia.org/wiki/3D_rendering">https://en.wikipedia.org/wiki/3D_rendering</a>
</li>

<li>3D computer graphics<br />
<a href="https://en.wikipedia.org/wiki/3D_computer_graphics">https://en.wikipedia.org/wiki/3D_computer_graphics</a>
</li>

<li>Primary 3D view planes<br />
<a href="https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html">https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html</a>
</li>

<li>Getting started in scikit-learn with the famous iris dataset<br />
<a href="https://www.youtube.com/watch?v=hd1W4CyPX58">https://www.youtube.com/watch?v=hd1W4CyPX58</a>
</li>

<li>Training a machine learning model with scikit-learn<br />
<a href="https://www.youtube.com/watch?v=RlQuVL6-qe8">https://www.youtube.com/watch?v=RlQuVL6-qe8</a>
</li>

<li>Iris (plant)<br />
<a href="https://en.wikipedia.org/wiki/Iris_(plant)">https://en.wikipedia.org/wiki/Iris_(plant)</a>
</li>

<li>Kosatec<br />
<a href="https://cs.wikipedia.org/wiki/Kosatec">https://cs.wikipedia.org/wiki/Kosatec</a>
</li>

<li>Iris setosa<br />
<a href="https://en.wikipedia.org/wiki/Iris_setosa">https://en.wikipedia.org/wiki/Iris_setosa</a>
</li>

<li>Iris versicolor<br />
<a href="https://en.wikipedia.org/wiki/Iris_versicolor">https://en.wikipedia.org/wiki/Iris_versicolor</a>
</li>

<li>Iris virginica<br />
<a href="https://en.wikipedia.org/wiki/Iris_virginica">https://en.wikipedia.org/wiki/Iris_virginica</a>
</li>

<li>Druh<br />
<a href="https://cs.wikipedia.org/wiki/Druh">https://cs.wikipedia.org/wiki/Druh</a>
</li>

<li>Iris subg. Limniris<br />
<a href="https://en.wikipedia.org/wiki/Iris_subg._Limniris">https://en.wikipedia.org/wiki/Iris_subg._Limniris</a>
</li>

<li>Iris Dataset Classification with Python: A Tutorial<br />
<a href="https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html">https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html</a>
</li>

<li>Iris flower data set<br />
<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">https://en.wikipedia.org/wiki/Iris_flower_data_set</a>
</li>

<li>List of datasets for machine-learning research<br />
<a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research</a>
</li>

<li>Analýza hlavních komponent<br />
<a href="https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent">https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent</a>
</li>

<li>Principal component analysis<br />
<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">https://en.wikipedia.org/wiki/Principal_component_analysis</a>
</li>

<li>Scikit-learn Crash Course - Machine Learning Library for Python<br />
<a href="https://www.youtube.com/watch?v=0B5eIE_1vpU">https://www.youtube.com/watch?v=0B5eIE_1vpU</a>
</li>

<li>calm-notebooks<br />
<a href="https://github.com/koaning/calm-notebooks">https://github.com/koaning/calm-notebooks</a>
</li>

<li>Should you teach Python or R for data science?<br />
<a href="https://www.dataschool.io/python-or-r-for-data-science/">https://www.dataschool.io/python-or-r-for-data-science/</a>
</li>

<li>nbviewer: A simple way to share Jupyter Notebooks<br />
<a href="https://nbviewer.org/">https://nbviewer.org/</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

<li>Matplotlib vs. seaborn vs. Plotly vs. MATLAB vs. ggplot2 vs. pandas<br />
<a href="https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/">https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/</a>
</li>

<li>Matplotlib, Seaborn or Plotnine?<br />
<a href="https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/">https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/</a>
</li>

<li>@Rabeez: Rabeez/plotting_comparison.ipynb<br />
<a href="https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc">https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc</a>
</li>

<li>Matplotlib, Seaborn, Plotly and Plotnine Comparison<br />
<a href="https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40">https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40</a>
</li>

<li>Data Visualization 101: How to Choose a Python Plotting Library<br />
<a href="https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a">https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a</a>
</li>

<li>Data science in Python: pandas, seaborn, scikit-learn<br />
<a href="https://www.youtube.com/watch?v=3ZWuPVWq7p4">https://www.youtube.com/watch?v=3ZWuPVWq7p4</a>
</li>

<li>7.2. Real world datasets<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>7.2.7. California Housing dataset<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>Comprehensive Guide to Classification Models in Scikit-Learn<br />
<a href="https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/">https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/</a>
</li>

<li>Tidy Data Visualization: ggplot2 vs seaborn<br />
<a href="https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/">https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/</a>
</li>

<li>seaborn: statistical data visualization<br />
<a href="https://seaborn.pydata.org/">https://seaborn.pydata.org/</a>
</li>

<li>Linear regression (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Linear_regression">https://en.wikipedia.org/wiki/Linear_regression</a>
</li>

<li>Lineární regrese (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese">https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese</a>
</li>

<li>Iris Flower Classification with MLP Classifier<br />
<a href="https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier">https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

