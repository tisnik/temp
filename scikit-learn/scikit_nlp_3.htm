<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Využití knihovny scikit-learn pro zpracování a analýzu přirozeného jazyka (NLP), 3.část</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Využití knihovny scikit-learn pro zpracování a analýzu přirozeného jazyka (NLP), 3.část</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>Budeme se zabývat velmi často řešenou úlohou: analýzou, zda je předložený text spam nebo se jedná o jiný typ textu (ham). Při vektorizaci textu využijeme takzvané n-gramy.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Využití knihovny scikit-learn pro zpracování a analýzu přirozeného jazyka (NLP), 3.část</a></p>
<p><a href="#k02">2. Získání datové sady a slovníku se slopslovy</a></p>
<p><a href="#k03">3. Pokus o načtení datové sady do datového rámce (<i>dataframe</i>)</a></p>
<p><a href="#k04">4. Specifikace kódování znaků v&nbsp;CSV souboru při jeho načítání do datového rámce</a></p>
<p><a href="#k05">5. Zjištění statistiky o ohodnocení textu</a></p>
<p><a href="#k06">6. Sloupce s&nbsp;očekávanými výsledky i s&nbsp;vlastním textem SMS</a></p>
<p><a href="#k07">7. Vektorizace dat SMSek s&nbsp;výpisem výsledného slovníku</a></p>
<p><a href="#k08">8. Výpis obsahu slovníku ve více sloupcích</a></p>
<p><a href="#k09">9. Vektorizace všech SMSek z&nbsp;datové sady</a></p>
<p><a href="#k10">10. Preprocesing textů z&nbsp;SMSsek s&nbsp;vyčištěním dat</a></p>
<p><a href="#k11">11. Vektorizace textových dat po jejich filtraci</a></p>
<p><a href="#k12">12. Trénink a predikce modelu nad vektorizovanými daty založený na třídě <strong>CountVectorizer</strong></a></p>
<p><a href="#k13">13. Trénink a predikce modelu nad vektorizovanými daty založený na třídě <strong>TfidfVectorizer</strong></a></p>
<p><a href="#k14">14. Jak pracovat s&nbsp;kontextem: řešení založené na n-gramech</a></p>
<p><a href="#k15">15. Vektorizace textových dat s použitím n-gramů o délce 1-2 slov s&nbsp;výpisem výsledného slovníku</a></p>
<p><a href="#k16">16. Trénink a predikce modelu s&nbsp;využitím třídy <strong>CountVectorizer</strong> při vektorizaci n-gramů</a></p>
<p><a href="#k17">17. Trénink a predikce modelu s&nbsp;využitím třídy <strong>TfidfVectorizer</strong> při vektorizaci n-gramů</a></p>
<p><a href="#k18">18. Zjištění vlivu minimální a maximální délky n-gramů na kvalitu modelu</a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Využití knihovny scikit-learn pro zpracování a analýzu přirozeného jazyka (NLP), 3.část</h2>

<p>Již potřetí se dnes vrátíme k&nbsp;problematice zpracování a analýzy
přirozeného jazyka (<i>Natural Language Processing</i> neboli <i>NLP</i>)
v&nbsp;Pythonu s&nbsp;využitím knihovny <i>scikit-learn</i>. Budeme se zabývat
velmi často řešenou úlohou &ndash; a to konkrétně analýzou, zda je předložený
text <i>spam</i> nebo se jedná o jiný typ textu (označuje se termínem
<i>ham</i>). A aby nebyl objem zpracovávaných dat obrovský, budeme tuto analýzu
provádět nad datovou sadou obsahující anglicky psané SMSky, tj.&nbsp;relativně
krátké texty. Jedná se tedy o zadání, které se do jisté míry podobá úloze,
kterou jsme již řešili, konkrétně k&nbsp;vytvoření modelu pro zjištění, zda
jsou tweety laděny pozitivně, negativně nebo neutrálně.</p>

<p>Při řešení dnes použijeme novou techniku vektorizace, která není založena na
vektorizaci jednotlivých slov, ale na zjištění, jaké kombinace slov se
v&nbsp;textu vyskytují. Vektorizovat se budou právě tyto kombinace slov,
tj.&nbsp;například &bdquo;dobrý den&ldquo; by byl samostatný záznam ve
slovníku. Díky tomu bude možné lépe podchytit kontext a (možná) tak zlepšit
predikční schopnosti modelu (i když, jak uvidíme dále, pro krátké SMSky od
mnoha autorů to nebude tak výrazné). Ovšem v&nbsp;oboru NLP se s&nbsp;n-gramy
pracuje poměrně často.</p>

<div class="rs-tip-major">Poznámka: udává se, že nejúspěšnější je použití
<i>bigramů</i>, tj.&nbsp;dvojic slov.</div>


<p><a name="k02"></a></p>
<h2 id="k02">2. Získání datové sady a slovníku se slopslovy</h2>

<p>V&nbsp;prvním kroku si, jak je již v&nbsp;tomto seriálu zvykem, stáhneme
datovou sadu, kterou použijeme pro trénink a validaci modelu. Tato datová sada
je tvořena jediným souborem ve formátu CSV, který je dostupný na adrese <a href="https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset?resource=download">https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset?resource=download</a>
(ve skutečnosti je nutné si projít potvrzovacím dialogem, na druhou stranu celá
platforma Kaggle nabízí i další užitečné materiály a dokonce i celé Jupyter
notebooky, takže je vhodné tento krok &bdquo;přetrpět&ldquo;).</p>

<a href="https://www.root.cz/obrazek/1155735/"><img src="https://i.iinfo.cz/images/651/scikit-learn-nlp-3-1-prev.webp" class="image-1155735" width="370" height="155" data-prev-filename="https://i.iinfo.cz/images/651/scikit-learn-nlp-3-1-prev.webp" data-prev-width="370" data-prev-height="155" data-large-filename="https://i.iinfo.cz/images/651/scikit-learn-nlp-3-1-large.webp" data-large-width="720" data-large-height="301" alt="&nbsp;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" /></a>
<p><i>Obrázek 1: Obsah staženého souboru CSV po jeho importu do spreadsheetu.</i></p>

<p>Dále budeme v&nbsp;některých skriptech vyžadovat slovník s&nbsp;takzvanými
stopslovy (<i>stopwords</i>), o nichž jsme se již zmínili předminule a minule.
Jedná se o slova, která v&nbsp;textu nenesou žádnou skutečně užitečnou
informaci a mohou být odfiltrována. Tento slovník stáhneme jednoduchým skriptem
založeným na knihovně NLTK. Vše se stáhne do adresáře
<strong>ntkl_data</strong> umístěného v&nbsp;domovském adresáři:</p>

<pre>
<i># Stažení slovníku, který bude použit pro předzpracování textu v dalších</i>
<i># demonstračních příkladech.</i>
&nbsp;
import nltk
&nbsp;
<i># tento příkaz zajistí stažení příslušných datových souborů</i>
nltk.download("stopwords")
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. Pokus o načtení datové sady do datového rámce (<i>dataframe</i>)</h2>

<p>Již při analýze datové sady s&nbsp;tweety o dopravcích jsme celý soubor ve
formátu CSV nejprve (před jeho dalším zpracováním) načetli do datového rámce
(<i>dataframe</i>) s&nbsp;využitím knihovny Pandas. Toto načtení se obešlo bez
problémů, takže se pokusme o provedení naprosto stejné operace, ovšem nyní nad
souborem <strong>spam.csv</strong> získaným v&nbsp;rámci <a href="#k02">předchozí kapitoly</a>:</p>

<pre>
<i># Pokus o načtení datové sady a zjištění základních údajů</i>
&nbsp;
import pandas as pd 
&nbsp;
<i># načtení tabulky do datového rámce</i>
spam = pd.read_csv("spam.csv")
&nbsp;
<i># základní informace o datovém rámci</i>
print(spam.describe())
</pre>

<p>Nyní ovšem tato operace vyvolá výjimku, která by měla vypadat zhruba
následovně:</p>

<pre>
Traceback (most recent call last):
  File "/home/ptisnovs/xy/205_spam_read.py", line 6, in &lt;module&gt;
    spam = pd.read_csv("spam.csv")
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ptisnovs/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py", line 1026, in read_csv
    return _read(filepath_or_buffer, kwds)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ptisnovs/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py", line 620, in _read
    parser = TextFileReader(filepath_or_buffer, **kwds)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ptisnovs/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py", line 1620, in __init__
    self._engine = self._make_engine(f, self.engine)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ptisnovs/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py", line 1898, in _make_engine
    return mapping[engine](f, **self.options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ptisnovs/.local/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py", line 93, in __init__
    self._reader = parsers.TextReader(src, **kwds)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "parsers.pyx", line 574, in pandas._libs.parsers.TextReader.__cinit__
  File "parsers.pyx", line 663, in pandas._libs.parsers.TextReader._get_header
  File "parsers.pyx", line 874, in pandas._libs.parsers.TextReader._tokenize_rows
  File "parsers.pyx", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status
  File "parsers.pyx", line 2053, in pandas._libs.parsers.raise_parser_error
UnicodeDecodeError: 'utf-8' codec can't decode bytes in position 606-607: invalid continuation byte
</pre>

<div class="rs-tip-major">Poznámka: tato výjimka možná není příliš čitelná,
protože si musíme uvědomit, že knihovnu Pandas používají i lidé, pro které není
vývoj primárním cílem práce. Ovšem z&nbsp;posledního řádku je patrné, jaký
problém nastal &ndash; v&nbsp;souboru CSV se objevují sekvence bajtů, které
není možné dekódovat jako UTF-8 znak. Konkrétně se jedná o tento úsek:
&bdquo;å£1.5&ldquo;0, ale s&nbsp;velkou pravděpodobností takových problémů
nalezneme větší množství.</div>


<p><a name="k04"></a></p>
<h2 id="k04">4. Specifikace kódování znaků v&nbsp;CSV souboru při jeho načítání do datového rámce</h2>

<p>Pokusme se nyní o načtení souboru ve formátu CSV do datového rámce se
specifikací kódování znaků. Již víme, že soubor, který jsme stáhli, nepoužívá
UTF-8 a vlastně i nepřímo víme, že se nejedná o čisté ASCII (to je totiž
podmnožinou UTF-8). Pokusme se tedy použít nějaké osmibitové kódování, kdy
Pandas ve skutečnosti nemůže zjistit žádné chyby &ndash; každý bajt je převeden
do jednoho znaku, ať již obsahuje jakoukoli hodnotu. Případné
&bdquo;paznaky&ldquo; později odfiltrujeme. Vzhledem k&nbsp;tomu, že kódování
jen odhadujeme, zkusme například zadat <strong>latin1</strong>, což je jedno ze
základních osmibitových rozšíření původní sedmibitové znakové sady ASCII:</p>

<pre>
<i># Načtení datové sady a zjištění základních údajů o načteném datovém rámci</i>
&nbsp;
import pandas as pd 
&nbsp;
<i># načtení tabulky do datového rámce, specifikace kódování souboru</i>
spam = pd.read_csv("spam.csv", <strong>encoding="latin1"</strong>)
&nbsp;
<i># základní informace o datovém rámci</i>
print(spam.describe())
</pre>

<p>Nyní se soubor načte a vytvoří se z&nbsp;něho kýžený datový rámec.
Z&nbsp;jeho popisu je patrné, že obsahuje dva skutečné datové sloupce nazvané
<strong>v1</strong> a <strong>v2</strong> a taktéž je patrné, že některé řádky
(ale je jich jen 12 z&nbsp;celkového počtu 5572) jsou uloženy tak netypickým
způsobem, že byl programový kód načítající CSV při dekódování tak zmaten, že
předpokládal, že věta obsahuje oddělovač jednotlivých buněk (což je ostatně pro
formát CSV typické &ndash; tento formát nabízí velkou volnost a není tak dobře
přenositelný, jak bychom si přáli):</p>

<pre>
          v1                      v2  ...             Unnamed: 3 Unnamed: 4
count   5572                    5572  ...                     12          6
unique     2                    5169  ...                     10          5
top      ham  Sorry, I'll call later  ...   MK17 92H. 450Ppw 16"    GNT:-)"
freq    4825                      30  ...                      2          2
&nbsp;
[4 rows x 5 columns]
</pre>

<p>Pro zajímavost se na jeden z&nbsp;problémových řádků podívejme:</p>

<pre>
spam,"Your free ringtone is waiting to be collected. Simply text the password \MIX\"" to 85069 to verify. Get Usher and Britney. FML",  PO Box 5249," MK17 92H. 450Ppw 16""",
</pre>

<p>To je skutečně pro většinou &bdquo;načítačů&ldquo; CSV matoucí.</p>


<p><a name="k05"></a></p>
<h2 id="k05">5. Zjištění statistiky o ohodnocení textu</h2>

<p>Další postup již vlastně známe. Zjistíme, jaké údaje jsou zapsány
v&nbsp;prvním sloupci datového rámce. Předpokladem přitom je, že tento sloupec
bude obsahovat pouze dvě možné hodnoty, konkrétně &bdquo;ham&ldquo; nebo
&bdquo;spam&ldquo;. Údaje o tom, jaké hodnoty jsou v&nbsp;tomto sloupci uloženy
a navíc i informace o počtu těchto hodnot (frekvenci) zjistíme s&nbsp;využitím
metody <strong>value_counts()</strong> zavolané nad objektem představujícím
sloupec <strong>v1</strong> (což je objekt typu datové řady &ndash;
<strong>Serie</strong>)</p>

<pre>
<i># Načtení datové sady do datového rámce a zjištění statistiky o ohodnocení textu</i>
&nbsp;
import pandas as pd 
&nbsp;
<i># načtení tabulky do datového rámce, specifikace kódování souboru</i>
spam = pd.read_csv("spam.csv", encoding="latin1")
&nbsp;
<i># početm spamů a hamů</i>
print(<strong>spam.v1.value_counts()</strong>)
</pre>

<p>Z&nbsp;výsledků je patrné, že v&nbsp;tomto sloupci jsou skutečně (korektně)
uloženy pouze dvě možné hodnoty. Navíc je patrné, že více SMS není ohodnoceno
jako spam (spamu je pouze 15%), což v&nbsp;důsledku ovlivní i trénink modelu a
vypočtené matice záměn (viz další text):</p>

<pre>
v1
ham     4825
spam     747
Name: count, dtype: int64
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. Sloupce s&nbsp;očekávanými výsledky i s&nbsp;vlastním textem SMS</h2>

<p>Vzhledem k&nbsp;tomu, že sloupce datové sady (přesněji řečeno <i>první
dva</i> sloupce) mají taková jména, která jsou v&nbsp;jazyce Python platnými
identifikátory, můžeme snadno přečíst hodnoty uložené v&nbsp;těchto sloupcích
&ndash; názvy těchto sloupců jsou totiž současně i názvy atributů datového
rámce <strong>spam</strong>. První sloupec přitom obsahuje očekávané výsledky
(ohodnocení textu) a druhý sloupec vlastní, nijak nezpracovaný text SMS:</p>

<pre>
<i># Načtení datové sady, charakteristiky sloupců s návěstím a vlastním textem</i>

import pandas as pd 

<i># načtení tabulky do datového rámce, specifikace kódování souboru</i>
spam = pd.read_csv("spam.csv", encoding="latin1")

<i># hodnocení (spam/ham)</i>
labels = spam.v1.values

<i># vlastní text SMS</i>
features = spam.v2.values

<i># hodnoty použité později pro trénink modelu</i>
print("Labels:")
print(labels)
print("Number of labels:", len(labels))
print()

print("Features:")
print(features)
print("Number of features:", len(features))
</pre>

<pre>
Labels:
['ham' 'ham' 'spam' ... 'ham' 'ham' 'ham']
Number of labels: 5572

Features:
['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...'
 'Ok lar... Joking wif u oni...'
 "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's"
 ... 'Pity, * was in mood for that. So...any other suggestions?'
 "The guy did some bitching but I acted like i'd be interested in buying something else next week and he gave it to us for free"
 'Rofl. Its true to its name']
Number of features: 5572
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. </h2>

<pre>
<i># Vektorizace textových dat, výpis výsledného slovníku</i>

import pandas as pd 
import re
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer

<i># načtení tabulky do datového rámce, specifikace kódování souboru</i>
spam = pd.read_csv("spam.csv", encoding="latin1")

<i># hodnocení (spam/ham)</i>
labels = spam.v1.values

<i># vlastní text SMS</i>
features = spam.v2.values

<i># hodnoty použité později pro trénink modelu</i>
print("Labels:")
print(labels)
print("Number of labels:", len(labels))
print()

print("Features:")
print(features)
print("Number of features:", len(features))
print()

<i># vektorizace textu</i>
vectorizer = CountVectorizer(
    max_features=2500,
    min_df=7, max_df=0.8, stop_words=stopwords.words("english")
)
vectorized_features = vectorizer.fit_transform(features).toarray()

<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
print("Feature names count:", len(feature_names))
print("Feature names:")
for feature_name in feature_names:
    print(feature_name)
</pre>

<pre>
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. </h2>

<pre>
<i># Vektorizace textových dat, výpis výsledného slovníku</i>

import pandas as pd
import re
from itertools import zip_longest
from nltk.corpus import stopwords
from sklearn.feature_extraction.text import CountVectorizer

<i># načtení tabulky do datového rámce, specifikace kódování souboru</i>
spam = pd.read_csv("spam.csv", encoding="latin1")

<i># hodnocení (spam/ham)</i>
labels = spam.v1.values

<i># vlastní text SMS</i>
features = spam.v2.values

<i># hodnoty použité později pro trénink modelu</i>
print("Labels:")
print(labels)
print("Number of labels:", len(labels))
print()

print("Features:")
print(features)
print("Number of features:", len(features))
print()

<i># vektorizace textu</i>
vectorizer = CountVectorizer(
    max_features=2500, min_df=7, max_df=0.8, stop_words=stopwords.words("english")
)
vectorized_features = vectorizer.fit_transform(features).toarray()

<i># slova pro dekódování vah</i>
feature_names = vectorizer.get_feature_names_out()
print("Feature names count:", len(feature_names))
print("Feature names:")

columns = 4
for c1, c2, c3, c4 in zip_longest(
    feature_names[::columns],
    feature_names[1::columns],
    feature_names[2::columns],
    feature_names[3::columns],
):
    print(f"{c1: &lt;20}{c2: &lt;20}{c3: &lt;20}{c4}")
</pre>

<pre>
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>

<pre>
</pre>

<pre>
</pre>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>

<pre>
</pre>

<pre>
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu Scikit-learn lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady i na (Jupyter) diáře s&nbsp;postupem
výpočtů a analýz:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
</table>

<p>V&nbsp;repositáři nalezneme taktéž projektový soubor a Jupyter Notebook
s&nbsp;vysvětlením, jak lze modely využít pro rozpoznávání obsahu rastrových
obrázků:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td>1</td><td>pyproject.toml</td><td>projektový soubor (pro PDM) se všemi závislostmi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>2</td><td>pdm.lock</td><td>lock soubor s&nbsp;konkrétními verzemi všech přímých i tranzitivních závislostí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>3</td><td>Rozpoznání_obrazu_scikit-learn.ipynb</td><td>Jupyter notebook s&nbsp;celým postupem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>4</td><td>particle_life.py</td><td>emergence: příklad vzniku struktury</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py">https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Python for NLP: Sentiment Analysis with Scikit-Learn<br />
<a href="https://stackabuse.com/python-for-nlp-sentiment-analysis-with-scikit-learn/">https://stackabuse.com/python-for-nlp-sentiment-analysis-with-scikit-learn/</a>
</li>

<li>Datová sada - hodnocení leteckých dopravců<br />
<a href="https://raw.githubusercontent.com/satyajeetkrjha/kaggle-Twitter-US-Airline-Sentiment-/refs/heads/master/Tweets.csv">https://raw.githubusercontent.com/satyajeetkrjha/kaggle-Twitter-US-Airline-Sentiment-/refs/heads/master/Tweets.csv</a>
</li>

<li>Twitter_US_Airline_Sentiment_Analysis <br />
<a href="https://github.com/rustagijanvi/Twitter_US_Airline_Sentiment_Analysis/tree/main">https://github.com/rustagijanvi/Twitter_US_Airline_Sentiment_Analysis/tree/main</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

<li>Rozpoznávání obrázků knihovnou Scikit-learn: první kroky<br />
<a href="https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/">https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/</a>
</li>

<li>scikit-learn: Machine Learning in Python<br />
<a href="https://scikit-learn.org/stable/index.html">https://scikit-learn.org/stable/index.html</a>
</li>

<li>Sklearn-pandas<br />
<a href="https://github.com/scikit-learn-contrib/sklearn-pandas">https://github.com/scikit-learn-contrib/sklearn-pandas</a>
</li>

<li>sklearn-xarray<br />
<a href="https://github.com/phausamann/sklearn-xarray/">https://github.com/phausamann/sklearn-xarray/</a>
</li>

<li>Clustering<br />
<a href="https://scikit-learn.org/stable/modules/clustering.html">https://scikit-learn.org/stable/modules/clustering.html</a>
</li>

<li>Cluster analysis (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Cluster_analysis">https://en.wikipedia.org/wiki/Cluster_analysis</a>
</li>

<li>Shluková analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza">https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza</a>
</li>

<li>K-means<br />
<a href="https://cs.wikipedia.org/wiki/K-means">https://cs.wikipedia.org/wiki/K-means</a>
</li>

<li>k-means clustering<br />
<a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a>
</li>

<li>Spectral clustering<br />
<a href="https://en.wikipedia.org/wiki/Spectral_clustering">https://en.wikipedia.org/wiki/Spectral_clustering</a>
</li>

<li>Emergence<br />
<a href="https://cs.wikipedia.org/wiki/Emergence">https://cs.wikipedia.org/wiki/Emergence</a>
</li>

<li>Particle Life: Vivid structures from rudimentary rules<br />
<a href="https://particle-life.com/">https://particle-life.com/</a>
</li>

<li>Hertzsprungův–Russellův diagram<br />
<a href="https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram">https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram</a>
</li>

<li>Using Machine Learning in an HR Diagram<br />
<a href="https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f">https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f</a>
</li>

<li>Gaia H-R diagrams: Querying Gaia data for one million nearby stars<br />
<a href="https://vlas.dev/post/gaia-dr2-hrd/">https://vlas.dev/post/gaia-dr2-hrd/</a>
</li>

<li>The Hertzsprung–Russell diagram<br />
<a href="https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/">https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/</a>
</li>

<li>Animated Hertzsprung-Russell Diagram with 119,614 datapoints<br />
<a href="https://github.com/zonination/h-r-diagram">https://github.com/zonination/h-r-diagram</a>
</li>

<li>Neuraxle Pipelines<br />
<a href="https://github.com/Neuraxio/Neuraxle">https://github.com/Neuraxio/Neuraxle</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Natural-language processing<br />
<a href="https://en.wikipedia.org/wiki/Natural-language_processing">https://en.wikipedia.org/wiki/Natural-language_processing</a>
</li>

<li>THE MNIST DATABASE of handwritten digits<br />
<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>
</li>

<li>MNIST database (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/MNIST_database">https://en.wikipedia.org/wiki/MNIST_database</a>
</li>

<li>MNIST For ML Beginners<br />
<a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch: Serialization<br />
<a href="https://github.com/torch/torch7/blob/master/doc/serialization.md">https://github.com/torch/torch7/blob/master/doc/serialization.md</a>
</li>

<li>Torch: modul image<br />
<a href="https://github.com/torch/image/blob/master/README.md">https://github.com/torch/image/blob/master/README.md</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>Neural network containres (Torch)<br />
<a href="https://github.com/torch/nn/blob/master/doc/containers.md">https://github.com/torch/nn/blob/master/doc/containers.md</a>
</li>

<li>Simple layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear">https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear</a>
</li>

<li>Transfer Function Layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok">https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>PyTorch<br />
<a href="http://pytorch.org/">http://pytorch.org/</a>
</li>

<li>JupyterLite na PyPi<br />
<a href="https://pypi.org/project/jupyterlite/">https://pypi.org/project/jupyterlite/</a>
</li>

<li>JupyterLite na GitHubu<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Dokumentace k&nbsp;projektu JupyterLite<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Matplotlib Home Page<br />
<a href="http://matplotlib.org/">http://matplotlib.org/</a>
</li>

<li>Matplotlib (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Matplotlib">https://en.wikipedia.org/wiki/Matplotlib</a>
</li>

<li>Popis barvových map modulu matplotlib.cm<br />
<a href="https://gist.github.com/endolith/2719900#id7">https://gist.github.com/endolith/2719900#id7</a>
</li>

<li>Ukázky (palety) barvových map modulu matplotlib.cm<br />
<a href="http://matplotlib.org/examples/color/colormaps_reference.html">http://matplotlib.org/examples/color/colormaps_reference.html</a>
</li>

<li>Galerie grafů vytvořených v&nbsp;Matplotlibu<br />
<a href="https://matplotlib.org/3.2.1/gallery/">https://matplotlib.org/3.2.1/gallery/</a>
</li>

<li>3D rendering<br />
<a href="https://en.wikipedia.org/wiki/3D_rendering">https://en.wikipedia.org/wiki/3D_rendering</a>
</li>

<li>3D computer graphics<br />
<a href="https://en.wikipedia.org/wiki/3D_computer_graphics">https://en.wikipedia.org/wiki/3D_computer_graphics</a>
</li>

<li>Primary 3D view planes<br />
<a href="https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html">https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html</a>
</li>

<li>Getting started in scikit-learn with the famous iris dataset<br />
<a href="https://www.youtube.com/watch?v=hd1W4CyPX58">https://www.youtube.com/watch?v=hd1W4CyPX58</a>
</li>

<li>Training a machine learning model with scikit-learn<br />
<a href="https://www.youtube.com/watch?v=RlQuVL6-qe8">https://www.youtube.com/watch?v=RlQuVL6-qe8</a>
</li>

<li>Iris (plant)<br />
<a href="https://en.wikipedia.org/wiki/Iris_(plant)">https://en.wikipedia.org/wiki/Iris_(plant)</a>
</li>

<li>Kosatec<br />
<a href="https://cs.wikipedia.org/wiki/Kosatec">https://cs.wikipedia.org/wiki/Kosatec</a>
</li>

<li>Iris setosa<br />
<a href="https://en.wikipedia.org/wiki/Iris_setosa">https://en.wikipedia.org/wiki/Iris_setosa</a>
</li>

<li>Iris versicolor<br />
<a href="https://en.wikipedia.org/wiki/Iris_versicolor">https://en.wikipedia.org/wiki/Iris_versicolor</a>
</li>

<li>Iris virginica<br />
<a href="https://en.wikipedia.org/wiki/Iris_virginica">https://en.wikipedia.org/wiki/Iris_virginica</a>
</li>

<li>Druh<br />
<a href="https://cs.wikipedia.org/wiki/Druh">https://cs.wikipedia.org/wiki/Druh</a>
</li>

<li>Iris subg. Limniris<br />
<a href="https://en.wikipedia.org/wiki/Iris_subg._Limniris">https://en.wikipedia.org/wiki/Iris_subg._Limniris</a>
</li>

<li>Iris Dataset Classification with Python: A Tutorial<br />
<a href="https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html">https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html</a>
</li>

<li>Iris flower data set<br />
<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">https://en.wikipedia.org/wiki/Iris_flower_data_set</a>
</li>

<li>List of datasets for machine-learning research<br />
<a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research</a>
</li>

<li>Analýza hlavních komponent<br />
<a href="https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent">https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent</a>
</li>

<li>Principal component analysis<br />
<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">https://en.wikipedia.org/wiki/Principal_component_analysis</a>
</li>

<li>Scikit-learn Crash Course - Machine Learning Library for Python<br />
<a href="https://www.youtube.com/watch?v=0B5eIE_1vpU">https://www.youtube.com/watch?v=0B5eIE_1vpU</a>
</li>

<li>calm-notebooks<br />
<a href="https://github.com/koaning/calm-notebooks">https://github.com/koaning/calm-notebooks</a>
</li>

<li>Should you teach Python or R for data science?<br />
<a href="https://www.dataschool.io/python-or-r-for-data-science/">https://www.dataschool.io/python-or-r-for-data-science/</a>
</li>

<li>nbviewer: A simple way to share Jupyter Notebooks<br />
<a href="https://nbviewer.org/">https://nbviewer.org/</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

<li>Matplotlib vs. seaborn vs. Plotly vs. MATLAB vs. ggplot2 vs. pandas<br />
<a href="https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/">https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/</a>
</li>

<li>Matplotlib, Seaborn or Plotnine?<br />
<a href="https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/">https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/</a>
</li>

<li>@Rabeez: Rabeez/plotting_comparison.ipynb<br />
<a href="https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc">https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc</a>
</li>

<li>Matplotlib, Seaborn, Plotly and Plotnine Comparison<br />
<a href="https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40">https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40</a>
</li>

<li>Data Visualization 101: How to Choose a Python Plotting Library<br />
<a href="https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a">https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a</a>
</li>

<li>Data science in Python: pandas, seaborn, scikit-learn<br />
<a href="https://www.youtube.com/watch?v=3ZWuPVWq7p4">https://www.youtube.com/watch?v=3ZWuPVWq7p4</a>
</li>

<li>7.2. Real world datasets<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>7.2.7. California Housing dataset<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>Comprehensive Guide to Classification Models in Scikit-Learn<br />
<a href="https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/">https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/</a>
</li>

<li>Tidy Data Visualization: ggplot2 vs seaborn<br />
<a href="https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/">https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/</a>
</li>

<li>seaborn: statistical data visualization<br />
<a href="https://seaborn.pydata.org/">https://seaborn.pydata.org/</a>
</li>

<li>Linear regression (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Linear_regression">https://en.wikipedia.org/wiki/Linear_regression</a>
</li>

<li>Lineární regrese (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese">https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese</a>
</li>

<li>Iris Flower Classification with MLP Classifier<br />
<a href="https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier">https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier</a>
</li>

<li>SMS Spam Collection Dataset<br />
<a href="https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset">https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

