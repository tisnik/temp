<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Neuronové sítě v knihovně scikit-learn (2.část)</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Neuronové sítě v knihovně scikit-learn (2.část)</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>Na předchozí článek o scikit-learn dnes přímo navážeme, jelikož se opět budeme zabývat neuronovými sítěmi. Ukážeme si změnu topologie neuronové sítě provádějící regresi, ale například i použití takzvané matice záměn (confusion matrix). Nakonec neuronovou síť naučíme malou násobilku.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Neuronové sítě v&nbsp;knihovně scikit-learn (2.část)</a></p>
<p><a href="#k02">2. Krátké zopakování z&nbsp;minula: neuronová síť provádějící regresi natrénovaná na datové sadě <i>California Housings</i></a></p>
<p><a href="#k03">3. Jakou strukturu neuronové sítě zvolit?</a></p>
<p><a href="#k04">4. Změna počtu neuronů v&nbsp;jediné skryté vrstvě</a></p>
<p><a href="#k05">5. Změna počtu neuronů ve větším množství skrytých vrstev</a></p>
<p><a href="#k06">6. Vliv postupného zvyšování počtu skrytých vrstev na kvalitu odpovědí neuronové sítě</a></p>
<p><a href="#k07">7. Zjištění kvality modelu s&nbsp;využitím matice záměn (<i>confusion matrix</i>)</a></p>
<p><a href="#k08">8. Vizualizace matice záměn s&nbsp;absolutními i relativními odchylkami pro model lineární regrese</a></p>
<p><a href="#k09">9. Získané a vizualizované výsledky</a></p>
<p><a href="#k10">10. Matice záměn pro odlišný model: hledání K nejbližších sousedů</a></p>
<p><a href="#k11">11. Získané a vizualizované výsledky</a></p>
<p><a href="#k12">12. Matice záměn pro klasifikátor implementovaný pomocí neuronové sítě</a></p>
<p><a href="#k13">13. Získané a vizualizované výsledky</a></p>
<p><a href="#k14">14. Lze regresní neuronovou síť naučit malou násobilku?</a></p>
<p><a href="#k15">15. Výsledek: neuronová síť na úrovni prváka</a></p>
<p><a href="#k16">16. Vizualizace rozdílů předpovědí neuronové sítě od korektních výsledků</a></p>
<p><a href="#k17">17. Numerické i grafické výsledky korektnosti výpočtů tabulky malé násobilky</a></p>
<p><a href="#k18">18. Dokáže takto natrénovaná neuronová síť generalizovat?</a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Neuronové sítě v&nbsp;knihovně scikit-learn (2.část)</h2>

<p>Na <a
href="https://www.root.cz/clanky/neuronove-site-v-knihovne-scikit-learn-vytvoreni-a-uceni-male-site/">předchozí
článek</a> o knihovně <i>scikit-learn</i> dnes přímo navážeme. Opět se totiž
budeme zabývat problematikou konstrukce, učení a validace neuronových sítí.
Nejprve si ukážeme, jakým způsobem je možné měnit resp.&nbsp;přesněji řečeno
definovat <i>topologii</i> neuronové sítě provádějící regresi (tedy nikoli
klasifikaci), ovšem v&nbsp;dalším pokračování nezapomeneme ani na problematiku
volby takzvané <i>aktivační funkce</i>, která může ovlivnit globální chování
celé neuronové sítě.</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-1.png" class="image-312261" alt="&#160;" width="459" height="140" />
<p><i>Obrázek 1: Idealizovaný model neuronu použitý v&nbsp;klasických neuronových sítích.</i></p>

<p>Pro zajímavost se pokusíme natrénovat si neuronovou síť pro výpočet malé i
velké násobilky (tam lze dobře pochopit různá úskalí neuronových sítí, i když
zrovna tento úkol se pro neuronové sítě příliš nehodí, což bude ostatně patrné
i z&nbsp;výsledků). Ukážeme si například i použití takzvané matice záměn
(<i>confusion matrix</i>), kterou lze využít proto, abychom dobře porozuměli,
jakým způsobem se &bdquo;pletou&ldquo; či naopak &bdquo;trefují&ldquo; modely
provádějící klasifikaci.</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-2.png" class="image-312262" alt="&#160;" width="465" height="145" />
<p><i>Obrázek 2: Idealizovaný model neuronu s&nbsp;biasem (což je vlastně
konstantní vstup 1, který je váhován podobně, jako i ostatní vstupy).</i></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Krátké zopakování z&nbsp;minula: neuronová síť provádějící regresi natrénovaná na datové sadě <i>California Housings</i></h2>

<p>Nejprve si připomeňme, jakým způsobem můžeme s&nbsp;využitím knihovny
<i>scikit-learn</i> realizovat jednoduchou neuronovou sít provádějící
<i>regresi</i> (tedy odhad numerické hodnoty z&nbsp;určitého rozsahu). Klasické
neuronové sítě mají neurony uspořádány do vrstev, přičemž první vrstva se
nazývá <i>vstupní</i>, poslední vrstva <i>výstupní</i> a mezivrstvy se nazývají
<i>skryté</i>:</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-5.png" class="image-312265" alt="&#160;" width="600" height="400" />
<p><i>Obrázek 3: Uspořádání neuronů do vrstev ve feed-forward síti.</i></p>

<p>Naše konkrétní neuronová síť bude mít ve vstupní vrstvě osm neuronů, protože
ve vstupní datové sadě je osm atributů. Výstupní vrstva bude obsahovat jen
jeden neuron, neboť se jedná o výpočet jediné konkrétní hodnoty (ceny bytu
resp.&nbsp;bloku). A jediná vnitřní vrstva bude obsahovat sto neuronů, protože
se jedná o výchozí hodnotu dosazenou přímo knihovnou <i>scikit-learn</i>:</p>

<pre>
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># ceny bloku</i>
targets = housings["target"]
&nbsp;
<i># X je matice, y je vektor</i>
X = data
y = targets
&nbsp;
<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)
&nbsp;
<i># konstrukce modelu</i>
nn = <strong>MLPRegressor(max_iter=5000)</strong>
&nbsp;
<i># trénink modelu</i>
nn.fit(X_train, y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = nn.predict(X_test)
&nbsp;
<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
&nbsp;
print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")
&nbsp;
for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
&nbsp;
print("Biases:")
&nbsp;
for layer, biases in enumerate(nn.intercepts_):
    print("\t", layer, biases.shape)
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na
adrese <a
href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/142_mlp_regression_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/142_mlp_regression_1.py</a>.</div></p>

<p>Po spuštění výše uvedeného skriptu se nejdříve zobrazí výsledek validace
modelu, ovšem nutno dodat, že v&nbsp;tomto případě s&nbsp;nepříliš lichotivými
výsledky (R2 skóre dokonce kleslo těsně pod nulu):</p>

<pre>
Mean squared error: 1.34
Coefficient of determination: -0.01
</pre>

<p>Posléze skript zobrazí informace o neuronové síti. Ze zpráv, které jsou
vytisknuty, plyne, že ve vstupní vrstvě je osm neuronů, což odpovídá počtu
atributů, na které byla síť natrénována. Výstupní vrstva má jeden neuron, což
je opět pochopitelné, protože výstupem má být jediné reálné číslo. A celkový
počet vrstev je roven třem &ndash; tedy kromě vstupní vrstvy a vrstvy výstupní
máme jedinou skrytou vrstvu:</p>

<pre>
Features: 8
Layers:   3
Outputs:  1
</pre>

<p>Posledními údaji, které skript uvedený v&nbsp;této kapitole zobrazí, jsou
tvary (<i>shape</i>) polí s&nbsp;váhami neuronů a taktéž pole s&nbsp;hodnotami
<i>bias</i>. Tvary těchto polí plně odpovídají očekávané topologii neuronové
sítě (tedy vazby 8:100:1 atd.):</p>

<pre>
Weights:
         0 (8, 100)
         1 (100, 1)
Biases:
         0 (100,)
         1 (1,)
</pre>

<p><div class="rs-tip-major">Poznámka: z&nbsp;těchto údajů nepřímo plyne, že
vnitřní (skrytá) vrstva obsahuje sto neuronů.</div></p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Jakou strukturu neuronové sítě zvolit?</h2>

<p>Při konstrukci neuronové sítě musíme nějakým způsobem zjistit nebo alespoň
odhadnout, kolik skrytých vrstev by se mělo použít a kolik neuronů by
v&nbsp;každé z&nbsp;těchto vrstev mělo být. Taktéž je nutné vybrat vhodnou
aktivační funkci, způsob realizace tréninkového algoritmu atd. Jedná se o velké
množství proměnných hodnot, takže výběr může probíhat v&nbsp;několika kolech,
které typicky obsahují křížovou validaci modelu.</p>

<p>Existuje několik více či méně kvalitních heuristik, které nám povídají,
jakou zvolit topologii neuronové sítě. Vybírám ty nejjednodušší a nejznámější
heuristiky:</p>

<ol>

<li>Počet neuronů ve skryté vrstvě by měl být zhruba 2/3 velikosti vstupní
vrstvy (někdo udává rozsah 70%-90%).</li>

<li>Počet neuronů ve skryté vrstvě by měl být menší, než dvojnásobek velikosti
(počtu neuronů) ve vstupní vrstvě.</li>

<li>Počet neuronů ve skryté vrstvě by měl ležet na rozsahu počtu neuronů
vstupní a výstupní vrstvy (což platí pro sítě provádějící klasifikaci).</li>

<li>Počet neuronů ve skrytých vrstvách by měl postupně klesat (někdy se uvádí
exponenciální pokles, ovšem zde skutečně záleží na množství vstupů).</li>

<li>Postupně přidávejte další skryté vrstvy až do chvíle, kdy se začne snižovat
přesnost nebo R2 skóre (většinou najdeme skokovou změnu po přidání další
vrstvy).</li>

</ol>

<p><div class="rs-tip-major">Poznámka: tyto heuristiky jsou většinou aplikovány
v&nbsp;případě, že neuronové sítě mají velký počet vstupů, například když je
vstupem rastrový obrázek atd. V&nbsp;našem konkrétním případě máme pouze osm
vstupů, takže počty neuronů ve skrytých vrstvách vychází velmi malé.</div></p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Změna počtu neuronů v&nbsp;jediné skryté vrstvě</h2>

<p>Pokusme se nyní zjistit, jakým způsobem se změní kvalita neuronové sítě
(tedy přesnosti předpovědí při provádění regrese) v&nbsp;případě, že budeme
měnit počet neuronů ve skryté vrstvě. Volba počtu neuronů je snadná, protože
při konstrukci neuronové sítě můžeme použít parametr
<strong>hidden_layer_sizes</strong>, kterému se předá n-tice obsahující počty
neuronů ve skryté vrstvě (jednice) či ve více vrstvách:</p>

<pre>
nn = <strong>MLPRegressor(max_iter=5000, hidden_layer_sizes = (neurons, ))</strong>
</pre>

<p>Celý skript, který provádí konstrukci neuronové sítě, její natrénování a
otestování, vypadá následovně:</p>

<pre>
import matplotlib.pyplot as plt
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># ceny bloku</i>
targets = housings["target"]
&nbsp;
<i># X je matice, y je vektor</i>
X = data
y = targets
&nbsp;
r = range(1, 12)
avg_scores = []
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for i in r:
    <i># konstrukce modelu</i>
    neurons = 2**i
    nn = <strong>MLPRegressor(max_iter=5000, hidden_layer_sizes = (neurons, ))</strong>
&nbsp;
    scores = cross_val_score(nn, X, y, cv=10, scoring='r2')
&nbsp;
    <i># vypsani prumerneho skore do tabulky</i>
    avg_score = scores.mean()
    print(neurons, avg_score)
&nbsp;
    avg_scores.append(avg_score)
&nbsp;
plt.plot(r, avg_scores)
plt.xlabel("Změna počtu neuronů v jedné vrstvě")
plt.ylabel("R2")
&nbsp;
<i># ulozeni grafu do souboru</i>
plt.savefig("144.png")
&nbsp;
<i># vykresleni grafu na obrazovku</i>
<i>#plt.show()</i>
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na
adrese <a
href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/144_mlp_regression_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/144_mlp_regression_3.py</a>.</div></p>

<p>Výsledky výpočtu R2 skóre pro postupně se měnící počty neuronů vypadají
takto:</p>

<pre>
2 -0.1454302734588354
4 -0.03707952396388188
8 0.024029461721653787
16 0.15975633333410563
32 0.0019421990876153927
64 0.2831746308829118
128 0.30220876727407814
256 -0.08924552002434508
512 -0.0007001958806893916
1024 -5.531109632506313
2048 -20.041735587898025
</pre>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-1.webp" class="image-1139785" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 4: Závislost kvality odpovědí neuronové sítě s&nbsp;jednou skrytou vrstvou na počtu neuronů v&nbsp;této vrstvě.</i></p>

<p><div class="rs-tip-major">Poznámka: můžeme zde skutečně vidět razantní
pokles kvality neuronové sítě u velkého počtu neuronů. Je to způsobeno buď
nedoučením neuronové sítě (je totiž příliš velká pro malý počet trénovacích
dat) popř.&nbsp;tím, že pro malé změny očekávaných výstupů již trénovací
algoritmus (<i>backtracing</i>) nedokáže měnit váhy jednotlivých neuronů (což
je efekt nazývaný <i>vanishing gradient</i>).</div></p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Změna počtu neuronů ve větším množství skrytých vrstev</h2>

<p>Naprosto stejným způsobem se můžeme pokusit o zjištění, jaký vliv má počet
neuronů umístěných ve větším množství skrytých vrstev na kvalitu odhadů
neuronové sítě.  Pokusíme se zjistit tyto vlastnosti pro neuronové sítě se
třemi a pěti skrytými vrstvami. Skript pro neuronovou síť se třemi
vrstvami:</p>

<pre>
import matplotlib.pyplot as plt
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># ceny bloku</i>
targets = housings["target"]
&nbsp;
<i># X je matice, y je vektor</i>
X = data
y = targets
&nbsp;
r = range(1, 12)
avg_scores = []
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for i in r:
    <i># konstrukce modelu</i>
    neurons = 2**i
    nn = <strong>MLPRegressor(max_iter=5000, hidden_layer_sizes = (neurons, neurons, neurons))</strong>
&nbsp;
    scores = cross_val_score(nn, X, y, cv=10, scoring='r2')
&nbsp;
    <i># vypsani prumerneho skore do tabulky</i>
    avg_score = scores.mean()
    print(neurons, avg_score)
&nbsp;
    avg_scores.append(avg_score)
&nbsp;
plt.plot(r, avg_scores)
plt.xlabel("Změna počtu neuronů ve třech vrstvách")
plt.ylabel("R2")
&nbsp;
<i># ulozeni grafu do souboru</i>
plt.savefig("145.png")
&nbsp;
<i># vykresleni grafu na obrazovku</i>
<i>#plt.show()</i>
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na
adrese <a
href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/145_mlp_regression_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/145_mlp_regression_4.py</a>.</div></p>

<p>Výsledky již nyní nejsou tak jednoznačné, jako tomu bylo v&nbsp;předchozím
příkladu, protože i neuronová síť se zbytečně velkým počtem neuronů dokázala
tuto nevýhodu do určité míry kompenzovat:</p>

<pre>
2 -0.283005105231359
4 0.148825137624293
8 0.3334395444819797
16 0.14779810169991886
32 -0.14617386521960413
64 0.17143912954224527
128 -0.35915114561290196
256 0.028327261438945373
512 -0.5219569442908789
1024 0.22234451593419272
2048 0.32266508344685396
</pre>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-2.webp" class="image-1139788" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 5: Závislost kvality odpovědí neuronové sítě se třemi skrytými
vrstvami na počtu neuronů v&nbsp;této vrstvě.</i></p>

<p>Realizace téhož příkladu, nyní ovšem pro pět skrytých vrstev vypadá
následovně:</p>

<pre>
import matplotlib.pyplot as plt
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># ceny bloku</i>
targets = housings["target"]
&nbsp;
<i># X je matice, y je vektor</i>
X = data
y = targets
&nbsp;
r = range(1, 12)
avg_scores = []
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for i in r:
    <i># konstrukce modelu</i>
    neurons = 2**i
    nn = <strong>MLPRegressor(max_iter=5000, hidden_layer_sizes = (neurons, neurons, neurons, neurons, neurons))</strong>
&nbsp;
    scores = cross_val_score(nn, X, y, cv=10, scoring='r2', n_jobs=-1)
&nbsp;
    <i># vypsani prumerneho skore do tabulky</i>
    avg_score = scores.mean()
    print(neurons, avg_score)
&nbsp;
    avg_scores.append(avg_score)
&nbsp;
plt.plot(r, avg_scores)
plt.xlabel("Změna počtu neuronů v pěti vrstvách")
plt.ylabel("R2")
&nbsp;
<i># ulozeni grafu do souboru</i>
plt.savefig("146.png")
&nbsp;
<i># vykresleni grafu na obrazovku</i>
<i>#plt.show()</i>
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na
adrese <a
href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/146_mlp_regression_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/146_mlp_regression_5.py</a>.</div></p>

<p>Numerické výsledky v&nbsp;tabulkové podobě:</p>

<pre>
2 -0.0754384824557155
4 -0.14798990918251986
8 0.3995421626439365
16 0.010342881370922475
32 0.19336159679802659
64 0.17877679646955416
128 0.2820772221907199
256 0.5288142058348293
512 0.44223558072990465
1024 0.44861141341888383
2048 0.40412403628968663
</pre>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-3.webp" class="image-1139791" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 6: Závislost kvality odpovědí neuronové sítě s&nbsp;pěti skrytými
vrstvami na počtu neuronů v&nbsp;této vrstvě.</i></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Vliv postupného zvyšování počtu skrytých vrstev na kvalitu odpovědí neuronové sítě</h2>

<p>Z&nbsp;výsledků, které jsme získali z&nbsp;předchozí trojice skriptů, by se
mohlo zdát, že spíše než zvyšování počtu neuronů ve skrytých vrstvách může být
výhodnější spíše zvýšit počet těchto vrstev s&nbsp;menším počtem neuronů.
Zkusme si tuto domněnku ověřit, a to tak, že ponecháme počet neuronů
v&nbsp;každé skryté vrstvě konstantní, ale budeme zvyšovat počet těchto vrstev.
Využijeme přitom možnosti &bdquo;opakování&ldquo; prvků v&nbsp;n-tici:</p>

<pre>
NEURONS = 5
&nbsp;
layer_sizes = (NEURONS, ) * layers
nn = MLPRegressor(max_iter=5000, hidden_layer_sizes = layer_sizes)
</pre>

<p>Celý skript, který postupně zvyšuje počet vrstev a následně ověřuje kvalitu
neuronové sítě, vypadá následovně:</p>

<pre>
import matplotlib.pyplot as plt
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># ceny bloku</i>
targets = housings["target"]
&nbsp;
<i># X je matice, y je vektor</i>
X = data
y = targets
&nbsp;
NEURONS = 5
r = range(1, 40)
&nbsp;
avg_scores = []
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for layers in r:
    <i># konstrukce modelu</i>
    layer_sizes = (NEURONS, ) * layers
    nn = <strong>MLPRegressor(max_iter=5000, hidden_layer_sizes = layer_sizes)</strong>
&nbsp;
    <i># vypocet skore</i>
    scores = cross_val_score(nn, X, y, cv=10, scoring='r2', n_jobs=-1)
&nbsp;
    <i># vypsani prumerneho skore do tabulky</i>
    avg_score = scores.mean()
    print(layers, avg_score)
&nbsp;
    avg_scores.append(avg_score)
&nbsp;
plt.plot(r, avg_scores)
plt.xlabel("Změna počtu vrstev")
plt.ylabel("R2")
&nbsp;
<i># ulozeni grafu do souboru</i>
plt.savefig("147.png")
&nbsp;
<i># vykresleni grafu na obrazovku</i>
plt.show()
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na
adrese <a
href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/147_mlp_regression_6.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/147_mlp_regression_6.py</a>.</div></p>

<p>Opět si nejprve uveďme výsledky v&nbsp;numerické podobě:</p>

<pre>
1 0.3756102466117746
2 0.33435201837938544
3 0.12054109495792083
4 0.09916830519723958
5 0.3239525018951458
6 0.06484265048651823
7 -0.10421240952695066
8 0.27187249385037804
9 0.2882272162105404
10 0.14207548441647116
11 0.2264986054565991
12 0.0731174214139199
13 0.13308221750444812
14 0.19895244674967708
15 0.1294763780958599
16 -0.12671951662229197
17 0.17829603759203674
18 0.12295044855822954
19 0.3231971403204573
20 0.08460788802486123
21 0.1255234820631603
22 0.22386452833322137
23 0.08215259556813452
24 -0.09532343419407868
25 -0.10410875091569269
26 -0.14048312380932332
27 -0.2770565595807387
28 -0.20586069878082425
29 -0.0911768500198286
30 -0.2797797072289029
31 -0.2698970179654826
32 -0.27684226485857805
33 -0.13352979202774717
34 -0.27688492300614664
35 -0.198615684982469
36 -0.18700389633765757
37 -0.264543446558973
38 -0.2696700809142521
39 -0.21418061259668536
</pre>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-4.webp" class="image-1139794" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 7: Závislost kvality odpovědí neuronové sítě na počtu skrytých vrstev.</i></p>

<p><div class="rs-tip-major">Poznámka: ani tento předpoklad tedy není zcela
pravdivý. Vždy dříve či později narazíme na limit způsobený nedoučením sítě
nebo efektem <i>vanishing gradientu</i>, o němž jsme se již
zmiňovali.</div></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Zjištění kvality modelu s&nbsp;využitím matice záměn (<i>confusion matrix</i>)</h2>

<p>Při zjišťování kvality modelů, které provádí klasifikaci, se s&nbsp;úspěchem
používá takzvaná <i>matice záměn</i> neboli <i>confusion matrix</i>. Jedná se o
matici, která ve sloupcích obsahuje očekávané hodnoty a v&nbsp;řádcích pak
předpovědi/odpovědi modelu. Pokud model odpoví ve všech případech správně, bude
matice obsahovat nenulové hodnoty pouze na hlavní diagonále a tyto hodnoty
budou znamenat "očekávalo se X odpovědí A a model takto odpověděl skutečně
X-krát". Ovšem ve chvíli, kdy se model splete, vypíše se tato hodnota mimo
hlavní diagonálu; tj.&nbsp;hodnoty mimo hlavní diagonálu znamenají chyby a
navíc můžeme zjistit, které odpovědi způsobují modelu největší problémy
(tj.&nbsp;například které druhy květin z&nbsp;datové sady <i>Iris</i> zaměňuje
a které naopak nalezne vždy bez problémů).</p>

<p>Podívejme se na příklad modelu, který vždy odpoví korektně:</p>

<pre>
  | A    B   C
--+------------
A | 10   0   0
B |  0  20   0
C |  0   0  30
</pre>

<p>Model pro 10 očekávaných odpovědí A skutečně desetkrát odpověděl
&bdquo;A&ldquo; atd. Celkem se provedlo 10+20+30 testů.</p>

<p>Naopak může model nesprávně rozlišovat mezi odpověďmi A a B. Potom může
matice vypadat například takto:</p>

<pre>
  | A    B   C
--+------------
A |  7   3   0
B |  0  20   0
C |  0   0  30
</pre>

<p>Nebo takto:</p>

<pre>
  | A    B   C
--+------------
A | 10   0   0
B | 10  10   0
C |  0   0  30
</pre>

<p>Zkoumáním obsahu matice záměn můžeme zjistit nejenom <i>citlivost
modelu</i>, ale i <i>specificitu modelu</i> (což je mnohdy důležitější atribut
&ndash; ještě se k&nbsp;němu vrátíme).</p>

<p>Matice záměn může obsahovat i relativní hodnoty, které jsou nezávislé na
počtu měření. Maximální hodnota prvku v&nbsp;takové matici je rovna 1.0 a
minimální pochopitelně 0.0.</p>



<p><a name="k08"></a></p>
<h2 id="k08">8. Vizualizace matice záměn s&nbsp;absolutními i relativními odchylkami pro model lineární regrese</h2>

<p>Podívejme se nyní na způsob výpočtu a vizualizace matice záměn (<i>confusion
matrix</i>). Nejprve zkonstruujeme nějaký model, natrénujeme ho běžným způsobem
a taktéž ho necháme odhadnout výsledky pro testovací (nikoli trénovací!) data.
Tyto kroky již velmi dobře známe:</p>

<pre>
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = <strong>LogisticRegression(max_iter=1000)</strong>
&nbsp;
<i># trening modelu (se vsemi dostupnymi daty)</i>
classifier.fit(trainX, trainY)
&nbsp;
y_pred = classifier.predict(testX)
</pre>

<p>Následně si na základě testovacích dat necháme vypočítat matici záměn. Ta
může obsahovat buď absolutní hodnoty (tedy jednotlivé testy a jejich výsledky
odhadnuté modelem) nebo hodnoty relativní. Matici záměn s&nbsp;absolutními
hodnotami získáme takto:</p>

<pre>
<i># absolutni hodnoty</i>
disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    testX,
    testY,
    display_labels=class_names,
    cmap=plt.cm.Blues,
    <u>normalize=None</u>,
)
</pre>

<p>Naopak matici s&nbsp;relativními hodnotami (nezávislými na počtu testů) si
necháme vypočítat tímto způsobem:</p>

<pre>
<i># relativni hodnoty</i>
disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    testX,
    testY,
    display_labels=class_names,
    cmap=plt.cm.Blues,
    <u>normalize="true"</u>,
)
</pre>

<p>Úplný zdrojový kód skriptu, který tyto výpočty provádí a obě matice následně
zobrazí, vypadá následovně:</p>

<pre>
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení dat</i>
trainX, testX, trainY, testY = train_test_split(X, y, test_size = 0.7)
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = <strong>LogisticRegression(max_iter=1000)</strong>
&nbsp;
<i># trening modelu (se vsemi dostupnymi daty)</i>
classifier.fit(trainX, trainY)
&nbsp;
y_pred = classifier.predict(testX)
&nbsp;
print(classification_report(testY, y_pred))
&nbsp;
class_names = iris.target_names
&nbsp;
<i># absolutni hodnoty</i>
disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    testX,
    testY,
    display_labels=class_names,
    cmap=plt.cm.Blues,
    normalize=None,
)
&nbsp;
<i># zobrazeni matice</i>
print(disp.confusion_matrix)
&nbsp;
<i># ulozeni vysledku</i>
plt.savefig("148_1.png")
&nbsp;
<i># vizualizace matice</i>
plt.show()
&nbsp;
<i># relativni hodnoty</i>
disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    testX,
    testY,
    display_labels=class_names,
    cmap=plt.cm.Blues,
    normalize="true",
)
&nbsp;
<i># zobrazeni matice</i>
print(disp.confusion_matrix)
&nbsp;
<i># ulozeni vysledku</i>
plt.savefig("148_2.png")
&nbsp;
<i># vizualizace matice</i>
plt.show()
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na adrese <a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/148_confusion_matrix_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/148_confusion_matrix_1.py</a>.</div></p>



<p><a name="k09"></a></p>
<h2 id="k09">9. Získané a vizualizované výsledky</h2>

<p>Po spuštění skriptu <a href="#k08">z&nbsp;předchozí kapitoly</a> se nejdříve
zobrazí vypočtené informace o validaci modelu, které byly získané zavoláním
<strong>classification_report</strong> (tyto informace nás však prozatím
nebudou zajímat, vyžadují totiž hlubší porozumění jednotlivým veličinám):</p>

<pre>
              precision    recall  f1-score   support
&nbsp;
           0       1.00      1.00      1.00        39
           1       1.00      0.94      0.97        35
           2       0.94      1.00      0.97        31
&nbsp;
    accuracy                           0.98       105
   macro avg       0.98      0.98      0.98       105
weighted avg       0.98      0.98      0.98       105
</pre>

<p>Důležitější je samotná matice záměn, která vypadá následovně:</p>

<pre>
[[39  0  0]
 [ 0 33  2]
 [ 0  0 31]]
</pre>

<p>Z&nbsp;matice je patrné, že se celkem otestovalo 39+33+31+2=105 vstupů, což
odpovídá nastavení <strong>test_size=0.7</strong>. Přitom první druh květiny
byl rozeznán vždy, ale u dalších dvou druhů se model ve dvou případech
spletl. Ideálně by totiž tato matice měla vypadat takto:</p>

<pre>
[[39  0  0]
 [ 0 33  0]
 [ 0  0 33]]
</pre>

<p>Aby byly výsledky nezávislé na počtu otestovaných záznamů, je lepší použít
relativní vyjádření, které dopadne následovně:</p>

<pre>
[[1.         0.         0.        ]
 [0.         0.94285714 0.05714286]
 [0.         0.         1.        ]]
</pre>

<p>Opět platí, že v&nbsp;ideálním případě by se mělo jednat o jednotkovou
matici.</p>

<p>Vizuální výsledky ve formě diagramu jsou ještě názornější, neboť jsou
přidány i popisky jednotlivých os:</p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-5.webp" class="image-1139797" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 8: Matice záměn s&nbsp;absolutními odchylkami.</i></p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-6.webp" class="image-1139800" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 9: Matice záměn s&nbsp;relativními odchylkami.</i></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Matice záměn pro odlišný model: hledání K nejbližších sousedů</h2>

<p>Samozřejmě nám vůbec nic nebrání v&nbsp;tom, abychom se pokusili matici
záměn vypočítat i pro odlišné modely. Společně s&nbsp;datovou sadou <i>Iris</i>
jsme již několikrát použili model <strong>KNeighborsClassifier</strong>, který
provádí klasifikaci na základě nalezení K sousedů k&nbsp;testovanému bodu
(atributy leží v&nbsp;n-rozměrném prostoru a od testovaného bodu postupně
rozšiřujeme oblast a hledáme sousedy). Tento model by mohl být přesnější, než
model lineární regrese, takže si to ověřme:</p>

<pre>
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení dat</i>
trainX, testX, trainY, testY = train_test_split(X, y, test_size = 0.5)
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = <strong>KNeighborsClassifier(n_neighbors=5)</strong>
&nbsp;
<i># trening modelu (se vsemi dostupnymi daty)</i>
classifier.fit(trainX, trainY)
&nbsp;
y_pred = classifier.predict(testX)
&nbsp;
print(classification_report(testY, y_pred))
&nbsp;
class_names = iris.target_names
&nbsp;
<i># absolutni hodnoty</i>
disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    testX,
    testY,
    display_labels=class_names,
    cmap=plt.cm.Blues,
    normalize=None,
)
&nbsp;
<i># zobrazeni matice</i>
print(disp.confusion_matrix)
&nbsp;
<i># ulozeni vysledku</i>
plt.savefig("149_1.png")
&nbsp;
<i># vizualizace matice</i>
plt.show()
&nbsp;
<i># relativni hodnoty</i>
disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    testX,
    testY,
    display_labels=class_names,
    cmap=plt.cm.Blues,
    normalize="true",
)
&nbsp;
<i># zobrazeni matice</i>
print(disp.confusion_matrix)
&nbsp;
<i># ulozeni vysledku</i>
plt.savefig("149_2.png")
&nbsp;
<i># vizualizace matice</i>
plt.show()
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na
adrese <a
href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/149_confusion_matrix_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/149_confusion_matrix_2.py</a>.</div></p>



<p><a name="k11"></a></p>
<h2 id="k11">11. Získané a vizualizované výsledky</h2>

<p>Opět se podívejme na výsledky, které jsme získali po spuštění skriptu <a
href="#k10">z&nbsp;předchozí kapitoly</a>. Podle očekávání budou výsledky
nepatrně odlišné, protože je jiný i model, který testujeme:</p>

<pre>
              precision    recall  f1-score   support
&nbsp;
           0       1.00      1.00      1.00        18
           1       0.89      0.94      0.91        33
           2       0.91      0.83      0.87        24
&nbsp;
    accuracy                           0.92        75
   macro avg       0.93      0.92      0.93        75
weighted avg       0.92      0.92      0.92        75
</pre>

<p>Z&nbsp;maticí záměn je patrné, že se opět model nemohl vždy správně
rozhodnout mezi druhým a třetím druhem květin, zatímco druh první rozpoznal
vždy na 100%:</p>

<pre>
[[18  0  0]
 [ 0 31  2]
 [ 0  4 20]]
&nbsp;
[[1.         0.         0.        ]
 [0.         0.93939394 0.06060606]
 [0.         0.16666667 0.83333333]]
</pre>

<p>A jak správně tušíte, je vizualizace matice záměn formou diagramu ještě
názornější:</p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-7.webp" class="image-1139803" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 10: Matice záměn s&nbsp;absolutními odchylkami.</i></p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-8.webp" class="image-1139806" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 11: Matice záměn s&nbsp;relativními odchylkami.</i></p>



<p><a name="k12"></a></p>
<h2 id="k12">12. Matice záměn pro klasifikátor implementovaný pomocí neuronové sítě</h2>

<p>Napotřetí si matici záměn necháme zobrazit pro klasifikátor, který je
implementovaný s&nbsp;využitím neuronové sítě. Jedná se tedy o model typu
<strong>MLPClassifier</strong>, s&nbsp;nímž jsme se podrobně seznámili
v&nbsp;předchozím článku:</p>

<pre>
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import ConfusionMatrixDisplay
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení dat</i>
trainX, testX, trainY, testY = train_test_split(X, y, test_size = 0.5)
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = <strong>MLPClassifier(max_iter=5000)</strong>
&nbsp;
<i># trening modelu (se vsemi dostupnymi daty)</i>
classifier.fit(trainX, trainY)
&nbsp;
y_pred = classifier.predict(testX)
&nbsp;
print(classification_report(testY, y_pred))
&nbsp;
class_names = iris.target_names
&nbsp;
<i># absolutni hodnoty</i>
disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    testX,
    testY,
    display_labels=class_names,
    cmap=plt.cm.Blues,
    normalize=None,
)
&nbsp;
<i># zobrazeni matice</i>
print(disp.confusion_matrix)
&nbsp;
<i># ulozeni vysledku</i>
plt.savefig("150_1.png")
&nbsp;
<i># vizualizace matice</i>
plt.show()
&nbsp;
<i># relativni hodnoty</i>
disp = ConfusionMatrixDisplay.from_estimator(
    classifier,
    testX,
    testY,
    display_labels=class_names,
    cmap=plt.cm.Blues,
    normalize="true",
)
&nbsp;
<i># zobrazeni matice</i>
print(disp.confusion_matrix)
&nbsp;
<i># ulozeni vysledku</i>
plt.savefig("150_2.png")
&nbsp;
<i># vizualizace matice</i>
plt.show()
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na
adrese <a
href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/150_confusion_matrix_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/150_confusion_matrix_3.py</a>.</div></p>



<p><a name="k13"></a></p>
<h2 id="k13">13. Získané a vizualizované výsledky</h2>

<p>A opět se podívejme na výsledky získané skriptem uvedeným <a
href="#k12">v&nbsp;předchozí kapitole</a>:</p>

<pre>
              precision    recall  f1-score   support
&nbsp;
           0       1.00      1.00      1.00        25
           1       0.96      0.96      0.96        23
           2       0.96      0.96      0.96        27
&nbsp;
    accuracy                           0.97        75
   macro avg       0.97      0.97      0.97        75
weighted avg       0.97      0.97      0.97        75
</pre>

<p>Z&nbsp;matice záměn je patrné, že i neuronová síť má, podobně jako ostatní
dva modely, problém rozlišit druhé dva druhy květin, zatímco první druh odliší
ve všech případech (což mnohé napovídá o volbě atributů):</p>

<pre>
[25  0  0]
 [ 0 22  1]
 [ 0  1 26]]
&nbsp;
[[1.         0.         0.        ]
 [0.         0.95652174 0.04347826]
 [0.         0.03703704 0.96296296]]
</pre>

<p>A takto vypadá vizualizovaný výsledek obou matic záměn (s&nbsp;absolutními i
relativními odchylkami):</p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-9.webp" class="image-1139809" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 12: Matice záměn s&nbsp;absolutními odchylkami.</i></p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-10.webp" class="image-1139812" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 13: Matice záměn s&nbsp;relativními odchylkami.</i></p>



<p><a name="k14"></a></p>
<h2 id="k14">14. Lze regresní neuronovou síť naučit malou násobilku?</h2>

<p>Nyní již známe způsob konstrukce a tréninku neuronové sítě provádějící
regresi. To znamená, že dokážeme zkonstruovat model, který na základě několika
numerických vstupů vypočte jeden numerický výstup. Je tedy možné například
vytvořit neuronovou síť, která dokáže vypočítat malou násobilku? Nejedná se o
typický případ využití neuronových sítí, ale o něco podobného se samozřejmě
můžeme pokusit. Tato sít bude mít dva vstupy (tedy dva neurony ve vstupní
vrstvě) a jeden výstup (jediný neuron ve výstupní vrstvě). A zvolme například,
že síť bude obsahovat dvě skryté vrstvy, každou se 100 neurony:</p>

<pre>
<i># konstrukce modelu</i>
nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(100, 100))
</pre>

<p>Tréninková a validační data budou tvořena maticí vstupů, tedy všech
kombinací celočíselných hodnot 0..10. A výstupy (trénovací hodnoty) budou
tvořeny součinem vstupů:</p>

<pre>
<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N*MAX_N, 2) )   <i># kombinace cinitelu</i>
y = np.zeros( (MAX_N*MAX_N, ))     <i># vektor soucinu</i>
i = 0
for a in range(1, MAX_N+1):
    for b in range(1, MAX_N+1):
        X[i, 0] = a                <i># cinitel</i>
        X[i, 1] = b                <i># cinitel</i>
        y[i] = a * b               <i># soucin</i>
        i+=1
</pre>

<p><div class="rs-tip-major">Poznámka: naplnění matice X a vektoru y lze
v&nbsp;Numpy provést i kratším způsobem, takto je však více názorné, jaké
výpočty se vlastně provádí.</div></p>

<p>Model následně natrénujeme a otestujeme ho na několika zadaných hodnotách
<strong>a</strong> a <strong>b</strong>. Teoreticky by měl model odpovědět
celým číslem, ovšem regresní sítě vrací reálné hodnoty, takže musíme provést
zaukrouhlení:</p>

<pre>
import numpy as np
&nbsp;
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
<i># velikost tabulky soucinu</i>
MAX_N = 10
&nbsp;
<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N*MAX_N, 2) )   <i>  # kombinace cinitelu</i>
y = np.zeros( (MAX_N*MAX_N, ))     <i>  # vektor soucinu</i>
i = 0
for a in range(1, MAX_N+1):
    for b in range(1, MAX_N+1):
        X[i, 0] = a                <i>  # cinitel</i>
        X[i, 1] = b                <i>  # cinitel</i>
        y[i] = a * b               <i>  # soucin</i>
        i+=1
&nbsp;
<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)
&nbsp;
<i># konstrukce modelu</i>
nn = <strong>MLPRegressor(max_iter=5000, hidden_layer_sizes=(100, 100))</strong>
&nbsp;
<i># trénink modelu</i>
nn.fit(X_train, y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = nn.predict(X_test)
&nbsp;
<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
&nbsp;
<i># zobrazit parametry neuronove site</i>
print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")
&nbsp;
<i># vahy neuronu</i>
for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
&nbsp;
<i># posuny (dalsi vstup do neuronu)</i>
print("Biases:")
for layer, biases in enumerate(nn.intercepts_):
    print("\t", layer, biases.shape)
&nbsp;
<i># nezname vstupy</i>
inputs = [[1, 1], [2,  3], [5, 5], [4, 10], [10, 4], [9, 9], [10, 10]]
predicted = nn.predict(inputs)
&nbsp;
<i># odhady neuronove site bez dalsich uprav</i>
print("w/o rounding:")
for i, p in zip(inputs, predicted):
    print(f"{i[0]:2} * {i[1]:2} = {p:6.2f}")
&nbsp;
<i># odhady neuronove site po zaokrouhleni</i>
print("rounded:")
for i, p in zip(inputs, predicted):
    print(f"{i[0]:2} * {i[1]:2} = {int(p):2}")
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na
adrese <a
href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/151_multiplication_table.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/151_multiplication_table.py</a>.</div></p>



<p><a name="k15"></a></p>
<h2 id="k15">15. Výsledek: neuronová síť na úrovni prváka</h2>

<p>Při numerickém vyjádření kvality modelu (tedy neuronové sítě) dostaneme
skóre 1.0, což je podezřele dobrý výsledek (ovšem trénujeme i validujeme nad
stejnými daty!):</p>

<pre>
Mean squared error: 0.34
Coefficient of determination: 1.00
</pre>

<p>Vlastnosti neuronové sítě odpovídají hodnotám, které jsme zadali
konstruktoru <strong>MLPClassifier</strong>:</p>

<pre>
Features: 2
Layers:   4
Outputs:  1
Weights:
         0 (2, 100)
         1 (100, 100)
         2 (100, 1)
Biases:
         0 (100,)
         1 (100,)
         2 (1,)
</pre>

<p>Zajímavější jsou však výsledky neuronové sítě pro zadané hodnoty
<strong>a</strong> a <strong>b</strong>. Síť vrátí reálné číslo, které by se
mělo přibližovat korektnímu výsledku součinu:</p>

<pre>
w/o rounding:
 1 *  1 =  -0.12
 2 *  3 =   6.50
 5 *  5 =  24.62
 4 * 10 =  40.02
10 *  4 =  40.73
 9 *  9 =  81.74
10 * 10 =  98.44
</pre>

<p>Po zaokrouhlení získáme sérii zcela korektních výsledků, ale i výsledky,
které se (nepatrně) odlišují od korektního součinu. Problémy nastávají zejména
na obou &bdquo;mezích&ldquo; tabulky malé násobilky, tj.&nbsp;pro hodnoty
blízké jedničce a naopak pro hodnoty blízké 100:</p>

<pre>
rounded:
 1 *  1 =  0    špatně
 2 *  3 =  6
 5 *  5 = 24    špatně
 4 * 10 = 40
10 *  4 = 40
 9 *  9 = 81
10 * 10 = 98    špatně
</pre>

<p><div class="rs-tip-major">Poznámka: jedná se o pochopitelné výsledky,
zejména když si uvědomíme, že neuronová síť je tvořena množinou uzlů, které
provádí váhování svých vstupů s&nbsp;jejich následným součtem a na takto
získanou sumu aplikují zvolenou aktivační funkci. V&nbsp;obou mezních stavech
tedy skutečně může docházet k&nbsp;chybám &ndash; a to platí i pro reálně
používané neuronové sítě.</div></p>



<p><a name="k16"></a></p>
<h2 id="k16">16. Vizualizace rozdílů předpovědí neuronové sítě od korektních výsledků</h2>

<p>Pro model provádějící regresi a nikoli klasifikaci sice nemůžeme použít
matici záměn, ale můžeme si pomoci jiným způsobem. Vypočteme si například
rozdíl mezi očekávanými výsledky a výsledky vypočtenými modelem. Bude se opět
jednat o matici 10&times;10:</p>

<pre>
<i># korektni tabulka male nasobilky</i>
W = y.reshape((MAX_N, MAX_N))
&nbsp;
print("Relative errors:")
errors = (100*(Z-W)/W).astype("int")
print(errors)
</pre>

<p>A takovou matici již můžeme zobrazit i formou grafu:</p>

<pre>
<i># vizualizace chyb</i>
plt.matshow(Z-W)
</pre>

<p>Podívejme se tedy na skript, který nejprve natrénuje neuronovou síť na
výpočet malé násobilky, potom nechá tuto síť vytvořit tabulku (matici) malé
násobilky a následně zobrazí chyby (jak ve tvaru matice, tak i grafu):</p>

<pre>
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
<i># velikost tabulky soucinu</i>
MAX_N = 10
&nbsp;
<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N*MAX_N, 2) )   <i>  # kombinace cinitelu</i>
y = np.zeros( (MAX_N*MAX_N, ))     <i>  # vektor soucinu</i>
i = 0
for a in range(1, MAX_N+1):
    for b in range(1, MAX_N+1):
        X[i, 0] = a                <i>  # cinitel</i>
        X[i, 1] = b                <i>  # cinitel</i>
        y[i] = a * b               <i>  # soucin</i>
        i+=1
&nbsp;
<i># konstrukce modelu</i>
nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(100, 100))
&nbsp;
<i># trénink modelu nad vsemi daty</i>
nn.fit(X, y)
&nbsp;
<i># zobrazit parametry neuronove site</i>
print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")
&nbsp;
<i># vahy neuronu</i>
for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
&nbsp;
<i># posuny (dalsi vstup do neuronu)</i>
print("Biases:")
for layer, biases in enumerate(nn.intercepts_):
    print("\t", layer, biases.shape)
&nbsp;
<i># odhady (odpovedi) neuronove site po uprave do matice 10x10</i>
Z = nn.predict(X).round().reshape((MAX_N, MAX_N))
&nbsp;
print("Prediction:")
print(Z)
&nbsp;
<i># korektni tabulka male nasobilky</i>
W = y.reshape((MAX_N, MAX_N))
&nbsp;
print("Relative errors:")
errors = (100*(Z-W)/W).astype("int")
print(errors)
&nbsp;
<i># vizualizace chyb</i>
plt.matshow(Z-W)
&nbsp;
<i># ulozeni vysledku</i>
plt.savefig("152.png")
&nbsp;
<i># zobrazeni</i>
plt.show()
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na
adrese <a
href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/152_multiplication_table.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/152_multiplication_table.py</a>.</div></p>



<p><a name="k17"></a></p>
<h2 id="k17">17. Numerické i grafické výsledky korektnosti výpočtů tabulky malé násobilky</h2>

<p>Po spuštění <a href="#k16">výše uvedeného skriptu</a> se nejprve zobrazí
parametry neuronové sítě, což již dobře známe:</p>

<pre>
Features: 2
Layers:   4
Outputs:  1
Weights:
         0 (2, 100)
         1 (100, 100)
         2 (100, 1)
Biases:
         0 (100,)
         1 (100,)
         2 (1,)
</pre>

<p>Dále se zobrazí tabulka malé násobilky vypočtená neuronovou sítí
(s&nbsp;chybami!):</p>

<pre>
Prediction:
[[-0.  2.  3.  4.  5.  6.  7.  8.  9. 10.]
 [ 2.  4.  6.  8. 10. 12. 14. 16. 18. 20.]
 [ 3.  6.  9. 12. 15. 18. 21. 24. 27. 30.]
 [ 4.  8. 12. 16. 20. 24. 28. 32. 36. 40.]
 [ 5. 10. 15. 20. 25. 30. 35. 40. 45. 50.]
 [ 6. 12. 18. 24. 30. 36. 42. 48. 54. 60.]
 [ 7. 14. 21. 28. 35. 42. 49. 56. 63. 70.]
 [ 8. 15. 24. 32. 40. 48. 57. 65. 73. 80.]
 [ 9. 18. 27. 36. 45. 54. 63. 73. 82. 89.]
 [10. 20. 30. 40. 50. 61. 70. 80. 89. 98.]]
</pre>

<p>Relativní chyby vyjádřené v&nbsp;procentech nejsou většinou příliš velké, až
na ten nejjednodušší výpočet 1&times;1 :-)</p>

<pre>
Relative errors:
[[-100    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0    0    0    0    0    0    0    0    0    0]
 [   0   -6    0    0    0    0    1    1    1    0]
 [   0    0    0    0    0    0    0    1    1   -1]
 [   0    0    0    0    0    1    0    0   -1   -2]]
</pre>

<p>Vizuální zobrazení chyb pro čtyři běhy skriptu (síť se pokaždé natrénuje
odlišně):</p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-11.webp" class="image-1139815" width="480" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 14: Z&nbsp;grafu je patrné, ve kterých místech neuronová síť
nejvíce chybuje (horní a dolní roh).</i></p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-12.webp" class="image-1139818" width="480" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 15: Výsledky pro nepatrně odlišně natrénovanou sít.</i></p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-13.webp" class="image-1139821" width="480" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 16: Výsledky pro nepatrně odlišně natrénovanou sít.</i></p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-14.webp" class="image-1139824" width="480" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 17: Výsledky pro nepatrně odlišně natrénovanou sít.</i></p>



<p><a name="k18"></a></p>
<h2 id="k18">18. Dokáže takto natrénovaná neuronová síť generalizovat?</h2>

<p>Nyní si otestujme, jestli neuronová síť natrénovaná pouze na výpočet malé
násobilky dokáže provádět součiny i pro větší hodnoty (například od 1 do 20,
tedy nejvyšším očekávaným výsledkem bude 20&times;20=400). Otestujeme tedy,
jestli neuronová síť dokáže nějakým způsobem generalizovat to, co se naučila (a
jestli si jako celek udělala správný &bdquo;mentální model&ldquo; řešeného
problému). Předchozí skript tedy upravíme tak, že nejdříve neuronovou síť
běžným způsobem natrénujeme pro malou násobilku a posléze jí pošleme pro
ohodnocení matici s&nbsp;kombinacemi činitelů 0 až 20, což znamená, že jen 25%
vstupů tato síť &bdquo;viděla&ldquo; při tréninku (<strong>MAX_N</strong> se
liší od <strong>MAX_TO_COMPUTE</strong>):</p>

<pre>
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
<i># velikost tabulky soucinu</i>
MAX_N = 10
&nbsp;
<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N*MAX_N, 2) )   <i>  # kombinace cinitelu</i>
y = np.zeros( (MAX_N*MAX_N, ))     <i>  # vektor soucinu</i>
i = 0
for a in range(1, MAX_N+1):
    for b in range(1, MAX_N+1):
        X[i, 0] = a                <i>  # cinitel</i>
        X[i, 1] = b                <i>  # cinitel</i>
        y[i] = a * b               <i>  # soucin</i>
        i+=1
&nbsp;
<i># konstrukce modelu</i>
nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(100, 100))
&nbsp;
<i># trénink modelu nad vsemi daty</i>
nn.fit(X, y)
&nbsp;
<i># zobrazit parametry neuronove site</i>
print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")
&nbsp;
<i># vahy neuronu</i>
for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
&nbsp;
<i># posuny (dalsi vstup do neuronu)</i>
print("Biases:")
for layer, biases in enumerate(nn.intercepts_):
    print("\t", layer, biases.shape)
&nbsp;
MAX_TO_COMPUTE = 20
&nbsp;
X2 = np.zeros( (MAX_TO_COMPUTE*MAX_TO_COMPUTE, 2) )   <i>  # kombinace cinitelu</i>
y2 = np.zeros( (MAX_TO_COMPUTE*MAX_TO_COMPUTE, ))     <i>  # vektor soucinu</i>
i = 0
for a in range(1, MAX_TO_COMPUTE+1):
    for b in range(1, MAX_TO_COMPUTE+1):
        X2[i, 0] = a                <i>  # cinitel</i>
        X2[i, 1] = b                <i>  # cinitel</i>
        y2[i] = a * b               <i>  # soucin</i>
        i+=1
&nbsp;
<i># odhady (odpovedi) neuronove site po uprave do matice 10x10</i>
Z = nn.predict(X2).round().reshape((MAX_TO_COMPUTE, MAX_TO_COMPUTE))
&nbsp;
print("Prediction:")
print(Z)
&nbsp;
<i># korektni tabulka male nasobilky</i>
W = y2.reshape((MAX_TO_COMPUTE, MAX_TO_COMPUTE))
&nbsp;
print("Relative errors:")
errors = (100*(Z-W)/W).astype("int")
print(errors)
&nbsp;
<i># vizualizace chyb</i>
plt.matshow(Z-W)
&nbsp;
<i># ulozeni vysledku</i>
plt.savefig("153.png")
&nbsp;
<i># zobrazeni</i>
plt.show()
</pre>

<p><div class="rs-tip-major">Poznámka: tento demonstrační příklad naleznete na
adrese <a
href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/153_multiplication_table.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/153_multiplication_table.py</a>.</div></p>

<p>Skript po svém spuštění opět zobrazí základní parametry neuronové sítě (ta
se přitom nijak nezměnila):</p>

<pre>
Features: 2
Layers:   4
Outputs:  1
Weights:
	 0 (2, 100)
	 1 (100, 100)
	 2 (100, 1)
Biases:
	 0 (100,)
	 1 (100,)
	 2 (1,)
</pre>

<p>Výsledky pro vyšší činitele již nejsou nijak oslňující &ndash; tuto část se
neuronová síť evidentně nenaučila ani neprovedla generalizaci:</p>

<pre>
Prediction:
[[  0.   2.   3.   4.   5.   6.   7.   8.   9.  10.  12.  13.  15.  18.  20.  22.  25.  27.  29.  32.]
 [  1.   4.   7.   8.  10.  12.  14.  16.  18.  20.  22.  24.  26.  28.  31.  33.  35.  38.  40.  42.]
 [  3.   6.   9.  12.  15.  18.  21.  24.  27.  30.  33.  35.  37.  40.  42.  44.  47.  49.  51.  54.]
 [  4.   8.  12.  16.  19.  24.  28.  32.  36.  40.  44.  47.  50.  52.  54.  56.  59.  61.  63.  66.]
 [  5.  10.  15.  20.  25.  30.  35.  40.  45.  50.  54.  58.  62.  65.  67.  69.  71.  73.  76.  78.]
 [  6.  12.  18.  24.  30.  36.  42.  48.  54.  60.  65.  70.  73.  77.  80.  83.  85.  87.  89.  91.]
 [  7.  14.  21.  28.  35.  42.  49.  56.  64.  70.  75.  81.  86.  90.  93.  97.  99. 101. 103. 105.]
 [  8.  16.  24.  32.  40.  48.  57.  66.  73.  80.  86.  92.  97. 102.  106. 110. 113. 116. 118. 120.]
 [  9.  18.  27.  36.  45.  54.  63.  73.  82.  89.  96. 102. 108. 113.  118. 122. 126. 129. 132. 135.]
 [ 10.  20.  30.  40.  50.  60.  70.  80.  89.  98. 106. 112. 118. 123.  129. 134. 138. 142. 145. 148.]
 [ 12.  22.  33.  44.  54.  65.  76.  86.  96. 105. 114. 121. 128. 133.  139. 144. 150. 154. 158. 162.]
 [ 15.  25.  36.  47.  59.  70.  81.  92. 102. 112. 121. 129. 137. 143.  149. 154. 160. 165. 170. 174.]
 [ 17.  28.  39.  50.  62.  74.  86.  97. 108. 117. 127. 136. 145. 152.  159. 164. 170. 175. 181. 186.]
 [ 20.  31.  41.  53.  65.  78.  90. 102. 113. 123. 133. 142. 151. 160.  167. 174. 180. 185. 191. 196.]
 [ 23.  33.  44.  56.  67.  81.  94. 106. 118. 129. 139. 148. 157. 166.  175. 182. 189. 195. 200. 206.]
 [ 26.  36.  47.  58.  70.  83.  97. 111. 122. 133. 144. 154. 163. 173.  181. 190. 198. 204. 210. 216.]
 [ 28.  39.  50.  61.  73.  86. 100. 114. 126. 138. 149. 159. 169. 179.  188. 196. 205. 213. 220. 226.]
 [ 31.  42.  53.  64.  76.  89. 102. 117. 131. 142. 154. 165. 175. 185.  194. 203. 212. 220. 228. 235.]
 [ 34.  45.  55.  67.  79.  91. 105. 119. 133. 147. 158. 169. 180. 190.  200. 209. 218. 227. 235. 243.]
 [ 37.  47.  58.  70.  81.  94. 108. 121. 136. 150. 163. 174. 185. 196.  206. 215. 224. 233. 242. 250.]]
</pre>

<p>Ještě více je to patrné při vyjádření relativní chyby:</p>

<pre>
Relative errors:
[[-100    0    0    0    0    0    0    0    0    0    9    8   15   28 33   37   47   50   52   60]
 [ -50    0   16    0    0    0    0    0    0    0    0    0    0    0 3    3    2    5    5    5]
 [   0    0    0    0    0    0    0    0    0    0    0   -2   -5   -4 -6   -8   -7   -9  -10  -10]
 [   0    0    0    0   -5    0    0    0    0    0    0   -2   -3   -7 -10  -12  -13  -15  -17  -17]
 [   0    0    0    0    0    0    0    0    0    0   -1   -3   -4   -7 -10  -13  -16  -18  -20  -22]
 [   0    0    0    0    0    0    0    0    0    0   -1   -2   -6   -8 -11  -13  -16  -19  -21  -24]
 [   0    0    0    0    0    0    0    0    1    0   -2   -3   -5   -8 -11  -13  -16  -19  -22  -25]
 [   0    0    0    0    0    0    1    3    1    0   -2   -4   -6   -8 -11  -14  -16  -19  -22  -25]
 [   0    0    0    0    0    0    0    1    1   -1   -3   -5   -7  -10 -12  -15  -17  -20  -22  -25]
 [   0    0    0    0    0    0    0    0   -1   -2   -3   -6   -9  -12 -14  -16  -18  -21  -23  -26]
 [   9    0    0    0   -1   -1   -1   -2   -3   -4   -5   -8  -10  -13 -15  -18  -19  -22  -24  -26]
 [  25    4    0   -2   -1   -2   -3   -4   -5   -6   -8  -10  -12  -14 -17  -19  -21  -23  -25  -27]
 [  30    7    0   -3   -4   -5   -5   -6   -7  -10  -11  -12  -14  -16 -18  -21  -23  -25  -26  -28]
 [  42   10   -2   -5   -7   -7   -8   -8  -10  -12  -13  -15  -17  -18 -20  -22  -24  -26  -28  -30]
 [  53   10   -2   -6  -10  -10  -10  -11  -12  -14  -15  -17  -19  -20 -22  -24  -25  -27  -29  -31]
 [  62   12   -2   -9  -12  -13  -13  -13  -15  -16  -18  -19  -21  -22 -24  -25  -27  -29  -30  -32]
 [  64   14   -1  -10  -14  -15  -15  -16  -17  -18  -20  -22  -23  -24 -26  -27  -29  -30  -31  -33]
 [  72   16   -1  -11  -15  -17  -19  -18  -19  -21  -22  -23  -25  -26 -28  -29  -30  -32  -33  -34]
 [  78   18   -3  -11  -16  -20  -21  -21  -22  -22  -24  -25  -27  -28 -29  -31  -32  -33  -34  -36]
 [  85   17   -3  -12  -19  -21  -22  -24  -24  -25  -25  -27  -28  -30 -31  -32  -34  -35  -36  -37]]
</pre>

<p>Poslední věcí, kterou si dnes ukážeme, je vizualizace chyb na grafu:</p>

<img src="https://i.iinfo.cz/images/404/scikit-learn-6-15.webp" class="image-1139827" width="480" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 18: Vizualizace chyb pro vstupní činitele od 1 do 20.</i></p>



<p><a name="19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu Scikit-learn lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady i na (Jupyter) diáře s&nbsp;postupem
výpočtů a analýz:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td>01_show_matrix.py</td><td>kooperace mezi knihovnami Matplotlib a NumPy: vizualizace obsahu 2D matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py</a></td></tr>
<tr><td> 2</td><td>02_get_digits.py</td><td>datová množina obsahující naskenované ručně napsané číslice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py</a></td></tr>
<tr><td> 3</td><td>03_get_features.py</td><td>další atributy datové množiny, které použijeme při trénování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py</a></td></tr>
<tr><td> 4</td><td>04_get_images.py</td><td>přečtení a následné vykreslení jednotlivých ručně nakreslených číslic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py</a></td></tr>
<tr><td> 5</td><td>05_show_grayscale_matrix.py</td><td>odstranění umělé aplikované barvové palety (obrázky ve stupních šedi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py</a></td></tr>
<tr><td> 6</td><td>06_grayscale_images.py</td><td>vykreslení ručně nakreslených číslic ve formě obrázků ve stupních šedi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py</a></td></tr>
<tr><td> 7</td><td>07_multiplot.py</td><td>rozdělení plochy grafu do oblastí; vykreslení více obrázků do jediného grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py</a></td></tr>
<tr><td> 8</td><td>08_model_preperation_1.py</td><td>obrázky s&nbsp;jejich ohodnocením</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py</a></td></tr>
<tr><td> 9</td><td>09_training_set.py</td><td>příprava dat pro trénink</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py</a></td></tr>
<tr><td>10</td><td>10_classification.py</td><td>klasifikace obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py</a></td></tr>
<tr><td>11</td><td>11_results.py</td><td>vykreslení obrázků společně s&nbsp;jejich klasifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py</a></td></tr>
<tr><td>12</td><td>12_change_training_set.py</td><td>změna poměru rozdělení dat na tréninkovou a testovací množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>13</td><td>13_blobs.py</td><td>použití funkce <strong>make_blobs</strong> pro vygenerování sady bodů v&nbsp;rovině sdružených do oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py</a></td></tr>
<tr><td>14</td><td>14_swap_coords.py</td><td>úprava předchozího příkladu: prohození souřadnic na osách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py</a></td></tr>
<tr><td>15</td><td>15_blobs_scatter_plot.py</td><td>základní podoba bodového diagramu (<i>scatter plot</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py</a></td></tr>
<tr><td>16</td><td>16_blobs_scatter_plot.py</td><td>úprava bodového diagramu při zobrazení většího množství bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py</a></td></tr>
<tr><td>17</td><td>17_colorized_blobs.py</td><td>obarvení bodů podle oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py</a></td></tr>
<tr><td>18</td><td>18_k-means.py</td><td>základní použití algoritmu K-means pro clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py</a></td></tr>
<tr><td>19</td><td>19_combination.py</td><td>zobrazení centroidů společně s&nbsp;původními body</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py</a></td></tr>
<tr><td>20</td><td>20_combinations.py</td><td>vizualizace clusteringu původní množiny bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py</a></td></tr>
<tr><td>21</td><td>21_other_settings.py</td><td>vizualizace clusteringu původní množiny bodů pro odlišnou množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py</a></td></tr>
<tr><td>22</td><td>22_random_points.py</td><td>clustering pro náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>23</td><td>23_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, menší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py</a></td></tr>
<tr><td>24</td><td>24_more_noise_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, větší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py</a></td></tr>
<tr><td>25</td><td>25_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, menší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py</a></td></tr>
<tr><td>26</td><td>26_more_noisy_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, větší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py</a></td></tr>
<tr><td>27</td><td>27_circles_kmeans.py</td><td>výsledek clusteringu provedeného algoritmem K-means na &bdquo;kružnice&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/27_circles_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/27_circles_kmeans.py</a></td></tr>
<tr><td>28</td><td>28_moons_kmeans.py</td><td>výsledek clusteringu provedeného algoritmem K-means na &bdquo;půlměsíce&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/28_moons_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/28_moons_kmeans.py</a></td></tr>
<tr><td>29</td><td>29_blobs_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné pomocí <strong>make_blobs</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/29_blobs_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/29_blobs_spectral_clustering.py</a></td></tr>
<tr><td>30</td><td>30_circles_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné do kružnic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/30_circles_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/30_circles_spectral_clustering.py</a></td></tr>
<tr><td>31</td><td>31_moons_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné do půlměsíců </td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/31_moons_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/31_moons_spectral_clustering.py</a></td></tr>
<tr><td>32</td><td>32_moons_spectral_clustering_limits.py</td><td>vyhledání limitů algoritmu spectral clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/32_moons_spectral_clustering_limits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/32_moons_spectral_clustering_limits.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>33</td><td>33_particles_load.py</td><td>načtení souřadnic částic uložených v&nbsp;souboru formátu CSV</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/33_particles_load.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/33_particles_load.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>34</td><td>34_lorenz_attractor.py</td><td>zobrazení Lorenzova atraktoru formou bodů propojených úsečkami</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/34_lorenz_attractor.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/34_lorenz_attractor.py</a></td></tr>
<tr><td>35</td><td>35_lorenz_attractor_points.py</td><td>Lorenzův atraktor vykreslený formou jednotlivých bodů s&nbsp;definovaným stylem zobrazení a velikostí stopy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/35_lorenz_attractor_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/35_lorenz_attractor_points.py</a></td></tr>
<tr><td>36</td><td>36_blobs_3d.py</td><td>vygenerování a zobrazení sady bodů v&nbsp;3D prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/36_blobs_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/36_blobs_3d.py</a></td></tr>
<tr><td>37</td><td>37_spread_blobs_3d.py</td><td>vygenerování a zobrazení sady bodů v&nbsp;3D prostoru, odlišné parametry při generování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/37_spread_blobs_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/37_spread_blobs_3d.py</a></td></tr>
<tr><td>38</td><td>38_views.py</td><td>různé pohledy na 3D graf</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/38_views.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/38_views.py</a></td></tr>
<tr><td>39</td><td>39_colorized_3d_blobs.py</td><td>obarvení bodů v&nbsp;prostoru na základě vstupních dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/39_colorized_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/39_colorized_3d_blobs.py</a></td></tr>
<tr><td>40</td><td>40_kmeans_3d_blobs.py</td><td>shluková analýza v&nbsp;3D prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/40_kmeans_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/40_kmeans_3d_blobs.py</a></td></tr>
<tr><td>41</td><td>41_kmeans_spread_3d_blobs.py</td><td>shluková analýza v&nbsp;3D prostoru pro odlišnou množinu bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/41_kmeans_spread_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/41_kmeans_spread_3d_blobs.py</a></td></tr>
<tr><td>42</td><td>42_kmeans_random_3d.py</td><td>shluková analýza pro body rozmístěné zcela náhodně v&nbsp;omezeném prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/42_kmeans_random_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/42_kmeans_random_3d.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>43</td><td>43_speed_measurements.py</td><td>benchmark pro postupně rostoucí počet bodů tvořících shluky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/43_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/43_speed_measurements.py</a></td></tr>
<tr><td>44</td><td>44_speed_measurements.py</td><td>benchmark pro postupně rostoucí počet bodů rozmístěných náhodně</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/44_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/44_speed_measurements.py</a></td></tr>
<tr><td>45</td><td>45_speed_measurements.py</td><td>benchmark pro stále stejný počet bodů, u jejichž rozmístění v&nbsp;prostoru se používá stále větší směrodatná odchylka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/45_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/45_speed_measurements.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>46</td><td>46_iris_dataset.py</td><td>načtení datové kolekce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/46_iris_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/46_iris_dataset.py</a></td></tr>
<tr><td>47</td><td>47_iris_description.py</td><td>metadata o datové kolekci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/47_iris_description.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/47_iris_description.py</a></td></tr>
<tr><td>48</td><td>48_iris_data.py</td><td>tvar dat &ndash; počet záznamů a počet proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/48_iris_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/48_iris_data.py</a></td></tr>
<tr><td>49</td><td>49_iris_targets.py</td><td>jména atributů, vztah mezi numerickou hodnotou atributu a jeho jménem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/49_iris_targets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/49_iris_targets.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>50</td><td>50_iris_scatter_plot_1.py</td><td>korelační diagram pro dvojici vybraných proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/50_iris_scatter_plot_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/50_iris_scatter_plot_1.py</a></td></tr>
<tr><td>51</td><td>51_iris_scatter_plot_2.py</td><td>příprava pro tvorbu složitějších grafů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/51_iris_scatter_plot_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/51_iris_scatter_plot_2.py</a></td></tr>
<tr><td>52</td><td>52_iris_mutliplot.py</td><td>mřížka obsahující více korelačních diagramů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/52_iris_mutliplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/52_iris_mutliplot.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>53</td><td>53_iris_histograms.py</td><td>zobrazení základního histogramu pro data v&nbsp;sadě Iris</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/53_iris_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/53_iris_histograms.py</a></td></tr>
<tr><td>54</td><td>54_iris_histograms.py</td><td>úprava histogramu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/54_iris_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/54_iris_histograms.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>55</td><td>55_pca.py</td><td>analýza hlavních komponent (PCA), výsledek zobrazený v&nbsp;2D grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/55_pca.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/55_pca.py</a></td></tr>
<tr><td>56</td><td>56_pca_3d.py</td><td>analýza hlavních komponent (PCA), výsledek zobrazený v&nbsp;3D grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/56_pca_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/56_pca_3d.py</a></td></tr>
<tr><td>57</td><td>57_kmeans.py</td><td>základní shluková analýza</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/57_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/57_kmeans.py</a></td></tr>
<tr><td>58</td><td>58_multiple_kmeans.py</td><td>větší množství výsledků shlukové analýzy pro různé atributy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/58_multiple_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/58_multiple_kmeans.py</a></td></tr>
<tr><td>59</td><td>59_kmeans_errors.py</td><td>korektní a nekorektní výsledky základní shlukové analýzy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/59_kmeans_errors.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/59_kmeans_errors.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>60</td><td>60_basic_classifier.py</td><td>aplikace jednoduchého modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/60_basic_classifier.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/60_basic_classifier.py</a></td></tr>
<tr><td>61</td><td>61_changed_model_parameters.py</td><td>změna parametrů modelu pro zjištění druhů rostil</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/61_changed_model_parameters.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/61_changed_model_parameters.py</a></td></tr>
<tr><td>62</td><td>62_different_model.py</td><td>použití odlišného modelu pro zjištění druhů rostlin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/62_different_model.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/62_different_model.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>63</td><td>63_verify_on_whole_data_1.py</td><td>otestování naučeného modelu s&nbsp;využitím tréninkových dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/63_verify_on_whole_data_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/63_verify_on_whole_data_1.py</a></td></tr>
<tr><td>64</td><td>64_verify_on_whole_data_2.py</td><td>využití funkce <strong>metrics.accuracy_score</strong> pro zjištění kvality modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/64_verify_on_whole_data_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/64_verify_on_whole_data_2.py</a></td></tr>
<tr><td>65</td><td>65_basic_comparison.py</td><td>porovnání vlastností různých modelů (prozatím nekorektní řešení)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/65_basic_comparison.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/65_basic_comparison.py</a></td></tr>
<tr><td>66</td><td>66_training_testing_split_1.py</td><td>rozdělení datové sady na trénovací data a testovací data (základní varianta)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/66_training_testing_split_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/66_training_testing_split_1.py</a></td></tr>
<tr><td>67</td><td>67_training_testing_split_2.py</td><td>rozdělení datové sady na trénovací data a testovací data (náhodné rozdělení sady)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/67_training_testing_split_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/67_training_testing_split_2.py</a></td></tr>
<tr><td>68</td><td>68_training_testing_split_3.py</td><td>rozdělení datové sady na trénovací data a testovací data (využití vestavěné funkce)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/68_training_testing_split_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/68_training_testing_split_3.py</a></td></tr>
<tr><td>69</td><td>69_better_comparison.py</td><td>vylepšené porovnání vlastností různých modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/69_better_comparison.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/69_better_comparison.py</a></td></tr>
<tr><td>70</td><td>70_multiple_runs.py</td><td>vliv generátoru náhodných čísel na změřené výsledky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/70_multiple_runs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/70_multiple_runs.py</a></td></tr>
<tr><td>71</td><td>71_stable_multiple_runs.py</td><td>generátor náhodných čísel a použití hodnoty <strong>random_state</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/71_stable_multiple_runs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/71_stable_multiple_runs.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>72</td><td>72_housings_dataset.py</td><td>načtení datové sady <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/72_housings_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/72_housings_dataset.py</a></td></tr>
<tr><td>73</td><td>73_housings_dataset_description.py</td><td>metainformace o datové sadě <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/73_housings_dataset_description.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/73_housings_dataset_description.py</a></td></tr>
<tr><td>74</td><td>74_housings_data.py</td><td>n-rozměrné pole s&nbsp;atributy jednotlivých domů/bloků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/74_housings_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/74_housings_data.py</a></td></tr>
<tr><td>75</td><td>75_housings_targets.py</td><td>jména atributů, ceny domů atd.</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/75_housings_targets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/75_housings_targets.py</a></td></tr>
<tr><td>76</td><td>76_housings_scatter_plot.py</td><td>korelační diagram pro dvojici vybraných proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/76_housings_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/76_housings_scatter_plot.py</a></td></tr>
<tr><td>77</td><td>77_housings_mutliplot.py</td><td>korelační diagram pro všechny kombinace dvojic proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/77_housings_mutliplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/77_housings_mutliplot.py</a></td></tr>
<tr><td>78</td><td>78_scatter.py</td><td>dvourozměrné hodnoty reprezentované jako dvojice atributů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/78_scatter.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/78_scatter.py</a></td></tr>
<tr><td>79</td><td>79_linear_regression_gen_data.py</td><td>model <i>LinearRegression</i> nad uměle vytvořenými daty</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/79_linear_regression_gen_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/79_linear_regression_gen_data.py</a></td></tr>
<tr><td>80</td><td>80_linear_regression_predictions.py</td><td>predikce modelu provádějícího lineární regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/80_linear_regression_predictions.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/80_linear_regression_predictions.py</a></td></tr>
<tr><td>81</td><td>81_linear_regression_random_data.py</td><td>chování modelu pro zcela náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/81_linear_regression_random_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/81_linear_regression_random_data.py</a></td></tr>
<tr><td>82</td><td>82_linear_regression_housings.py</td><td>model <i>LinearRegression</i> pro datovou sadu <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/82_linear_regression_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/82_linear_regression_housings.py</a></td></tr>
<tr><td>83</td><td>83_polynomial_regression_gen_data.py</td><td>polynomiální regrese (základní příklad)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/83_polynomial_regression_gen_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/83_polynomial_regression_gen_data.py</a></td></tr>
<tr><td>84</td><td>84_polynomial_regression_housings.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, první příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/84_polynomial_regression_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/84_polynomial_regression_housings.py</a></td></tr>
<tr><td>85</td><td>85_polynomial_regression_housings_2.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, druhý příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/85_polynomial_regression_housings_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/85_polynomial_regression_housings_2.py</a></td></tr>
<tr><td>86</td><td>86_polynomial_regression_housings_3.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, třetí příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/86_polynomial_regression_housings_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/86_polynomial_regression_housings_3.py</a></td></tr>
<tr><td>87</td><td>87_linear_regression_errors.py</td><td>výpočet chyby a skóre modelu lineární regrese</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/87_linear_regression_errors.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/87_linear_regression_errors.py</a></td></tr>
<tr><td>88</td><td>88_linear_regression_non_linear_data.py</td><td>lineární regrese nad nelineárními daty</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/88_linear_regression_non_linear_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/88_linear_regression_non_linear_data.py</a></td></tr>
<tr><td>89</td><td>89_polynomial_regression_error.py</td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/89_polynomial_regression_error.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/89_polynomial_regression_error.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>90</td><td>90_housings_prediction_1.py</td><td>regresní analýza nad daty <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/90_housings_prediction_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/90_housings_prediction_1.py</a></td></tr>
<tr><td>91</td><td>91_housings_prediction_2.py</td><td>korektní natrénování modelu pro regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/91_housings_prediction_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/91_housings_prediction_2.py</a></td></tr>
<tr><td>92</td><td>92_housings_prediction_3.py</td><td>omezení množství atributů (proměnných), na kterých je model natrénován</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/92_housings_prediction_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/92_housings_prediction_3.py</a></td></tr>
<tr><td>93</td><td>93_housings_prediction_errors_1.py</td><td>chybně natrénovaný model při náhodné volbě dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/93_housings_prediction_errors_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/93_housings_prediction_errors_1.py</a></td></tr>
<tr><td>94</td><td>94_housings_prediction_errors_2.py</td><td>omezení atributů + chybně natrénovaný model</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/94_housings_prediction_errors_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/94_housings_prediction_errors_2.py</a></td></tr>
<tr><td>95</td><td>95_housings_histograms.py</td><td>histogramy pro jednotlivé atributy (proměnné)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/95_housings_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/95_housings_histograms.py</a></td></tr>
<tr><td>96</td><td>96_housings_statistic.py</td><td>statistické údaje pro jednotlivé atributy (proměnné)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/96_housings_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/96_housings_statistic.py</a></td></tr>
<tr><td>97</td><td>97_housings_statistic_normalized.py</td><td>statistické údaje získané po normalizaci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/97_housings_statistic_normalized.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/97_housings_statistic_normalized.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 98</td><td>98_k_fold_help.py</td><td>zobrazení nápovědy ke třídě s&nbsp;realizací k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/98_k_fold_help.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/98_k_fold_help.py</a></td></tr>
<tr><td> 99</td><td>99_k_fold_old.py</td><td>původní (nepodporovaná) varianta provedení k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/99_k_fold_old.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/99_k_fold_old.py</a></td></tr>
<tr><td>100</td><td>100_k_fold_1.py</td><td>interní chování algoritmu k-foldingu (základní parametry)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/100_k_fold_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/100_k_fold_1.py</a></td></tr>
<tr><td>101</td><td>101_k_fold_2.py</td><td>interní chování algoritmu k-foldingu (odlišné parametry)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/101_k_fold_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/101_k_fold_2.py</a></td></tr>
<tr><td>102</td><td>102_k_fold_selection.py</td><td>k-folding a výběr dat pro otestování modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/102_k_fold_selection.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/102_k_fold_selection.py</a></td></tr>
<tr><td>103</td><td>103_average_score.py</td><td>realizace výpočtu průměrného skóre pro otestování modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/103_average_score.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/103_average_score.py</a></td></tr>
<tr><td>104</td><td>104_hyperparams_score.py</td><td>změna hyperparametrů s&nbsp;výpočtem průměrného skóre (tabulka)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/104_hyperparams_score.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/104_hyperparams_score.py</a></td></tr>
<tr><td>105</td><td>105_hyperparams_score_plot.py</td><td>změna hyperparametrů s&nbsp;výpočtem průměrného skóre (graf)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/105_hyperparams_score_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/105_hyperparams_score_plot.py</a></td></tr>
<tr><td>106</td><td>106_model_selection.py</td><td>výběr nejlepšího modelu s&nbsp;využitím k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/106_model_selection.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/106_model_selection.py</a></td></tr>
<tr><td>107</td><td>107_features_selection_basic.py</td><td>výběr atributů (proměnných) pro trénink modelu (základní varianta)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/107_features_selection_basic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/107_features_selection_basic.py</a></td></tr>
<tr><td>108</td><td>108_features_selection_iris.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada Iris)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/108_features_selection_iris.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/108_features_selection_iris.py</a></td></tr>
<tr><td>109</td><td>109_features_selection_houses.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada California Housings)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/109_features_selection_houses.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/109_features_selection_houses.py</a></td></tr>
<tr><td>110</td><td>110_best_features_selection_houses.py</td><td>získání nejlepší sady atributů (proměnných)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/110_best_features_selection_houses.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/110_best_features_selection_houses.py</a></td></tr>
<tr><td>111</td><td>111_features_selection_graphical.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada Iris), grafický výstup</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/111_features_selection_graphical.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/111_features_selection_graphical.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>112</td><td>112_simplest_linear_regression.py</td><td>lineární regrese bodů ležících v&nbsp;rovině</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/112_simplest_linear_regression.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/112_simplest_linear_regression.py</a></td></tr>
<tr><td>113</td><td>113_linear_regression_no_intercept.py</td><td>lineární regrese při vynucení <i>w<sub>0</sub>=0</i> pro obecná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/113_linear_regression_no_intercept.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/113_linear_regression_no_intercept.py</a></td></tr>
<tr><td>114</td><td>114_linear_regression_from_0_0.py</td><td>lineární regrese při vynucení <i>w<sub>0</sub>=0</i> v&nbsp;případě, že vstupní body obsahují počátek souřadného systému</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/114_linear_regression_from_0_0.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/114_linear_regression_from_0_0.py</a></td></tr>
<tr><td>115</td><td>115_linear_regression_multiple_y.py</td><td>model předpovídající pro každou vstupní hodnotu dvě výstupní hodnoty (odpovědi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/115_linear_regression_multiple_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/115_linear_regression_multiple_y.py</a></td></tr>
<tr><td>116</td><td>116_grid_operations.py</td><td>konstrukce matice obsahující souřadnice bodů v&nbsp;mřížce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/116_grid_operations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/116_grid_operations.py</a></td></tr>
<tr><td>117</td><td>117_linear_regression_multiple_x.py</td><td>proložení bodů v&nbsp;prostoru rovinou</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/117_linear_regression_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/117_linear_regression_multiple_x.py</a></td></tr>
<tr><td>118</td><td>118_linear_regression_multiple_x.py</td><td>proložení bodů s&nbsp;náhodnou výškou rovinou</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/118_linear_regression_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/118_linear_regression_multiple_x.py</a></td></tr>
<tr><td>119</td><td>119_linear_regression_multiple_x_and_y.py</td><td>proložení dvou sad bodů dvojicí rovin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/119_linear_regression_multiple_x_and_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/119_linear_regression_multiple_x_and_y.py</a></td></tr>
<tr><td>120</td><td>120_linear_regression_multiple_x_and_y.py</td><td>proložení dvou sad bodů dvojicí rovin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/120_linear_regression_multiple_x_and_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/120_linear_regression_multiple_x_and_y.py</a></td></tr>
<tr><td>121</td><td>121_linear_regression_poly.py</td><td>základní polynomická regrese</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/121_linear_regression_poly.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/121_linear_regression_poly.py</a></td></tr>
<tr><td>122</td><td>122_linear_regression_poly_multiple_x.py</td><td>polynomická regrese a body v&nbsp;prostoru, první příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/122_linear_regression_poly_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/122_linear_regression_poly_multiple_x.py</a></td></tr>
<tr><td>123</td><td>123_linear_regression_poly_multiple_x.py</td><td>polynomická regrese a body v&nbsp;prostoru, druhý příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/123_linear_regression_poly_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/123_linear_regression_poly_multiple_x.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>124</td><td>124_iris_set_statistic.py</td><td>získání statistických informací o datové sadě <i>Iris</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/124_iris_set_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/124_iris_set_statistic.py</a></td></tr>
<tr><td>125</td><td>125_california_housings_statistic.py</td><td>získání statistických informací o datové sadě <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/125_california_housings_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/125_california_housings_statistic.py</a></td></tr>
<tr><td>126</td><td>126_variance_threshold_1.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/126_variance_threshold_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/126_variance_threshold_1.py</a></td></tr>
<tr><td>127</td><td>127_variance_threshold_2.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/127_variance_threshold_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/127_variance_threshold_2.py</a></td></tr>
<tr><td>128</td><td>128_variance_threshold_3.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/128_variance_threshold_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/128_variance_threshold_3.py</a></td></tr>
<tr><td>129</td><td>129_select_best_iris.py</td><td>výběr nejvhodnějších atributů pro datovou sadu <i>Iris</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/129_select_best_iris.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/129_select_best_iris.py</a></td></tr>
<tr><td>130</td><td>130_select_best_housings.py</td><td>výběr nejvhodnějších atributů pro datovou sadu <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/130_select_best_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/130_select_best_housings.py</a></td></tr>
<tr><td>131</td><td>131_select_k_best_housings.py</td><td>výběr K nejvhodnějších atributů pro datovou sadu <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/131_select_k_best_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/131_select_k_best_housings.py</a></td></tr>
<tr><td>132</td><td>132_select_from_model.py</td><td>výběr atributů na základě k&nbsp;tomu určeného modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/132_select_from_model.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/132_select_from_model.py</a></td></tr>
<tr><td>133</td><td>133_cross_validation_1.py</td><td>křížová validace po výběru (filtraci) modelů (datová sada <i>Iris</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/133_cross_validation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/133_cross_validation_1.py</a></td></tr>
<tr><td>134</td><td>134_cross_validation_2.py</td><td>křížová validace po výběru (filtraci) modelů (datová sada <i>California Housings</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/134_cross_validation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/134_cross_validation_2.py</a></td></tr>
<tr><td>135</td><td>135_cross_validation_3.py</td><td>křížová validace po výběru (filtraci) modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/135_cross_validation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/135_cross_validation_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>136</td><td>136_mlp_classifier_01.py</td><td>použití neuronové sítě pro klasifikaci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/136_mlp_classifier_01.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/136_mlp_classifier_01.py</a></td></tr>
<tr><td>137</td><td>137_mlp_classifier_02.py</td><td>výpočet úspěšnosti modelu založeného na neuronové síti</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/137_mlp_classifier_02.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/137_mlp_classifier_02.py</a></td></tr>
<tr><td>138</td><td>138_mlp_classifier_03.py</td><td>konfigurace vrstev neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/138_mlp_classifier_03.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/138_mlp_classifier_03.py</a></td></tr>
<tr><td>139</td><td>139_mlp_classifier_04.py</td><td>proměnný počet neuronů ve vrstvách neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/139_mlp_classifier_04.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/139_mlp_classifier_04.py</a></td></tr>
<tr><td>140</td><td>140_mlp_classifier_05.py</td><td>proměnný počet neuronů ve více vrstvách neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/140_mlp_classifier_05.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/140_mlp_classifier_05.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>141</td><td>141_mlp_regression_1.py</td><td>použití neuronové sítě pro regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/141_mlp_regression_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/141_mlp_regression_1.py</a></td></tr>
<tr><td>142</td><td>142_mlp_regression_2.py</td><td>modifikace parametrů neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/142_mlp_regression_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/142_mlp_regression_2.py</a></td></tr>
<tr><td>143</td><td>143_mlp_regression_2.py</td><td>další modifikace parametrů neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/143_mlp_regression_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/143_mlp_regression_2.py</a></td></tr>
<tr><td>144</td><td>144_mlp_regression_3.py</td><td>postupná změna počtu neuronů v&nbsp;jedné skryté vrstvě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/144_mlp_regression_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/144_mlp_regression_3.py</a></td></tr>
<tr><td>145</td><td>145_mlp_regression_4.py</td><td>postupná změna počtu neuronů ve třech skrytých vrstvách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/145_mlp_regression_4.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/145_mlp_regression_4.py</a></td></tr>
<tr><td>146</td><td>146_mlp_regression_5.py</td><td>postupná změna počtu neuronů v&nbsp;pěti skrytých vrstvách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/146_mlp_regression_5.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/146_mlp_regression_5.py</a></td></tr>
<tr><td>147</td><td>147_mlp_regression_6.py</td><td>postupná změna počtu skrytých vrstev při zachování počtu neuronů v&nbsp;každé vrstvě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/147_mlp_regression_6.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/147_mlp_regression_6.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>148</td><td>148_confusion_matrix_1.py</td><td>zjištění kvality modelu s&nbsp;využitím matice záměn (<i>confusion matrix</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/148_confusion_matrix_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/148_confusion_matrix_1.py</a></td></tr>
<tr><td>149</td><td>149_confusion_matrix_2.py</td><td>zjištění kvality modelu hledajícího K nejbližších sousedů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/149_confusion_matrix_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/149_confusion_matrix_2.py</a></td></tr>
<tr><td>150</td><td>150_confusion_matrix_3.py</td><td>zjištění kvality modelu tvořeného neuronovou sítí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/150_confusion_matrix_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/150_confusion_matrix_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>151</td><td>151_multiplication_table.py</td><td>využití neuronové sítě pro odhad výsledků součinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/151_multiplication_table.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/151_multiplication_table.py</a></td></tr>
<tr><td>152</td><td>152_multiplication_table.py</td><td>odhad/vygenerování celé matice malé násobilky neuronovou sítí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/152_multiplication_table.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/152_multiplication_table.py</a></td></tr>
<tr><td>153</td><td>153_multiplication_table.py</td><td>rozšíření výpočtu součinu na rozsah 20&times;20 (při zachování původní sítě)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/153_multiplication_table.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/153_multiplication_table.py</a></td></tr>
</table>

<p>V&nbsp;repositáři nalezneme taktéž projektový soubor a Jupyter Notebook
s&nbsp;vysvětlením, jak lze modely využít pro rozpoznávání obsahu rastrových
obrázků:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td>1</td><td>pyproject.toml</td><td>projektový soubor (pro PDM) se všemi závislostmi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>2</td><td>pdm.lock</td><td>lock soubor s&nbsp;konkrétními verzemi všech přímých i tranzitivních závislostí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>3</td><td>Rozpoznání_obrazu_scikit-learn.ipynb</td><td>Jupyter notebook s&nbsp;celým postupem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>4</td><td>particle_life.py</td><td>emergence: příklad vzniku struktury</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py">https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

<li>Rozpoznávání obrázků knihovnou Scikit-learn: první kroky<br />
<a href="https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/">https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/</a>
</li>

<li>scikit-learn: Machine Learning in Python<br />
<a href="https://scikit-learn.org/stable/index.html">https://scikit-learn.org/stable/index.html</a>
</li>

<li>Sklearn-pandas<br />
<a href="https://github.com/scikit-learn-contrib/sklearn-pandas">https://github.com/scikit-learn-contrib/sklearn-pandas</a>
</li>

<li>sklearn-xarray<br />
<a href="https://github.com/phausamann/sklearn-xarray/">https://github.com/phausamann/sklearn-xarray/</a>
</li>

<li>Clustering<br />
<a href="https://scikit-learn.org/stable/modules/clustering.html">https://scikit-learn.org/stable/modules/clustering.html</a>
</li>

<li>Cluster analysis (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Cluster_analysis">https://en.wikipedia.org/wiki/Cluster_analysis</a>
</li>

<li>Shluková analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza">https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza</a>
</li>

<li>K-means<br />
<a href="https://cs.wikipedia.org/wiki/K-means">https://cs.wikipedia.org/wiki/K-means</a>
</li>

<li>k-means clustering<br />
<a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a>
</li>

<li>Spectral clustering<br />
<a href="https://en.wikipedia.org/wiki/Spectral_clustering">https://en.wikipedia.org/wiki/Spectral_clustering</a>
</li>

<li>Emergence<br />
<a href="https://cs.wikipedia.org/wiki/Emergence">https://cs.wikipedia.org/wiki/Emergence</a>
</li>

<li>Particle Life: Vivid structures from rudimentary rules<br />
<a href="https://particle-life.com/">https://particle-life.com/</a>
</li>

<li>Hertzsprungův–Russellův diagram<br />
<a href="https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram">https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram</a>
</li>

<li>Using Machine Learning in an HR Diagram<br />
<a href="https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f">https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f</a>
</li>

<li>Gaia H-R diagrams: Querying Gaia data for one million nearby stars<br />
<a href="https://vlas.dev/post/gaia-dr2-hrd/">https://vlas.dev/post/gaia-dr2-hrd/</a>
</li>

<li>The Hertzsprung–Russell diagram<br />
<a href="https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/">https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/</a>
</li>

<li>Animated Hertzsprung-Russell Diagram with 119,614 datapoints<br />
<a href="https://github.com/zonination/h-r-diagram">https://github.com/zonination/h-r-diagram</a>
</li>

<li>Neuraxle Pipelines<br />
<a href="https://github.com/Neuraxio/Neuraxle">https://github.com/Neuraxio/Neuraxle</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Natural-language processing<br />
<a href="https://en.wikipedia.org/wiki/Natural-language_processing">https://en.wikipedia.org/wiki/Natural-language_processing</a>
</li>

<li>THE MNIST DATABASE of handwritten digits<br />
<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>
</li>

<li>MNIST database (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/MNIST_database">https://en.wikipedia.org/wiki/MNIST_database</a>
</li>

<li>MNIST For ML Beginners<br />
<a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch: Serialization<br />
<a href="https://github.com/torch/torch7/blob/master/doc/serialization.md">https://github.com/torch/torch7/blob/master/doc/serialization.md</a>
</li>

<li>Torch: modul image<br />
<a href="https://github.com/torch/image/blob/master/README.md">https://github.com/torch/image/blob/master/README.md</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>Neural network containres (Torch)<br />
<a href="https://github.com/torch/nn/blob/master/doc/containers.md">https://github.com/torch/nn/blob/master/doc/containers.md</a>
</li>

<li>Simple layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear">https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear</a>
</li>

<li>Transfer Function Layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok">https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>PyTorch<br />
<a href="http://pytorch.org/">http://pytorch.org/</a>
</li>

<li>JupyterLite na PyPi<br />
<a href="https://pypi.org/project/jupyterlite/">https://pypi.org/project/jupyterlite/</a>
</li>

<li>JupyterLite na GitHubu<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Dokumentace k&nbsp;projektu JupyterLite<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Matplotlib Home Page<br />
<a href="http://matplotlib.org/">http://matplotlib.org/</a>
</li>

<li>Matplotlib (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Matplotlib">https://en.wikipedia.org/wiki/Matplotlib</a>
</li>

<li>Popis barvových map modulu matplotlib.cm<br />
<a href="https://gist.github.com/endolith/2719900#id7">https://gist.github.com/endolith/2719900#id7</a>
</li>

<li>Ukázky (palety) barvových map modulu matplotlib.cm<br />
<a href="http://matplotlib.org/examples/color/colormaps_reference.html">http://matplotlib.org/examples/color/colormaps_reference.html</a>
</li>

<li>Galerie grafů vytvořených v&nbsp;Matplotlibu<br />
<a href="https://matplotlib.org/3.2.1/gallery/">https://matplotlib.org/3.2.1/gallery/</a>
</li>

<li>3D rendering<br />
<a href="https://en.wikipedia.org/wiki/3D_rendering">https://en.wikipedia.org/wiki/3D_rendering</a>
</li>

<li>3D computer graphics<br />
<a href="https://en.wikipedia.org/wiki/3D_computer_graphics">https://en.wikipedia.org/wiki/3D_computer_graphics</a>
</li>

<li>Primary 3D view planes<br />
<a href="https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html">https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html</a>
</li>

<li>Getting started in scikit-learn with the famous iris dataset<br />
<a href="https://www.youtube.com/watch?v=hd1W4CyPX58">https://www.youtube.com/watch?v=hd1W4CyPX58</a>
</li>

<li>Training a machine learning model with scikit-learn<br />
<a href="https://www.youtube.com/watch?v=RlQuVL6-qe8">https://www.youtube.com/watch?v=RlQuVL6-qe8</a>
</li>

<li>Iris (plant)<br />
<a href="https://en.wikipedia.org/wiki/Iris_(plant)">https://en.wikipedia.org/wiki/Iris_(plant)</a>
</li>

<li>Kosatec<br />
<a href="https://cs.wikipedia.org/wiki/Kosatec">https://cs.wikipedia.org/wiki/Kosatec</a>
</li>

<li>Iris setosa<br />
<a href="https://en.wikipedia.org/wiki/Iris_setosa">https://en.wikipedia.org/wiki/Iris_setosa</a>
</li>

<li>Iris versicolor<br />
<a href="https://en.wikipedia.org/wiki/Iris_versicolor">https://en.wikipedia.org/wiki/Iris_versicolor</a>
</li>

<li>Iris virginica<br />
<a href="https://en.wikipedia.org/wiki/Iris_virginica">https://en.wikipedia.org/wiki/Iris_virginica</a>
</li>

<li>Druh<br />
<a href="https://cs.wikipedia.org/wiki/Druh">https://cs.wikipedia.org/wiki/Druh</a>
</li>

<li>Iris subg. Limniris<br />
<a href="https://en.wikipedia.org/wiki/Iris_subg._Limniris">https://en.wikipedia.org/wiki/Iris_subg._Limniris</a>
</li>

<li>Iris Dataset Classification with Python: A Tutorial<br />
<a href="https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html">https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html</a>
</li>

<li>Iris flower data set<br />
<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">https://en.wikipedia.org/wiki/Iris_flower_data_set</a>
</li>

<li>List of datasets for machine-learning research<br />
<a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research</a>
</li>

<li>Analýza hlavních komponent<br />
<a href="https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent">https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent</a>
</li>

<li>Principal component analysis<br />
<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">https://en.wikipedia.org/wiki/Principal_component_analysis</a>
</li>

<li>Scikit-learn Crash Course - Machine Learning Library for Python<br />
<a href="https://www.youtube.com/watch?v=0B5eIE_1vpU">https://www.youtube.com/watch?v=0B5eIE_1vpU</a>
</li>

<li>calm-notebooks<br />
<a href="https://github.com/koaning/calm-notebooks">https://github.com/koaning/calm-notebooks</a>
</li>

<li>Should you teach Python or R for data science?<br />
<a href="https://www.dataschool.io/python-or-r-for-data-science/">https://www.dataschool.io/python-or-r-for-data-science/</a>
</li>

<li>nbviewer: A simple way to share Jupyter Notebooks<br />
<a href="https://nbviewer.org/">https://nbviewer.org/</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

<li>Matplotlib vs. seaborn vs. Plotly vs. MATLAB vs. ggplot2 vs. pandas<br />
<a href="https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/">https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/</a>
</li>

<li>Matplotlib, Seaborn or Plotnine?<br />
<a href="https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/">https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/</a>
</li>

<li>@Rabeez: Rabeez/plotting_comparison.ipynb<br />
<a href="https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc">https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc</a>
</li>

<li>Matplotlib, Seaborn, Plotly and Plotnine Comparison<br />
<a href="https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40">https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40</a>
</li>

<li>Data Visualization 101: How to Choose a Python Plotting Library<br />
<a href="https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a">https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a</a>
</li>

<li>Data science in Python: pandas, seaborn, scikit-learn<br />
<a href="https://www.youtube.com/watch?v=3ZWuPVWq7p4">https://www.youtube.com/watch?v=3ZWuPVWq7p4</a>
</li>

<li>7.2. Real world datasets<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>7.2.7. California Housing dataset<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>Comprehensive Guide to Classification Models in Scikit-Learn<br />
<a href="https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/">https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/</a>
</li>

<li>Tidy Data Visualization: ggplot2 vs seaborn<br />
<a href="https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/">https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/</a>
</li>

<li>seaborn: statistical data visualization<br />
<a href="https://seaborn.pydata.org/">https://seaborn.pydata.org/</a>
</li>

<li>Linear regression (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Linear_regression">https://en.wikipedia.org/wiki/Linear_regression</a>
</li>

<li>Lineární regrese (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese">https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese</a>
</li>

<li>Iris Flower Classification with MLP Classifier<br />
<a href="https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier">https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

