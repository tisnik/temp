<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Využití knihovny Pygments (nejenom) pro obarvení zdrojových kódů: vlastní filtry a lexery</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Využití knihovny Pygments (nejenom) pro obarvení zdrojových kódů: vlastní filtry a lexery</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>Ve druhé části článku o knihovně Pygments si nejprve řekneme, jakým způsobem je možné navrhnout vlastní filtry určené pro zpracování proudu tokenů. Dále si ukážeme způsob vytvoření nových lexerů popř. úprav lexerů, které jsou již v Pygments implementovány.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Využití knihovny Pygments (nejenom) pro obarvení zdrojových kódů: vlastní filtry a lexery</a></p>
<p><a href="#k02">2. Proces zpracování zdrojového kódu třídami z&nbsp;knihovny Pygments</a></p>
<p><a href="#k03">3. Konstrukce jednoduchého filtru pro zpracování funkcí používajících CamelCase</a></p>
<p><a href="#k04">4. První varianta filtru pro zpracování funkcí používajících CamelCase</a></p>
<p><a href="#k05">5. Zařazení filtru do &bdquo;kolony&ldquo; zpracování tokenů</a></p>
<p><a href="#k06">6. Použití dekorátoru @simplefilter</a></p>
<p><a href="#k07">7. Nepatrné vylepšení předchozího příkladu</a></p>
<p><a href="#k08">8. Korektnější varianta filtru &ndash; test typu a hodnoty následujícího tokenu</a></p>
<p><a href="#k09">9. Upravený kód filtru a jeho výsledky</a></p>
<p><a href="#k10">10. Zpracování posledního tokenu v&nbsp;proudu</a></p>
<p><a href="#k11">11. Konfigurovatelný filtr</a></p>
<p><a href="#k12">12. Třída s&nbsp;implementací vlastního lexeru</a></p>
<p><a href="#k13">13. Lexer se dvěma stavy &ndash; rozpoznání definice funkce</a></p>
<p><a href="#k14">14. Výsledek zvýraznění syntaxe a úplný kód demonstračního příkladu s&nbsp;lexerem se dvěma stavy</a></p>
<p><a href="#k15">15. Lexer se třemi stavy</a></p>
<p><a href="#k16">16. Výsledek zvýraznění syntaxe a úplný kód demonstračního příkladu s&nbsp;lexerem se třemi stavy</a></p>
<p><a href="#k17">17. Použití klauzule <strong>bygroups</strong> aneb lexer pro zpracování INI souborů</a></p>
<p><a href="#k18">18. Příklad pro třetí část článku &ndash; lexer pro klasický jazyk BASIC</a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Využití knihovny Pygments (nejenom) pro obarvení zdrojových kódů: vlastní filtry a lexery</h2>

<p><a
href="https://www.root.cz/clanky/vyuziti-knihovny-pygments-nejenom-pro-obarveni-zdrojovych-kodu/">V&nbsp;prvním
článku</a> věnovaném knihovně <i>Pygments</i>, jsme se seznámili s&nbsp;tím,
k&nbsp;čemu vlastně tato knihovna slouží a jak ji lze využít v&nbsp;praxi
(obarvování zdrojových kódů, úpravy textu na úrovni tokenů atd.). Také jsme si
ve stručnosti popsali celý způsob zpracování &ndash; od vstupních zdrojových
textů přes proud <i>tokenů</i> až po výsledný dokument popř.&nbsp;obarvený text
zobrazený na ploše terminálu. V&nbsp;závěru článku byly popsány i některé
standardní filtry, které jsou již v&nbsp;této knihovně implementovány a je
možné je použít &ndash;
<a href="https://www.root.cz/clanky/vyuziti-knihovny-pygments-nejenom-pro-obarveni-zdrojovych-kodu/#k14">NameHighlightFilter</a>,
<a href="https://www.root.cz/clanky/vyuziti-knihovny-pygments-nejenom-pro-obarveni-zdrojovych-kodu/#k15">VisibleWhitespaceFilter</a>
a <a href="https://www.root.cz/clanky/vyuziti-knihovny-pygments-nejenom-pro-obarveni-zdrojovych-kodu/#k16">KeywordCaseFilter</a>.</p>

<img src="https://i.iinfo.cz/images/201/pygments1-6.png" class="image-334768" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 1: Obarvení zdrojového kódu na terminálu rozpoznávajícího
minimálně 256 barev. Barva pozadí je nastavena na černou.</i></p>

<p>Dnes se již budeme věnovat poněkud složitější problematice. Nejdříve si
totiž ukážeme, jak je možné navrhnout vlastní filtry, které budou sloužit pro
zpracování proudu tokenů, tj.&nbsp;k&nbsp;modifikaci tokenů, jejich mazání či
naopak přidávání dalších vlastních tokenů do proudu. Posléze se seznámíme se
způsobem vytvoření nových lexerů a samozřejmě také s&nbsp;možností upravit si
stávající lexery (ty dnes podporují cca 300 programovacích jazyků, značkovacích
jazyků, konfiguračních souborů aj.). Samozřejmě nesmíme zapomenout ani na
poslední část celého řetězce zpracování, takže se ve třetím článku zmíníme o
možnostech při psaní formátovačů. Díky tomu, jak knihovna <i>Pygments</i>
pracuje, je vytvoření nového formátovače relativně snadné a přímočaré (navíc se
nový formátovač automaticky stane dostupným pro všech již zmíněných cca 300
podporovaných jazyků).</p>

<img src="https://i.iinfo.cz/images/201/pygments1-11.png" class="image-334774" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 2: Změna stylu zobrazení při použití terminálu s&nbsp;možností
práce s&nbsp;256 barvami.</i></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Proces zpracování zdrojového kódu třídami z&nbsp;knihovny Pygments</h2>

<p>Před popisem dalších možností nabízených knihovnou <i>Pygments</i> si jen ve
stručnosti připomeňme, jakým způsobem vlastně probíhá celý proces zpracování od
vstupního zdrojového kódu po výsledný dokument nebo text zobrazený na
terminálu:</p>

<ol>

<li>Na začátku zpracování se nachází takzvaný <i>lexer</i>, který postupně
načítá jednotlivé znaky ze vstupního řetězce (resp.&nbsp;ze souboru) a vytváří
z&nbsp;nich <i>lexikální tokeny</i> (zkráceně jen <i>tokeny</i>). Pro každý
podporovaný jazyk se používá jiný lexer a samozřejmě je možné v&nbsp;případě
potřeby si napsat lexer vlastní. Již minule jsme se seznámili se dvěma
standardními lexery &ndash; <strong>pygments.lexers.PythonLexer</strong> a
<strong>pygments.lexers.pascal.DelphiLexer</strong>. První z&nbsp;nich je
určený pro vytvoření tokenizovaného kódu Pythonu, druhý se používá pro Delphi,
ObjectPascal i &bdquo;obyčejný&ldquo; Pascal.</li>

<li>Výstup produkovaný <i>lexerem</i> může procházet libovolným počtem
<i>filtrů</i> sloužících pro odstranění nebo (mnohem častěji) modifikaci
jednotlivých tokenů; ať již jejich typů či přímo textu, který tvoří hodnotu
tokenu. Díky existenci filtrů je například možné nechat si zvýraznit vybrané
bílé znaky, slova se speciálním významem v&nbsp;komentářích (typicky
&bdquo;TODO:&ldquo;, &bdquo;FIX:&ldquo;) apod. Některé standardní filtry
dodávané společně s&nbsp;knihovnou <i>Pygments</i> již známe:
<strong>pygments.filters.NameHighlightFilter</strong>,
<strong>pygments.filters.VisibleWhitespaceFilter</strong>,
<strong>pygments.filters.CodeTagFilter</strong> a
<strong>pygments.filters.KeywordCaseFilter</strong>.</li>

<li>Za filtry (pokud jsou samozřejmě použity) se nachází formátovač
(formatter), který postupně načítá jednotlivé tokeny a převádí je do výstupního
formátu. K&nbsp;dispozici je několik standardních formátovačů zajišťujících
například tisk na terminál, výstup do HTML, LaTeXu, RTF, <a
href="https://www.root.cz/clanky/vektorovy-graficky-format-svg/">SVG</a> apod.
S&nbsp;některými formátovači jsme se opět seznámili minule. Patří mezi ně
<strong>pygments.formatters.TerminalFormatter</strong> (s&nbsp;variantami
<strong>pygments.formatters.Terminal256Formatter</strong> a
<strong>pygments.formatters.TerminalTrueColorFormatter</strong>),
<strong>pygments.formatters.HtmlFormatter</strong>,
<strong>pygments.formatters.LaTexFormatter</strong>,
<strong>pygments.formatters.SvgFormatter</strong> a pro ladění užitečný
<strong>pygments.formatters.RawTokenFormatter</strong>. Další formátovače
závisí na externích knihovnách; typicky na knihovně PIL/Pillow.</li>

</ol>

<a href="https://www.root.cz/obrazek/335298/"><img src="https://i.iinfo.cz/images/615/pygments2-1-prev.png" class="image-335298" alt="&#160;" width="370" height="30" /></a>
<p><i>Obrázek 3: Příklad konfigurace celé &bdquo;kolony&ldquo; určené pro
zpracování zdrojových kódů ve čtyřech programovacích jazycích.</i></p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Konstrukce jednoduchého filtru pro zpracování funkcí používajících CamelCase</h2>

<p>Podívejme se nyní na konstrukci jednoduchého filtru, který bude určen pro
zpracování jmen funkcí používajících <i>CamelCase</i>, tj.&nbsp;způsob
pojmenování, v&nbsp;němž jsou jednotlivá slova oddělena pouze velikostí znaků
(verzálky/mínusky). Filtr bude takové názvy přejmenovávat do formy známé pod
označením <i>snake_case</i>, v&nbsp;níž jsou jednotlivá slova od sebe oddělena
podtržítkem. Toto přejmenování je možné pro jakýkoli řetězec implementovat
pomocí dvou regulárních výrazů doplněných o metodu
<strong>lower()</strong>.</p>

<p>První regulární výraz zajistí oddělení poslední verzálky ze sekvence
verzálek:</p>

<pre>
thisIsFOOBARFunction &rarr; this_IsFOOBAR_Function
</pre>

<p>Druhý regulární výraz vloží mezi jednotlivá slova podtržítka:</p>

<pre>
this_IsFOOBAR_Function &rarr; this_Is_FOOBAR_Function
</pre>

<p>Poslední řádek již jen zajistí převod celého řetězce na mínusky:</p>

<pre>
this_Is_FOOBAR_Function &rarr; this_is_foobar_function
</pre>

<p>Implementovaná konverzní funkce:</p>

<pre>
def <strong>convert</strong>(self, name):
    results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    results = re.sub('([a-z0-9])([A-Z])', r'\1_\2', results)
    return results.lower()
</pre>

<p>Vlastní filtr je tvořen třídou odvozenou od třídy <strong>Filter</strong>.
Nutné je reimplementovat metodu <strong>filter</strong>, které je (po jejím
automatickém zavolání) předán objekt představující lexer a generátor
představovaný proudem tokenů. Metoda <strong>filter</strong> bude taktéž
implementována formou generátoru, který bude postupně vracet dvojice
<i>typ-tokenu</i> + <i>hodnota-tokenu</i>. Filtr, který bude všechny tokeny
pouze předávat pro další zpracování, tedy může vypadat následovně::</p>

<pre>
class <strong>NopFilter</strong>(Filter):
&nbsp;
    def <strong>__init__</strong>(self, **options):
        Filter.__init__(self, **options)
&nbsp;
    def <strong>filter</strong>(self, lexer, stream):
        for ttype, value in stream:
            yield ttype, value
</pre>

<p>Náš filtr bude muset být implementován nepatrně složitěji &ndash; pro tokeny
typu <strong>Name.Function</strong> a <strong>Name</strong> (to není přesné,
ale prozatím si s&nbsp;touto implementací vystačíme) se změní jejich hodnota
(řetězec) s&nbsp;využitím výše popsané metody <strong>convert</strong>:</p>

<pre>
def <strong>filter</strong>(self, lexer, stream):
    for ttype, value in stream:
        if ttype is Name.Function or ttype is Name:
            value = self.convert(value)
        yield ttype, value
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. První varianta filtru pro zpracování funkcí používajících CamelCase</h2>

<p>První &ndash; doposud značně neúplná &ndash; varianta našeho filtru by mohla
být implementována následujícím způsobem:</p>

<pre>
class <strong>CamelCaseFilter</strong>(Filter):
&nbsp;
    def <strong>__init__</strong>(self, **options):
        Filter.__init__(self, **options)
&nbsp;
    def <strong>convert</strong>(self, name):
        results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
        results = re.sub('([a-z0-9])([A-Z])', r'\1_\2', results)
        return results.lower()
&nbsp;
    def <strong>filter</strong>(self, lexer, stream):
        for ttype, value in stream:
            if ttype is Name.Function or ttype is Name:
                value = self.convert(value)
            yield ttype, value
</pre>

<p><div class="rs-tip-major">Poznámka: ve skutečnosti bude filtr konvertovat
hodnoty všech tokenů typu <strong>Name</strong>, což ovšem zahrnuje například i
názvy proměnných. Později si ukážeme jedno z&nbsp;možných řešení tohoto
problému.</div></p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Zařazení filtru do &bdquo;kolony&ldquo; zpracování tokenů</h2>

<p>Náš nově vytvořený filtr se nyní pokusíme přidat do &bdquo;kolony&ldquo;
určené pro zpracování tokenů. Klasický způsob zpracování (bez filtru) vypadá
takto:</p>

<pre>
print(highlight(code, PythonLexer(), TerminalFormatter()))
</pre>

<p>Zařazení filtru je jen nepatrně delší:</p>

<pre>
lexer = PythonLexer()
&nbsp;
<i># pridani filtru</i>
lexer.add_filter(CamelCaseFilter())
&nbsp;
print(highlight(code, lexer, TerminalFormatter()))
</pre>

<p>Filtr si otestujeme na následujícím fragmentu kódu naprogramovaného
v&nbsp;Pythonu:</p>

<pre>
code = """
for i in range(1, 11):
    print("Hello world!")
&nbsp;
if x and y:
    print("yes")
&nbsp;
if x or y:
    print("dunno")
&nbsp;
globalVariable = 42
&nbsp;
def helloWorld():
    print("Hello world!")
&nbsp;
helloWorld()
&nbsp;
print(globalVariable)
"""
</pre>

<img src="https://i.iinfo.cz/images/615/pygments2-2.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 4: Barevné zvýraznění syntaxe provedené před aplikací
filtru.</i></p>

<p>Výsledek aplikace filtru by měl vypadat následovně:</p>

<img src="https://i.iinfo.cz/images/615/pygments2-3.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 5: Barevné zvýraznění syntaxe provedené společně s&nbsp;filtrem
<strong>CamelCaseFilter</strong>.</i></p>

<p><div class="rs-tip-major">Poznámka: povšimněte si, že se změnilo i jméno
globální proměnné. Tento zásadní nedostatek filtru postupně
odstraníme.</div></p>

<p>Následuje výpis <a
href="https://github.com/tisnik/presentations/blob/master/pygments/pygments19_custom_filter.py">úplného
zdrojového kódu</a> tohoto demonstračního příkladu:</p>

<pre>
import re
&nbsp;
from pygments import highlight
from pygments.lexers import PythonLexer
from pygments.formatters import TerminalFormatter
from pygments.filter import Filter
from pygments.token import Name
from pygments.util import get_bool_opt
&nbsp;
&nbsp;
class CamelCaseFilter(Filter):
&nbsp;
    def <strong>__init__</strong>(self, **options):
        Filter.__init__(self, **options)
&nbsp;
    def <strong>convert</strong>(self, name):
        results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
        results = re.sub('([a-z0-9])([A-Z])', r'\1_\2', results)
        return results.lower()
&nbsp;
    def <strong>filter</strong>(self, lexer, stream):
        for ttype, value in stream:
            if ttype is Name.Function or ttype is Name:
                value = self.convert(value)
            yield ttype, value
&nbsp;
&nbsp;
code = """
for i in range(1, 11):
    print("Hello world!")
&nbsp;
if x and y:
    print("yes")
&nbsp;
if x or y:
    print("dunno")
&nbsp;
globalVariable = 42
&nbsp;
def helloWorld():
    print("Hello world!")
&nbsp;
helloWorld()
&nbsp;
print(globalVariable)
"""
&nbsp;
&nbsp;
print(highlight(code, PythonLexer(), TerminalFormatter()))
&nbsp;
print("-----------------------")
&nbsp;
lexer = PythonLexer()
&nbsp;
<i># pridani filtru</i>
lexer.add_filter(CamelCaseFilter())
&nbsp;
print(highlight(code, lexer, TerminalFormatter()))
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. Použití dekorátoru @simplefilter</h2>

<p>Ve skutečnosti existuje ještě jeden alternativní a pro zápis kratší způsob
vytvoření filtru. Tento způsob je založen na dekorátoru nazvaném
<strong>@simplefilter</strong>, který se zapisuje před funkci
s&nbsp;implementací filtru. Tato funkce musí akceptovat čtyři parametry &ndash;
<strong>self</strong> (ve skutečnosti totiž dekorátor vytvoří třídu
s&nbsp;metodou), <strong>lexer</strong> s&nbsp;referencí na použitý lexer,
<strong>stream</strong> s&nbsp;referencí na generátor tokenů a nakonec parametr
<strong>options</strong> s&nbsp;případnými konfiguračními volbami:</p>

<pre>
@simplefilter
def <strong>to_snake_case</strong>(self, lexer, stream, options):
    for ttype, value in stream:
        if ttype is Name.Function or ttype is Name:
            results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', value)
            results = re.sub('([a-z0-9])([A-Z])', r'\1_\2', value)
            value = results.lower()
        yield ttype, value
</pre>

<p>Registrace filtru s&nbsp;jeho přidáním do &bdquo;kolony&ldquo;:</p>

<pre>
lexer = PythonLexer()
&nbsp;
<i># pridani filtru</i>
lexer.add_filter(to_snake_case())
&nbsp;
print(highlight(code, lexer, TerminalFormatter()))
</pre>

<p>Opět se podívejme na <a
href="https://github.com/tisnik/presentations/blob/master/pygments/pygments20_custom_filter_decorator.py">úplný
zdrojový kód</a> upraveného demonstračního příkladu:</p>

<pre>
import re
&nbsp;
from pygments import highlight
from pygments.lexers import PythonLexer
from pygments.formatters import TerminalFormatter
from pygments.filter import simplefilter
from pygments.token import Name
from pygments.util import get_bool_opt
&nbsp;
&nbsp;
@simplefilter
def <strong>to_snake_case</strong>(self, lexer, stream, options):
    for ttype, value in stream:
        if ttype is Name.Function or ttype is Name:
            results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', value)
            results = re.sub('([a-z0-9])([A-Z])', r'\1_\2', value)
            value = results.lower()
        yield ttype, value
&nbsp;
&nbsp;
code = """
for i in range(1, 11):
    print("Hello world!")
&nbsp;
if x and y:
    print("yes")
&nbsp;
if x or y:
    print("dunno")
&nbsp;
globalVariable = 42
&nbsp;
def helloWorld():
    print("Hello world!")
&nbsp;
helloWorld()
&nbsp;
print(globalVariable)
"""
&nbsp;
&nbsp;
print(highlight(code, PythonLexer(), TerminalFormatter()))
&nbsp;
print("-----------------------")
&nbsp;
lexer = PythonLexer()
&nbsp;
<i># pridani filtru</i>
lexer.add_filter(to_snake_case())
&nbsp;
print(highlight(code, lexer, TerminalFormatter()))
</pre>

<p>Pro zajímavost se podívejme, jakým způsobem je vlastně dekorátor
<strong>@simplefilter</strong> implementován. Základem je třída nazvaná
<strong>FunctionFilter</strong> s&nbsp;implementací obecného filtru &ndash;
generátoru, který je založen na použití druhého programátorem definovaného
generátoru představovaného metodou <strong>FunctionFilter.function()</strong>.
Při konstrukci objektu se kontroluje, jestli metoda <strong>function()</strong>
existuje:</p>

<pre>
class <strong>FunctionFilter</strong>(Filter):
    function = None
&nbsp;
    def <strong>__init__</strong>(self, **options):
        if not hasattr(self, 'function'):
            raise TypeError('%r used without bound function' %
                            self.__class__.__name__)
        Filter.__init__(self, **options)
&nbsp;
    def <strong>filter</strong>(self, lexer, stream):
        for ttype, value in self.function(lexer, stream, self.options):
            yield ttype, value
</pre>

<p>Implementace <strong>@simplefilter</strong> je následující &ndash; funkce
<strong>f</strong>, která tento dekorátor používá, je využita pro vytvoření
nové třídy nazvané stejně jako dekorovaná funkce. Tato nová třída je odvozena
od <strong>FunctionFilter</strong>, samozřejmě již s&nbsp;navázanou metodou
<strong>FunctionFilter.function()</strong>:</p>

<pre>
def <strong>simplefilter</strong>(f):
    return type(f.__name__, (FunctionFilter,), {
                'function':     f,
                '__module__':   getattr(f, '__module__'),
                '__doc__':      f.__doc__
})
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. Nepatrné vylepšení předchozího příkladu</h2>

<p>Předchozí příklad si ještě před dalšími úpravami nepatrně vylepšíme tak, aby
byla konverzí funkce osamostatněna (tak se dá lépe testovat a upravovat). <a
href="https://github.com/tisnik/presentations/blob/master/pygments/pygments21_better_custom_filter.py">Výsledná
podoba příkladu</a> je následující:</p>

<pre>
import re
&nbsp;
from pygments import highlight
from pygments.lexers import PythonLexer
from pygments.formatters import TerminalFormatter
from pygments.filter import simplefilter
from pygments.token import Name
from pygments.util import get_bool_opt
&nbsp;
&nbsp;
def <strong>name_to_snake_case</strong>(name):
    results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    results = re.sub('([a-z0-9])([A-Z])', r'\1_\2', results)
    return results.lower()
&nbsp;
&nbsp;
@simplefilter
def <strong>to_snake_case</strong>(self, lexer, stream, options):
    for ttype, value in stream:
        if ttype is Name.Function or ttype is Name:
            value = name_to_snake_case(value)
        yield ttype, value
&nbsp;
&nbsp;
code = """
for i in range(1, 11):
    print("Hello world!")
&nbsp;
if x and y:
    print("yes")
&nbsp;
if x or y:
    print("dunno")
&nbsp;
globalVariable = 42
&nbsp;
def helloWorld():
    print("Hello world!")
&nbsp;
helloWorld()
&nbsp;
print(globalVariable)
"""
&nbsp;
&nbsp;
print(highlight(code, PythonLexer(), TerminalFormatter()))
&nbsp;
print("-----------------------")
&nbsp;
lexer = PythonLexer()
&nbsp;
<i># pridani filtru</i>
lexer.add_filter(to_snake_case())
&nbsp;
print(highlight(code, lexer, TerminalFormatter()))
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. Korektnější varianta filtru &ndash; test typu a hodnoty následujícího tokenu</h2>

<p>Filtr, který byl ukázán v&nbsp;předchozích dvou kapitolách, ve skutečnosti
není příliš přesný. Na screenshotech jste si pravděpodobně všimli, že kromě
názvů funkcí v&nbsp;jejich definicích a při jejich volání (což chceme) mění i
názvy proměnných, protože i ty jsou v&nbsp;tokenizovaném kódu reprezentovány
tokenem typu <strong>Name</strong>, který je sám o sobě neodlišitelný od tokenu
použitého při volání funkce (ne při její deklaraci). Ostatně můžeme se sami
podívat, jak vypadá tokenizovaný výstup tohoto příkladu psaného
v&nbsp;Pythonu:</p>

<pre>
globalVariable = 42
def helloWorld():
    print("Hello world!")
helloWorld()
print(globalVariable)
</pre>

<p>Tokenizovaný výstup se zvýrazněním typů tokenů, které nás zajímají při
konverzi:</p>

<pre>
<strong>Token.Name                        'globalVariable'</strong>
Token.Text                        ' '
Token.Operator                    '='
Token.Text                        ' '
Token.Literal.Number.Integer      '42'
Token.Text                        '\n'
Token.Keyword                     'def'
Token.Text                        ' '
<strong>Token.Name.Function               'helloWorld'</strong>
Token.Punctuation                 '('
Token.Punctuation                 ')'
Token.Punctuation                 ':'
Token.Text                        '\n'
Token.Text                        '    '
Token.Keyword                     'print'
Token.Punctuation                 '('
Token.Literal.String.Double       '"'
Token.Literal.String.Double       'Hello world!'
Token.Literal.String.Double       '"'
Token.Punctuation                 ')'
Token.Text                        '\n'
<strong>Token.Name                        'helloWorld'</strong>
Token.Punctuation                 '('
Token.Punctuation                 ')'
Token.Text                        '\n'
Token.Keyword                     'print'
Token.Punctuation                 '('
<strong>Token.Name                        'globalVariable'</strong>
Token.Punctuation                 ')'
Token.Text                        '\n'
</pre>

<p>Samozřejmě existuje možnost, jak tento poměrně zásadní problém vyřešit. Ta
spočívá v&nbsp;tom, že se budeme dívat na <i>dva</i> po sobě jdoucí tokeny
&ndash; vždy na ten token, který bude výsledkem volání generátoru (viz příkaz
<strong>yield</strong>) a token následující. Pokud bude následující token typu
<strong>Punctuation</strong> a současně bude mít hodnotu &bdquo;(&ldquo; (levá
kulatá závorka), můžeme v&nbsp;Pythonu předpokládat, že se jedná o volání
funkce (ve skutečnosti to není zcela přesné, ale pro první přiblížení může být
tento postup dostatečně dobrý). Samotná funkce zjišťující, jestli se má
konverze názvu provést či nikoli, může vypadat následovně (funkci předáváme
typy a hodnoty dvou po sobě jdoucích tokenů, u současného tokenu však pouze
jeho typ):</p>

<pre>
def <strong>is_function_call_token</strong>(current_type, next_type, next_value):
    return current_type is Name \
           and next_type is Punctuation \
           and next_value == "("
</pre>

<p>Samozřejmě je nutné upravit i celý kód filtru takovým způsobem, aby dokázal
získat současný token (což je primitivní) i token následující. Jedno
z&nbsp;možných řešení (je jich ovšem více) spočívá ve využití funkce <a
href="https://docs.python.org/3.6/library/itertools.html#itertools.tee">itertools.tee()</a>,
která dokáže z&nbsp;jednoho iterátoru vytvořit větší množství nezávislých
iterátorů. My budeme potřebovat iterátory dva:</p>

<pre>
lookahead, tokens = itertools.tee(stream)
</pre>

<p>Jeden z&nbsp;těchto iterátorů hned na začátku <i>posuneme dopředu</i> o
jeden token:</p>

<pre>
next(lookahead)
</pre>

<p>A následně již můžeme ve smyčce používat dva tokeny &ndash; současný a ten
následující:</p>

<pre>
@simplefilter
def <strong>to_snake_case</strong>(self, lexer, stream, options):
    lookahead, tokens = itertools.tee(stream)
    next(lookahead)
    for current_token in tokens:
        current_type = current_token[0]
        current_value = current_token[1]
        next_token = next(lookahead)
        next_type = next_token[0]
        next_value = next_token[1]
        if current_type is Name.Function \
           or is_function_call_token(current_type, next_type, next_value):
            current_value = name_to_snake_case(current_value)
        yield current_type, current_value
</pre>

<p>V&nbsp;proudu tokenů se tedy budou měnit pouze ty tokeny, které jsou na
následujícím výpisu zvýrazněny:</p>

<pre>
Token.Name                        'globalVariable'     <i>ne, protože nenásleduje token s otvírací závorkou</i>
Token.Text                        ' '
Token.Operator                    '='
Token.Text                        ' '
Token.Literal.Number.Integer      '42'
Token.Text                        '\n'
Token.Keyword                     'def'
Token.Text                        ' '
<strong>Token.Name.Function               'helloWorld'</strong>
Token.Punctuation                 '('
Token.Punctuation                 ')'
Token.Punctuation                 ':'
Token.Text                        '\n'
Token.Text                        '    '
Token.Keyword                     'print'
Token.Punctuation                 '('
Token.Literal.String.Double       '"'
Token.Literal.String.Double       'Hello world!'
Token.Literal.String.Double       '"'
Token.Punctuation                 ')'
Token.Text                        '\n'
<strong>Token.Name                        'helloWorld'</strong>         <i>ano, protože následuje token se závorkou</i>
Token.Punctuation                 '('                  <i>budoucí/následující token, který byl otestován</i>
Token.Punctuation                 ')'
Token.Text                        '\n'
Token.Keyword                     'print'
Token.Punctuation                 '('
Token.Name                        'globalVariable'     <i>ne, protože nenásleduje token s otvírací závorkou</i>
Token.Punctuation                 ')'
Token.Text                        '\n'
</pre>

<p><div class="rs-tip-major">Poznámka: navržené řešení obsahuje jednu chybu. Ta
je popsána v&nbsp;navazujícím textu, ovšem pokuste se zamyslet nad tím, proč a
v&nbsp;jaké chvíli k&nbsp;chybě dojde.</div></p>



<p><a name="k09"></a></p>
<h2 id="k09">9. Upravený kód filtru a jeho výsledky</h2>

<p><a
href="https://github.com/tisnik/presentations/blob/master/pygments/pygments22_lookahead_filter.py">Úplný
zdrojový kód po všech úpravách</a> vypadá následovně:</p>

<pre>
import re
&nbsp;
from pygments import highlight
from pygments.lexers import PythonLexer
from pygments.formatters import TerminalFormatter
from pygments.filter import simplefilter
from pygments.token import Name, Punctuation
from pygments.util import get_bool_opt
&nbsp;
import itertools
&nbsp;
&nbsp;
def <strong>name_to_snake_case</strong>(name):
    results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', results).lower()
&nbsp;
&nbsp;
def <strong>is_function_call_token</strong>(current_type, next_type, next_value):
    return current_type is Name \
           and next_type is Punctuation \
           and next_value == "("
&nbsp;
&nbsp;
@simplefilter
def <strong>to_snake_case</strong>(self, lexer, stream, options):
    lookahead, tokens = itertools.tee(stream)
    next(lookahead)
    for current_token in tokens:
        current_type = current_token[0]
        current_value = current_token[1]
        next_token = next(lookahead)
        next_type = next_token[0]
        next_value = next_token[1]
        if current_type is Name.Function \
           or is_function_call_token(current_type, next_type, next_value):
            current_value = name_to_snake_case(current_value)
        yield current_type, current_value
&nbsp;
&nbsp;
code = """
for i in range(1, 11):
    print("Hello world!")
&nbsp;
if x and y:
    print("yes")
&nbsp;
if x or y:
    print("dunno")
&nbsp;
globalVariable = 42
&nbsp;
def helloWorld():
    print("Hello world!")
&nbsp;
helloWorld()
&nbsp;
print(globalVariable)
"""
&nbsp;
&nbsp;
print(highlight(code, PythonLexer(), TerminalFormatter()))
&nbsp;
print("-----------------------")
&nbsp;
lexer = PythonLexer()
&nbsp;
# pridani filtru
lexer.add_filter(to_snake_case())
&nbsp;
print(highlight(code, lexer, TerminalFormatter()))
</pre>

<img src="https://i.iinfo.cz/images/615/pygments2-4.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 6: Obarvený kód bez použití filtru.</i></p>

<img src="https://i.iinfo.cz/images/615/pygments2-5.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 7: Obarvený kód při použití nové varianty filtru.</i></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Zpracování posledního tokenu v&nbsp;proudu</h2>

<p>Předchozí demonstrační příklad s&nbsp;filtrem měl jednu vadu: ve chvíli, kdy
se přečetl poslední <i>budoucí/následující</i> token, byl generátor
představovaný filtrem automaticky ukončen, protože došlo k&nbsp;vyhození
výjimky typu <strong>StopIteration</strong>. To je sice očekávané chování,
ovšem znamená, že poslední token (ať již byl jakéhokoli typu) nebyl poslán na
výstup filtru a tudíž se ve výsledku neobjevila příslušná část kódu.
V&nbsp;našem konkrétním příkladu to příliš nevadilo, protože poslední token byl
typu <strong>Token.Text</strong> s&nbsp;hodnotou &bdquo;\n&ldquo; (konec
řádku), ale u jiného vstupu by to mohlo mít mnohem horší následky. Jedno
z&nbsp;možných řešení tohoto problému spočívá v&nbsp;explicitním otestování,
zda <i>budoucí/následující</i> token existuje a v&nbsp;zákazu vyhození výjimky
ve chvíli, kdy neexistuje (místo hodnoty tokenu se vrátí předdefinovaná hodnota
<strong>None</strong>):</p>

<pre>
@simplefilter
def <strong>to_snake_case</strong>(self, lexer, stream, options):
    lookahead, tokens = itertools.tee(stream)
    next(lookahead)
    for current_token in tokens:
        current_type = current_token[0]
        current_value = current_token[1]
        next_token = next(lookahead, None)
        if next_token:
            next_type = next_token[0]
            next_value = next_token[1]
            if current_type is Name.Function \
               or is_function_call_token(current_type, next_type, next_value):
                current_value = name_to_snake_case(current_value)
        yield current_type, current_value
</pre>

<p>Výsledky:</p>

<img src="https://i.iinfo.cz/images/615/pygments2-6.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 8: Obarvený kód bez použití filtru.</i></p>

<img src="https://i.iinfo.cz/images/615/pygments2-7.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 9: Obarvený kód při použití nové (korektní) varianty
filtru.</i></p>

<p>Opět následuje výpis <a
href="https://github.com/tisnik/presentations/blob/master/pygments/pygments23_correct_lookahead_filter.py">úplného
zdrojového kódu vylepšeného příkladu</a>:</p>

<pre>
import re
&nbsp;
from pygments import highlight
from pygments.lexers import PythonLexer
from pygments.formatters import TerminalFormatter
from pygments.filter import simplefilter
from pygments.token import Name, Punctuation
from pygments.util import get_bool_opt
&nbsp;
import itertools
&nbsp;
&nbsp;
def <strong>name_to_snake_case</strong>(name):
    results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    return re.sub('([a-z0-9])([A-Z])', r'\1_\2', results).lower()
&nbsp;
&nbsp;
def <strong>is_function_call_token</strong>(current_type, next_type, next_value):
    return current_type is Name \
           and next_type is Punctuation \
           and next_value == "("
&nbsp;
&nbsp;
@simplefilter
def <strong>to_snake_case</strong>(self, lexer, stream, options):
    lookahead, tokens = itertools.tee(stream)
    next(lookahead)
    for current_token in tokens:
        current_type = current_token[0]
        current_value = current_token[1]
        next_token = next(lookahead, None)
        if next_token:
            next_type = next_token[0]
            next_value = next_token[1]
            if current_type is Name.Function \
               or is_function_call_token(current_type, next_type, next_value):
                current_value = name_to_snake_case(current_value)
        yield current_type, current_value
&nbsp;
&nbsp;
code = """
for i in range(1, 11):
    print("Hello world!")
&nbsp;
if x and y:
    print("yes")
&nbsp;
if x or y:
    print("dunno")
&nbsp;
globalVariable = 42
&nbsp;
def helloWorld():
    print("Hello world!")
&nbsp;
helloWorld()
&nbsp;
print(globalVariable)
"""
&nbsp;
&nbsp;
print(highlight(code, PythonLexer(), TerminalFormatter()))
&nbsp;
print("-----------------------")
&nbsp;
lexer = PythonLexer()
&nbsp;
# pridani filtru
lexer.add_filter(to_snake_case())
&nbsp;
print(highlight(code, lexer, TerminalFormatter()))
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. Konfigurovatelný filtr</h2>

<p>Ukažme si ještě jednu možnou modifikaci filtru, s&nbsp;níž se poměrně často
setkáme (ostatně ji obsahují i všechny standardní filtry). Ta bude spočívat
v&nbsp;přidání nepovinných parametrů, které je možné filtru předat. Těchto
parametrů může být libovolný počet a předávají se formou slovníku obsahujícího
dvojice (jméno parametru+hodnota). U našeho konkrétního příkladu můžeme
uživatelům filtru umožnit měnit nejenom jména funkcí, ale i všechna další jména
(proměnných atd.), která jsou v&nbsp;tokenizovaném kódu reprezentována tokeny
typu <strong>Token.Name</strong>. Povšimněte si, jakým způsobem se využívá
pomocná funkce pro získání pravdivostní hodnoty z&nbsp;předaných parametrů:</p>

<pre>
@simplefilter
def <strong>to_snake_case</strong>(self, lexer, stream, options):
    convert_all_names = <strong>get_bool_opt(options, 'convert_all_names', default=False)</strong>
    if convert_all_names:
        for ttype, value in stream:
            if ttype is Name.Function or ttype is Name:
                results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', value)
                results = re.sub('([a-z0-9])([A-Z])', r'\1_\2', results)
                value = results.lower()
            yield ttype, value
    else:
        lookahead, tokens = itertools.tee(stream)
        next(lookahead)
        for current_token in tokens:
            current_type = current_token[0]
            current_value = current_token[1]
            next_token = next(lookahead, None)
            if next_token:
                next_type = next_token[0]
                next_value = next_token[1]
                if current_type is Name.Function \
                   or is_function_call_token(current_type, next_type, next_value):
                    current_value = name_to_snake_case(current_value)
            yield current_type, current_value
</pre>

<p>Příklad použití:</p>

<pre>
<i># pridani filtru</i>
lexer.add_filter(to_snake_case())
&nbsp;
print(highlight(code, lexer, TerminalFormatter()))
&nbsp;
input()
print("-----------------------")
&nbsp;
lexer = PythonLexer()
&nbsp;
<i># pridani filtru</i>
lexer.add_filter(to_snake_case(convert_all_names=True))
</pre>

<p>Výsledky:</p>

<img src="https://i.iinfo.cz/images/615/pygments2-8.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 10: Obarvený kód bez použití filtru.</i></p>

<img src="https://i.iinfo.cz/images/615/pygments2-9.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 11: Obarvený kód při použití nové (korektní) varianty
filtru.</i></p>

<img src="https://i.iinfo.cz/images/615/pygments2-10.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 12: Obarvený kód při použití nové (korektní) varianty filtru
s&nbsp;parametrem <strong>convert_all_names=True</strong>.</i></p>

<p>Opět si ukažme <a
href="https://github.com/tisnik/presentations/blob/master/pygments/pygments24_configurable_lookahead_filter.py">zdrojový
kód tohoto příkladu</a>:</p>

<pre>
import re
&nbsp;
from pygments import highlight
from pygments.lexers import PythonLexer
from pygments.formatters import TerminalFormatter
from pygments.filter import simplefilter
from pygments.token import Name, Punctuation
from pygments.util import get_bool_opt
&nbsp;
import itertools
&nbsp;
&nbsp;
def <strong>name_to_snake_case</strong>(name):
    results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', name)
    results = re.sub('([a-z0-9])([A-Z])', r'\1_\2', results)
    return results.lower()
&nbsp;
&nbsp;
def <strong>is_function_call_token</strong>(current_type, next_type, next_value):
    return current_type is Name \
           and next_type is Punctuation \
           and next_value == "("
&nbsp;
&nbsp;
@simplefilter
def <strong>to_snake_case</strong>(self, lexer, stream, options):
    convert_all_names = get_bool_opt(options, 'convert_all_names', default=False)
    if convert_all_names:
        for ttype, value in stream:
            if ttype is Name.Function or ttype is Name:
                results = re.sub('(.)([A-Z][a-z]+)', r'\1_\2', value)
                results = re.sub('([a-z0-9])([A-Z])', r'\1_\2', results)
                value = results.lower()
            yield ttype, value
    else:
        lookahead, tokens = itertools.tee(stream)
        next(lookahead)
        for current_token in tokens:
            current_type = current_token[0]
            current_value = current_token[1]
            next_token = next(lookahead, None)
            if next_token:
                next_type = next_token[0]
                next_value = next_token[1]
                if current_type is Name.Function \
                   or is_function_call_token(current_type, next_type, next_value):
                    current_value = name_to_snake_case(current_value)
            yield current_type, current_value
&nbsp;
&nbsp;
code = """
for i in range(1, 11):
    print("Hello world!")
&nbsp;
if x and y:
    print("yes")
&nbsp;
if x or y:
    print("dunno")
&nbsp;
globalVariable = 42
&nbsp;
def helloWorld():
    print("Hello world!")
&nbsp;
helloWorld()
&nbsp;
print(globalVariable)
"""
&nbsp;
&nbsp;
print(highlight(code, PythonLexer(), TerminalFormatter()))
&nbsp;
input()
print("-----------------------")
&nbsp;
lexer = PythonLexer()
&nbsp;
# pridani filtru
lexer.add_filter(to_snake_case())
&nbsp;
print(highlight(code, lexer, TerminalFormatter()))
&nbsp;
input()
print("-----------------------")
&nbsp;
lexer = PythonLexer()
&nbsp;
# pridani filtru
lexer.add_filter(to_snake_case(convert_all_names=True))
&nbsp;
print(highlight(code, lexer, TerminalFormatter()))
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Třída s&nbsp;implementací vlastního lexeru</h2>

<p>Uživatelem-programátorem definované filtry sice mohou být hodně užitečné,
ovšem ve chvíli, kdy budeme potřebovat zpracovat (obarvit) zdrojový kód nebo
konfigurační soubor psaný v&nbsp;jazyce nepodporovaném knihovnou
<i>Pygments</i>, je nutné zjistit, jakým způsobem se implementují nové lexery
popř.&nbsp;jak lze upravit lexery stávající. S&nbsp;tímto problémem jsme se již
setkali v&nbsp;předchozím článku, v&nbsp;němž jsme si ukázali následující lexer
založený na jednoduchých regulárních výrazech určených pro rozpoznání několika
klíčových slov v&nbsp;textu:</p>

<pre>
class <strong>FooLangLexer</strong>(RegexLexer):
    name = 'foolang'
    aliases = ['foolang']
    filenames = ['*.foolang']
&nbsp; 
    tokens = {
        'root': [
            (r'\ *print', Name.Function),
            (r'for', Keyword),
            (r'while', Keyword),
            (r'goto', Generic.Error),
            (r'begin', Keyword),
            (r'end', Keyword),
            (r'.+', Generic.Normal),
        ]
    }
</pre>

<p>Povšimněte si, jakým způsobem je celá třída s&nbsp;novým lexerem
strukturována. Obsahuje tři statické atributy s&nbsp;popisem jména jazyka,
případných alternativních jmen (<i>aliases</i>) a taktéž se seznamem přípon,
které mají soubory psané v&nbsp;daném programovacím nebo značkovacím jazyku.
Ovšem nejdůležitější částí lexeru je statický atribut <strong>tokens</strong>,
který je uložen ve formě slovníku. Tento slovník slouží k&nbsp;popisu konečného
automatu (<a
href="https://en.wikipedia.org/wiki/Finite-state_machine">finite-state
machine</a>) se zásobníkem stavů, přičemž v&nbsp;každém stavu může lexer
rozpoznávat libovolné množství regulárních výrazů. Pokud je regulární výraz
nalezen, provede se vygenerování tokenu s&nbsp;příslušným typem (například
<strong>Name.Function</strong> nebo <strong>Generic.Normal</strong>) a konečný
automat se může přepnout do jiného stavu :-) (původní stav se uloží na
zásobník, takže je možné se k&nbsp;němu kdykoli vrátit pomocí operace
&bdquo;#pop&ldquo;). V&nbsp;našem konkrétním lexeru je však použit jen jediný
stav nazvaný <strong>root</strong> a automat se tedy nepřepíná (je tedy
zredukován na pouhou kombinační logiku a bylo by ho možné zjednodušit na
konstrukci typu switch-case).</p>



<p><a name="k13"></a></p>
<h2 id="k13">13. Lexer se dvěma stavy &ndash; rozpoznání definice funkce</h2>

<p>Můžeme si samozřejmě ukázat nepatrně složitější lexer, v&nbsp;němž se budou
rozeznávat dva stavy &ndash; běžný program a definici funkce, která bude
začínat klíčovými slovy <strong>def function</strong> a končit slovy
<strong>end function</strong>. Tělo definované funkce bude pro jednoduchost
obarveno konstantní barvou (samozřejmě si však můžeme lexer později vylepšit).
Vzhledem k&nbsp;tomu, že se stav ukládá na zásobník, můžeme se
k&nbsp;předchozímu stavu dostat snadno speciálním jménem
&bdquo;#pop&ldquo;:</p>

<pre>
class <strong>FooLangLexer</strong>(RegexLexer):
    name = 'foolang'
    aliases = ['foolang']
    filenames = ['*.foolang']
&nbsp;
    tokens = {
        'root': [
            (r'\ *print', Name.Function),
            (r'for', Keyword),
            (r'while', Keyword),
            (r'goto', Generic.Error),
            (r'begin', Keyword),
            (r'end', Keyword),
            (r'def function', Name.Function, 'function'),
            (r'.+', Generic.Normal),
            (r'\n', Generic.Normal)
        ],
        'function': [
            (r'end function', Name.Function, '#pop'),
            (r'.+', Comment),
            (r'\n', Comment)
        ]
    }
</pre>

<p>Zdrojový kód jazyka &bdquo;FooLang&ldquo; pro otestování lexeru:</p>

<pre>
for i in range(1, 11)
begin
    print("Hello world!")
end
&nbsp;
def function Foo
    for i in range(5):
        print("hello world!")
end function
&nbsp;
while i &lt; 10
begin
    inc i
    print(i)
end
&nbsp;
def function Bar
    for i in range(5):
        print("hello world!")
end function
&nbsp;
goto 10
</pre>

<p>Výsledný proud tokenů generovaný naším novým lexerem se zvýrazněním těch
tokenů, které byly nalezeny ve stavu &bdquo;function&ldquo;:</p>

<pre>
Token.Keyword                     'for'
Token.Generic.Normal              ' i in range(1, 11)'
Token.Generic.Normal              '\n'
Token.Keyword                     'begin'
Token.Generic.Normal              '\n'
Token.Name.Function               '    print'
Token.Generic.Normal              '("Hello world!")'
Token.Generic.Normal              '\n'
Token.Keyword                     'end'
Token.Generic.Normal              '\n'
Token.Generic.Normal              '\n'
Token.Name.Function               'def function'
<strong>Token.Comment                     ' Foo'</strong>
<strong>Token.Comment                     '\n'</strong>
<strong>Token.Comment                     '    for i in range(5):'</strong>
<strong>Token.Comment                     '\n'</strong>
<strong>Token.Comment                     '        print("hello world!")'</strong>
<strong>Token.Comment                     '\n'</strong>
<strong>Token.Name.Function               'end function'</strong>
Token.Generic.Normal              '\n'
Token.Generic.Normal              '\n'
Token.Keyword                     'while'
Token.Generic.Normal              ' i &lt; 10'
Token.Generic.Normal              '\n'
Token.Keyword                     'begin'
Token.Generic.Normal              '\n'
Token.Generic.Normal              '    inc i'
Token.Generic.Normal              '\n'
Token.Name.Function               '    print'
Token.Generic.Normal              '(i)'
Token.Generic.Normal              '\n'
Token.Keyword                     'end'
Token.Generic.Normal              '\n'
Token.Generic.Normal              '\n'
Token.Name.Function               'def function'
<strong>Token.Comment                     ' Bar'</strong>
<strong>Token.Comment                     '\n'</strong>
<strong>Token.Comment                     '    for i in range(5):'</strong>
<strong>Token.Comment                     '\n'</strong>
<strong>Token.Comment                     '        print("hello world!")'</strong>
<strong>Token.Comment                     '\n'</strong>
<strong>Token.Name.Function               'end function'</strong>
Token.Generic.Normal              '\n'
Token.Generic.Normal              '\n'
Token.Generic.Error               'goto'
Token.Generic.Normal              ' 10'
Token.Generic.Normal              '\n'
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Výsledek zvýraznění syntaxe a úplný kód demonstračního příkladu s&nbsp;lexerem se dvěma stavy</h2>

<p>Příklad výsledku vytvořeného novým lexerem se dvěma stavy. Povšimněte si,
jak je obarven vnitřek funkce:</p>

<img src="https://i.iinfo.cz/images/615/pygments2-11.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 13: Výsledek zvýraznění syntaxe novým lexerem.</i></p>

<p><a
href="https://github.com/tisnik/presentations/blob/master/pygments/pygments25_lexer_states.py">Celý
kód demonstračního příkladu</a> s&nbsp;novým dvoustavovým lexerem vypadá
následovně:</p>

<pre>
from pygments import highlight
from pygments.lexer import RegexLexer
from pygments.token import *
from pygments.formatters import TerminalFormatter, RawTokenFormatter
from pygments.filters import NameHighlightFilter
&nbsp;
&nbsp;
class <strong>FooLangLexer</strong>(RegexLexer):
    name = 'foolang'
    aliases = ['foolang']
    filenames = ['*.foolang']
&nbsp;
    tokens = {
        'root': [
            (r'\ *print', Name.Function),
            (r'for', Keyword),
            (r'while', Keyword),
            (r'goto', Generic.Error),
            (r'begin', Keyword),
            (r'end', Keyword),
            (r'def function', Name.Function, 'function'),
            (r'.+', Generic.Normal),
            (r'\n', Generic.Normal)
        ],
        'function': [
            (r'end function', Name.Function, '#pop'),
            (r'.+', Comment),
            (r'\n', Comment)
        ]
    }
&nbsp;
&nbsp;
code = """
for i in range(1, 11)
begin
    print("Hello world!")
end
&nbsp;
def function Foo
    for i in range(5):
        print("hello world!")
end function
&nbsp;
while i &lt; 10
begin
    inc i
    print(i)
end
&nbsp;
def function Bar
    for i in range(5):
        print("hello world!")
end function
&nbsp;
goto 10
"""
&nbsp;
&nbsp;
print(highlight(code, FooLangLexer(), TerminalFormatter()))
input()
&nbsp;
tokens = highlight(code, FooLangLexer(), RawTokenFormatter())
&nbsp;
tokens = tokens.decode()
&nbsp;
for token in tokens.split("\n"):
    foobar = token.split("\t")
    if len(foobar) == 2:
        print("{token:30}    {value}".format(token=foobar[0], value=foobar[1]))
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. Lexer se třemi stavy</h2>

<p>Nepatrně složitější lexer, jehož zdrojový kód je umístěn pod tento odstavec,
navíc rozpoznává jméno funkce a proto používá tři stavy: výchozí stav (root),
stav po <strong>def function</strong> a stav po zadání jména funkce. Zde si
povšimněte způsobu odstranění DVOU prvků ze zásobníku stavů pomocí
&bdquo;#pop:2&ldquo;. Je tomu tak z&nbsp;toho důvodu, že zásobník bude postupně
obsahovat stavy [&bdquo;root&ldquo;], [&bdquo;root&ldquo;,
&bdquo;function_name&ldquo;] a [&bdquo;root&ldquo;,
&bdquo;function_name&ldquo;, &bdquo;function&ldquo;] a ze stavu
&bdquo;function&ldquo; budeme chtít ihned přejít zpět do stavu
&bdquo;root&ldquo;:</p>

<pre>
class <strong>FooLangLexer</strong>(RegexLexer):
    name = 'foolang'
    aliases = ['foolang']
    filenames = ['*.foolang']
&nbsp;
    tokens = {
        'root': [
            (r'\ *print', Name.Function),
            (r'for', Keyword),
            (r'while', Keyword),
            (r'goto', Generic.Error),
            (r'begin', Keyword),
            (r'end', Keyword),
            (r'def function ', Keyword, 'function_name'),
            (r'.+', Generic.Normal),
            (r'\n', Generic.Normal)
        ],
        'function': [
            (r'end function', Keyword, '#pop:2'),
            (r'.+', Comment),
            (r'\n', Comment)
        ],
        'function_name': [
            (r'[A-Za-z]+', Name.Function, 'function'),
            (r'.+', Comment),
            (r'\n', Comment)
        ]
    }
</pre>

<p>Výsledný proud tokenů generovaný naším novým lexerem:</p>

<pre>
Token.Keyword                     'for'
Token.Generic.Normal              ' i in range(1, 11)'
Token.Generic.Normal              '\n'
Token.Keyword                     'begin'
Token.Generic.Normal              '\n'
Token.Name.Function               '    print'
Token.Generic.Normal              '("Hello world!")'
Token.Generic.Normal              '\n'
Token.Keyword                     'end'
Token.Generic.Normal              '\n'
Token.Generic.Normal              '\n'
Token.Keyword                     'def function '
<strong>Token.Name.Function               'Foo'</strong>
Token.Comment                     '\n'
Token.Comment                     '    for i in range(5):'
Token.Comment                     '\n'
Token.Comment                     '        print("hello world!")'
Token.Comment                     '\n'
Token.Keyword                     'end function'
Token.Generic.Normal              '\n'
Token.Generic.Normal              '\n'
Token.Keyword                     'while'
Token.Generic.Normal              ' i &lt; 10'
Token.Generic.Normal              '\n'
Token.Keyword                     'begin'
Token.Generic.Normal              '\n'
Token.Generic.Normal              '    inc i'
Token.Generic.Normal              '\n'
Token.Name.Function               '    print'
Token.Generic.Normal              '(i)'
Token.Generic.Normal              '\n'
Token.Keyword                     'end'
Token.Generic.Normal              '\n'
Token.Generic.Normal              '\n'
Token.Keyword                     'def function '
<strong>Token.Name.Function               'Bar'</strong>
Token.Comment                     '\n'
Token.Comment                     '    for i in range(5):'
Token.Comment                     '\n'
Token.Comment                     '        print("hello world!")'
Token.Comment                     '\n'
Token.Keyword                     'end function'
Token.Generic.Normal              '\n'
Token.Generic.Normal              '\n'
Token.Generic.Error               'goto'
Token.Generic.Normal              ' 10'
Token.Generic.Normal              '\n'
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. Výsledek zvýraznění syntaxe a úplný kód demonstračního příkladu s&nbsp;lexerem se třemi stavy</h2>

<p>Příklad výsledku vytvořeného novým lexerem se třemi stavy. Povšimněte si,
jak je obarven vnitřek funkce a jakým způsobem je zvýrazněno její jméno:</p>

<img src="https://i.iinfo.cz/images/615/pygments2-12.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 14: Výsledek zvýraznění syntaxe novým lexerem se třemi
stavy.</i></p>

<p><a
href="https://github.com/tisnik/presentations/blob/master/pygments/pygments26_three_states.py">Celý
kód demonstračního příkladu</a> s&nbsp;novým třístavovým lexerem vypadá
následovně:</p>

<pre>
from pygments import highlight
from pygments.lexer import RegexLexer
from pygments.token import *
from pygments.formatters import TerminalFormatter, RawTokenFormatter
from pygments.filters import NameHighlightFilter
&nbsp;
&nbsp;
class <strong>FooLangLexer</strong>(RegexLexer):
    name = 'foolang'
    aliases = ['foolang']
    filenames = ['*.foolang']
&nbsp;
    tokens = {
        'root': [
            (r'\ *print', Name.Function),
            (r'for', Keyword),
            (r'while', Keyword),
            (r'goto', Generic.Error),
            (r'begin', Keyword),
            (r'end', Keyword),
            (r'def function ', Keyword, 'function_name'),
            (r'.+', Generic.Normal),
            (r'\n', Generic.Normal)
        ],
        'function': [
            (r'end function', Keyword, '#pop:2'),
            (r'.+', Comment),
            (r'\n', Comment)
        ],
        'function_name': [
            (r'[A-Za-z]+', Name.Function, 'function'),
            (r'.+', Comment),
            (r'\n', Comment)
        ]
    }
&nbsp;
&nbsp;
code = """
for i in range(1, 11)
begin
    print("Hello world!")
end
&nbsp;
def function Foo
    for i in range(5):
        print("hello world!")
end function
&nbsp;
while i &lt; 10
begin
    inc i
    print(i)
end
&nbsp;
def function Bar
    for i in range(5):
        print("hello world!")
end function
&nbsp;
goto 10
"""
&nbsp;
&nbsp;
print(highlight(code, FooLangLexer(), TerminalFormatter()))
input()
&nbsp;
tokens = highlight(code, FooLangLexer(), RawTokenFormatter())
&nbsp;
tokens = tokens.decode()
&nbsp;
for token in tokens.split("\n"):
    foobar = token.split("\t")
    if len(foobar) == 2:
        print("{token:30}    {value}".format(token=foobar[0], value=foobar[1]))
</pre>



<p><a name="k17"></a></p>
<h2 id="k17">17. Použití klauzule <strong>bygroups</strong> aneb lexer pro zpracování INI souborů</h2>

<p>Zkusme si nyní vytvořit lexer pro jednoduché INI soubory, s&nbsp;nimiž se
pravděpodobně většina čtenářů Roota již setkala. Zvýraznění syntaxe INI souborů
budeme testovat na tomto úryvku kódu:</p>

<pre>
; komentar
&nbsp;
[sekce]
x=10
y=20
&nbsp;
[dalsi-sekce]
foo=bar
</pre>

<p>Budeme vyžadovat zhruba následující zvýraznění syntaxe, v&nbsp;němž je
parametr před znakem &bdquo;=&ldquo; vybarven odlišně než hodnota za znakem
&bdquo;=&ldquo;:</p>

<img src="https://i.iinfo.cz/images/615/pygments2-13.png" class="image-335299" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 15: Zvýraznění INI souboru dále popsaným lexerem.</i></p>

<p>Toho lze dosáhnout různými způsoby, ovšem nejpřímější bude použití
regulárního výrazu s&nbsp;několika skupinami, kde každá skupina je uzavřena
mezi kulaté závorky. Každé takto definované skupině bude přiřazen jeden typ
tokenu, a to s&nbsp;využitím klauzule <strong>bygroups</strong>:</p>

<pre>
(r'(.*?)(\s*)(=)(\s*)(.*?)$', bygroups(Name.Attribute, Text, Operator, Text, String))
</pre>

<p>Tento zápis je zpracován následovně:</p>

<ol>
<li>Ze skupiny libovolných alfanumerických znaků je vytvořen token s&nbsp;typem <strong>Name.Attribute</strong></li>
<li>Případné mezery jsou seskupeny do tokenu s&nbsp;typem <strong>Text</strong></li>
<li>Samotný znak &bdquo;=&ldquo; bude samostatným tokenem <strong>Operator</strong></li>
<li>Za ním následující případné mezery jsou seskupeny do tokenu s&nbsp;typem <strong>Text</strong></li>
<li>Zbylé znaky jsou seskupeny do tokenu <strong>String</strong></li>
</ol>

<p>Samozřejmě musíme doplnit další pravidla pro jednořádkové komentáře a sekce
[], takže výsledný lexer bude vypadat takto:</p>

<pre>
<i># viz http://pygments.org/docs/lexerdevelopment/</i>
class <strong>IniFileLexer</strong>(RegexLexer):
    name = 'INI'
    aliases = ['ini', 'cfg']
    filenames = ['*.ini', '*.cfg']
&nbsp;
    tokens = {
        'root': [
            (r'\s+', Text),
            (r';.*?$', Comment),
            (r'\[.*?\]$', Keyword),
            (r'(.*?)(\s*)(=)(\s*)(.*?)$',
             bygroups(Name.Attribute, Text, Operator, Text, String))
        ]
    }
</pre>

<p>Opět se podívejme na <a
href="https://github.com/tisnik/presentations/blob/master/pygments/pygments27_bygroups.py">celý
demonstrační příklad</a>:</p>

<pre>
import re
from pygments import highlight
from pygments.lexer import *
from pygments.token import *
from pygments.style import Style
from pygments.formatters import Terminal256Formatter
from pygments.filters import NameHighlightFilter
&nbsp;
from pygments.lexer import RegexLexer, bygroups
from pygments.token import *
&nbsp;
&nbsp;
<i># viz http://pygments.org/docs/lexerdevelopment/</i>
class <strong>IniFileLexer</strong>(RegexLexer):
    name = 'INI'
    aliases = ['ini', 'cfg']
    filenames = ['*.ini', '*.cfg']
&nbsp;
    tokens = {
        'root': [
            (r'\s+', Text),
            (r';.*?$', Comment),
            (r'\[.*?\]$', Keyword),
            (r'(.*?)(\s*)(=)(\s*)(.*?)$',
             bygroups(Name.Attribute, Text, Operator, Text, String))
        ]
    }
&nbsp;
&nbsp;
code = """
; komentar
&nbsp;
[sekce]
x=10
y=20
&nbsp;
[dalsi-sekce]
foo=bar
"""
&nbsp;
&nbsp;
class <strong>NewStyle</strong>(Style):
    default_style = ""
    styles = {
        Comment:        '#888',
        Text:           '#ansired',
        Keyword:        '#88f',
        Name.Attribute: 'nobold #ansiyellow',
    }
&nbsp;
&nbsp;
print(highlight(code, IniFileLexer(), Terminal256Formatter(style=NewStyle)))
</pre>



<p><a name="k18"></a></p>
<h2 id="k18">18. Příklad pro třetí část článku &ndash; lexer pro klasický jazyk BASIC</h2>

<p>Ve třetím článku si ukážeme ještě složitější lexery, například lexer určený
pro obarvení klasického BASICu:</p>

<img src="https://i.iinfo.cz/images/615/pygments2-14.png" class="image-335311" alt="&#160;" width="806" height="531" />
<p><i>Obrázek 16: Obarvení zdrojového kódu v&nbsp;klasickém BASICu.</i></p>

<p>Již dopředu si pro samostudium můžeme ukázat, jak bude implementace takového
lexeru vypadat:</p>

<pre>
import re
from pygments import highlight
from pygments.lexer import *
from pygments.token import *
from pygments.style import Style
from pygments.formatters import Terminal256Formatter
from pygments.filters import NameHighlightFilter
&nbsp;
&nbsp;
<i># odvozeno od tridy QBasicLexer</i>
<i># http://pygments.org/docs/lexers/#lexers-for-basic-like-languages-other-than-vb-net</i>
&nbsp;
class <strong>BasicLexer</strong>(RegexLexer):
    name = 'Basic'
    aliases = ['basic']
    filenames = ['*.BAS', '*.bas']
    mimetypes = ['text/basic']
&nbsp;
    declarations = ('DATA', 'LET')
&nbsp;
    functions = (
        'ABS', 'ASC', 'ATN', 'COS', 'DATE$', 'EXP', 'FRE',
        'INKEY$', 'INPUT$', 'LEN', 'LOG', 'PEEK', 'SGN', 'SIN',
        'SQR', 'STICK', 'STR$', 'STRIG', 'TAN', 'TIME$', 'VAL'
    )
&nbsp;
    operators = ('AND', 'OR', 'XOR', 'NOT')
&nbsp;
    statements = (
        'BEEP', 'CLEAR', 'CLS', 'DATA', 'DATE$', 'DIM', 'PLOT',
        'DRAWTO', 'FOR', 'NEXT', 'GOSUB', 'GOTO', 'IF', 'THEN', 'INPUT',
        'LET', 'LINE', 'POKE', 'PRINT', 'PRINT #', 'PRINT USING', 'REM',
        'RETURN', 'RUN', 'STOP', 'STRIG', 'TIME$'
    )
&nbsp;
    tokens = {
        'root': [
            (r'\n+', Text),
            (r'\s+', Text.Whitespace),
            (r'^(\s*)(\d*)(\s*)(REM .*)$',
             bygroups(Text.Whitespace, Name.Label, Text.Whitespace,
                      Comment.Single)),
            (r'^(\s*)(\d+)(\s*)',
             bygroups(Text.Whitespace, Name.Label, Text.Whitespace)),
            (r'(?=[\s]*)(\w+)(?=[\s]*=)', Name.Variable.Global),
            (r'(?=[^"]*)\'.*$', Comment.Single),
            (r'"[^\n"]*"', String.Double),
            (r'(DIM)(\s+)([^\s(]+)',
             bygroups(Keyword.Declaration, Text.Whitespace, Name.Variable.Global)),
            (r'^(\s*)([a-zA-Z_]+)(\s*)(\=)',
             bygroups(Text.Whitespace, Name.Variable.Global, Text.Whitespace,
                      Operator)),
            (r'(GOTO|GOSUB)(\s+)(\w+\:?)',
             bygroups(Keyword.Reserved, Text.Whitespace, Name.Label)),
            include('declarations'),
            include('functions'),
            include('operators'),
            include('statements'),
            (r'[a-zA-Z_]\w*[$@#&amp;!]', Name.Variable.Global),
            (r'[a-zA-Z_]\w*\:', Name.Label),
            (r'\-?\d*\.\d+[@|#]?', Number.Float),
            (r'\-?\d+[@|#]', Number.Float),
            (r'\-?\d+#?', Number.Integer.Long),
            (r'\-?\d+#?', Number.Integer),
            (r'!=|==|:=|\.=|&lt;&lt;|&gt;&gt;|[-~+/\\*%=&lt;&gt;&amp;^|?:!.]', Operator),
            (r'[\[\]{}(),;]', Punctuation),
            (r'[\w]+', Name.Variable.Global),
        ],
        'declarations': [
            (r'\b(%s)(?=\(|\b)' % '|'.join(map(re.escape, declarations)),
             Keyword.Declaration),
        ],
        'functions': [
            (r'\b(%s)(?=\(|\b)' % '|'.join(map(re.escape, functions)),
             Name.Builtin),
        ],
        'operators': [
            (r'\b(%s)(?=\(|\b)' % '|'.join(map(re.escape, operators)), Operator.Word),
        ],
        'statements': [
            (r'\b(%s)\b' % '|'.join(map(re.escape, statements)),
             Keyword.Reserved),
        ],
    }
&nbsp;
&nbsp;
code = """
1500 REM === DRAW a LINE. Ported from C version
1510 REM Inputs are X1, Y1, X2, Y2: Destroys value of X1, Y1
1520 DX = ABS(X2 - X1):SX = -1:IF X1 &lt; X2 THEN SX = 1
1530 DY = ABS(Y2 - Y1):SY = -1:IF Y1 &lt; Y2 THEN SY = 1
1540 ER = -DY
1545 IF DX &gt; DY THEN ER = DX
1550 ER = INT(ER / 2)
1555 REM This command may differ depending ON BASIC dialect
1560 PLOT X1,Y1
1570 IF X1 = X2 AND Y1 = Y2 THEN RETURN
1580 E2 = ER
1590 IF E2 &gt; -DX THEN ER = ER - DY:X1 = X1 + SX
1600 IF E2 &lt; DY THEN ER = ER + DX:Y1 = Y1 + SY
1610 GOTO 1560
"""
&nbsp;
&nbsp;
class &lt;strong&gt;NewStyle&lt;/strong&gt;(Style):
    default_style = ""
    styles = {
        Comment:                '#888',
        Keyword.Declaration:    '#ansired',
        Keyword.Reserved:       '#88f',
        Name.Builtin:           'nobold #ansiyellow',
        String:                 '#ansilightgray',
        Operator.Word:          '#f0f',
        Name.Label:             '#fff'
    }
&nbsp;
&nbsp;
print(highlight(code, BasicLexer(), Terminal256Formatter(style=NewStyle)))
</pre>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny dnes popisované demonstrační příklady byly uloženy do Git
repositáře, který je dostupný na adrese <a
href="https://github.com/tisnik/presentations">https://github.com/tisnik/presentations</a>.
Příklady si můžete v&nbsp;případě potřeby stáhnout i jednotlivě bez nutnosti
klonovat celý (dnes již poměrně rozsáhlý) repositář:</p>

<table>
<tr><th> #</th><th>Příklad</th><th>Popis</th><th>Odkaz</th></tr>
<tr><td> 1</td><td>pygments19_custom_filter.py</td><td>uživatelsky definovaný filtr</td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments19_custom_filter.py">https://github.com/tisnik/presentations/blob/master/pygments/pygments19_custom_filter.py</a></td></tr>
<tr><td> 2</td><td>pygments20_custom_filter_decorator.py</td><td>filtr definovaný přes dekorátor</td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments20_custom_filter_decorator.py">https://github.com/tisnik/presentations/blob/master/pygments/pygments20_custom_filter_decorator.py</a></td></tr>
<tr><td> 3</td><td>pygments21_better_custom_filter.py</td><td>vylepšení předchozích filtrů</td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments21_better_custom_filter.py">https://github.com/tisnik/presentations/blob/master/pygments/pygments21_better_custom_filter.py</a></td></tr>
<tr><td> 4</td><td>pygments22_lookahead_filter.py</td><td>filtr se sledováním dalšího tokenu</td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments22_lookahead_filter.py">https://github.com/tisnik/presentations/blob/master/pygments/pygments22_lookahead_filter.py</a></td></tr>
<tr><td> 5</td><td>pygments23_correct_lookahead_filter.py</td><td>oprava zpracování posledního tokenu</td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments23_correct_lookahead_filter.py">https://github.com/tisnik/presentations/blob/master/pygments/pygments23_correct_lookahead_filter.py</a></td></tr>
<tr><td> 6</td><td>pygments24_configurable_lookahead_filter.py</td><td>konfigurovatelný filtr</td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments24_configurable_lookahead_filter.py">https://github.com/tisnik/presentations/blob/master/pygments/pygments24_configurable_lookahead_filter.py</a></td></tr>
<tr><td> 7</td><td>pygments25_lexer_states.py</td><td>lexer se dvěma stavy</td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments25_lexer_states.py">https://github.com/tisnik/presentations/blob/master/pygments/pygments25_lexer_states.py</a></td></tr>
<tr><td> 8</td><td>pygments26_three_states.py</td><td>lexer se třemi stavy</td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments26_three_states.py">https://github.com/tisnik/presentations/blob/master/pygments/pygments26_three_states.py</a></td></tr>
<tr><td> 9</td><td>pygments27_bygroups.py</td><td>použití klauzule <strong>bygroups</strong></td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments27_bygroups.py">https://github.com/tisnik/presentations/blob/master/pygments/pygments27_bygroups.py</a></td></tr>
<tr><td>10</td><td>pygments28_basic_lexer.py</td><td>lexer pro BASIC</td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments28_basic_lexer.py">https://github.com/tisnik/presentations/blob/master/pygments/pygments28_basic_lexer.py</a></td></tr>
</table>

<p>Další soubory, s&nbsp;nimiž jsme se dnes setkali:</p>

<table>
<tr><th>#</th><th>Soubor</th><th>Popis</th><th>Odkaz</th></tr>
<tr><td>1</td><td>pygments.mm</td><td>schéma zpracování</td><td><a href="https://github.com/tisnik/presentations/blob/master/pygments/pygments.mm">https://github.com/tisnik/presentations/blob/master/pygments/pygments.mm</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Pygments - Python syntax highlighter<br />
<a href="http://pygments.org/">http://pygments.org/</a>
</li>

<li>Pygments (dokumentace)<br />
<a href="http://pygments.org/docs/">http://pygments.org/docs/</a>
</li>

<li>Write your own filter<br />
<a href="http://pygments.org/docs/filterdevelopment/">http://pygments.org/docs/filterdevelopment/</a>
</li>

<li>Write your own lexer<br />
<a href="http://pygments.org/docs/lexerdevelopment/">http://pygments.org/docs/lexerdevelopment/</a>
</li>

<li>Write your own formatter<br />
<a href="http://pygments.org/docs/formatterdevelopment/">http://pygments.org/docs/formatterdevelopment/</a>
</li>

<li>Jazyky podporované knihovnou Pygments<br />
<a href="http://pygments.org/languages/">http://pygments.org/languages/</a>
</li>

<li>Pygments FAQ<br />
<a href="http://pygments.org/faq/">http://pygments.org/faq/</a>
</li>

<li>Pygments 2.2.0 (na PyPi)<br />
<a href="https://pypi.org/project/Pygments/">https://pypi.org/project/Pygments/</a>
</li>

<li>Syntax highlighting<br />
<a href="https://en.wikipedia.org/wiki/Syntax_highlighting">https://en.wikipedia.org/wiki/Syntax_highlighting</a>
</li>

<li>Lexical analysis<br />
<a href="https://en.wikipedia.org/wiki/Lexical_analysis">https://en.wikipedia.org/wiki/Lexical_analysis</a>
</li>

<li>Lexical grammar<br />
<a href="https://en.wikipedia.org/wiki/Lexical_grammar">https://en.wikipedia.org/wiki/Lexical_grammar</a>
</li>

<li>Compiler Construction/Lexical analysis<br />
<a href="https://en.wikibooks.org/wiki/Compiler_Construction/Lexical_analysis">https://en.wikibooks.org/wiki/Compiler_Construction/Lexical_analysis</a>
</li>

<li>Compiler Design - Lexical Analysis<br />
<a href="https://www.tutorialspoint.com/compiler_design/compiler_design_lexical_analysis.htm">https://www.tutorialspoint.com/compiler_design/compiler_design_lexical_analysis.htm</a>
</li>

<li>Lexical Analysis - An Intro<br />
<a href="https://www.scribd.com/document/383765692/Lexical-Analysis">https://www.scribd.com/document/383765692/Lexical-Analysis</a>
</li>

<li>prompt_toolkit 2.0.3 na PyPi<br />
<a href="https://pypi.org/project/prompt_toolkit/">https://pypi.org/project/prompt_toolkit/</a>
</li>

<li>python-prompt-toolkit na GitHubu<br />
<a href="https://github.com/jonathanslenders/python-prompt-toolkit">https://github.com/jonathanslenders/python-prompt-toolkit</a>
</li>

<li>Comparing Python Command-Line Parsing Libraries – Argparse, Docopt, and Click<br />
<a href="https://realpython.com/comparing-python-command-line-parsing-libraries-argparse-docopt-click/">https://realpython.com/comparing-python-command-line-parsing-libraries-argparse-docopt-click/</a>
</li>

<li>Rosetta Code<br />
<a href="http://rosettacode.org/wiki/Rosetta_Code">http://rosettacode.org/wiki/Rosetta_Code</a>
</li>

<li>Mandelbrot set: Sinclair ZX81 BASIC<br />
<a href="http://rosettacode.org/wiki/Mandelbrot_set#Sinclair_ZX81_BASIC">http://rosettacode.org/wiki/Mandelbrot_set#Sinclair_ZX81_BASIC</a>
</li>

<li>Lexikální analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Lexik%C3%A1ln%C3%AD_anal%C3%BDza">https://cs.wikipedia.org/wiki/Lexik%C3%A1ln%C3%AD_anal%C3%BDza</a>
</li>

<li>Quex, a lexical analyzer generator<br />
<a href="http://quex.sourceforge.net/">http://quex.sourceforge.net/</a>
</li>

<li>ATARI BASIC &ndash; tokenizace<br />
<a href="https://www.atariarchives.org/dere/chapt10.php">https://www.atariarchives.org/dere/chapt10.php</a>
</li>

<li>BASIC token<br />
<a href="https://www.c64-wiki.com/wiki/BASIC_token">https://www.c64-wiki.com/wiki/BASIC_token</a>
</li>

<li>CamelCase (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Camel_case">https://en.wikipedia.org/wiki/Camel_case</a>
</li>

<li>Snake case<br />
<a href="https://en.wikipedia.org/wiki/Snake_case">https://en.wikipedia.org/wiki/Snake_case</a>
</li>

<li>Kebab-case<br />
<a href="https://en.wikipedia.org/wiki/Letter_case#Special_case_styles">https://en.wikipedia.org/wiki/Letter_case#Special_case_styles</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2018</small></p>
</body>
</html>

