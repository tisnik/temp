<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Lexikální a syntaktická analýza zdrojových kódů programovacího jazyka Python</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Lexikální a syntaktická analýza zdrojových kódů programovacího jazyka Python</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. Lexikální a syntaktická analýza zdrojových kódů programovacího jazyka Python</a></p>
<p><a href="#k02">*** 2. Od volně zapsaného zdrojového kódu k&nbsp;AST</a></p>
<p><a href="#k03">*** 3. Lexémy a tokeny (tokenizace)</a></p>
<p><a href="#k04">*** 4. </a></p>
<p><a href="#k05">*** 5. </a></p>
<p><a href="#k06">*** 6. </a></p>
<p><a href="#k07">*** 7. </a></p>
<p><a href="#k08">*** 8. </a></p>
<p><a href="#k09">*** 9. </a></p>
<p><a href="#k10">*** 10. </a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">*** 20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Lexikální a syntaktická analýza zdrojových kódů programovacího jazyka Python</h2>

<p>Na trojici článků, v&nbsp;nichž jsme se zabývali problematikou lexikální a syntaktické analýzy zdrojových kódů jazyka Go [<a href="">1</a>] [<a href="">2</a>] [<a href="">3</a>] dnes do jisté míry navážeme, ovšem přesuneme se <a href="">z&nbsp;jazyka Go</a> k&nbsp;pravděpodobně nejpopulárnějšímu jazyku současnosti &ndash; <a href="">k&nbsp;Pythonu</a>. Ukážeme si, jak lze provést takzvanou <i>tokenizaci</i> a následně <i>parsing</i> zdrojových kódů, jehož výsledkem je AST neboli abstraktní syntaktický strom (<i>Abstract Syntax Tree</i>). A samozřejmě se zmíníme i o tom, jakým způsobem lze abstraktním syntaktickým stromem procházet či jinak manipulovat.</p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Od volně zapsaného zdrojového kódu k&nbsp;AST</h2>

<p>Při zpracování zdrojových kódů se postupně provádí jednotlivé dílčí kroky.  Díky rozdělení celého zpracování do několika konfigurovatelných kroků je zajištěna velká flexibilita a možnost případného relativně snadného rozšiřování o další podporované jazyky, výstupní formáty, speciální filtry atd. (nehledě na to, že každá činnost je založena na odlišné teorii). Celý průběh zpracování vypadá následovně:</p>

<ol>

<li>Na začátku zpracování se nachází takzvaný <i>lexer</i>, který postupně načítá jednotlivé znaky ze vstupního řetězce (resp.&nbsp;souboru) a vytváří z&nbsp;nich lexikální <i>tokeny</i>. Teoreticky se pro každý programovací jazyk používá odlišný lexer a samozřejmě je možné v&nbsp;případě potřeby si napsat lexer vlastní.</li>

<li>Výstup z&nbsp;lexeru může procházet libovolným počtem <i>filtrů</i> sloužících pro odstranění nebo (častěji) modifikaci jednotlivých tokenů; ať již jejich typů či přímo textu, který tvoří hodnotu tokenu. Díky existenci filtrů je například možné nechat si zvýraznit vybrané bílé znaky, slova se speciálním významem v&nbsp;komentářích (TODO:, FIX:) apod.</li>

<li>Sekvence <i>tokenů</i> tvoří základ pro syntaktickou analýzu. Nástroj, který syntaktickou analýzu provádí, se většinou nazývá <i>parser</i> a proto se taktéž někdy setkáme s&nbsp;pojmem <i>parsing</i> (ten je ovšem chybně používán i v&nbsp;těch případech, kdy se provádí &bdquo;pouze&ldquo; lexikální analýza).  Výsledkem parseru je vhodně zvolená datová struktura, typicky abstraktní syntaktický strom (AST); někdy též strom derivační.</li>

</ol>

<p><div class="rs-tip-major">Poznámka: díky tomu, že se prakticky veškeré zpracování zdrojových textů odehrává na úrovni tokenů, není nutné, aby byl celý zpracovávaný zdrojový kód (nebo jeho tokenizovaná podoba) uložen v&nbsp;operační paměti. Je tedy možné zpracovávat i velmi rozsáhlé dokumenty, a to bez větších nároků na operační paměť &ndash; i to je ostatně použito v&nbsp;balíčku <strong>go/scanner</strong>.</div></p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Lexémy a tokeny (tokenizace)</h2>

<p>První část zpracování zdrojových textů je nejzajímavější a implementačně i nejsložitější. <i>Lexer</i> totiž musí v&nbsp;sekvenci znaků tvořících zdrojový text najít takzvané <i>lexémy</i>, tj.&nbsp;skupiny (sousedních) znaků odpovídajících nějakému vzorku (použít lze gramatiku, regulární výraz či ad-hoc testy). Z&nbsp;lexémů se posléze tvoří již zmíněné lexikální <i>tokeny</i>, což je &ndash; poněkud zjednodušeně řečeno &ndash; dvojice obsahující typ tokenu (někdy se namísto &bdquo;typ&ldquo; používá označení &bdquo;jméno&ldquo;) a řetězec ze vstupního zdrojového souboru. Převodu zdrojového textu na sekvenci tokenů se někdy říká <i>tokenizace</i>. Účelem tokenizace může být:</p>

<ul>

<li>Transformace zdrojového textu do podoby, která může být dále zpracovávána dalším modulem překladače (syntaktická analýza). V&nbsp;takovém případě se však některé tokeny mohou zahazovat; příkladem mohou být komentáře, tokeny představující bílé znaky apod. Spojením lexeru a modulu pro syntaktickou analýzu vznikne <i>parser</i> (jeho typickým výsledkem je AST).</li>

<li>Transformace zdrojového kódu pro účely zvýraznění syntaxe v&nbsp;editorech či prohlížečích. V&nbsp;tomto případě se žádné tokeny nezahazují, což je případ knihovny Pygments.</li>

</ul>

<p><div class="rs-tip-major">Poznámka: výše zmíněná <i>tokenizace</i> se používala například již v&nbsp;interpretrech programovacího jazyka BASIC na mnoha osmibitových domácích počítačích. Ovšem v&nbsp;tomto případě měly tokeny poněkud odlišnou strukturu, protože všechny příkazy a funkce byly většinou reprezentovány jednoznačným osmibitovým celým číslem, které tak současně představovalo jak typ tokenu, tak i jeho hodnotu. Důvod byl jednoduchý &ndash; v&nbsp;operační paměti byl uložen tokenizovaný kód a nikoli kód zapsaný uživatelem. Tento kód byl již mnohem jednodušeji zpracovatelný interpretrem, než původní zdrojový kód (odpadlo neustálé volání <i>lexeru</i>). Navíc se každý programový řádek ihned po svém zápisu automaticky normalizoval (odstranily se bílé znaky, zkratky příkazů se expandovaly atd.). Ostatně množina příkazů a funkcí byla předem známá a nebyla rozšiřitelná (až na uživatelské funkce dostupné jen v&nbsp;některých BASICech). Příkladem tokenizace tohoto typu mohou být tokeny použité v&nbsp;interpretru programovacího jazyka Atari BASIC, které skutečně přímo odpovídají příkazům, funkcím a operátorům tohoto jazyka. Pro zajímavost:</div></p>

<table>
<tr><th>Příkaz</th><th>Kód tokenu</th><th>Příkaz</th><th>Kód tokenu</th><th>Příkaz</th><th>Kód tokenu</th><th>Příkaz</th><th>Kód tokenu</th></tr>
<tr><td>REM</td><td>00</td><td>NEXT</td><td>09</td><td>CLR</td><td>18</td><td>NOTE</td><td>27</td></tr>
<tr><td>DATA</td><td>01</td><td>GOTO</td><td>10</td><td>DEG</td><td>19</td><td>POINT</td><td>28</td></tr>
<tr><td>INPUT</td><td>02</td><td>GO TO</td><td>11</td><td>DIM</td><td>20</td><td>XIO</td><td>29</td></tr>
<tr><td>COLOR</td><td>03</td><td>GOSUB</td><td>12</td><td>END</td><td>21</td><td>ON</td><td>30</td></tr>
<tr><td>LIST</td><td>04</td><td>TRAP</td><td>13</td><td>NEW</td><td>22</td><td>POKE</td><td>31</td></tr>
<tr><td>ENTER</td><td>05</td><td>BYE</td><td>14</td><td>OPEN</td><td>23</td><td>PRINT</td><td>32</td></tr>
<tr><td>LET</td><td>06</td><td>CONT</td><td>15</td><td>LOAD</td><td>24</td><td>RAD</td><td>33</td></tr>
<tr><td>IF</td><td>07</td><td>COM</td><td>16</td><td>SAVE</td><td>25</td><td>READ</td><td>34</td></tr>
<tr><td>FOR</td><td>08</td><td>CLOSE</td><td>17</td><td>STATUS</td><td>26</td><td>RESTORE</td><td>35</td></tr>
</table>

<p>...atd...</p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Příklad tokenizace jednoduchého kódu napsaného v&nbsp;Pythonu</h2>

<p>Podívejme se nyní na příklad tokenizace velmi jednoduchého a krátkého kódu, který je naprogramován v&nbsp;Pythonu:</p>

<pre>
for i in range(1, 11):
    print("Hello world!")
</pre>

<p>Výsledkem tokenizace je následující sekvence tokenů, tj.&nbsp;dvojic typ+hodnota (řetězec):</p>

<table>
<tr><th>Typ tokenu</th><th>Řetězec</th></tr>
<tr><td>Token.Keyword</td><td>'for'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Name</td><td>'i'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Operator.Word</td><td>'in'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Name.Builtin</td><td>'range'</td></tr>
<tr><td>Token.Punctuation</td><td>'('</td></tr>
<tr><td>Token.Literal.Number.Integer</td><td>'1'</td></tr>
<tr><td>Token.Punctuation</td><td>','</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Literal.Number.Integer</td><td>'11'</td></tr>
<tr><td>Token.Punctuation</td><td>')'</td></tr>
<tr><td>Token.Punctuation</td><td>':'</td></tr>
<tr><td>Token.Text</td><td>'\n'</td></tr>
<tr><td>Token.Text</td><td>'    '</td></tr>
<tr><td>Token.Keyword</td><td>'print'</td></tr>
<tr><td>Token.Punctuation</td><td>'('</td></tr>
<tr><td>Token.Literal.String.Double</td><td>'"'</td></tr>
<tr><td>Token.Literal.String.Double</td><td>'Hello world!'</td></tr>
<tr><td>Token.Literal.String.Double</td><td>'"'</td></tr>
<tr><td>Token.Punctuation</td><td>')'</td></tr>
<tr><td>Token.Text</td><td>'\n'</td></tr>
</table>

<p><div class="rs-tip-major">Poznámka: lexer se v&nbsp;žádném případě nesnaží o nalezení syntaktických (a už vůbec ne sémantických) chyb v&nbsp;programu! Pouze se snaží rozeznat známé vzorky. To například znamená, že tokenizace proběhne i pro tento zdrojový kód, který je sémanticky naprosto chybný:</div></p>

<pre>
range(1, "FDA") for while with i
except for for i else
    print("Hello world!")
</pre>

<p>Výsledek tokenizace:</p>

<table>
<tr><th>Typ tokenu</th><th>Řetězec</th></tr>
<tr><td>Token.Name.Builtin</td><td>'range'</td></tr>
<tr><td>Token.Punctuation</td><td>'('</td></tr>
<tr><td>Token.Literal.Number.Integer</td><td>'1'</td></tr>
<tr><td>Token.Punctuation</td><td>','</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Literal.String.Double</td><td>'"'</td></tr>
<tr><td>Token.Literal.String.Double</td><td>'FDA'</td></tr>
<tr><td>Token.Literal.String.Double</td><td>'"'</td></tr>
<tr><td>Token.Punctuation</td><td>')'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Keyword</td><td>'for'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Keyword</td><td>'while'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Keyword</td><td>'with'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Name</td><td>'i'</td></tr>
<tr><td>Token.Text</td><td>'\n'</td></tr>
<tr><td>Token.Keyword</td><td>'except'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Keyword</td><td>'for'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Keyword</td><td>'for'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Name</td><td>'i'</td></tr>
<tr><td>Token.Text</td><td>' '</td></tr>
<tr><td>Token.Keyword</td><td>'else'</td></tr>
<tr><td>Token.Text</td><td>'\n'</td></tr>
<tr><td>Token.Text</td><td>'    '</td></tr>
<tr><td>Token.Keyword</td><td>'print'</td></tr>
<tr><td>Token.Punctuation</td><td>'('</td></tr>
<tr><td>Token.Literal.String.Double</td><td>'"'</td></tr>
<tr><td>Token.Literal.String.Double</td><td>'Hello world!'</td></tr>
<tr><td>Token.Literal.String.Double</td><td>'"'</td></tr>
<tr><td>Token.Punctuation</td><td>')'</td></tr>
<tr><td>Token.Text</td><td>'\n'</td></tr>
</table>



<p><a name="k05"></a></p>
<h2 id="k05">5. </h2>

<p></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. </h2>

<p></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. </h2>

<p></p>



<p><a name="k08"></a></p>
<h2 id="k08">8. </h2>

<p></p>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>

<p></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>

<p></p>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>

<p></p>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>

<p></p>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>

<p></p>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>

<p></p>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>

<p></p>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>

<p></p>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>

<p></p>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>

<p></p>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Zdrojové kódy všech prozatím popsaných demonstračních příkladů určených pro
programovací jazyk Python 3 byly uloženy do Git repositáře dostupného na adrese
<a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
V&nbsp;případě, že nebudete chtít klonovat celý repositář (ten je ovšem stále
velmi malý, dnes má velikost zhruba několik desítek kilobajtů), můžete namísto
toho použít odkazy na jednotlivé příklady, které naleznete v&nbsp;následující
tabulce:</p>

<table>
<tr><th> #</th><th>Demonstrační příklad</th><th>Stručný popis příkladu</th><th>Cesta</th></tr>
<tr><td> 1</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/ast/">https://github.com/tisnik/most-popular-python-libs/blob/master/ast/</a></td></tr>
<tr><td> 2</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/ast/">https://github.com/tisnik/most-popular-python-libs/blob/master/ast/</a></td></tr>
<tr><td> 3</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/ast/">https://github.com/tisnik/most-popular-python-libs/blob/master/ast/</a></td></tr>
<tr><td> 4</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/ast/">https://github.com/tisnik/most-popular-python-libs/blob/master/ast/</a></td></tr>
<tr><td> 5</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/ast/">https://github.com/tisnik/most-popular-python-libs/blob/master/ast/</a></td></tr>
<tr><td> 6</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/ast/">https://github.com/tisnik/most-popular-python-libs/blob/master/ast/</a></td></tr>
<tr><td> 7</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/ast/">https://github.com/tisnik/most-popular-python-libs/blob/master/ast/</a></td></tr>
<tr><td> 8</td><td></td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/ast/">https://github.com/tisnik/most-popular-python-libs/blob/master/ast/</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Abstract syntax tree<br />
<a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">https://en.wikipedia.org/wiki/Abstract_syntax_tree</a>
</li>

<li>Lexical analysis<br />
<a href="https://en.wikipedia.org/wiki/Lexical_analysis">https://en.wikipedia.org/wiki/Lexical_analysis</a>
</li>

<li>Parser<br />
<a href="https://en.wikipedia.org/wiki/Parsing#Parser">https://en.wikipedia.org/wiki/Parsing#Parser</a>
</li>

<li>Python doc: ast — Abstract Syntax Trees<br />
<a href="https://docs.python.org/3/library/ast.html">https://docs.python.org/3/library/ast.html</a>
</li>

<li>Python doc: tokenize — Tokenizer for Python source<br />
<a href="https://docs.python.org/3/library/tokenize.html">https://docs.python.org/3/library/tokenize.html</a>
</li>

<li>5 Amazing Python AST Module Examples<br />
<a href="https://www.pythonpool.com/python-ast/">https://www.pythonpool.com/python-ast/</a>
</li>

<li>Intro to Python ast Module<br />
<a href="https://medium.com/@wshanshan/intro-to-python-ast-module-bbd22cd505f7">https://medium.com/@wshanshan/intro-to-python-ast-module-bbd22cd505f7</a>
</li>

<li>Golang AST Package<br />
<a href="https://golangdocs.com/golang-ast-package">https://golangdocs.com/golang-ast-package</a>
</li>

<li>AP8, IN8 Regulární jazyky<br />
<a href="http://statnice.dqd.cz/home:inf:ap8">http://statnice.dqd.cz/home:inf:ap8</a>
</li>

<li>AP9, IN9 Konečné automaty<br />
<a href="http://statnice.dqd.cz/home:inf:ap9">http://statnice.dqd.cz/home:inf:ap9</a>
</li>

<li>AP10, IN10 Bezkontextové jazyky<br />
<a href="http://statnice.dqd.cz/home:inf:ap10">http://statnice.dqd.cz/home:inf:ap10</a>
</li>

<li>AP11, IN11 Zásobníkové automaty, Syntaktická analýza<br />
<a href="http://statnice.dqd.cz/home:inf:ap11">http://statnice.dqd.cz/home:inf:ap11</a>
</li>

<li>Introduction to YACC<br />
<a href="https://www.geeksforgeeks.org/introduction-to-yacc/">https://www.geeksforgeeks.org/introduction-to-yacc/</a>
</li>

<li>Introduction of Lexical Analysis<br />
<a href="https://www.geeksforgeeks.org/introduction-of-lexical-analysis/?ref=lbp">https://www.geeksforgeeks.org/introduction-of-lexical-analysis/?ref=lbp</a>
</li>

<li>Využití knihovny Pygments (nejenom) pro obarvení zdrojových kódů<br />
<a href="https://www.root.cz/clanky/vyuziti-knihovny-pygments-nejenom-pro-obarveni-zdrojovych-kodu/">https://www.root.cz/clanky/vyuziti-knihovny-pygments-nejenom-pro-obarveni-zdrojovych-kodu/</a>
</li>

<li>Pygments - Python syntax highlighter<br />
<a href="http://pygments.org/">http://pygments.org/</a>
</li>

<li>Pygments (dokumentace)<br />
<a href="http://pygments.org/docs/">http://pygments.org/docs/</a>
</li>

<li>Write your own filter<br />
<a href="http://pygments.org/docs/filterdevelopment/">http://pygments.org/docs/filterdevelopment/</a>
</li>

<li>Write your own lexer<br />
<a href="http://pygments.org/docs/lexerdevelopment/">http://pygments.org/docs/lexerdevelopment/</a>
</li>

<li>Write your own formatter<br />
<a href="http://pygments.org/docs/formatterdevelopment/">http://pygments.org/docs/formatterdevelopment/</a>
</li>

<li>Jazyky podporované knihovnou Pygments<br />
<a href="http://pygments.org/languages/">http://pygments.org/languages/</a>
</li>

<li>Pygments FAQ<br />
<a href="http://pygments.org/faq/">http://pygments.org/faq/</a>
</li>

<li>Compiler Construction/Lexical analysis<br />
<a href="https://en.wikibooks.org/wiki/Compiler_Construction/Lexical_analysis">https://en.wikibooks.org/wiki/Compiler_Construction/Lexical_analysis</a>
</li>

<li>Compiler Design - Lexical Analysis<br />
<a href="https://www.tutorialspoint.com/compiler_design/compiler_design_lexical_analysis.htm">https://www.tutorialspoint.com/compiler_design/compiler_design_lexical_analysis.htm</a>
</li>

<li>Lexical Analysis - An Intro<br />
<a href="https://www.scribd.com/document/383765692/Lexical-Analysis">https://www.scribd.com/document/383765692/Lexical-Analysis</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2022</small></p>
</body>
</html>

