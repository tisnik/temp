<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Balíček scikit-learn: modely provádějící regresní analýzu</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Balíček scikit-learn: modely provádějící regresní analýzu</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">1. Balíček scikit-learn: modely provádějící regresní analýzu</a></p>
<p><a href="#k02">2. Regresní analýza a lineární regrese</a></p>
<p><a href="#k03">3. Datová sada <i>California housing</i></a></p>
<p><a href="#k04">4. Přístup k&nbsp;atributům jednotlivých domů, zjištění jmen atributů i cen domů</a></p>
<p><a href="#k05">5. Korelační diagram pro dvojici vybraných proměnných</a></p>
<p><a href="#k06">6. Korelační diagram pro všechny kombinace dvojic proměnných</a></p>
<p><a href="#k07">7. Dvourozměrné hodnoty reprezentované jako dvojice atributů</a></p>
<p><a href="#k08">8. Regresní analýza</a></p>
<p><a href="#k09">9. Model <i>LinearRegression</i> nad uměle vytvořenými daty</a></p>
<p><a href="#k10">10. Predikce modelu provádějícího lineární regresi</a></p>
<p><a href="#k11">11. Chování modelu pro zcela náhodná data</a></p>
<p><a href="#k12">12. Výpočet chyby &ndash; základní metriky modelu lineární regrese</a></p>
<p><a href="#k13">13. Praktický příklad: výpočet chyby a skóre modelu pro čtyři odlišné datové sady</a></p>
<p><a href="#k14">14. Predikce modelu pro datovou sadu <i>California housing: umístění bloků na mapě</a></p>
<p><a href="#k15">15. Lineární regrese nad daty s&nbsp;nelineární závislostí</a></p>
<p><a href="#k16">16. Polynomická regrese</a></p>
<p><a href="#k17">17. Polynomická regrese nad daty s&nbsp;nelinearitou</a></p>
<p><a href="#k18">18. Vyšší stupeň polynomu = lepší model?</a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Balíček scikit-learn: modely provádějící regresní analýzu</h2>

<p><a
href="https://www.root.cz/clanky/balicek-scikit-learn-modely-provadejici-klasifikaci/">V&nbsp;předchozím
článku</a> o knihovně <i>scikit-learn</i> jsme si ukázali některé základní
koncepty, které se aplikují při práci s&nbsp;modely provádějícími takzvanou
<i>klasifikaci</i>. Jedná se o takové modely, které pro nějaká (neznámá)
vstupní data odhadnou resp.&nbsp;přesněji řečeno vypočítají hodnotu, která
patří do nějaké spočetné (a typicky relativně malé) množiny. Příkladem může být
model, který rozpoznává číslice na obrázku. Výsledkem je potom celočíselná
hodnota v&nbsp;rozsahu &bdquo;0&ldquo; až &bdquo;9&ldquo;.</p>

<p>A samozřejmě i naše jednoduché modely určené pro rozpoznávání druhů kosatců
odpovídaly celočíselnými hodnotami &bdquo;0&ldquo; až &bdquo;2&ldquo;, které
jsou přiřazeny druhům &bdquo;Iris setoza&ldquo;, &bdquo;Iris versicolor&ldquo;
a &bdquo;Iris virginica&ldquo;. Nebo se například může jednat o model, kterému
se předá e-mail a výsledkem bude hodnota &bdquo;spam&ldquo; nebo  &bdquo;není
to spam&ldquo;. Podobných modelů a příkladů <i>klasifikace</i> lze najít velké
množství.</p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Regresní analýza a lineární regrese</h2>

<p>Existuje však ještě jeden typ problémů, které lze řešit s&nbsp;využitím
(natrénovaných) modelů. U těchto problémů očekáváme, že model odpoví nějakou
číselnou hodnotou, která ovšem typicky sice spadá do nějakého intervalu, ale
hodnoty netvoří nějakou malou množinu a typicky se ani nejedná o hodnoty
celočíselné. Příkladem mohou být modely předpovídající nějakou událost
v&nbsp;rozsahu 0-100%, modely naznačující, kolik akcií koupit nebo prodat
(kladná či záporná hodnota), model který na základě různých zadaných údajů
odhadne cenu nemovitosti atd. &ndash; takových problémů a jejich řešení pomocí
modelů opět existuje celá řada.</p>

<p>Modely s&nbsp;tímto typem odpovědí se nazývají modely provádějící
<i>regresní analýzu</i>. Nejjednodušší je přitom využití <i>lineární
regrese</i>, která je velmi užitečná, protože parametrům regresní přímky je
typicky možné přiřadit reálný význam &ndash; a tak pochopit, co se vlastně
model naučil a jaké fakty si odvodil (to u složitějších modelů bývá
problematické).</p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Datová sada <i>California housing</i></h2>

<p>V&nbsp;dnešním článku využijeme datovou sadu, která je součástí knihovny
<i>scikit-learn</i>. Tato datová sada se jmenuje <i>California housings</i> a
obsahuje parametry domů (resp.&nbsp;celých bloků) a jejich cenu. Cena může být
prakticky libovolná, takže tuto datovou sadu skutečně budeme zpracovávat pomocí
modelů provádějících regresní analýzu.</p>

<p>Načtení datové sady <i>California housings</i> je prakticky stejně snadné,
jako načtení sady <i>Iris</i>. Je zde ovšem jedna změna &ndash; při prvním
spuštění příkladu se stáhne soubor <strong>cal_housing_py3.pkz</strong>, který
se uloží v&nbsp;domovském adresáři do podadresáře
<strong>scikit_learn_data</strong>. Tento soubor je následně používán:</p>

<pre>
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># jakeho typu je vlastne datova sada?</i>
print(type(housings))
&nbsp;
print("-" * 100)
&nbsp;
<i># dostupne atributy a metody</i>
print(dir(housings))
</pre>

<p>Načtená datová sada je opět typu <strong>Bunch</strong> a obsahuje nám známé
atributy:</p>

<pre>
&lt;class 'sklearn.utils._bunch.Bunch'&gt;
----------------------------------------------------------------------------------------------------
['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']
</pre>

<p>Pro zajímavost si zobrazme i metainformace o načtené datové sadě:</p>

<pre>
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
print(dir(housings))
&nbsp;
print("-" * 100)
&nbsp;
<i># podrobny popis datove sady</i>
print(housings["DESCR"])
</pre>

<p>Výsledek:</p>

<pre>
['DESCR', 'data', 'feature_names', 'frame', 'target', 'target_names']
----------------------------------------------------------------------------------------------------
.. _california_housing_dataset:
&nbsp;
California Housing dataset
--------------------------
&nbsp;
**Data Set Characteristics:**
&nbsp;
:Number of Instances: 20640
&nbsp;
:Number of Attributes: 8 numeric, predictive attributes and the target
&nbsp;
:Attribute Information:
    - MedInc        median income in block group
    - HouseAge      median house age in block group
    - AveRooms      average number of rooms per household
    - AveBedrms     average number of bedrooms per household
    - Population    block group population
    - AveOccup      average number of household members
    - Latitude      block group latitude
    - Longitude     block group longitude
&nbsp;
:Missing Attribute Values: None
&nbsp;
This dataset was obtained from the StatLib repository.
https://www.dcc.fc.up.pt/~ltorgo/Regression/cal_housing.html
&nbsp;
The target variable is the median house value for California districts,
expressed in hundreds of thousands of dollars ($100,000).
&nbsp;
This dataset was derived from the 1990 U.S. census, using one row per census
block group. A block group is the smallest geographical unit for which the U.S.
Census Bureau publishes sample data (a block group typically has a population
of 600 to 3,000 people).
&nbsp;
A household is a group of people residing within a home. Since the average
number of rooms and bedrooms in this dataset are provided per household, these
columns may take surprisingly large values for block groups with few households
and many empty houses, such as vacation resorts.
&nbsp;
It can be downloaded/loaded using the
:func:`sklearn.datasets.fetch_california_housing` function.
&nbsp;
.. topic:: References
&nbsp;
    - Pace, R. Kelley and Ronald Barry, Sparse Spatial Autoregressions,
      Statistics and Probability Letters, 33 (1997) 291-297
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. Přístup k&nbsp;atributům jednotlivých domů, zjištění jmen atributů i cen domů</h2>

<p>Samotné informace o domech/blocích jsou dostupné v&nbsp;atributu nazvaném
<strong>data</strong> popř.&nbsp;pod klíčem &bdquo;data&ldquo;, pokud budeme
k&nbsp;datové sadě přistupovat tak, jakoby se jednalo o slovník. Všechny
atributy jsou uloženy formou n-dimenzionálního pole knihovny NumPy, což je
datová struktura, se kterou jsme se již na Rootu několikrát setkali.
V&nbsp;tomto konkrétním případě bude pole dvourozměrné, takže si ho můžeme
představit jako matici se 20640 řádky (počet záznamů) a osmi sloupci:</p>

<pre>
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
print("Feature data:")
print(data)
print("-" * 100)
&nbsp;
<i># typ a "tvar" n-dimenzionalniho pole</i>
print("Data type:")
print(type(data))
print()
&nbsp;
print("Data shape:")
print(data.shape)
</pre>

<p>Takto by měly vypadat výsledky (samotné pole je zobrazeno ve zkrácené
podobě):</p>

<pre>
Feature data:
[[   8.3252       41.            6.98412698 ...    2.55555556
    37.88       -122.23      ]
 [   8.3014       21.            6.23813708 ...    2.10984183
    37.86       -122.22      ]
 [   7.2574       52.            8.28813559 ...    2.80225989
    37.85       -122.24      ]
 ...
 [   1.7          17.            5.20554273 ...    2.3256351
    39.43       -121.22      ]
 [   1.8672       18.            5.32951289 ...    2.12320917
    39.43       -121.32      ]
 [   2.3886       16.            5.25471698 ...    2.61698113
    39.37       -121.24      ]]
----------------------------------------------------------------------------------------------------
Data type:
&lt;class 'numpy.ndarray'&gt;
&nbsp;
Data shape:
(20640, 8)
</pre>

<p>Jednotlivé atributy (taktéž proměnné), což jsou v&nbsp;našem konkrétním
případě atributy domů/bloků, jsou pojmenovány, přičemž tato jména nalezneme
v&nbsp;atributu objektu typu Bunch, který se jmenuje
<strong>feature_names</strong>, popř.&nbsp;pod stejně pojmenovaným klíčem.
Jedná se o pole obsahující osmici řetězců obsahujících jak měřenou veličinu,
tak i její jednotku. V&nbsp;atributu <strong>target_names</strong> je nyní
jediná položka: cena domu. A jednotlivé ceny jsou uloženy v&nbsp;atributu
<strong>targets</strong>. Jedná se o vektor (tedy vlastně o jednorozměrné pole)
s&nbsp;20640 prvky:</p>

<pre>
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># jmena atributu</i>
print("Feature names:")
print(housings["feature_names"])
&nbsp;
print("-" * 100)
&nbsp;
<i># vazba mezi numerickou hodnotou a lidskym vyjadrenim hodnoty</i>
<i># atributu</i>
print("Target names:")
print(housings["target_names"])
&nbsp;
print("-" * 100)
&nbsp;
<i># druhy rostlin z datove sady v numericke podobe</i>
print("Targets:")
print(housings["target"])
</pre>

<p>Opět se podívejme na zobrazené výsledky:</p>

<pre>
Feature names:
['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']
----------------------------------------------------------------------------------------------------
Target names:
['MedHouseVal']
----------------------------------------------------------------------------------------------------
Targets:
[4.526 3.585 3.521 ... 0.923 0.847 0.894]
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Korelační diagram pro dvojici vybraných proměnných</h2>

<p>Podobně jako u sady <i>Iris</i> i nyní můžeme při zkoumání dat začít
klasickým korelačním diagramem a zjistit, jaký je vztah (například) mezi dvěma
proměnnými (vyberme <i>MedInc</i> a <i>AveRooms</i>, tedy medián příjmů a
průměrný počet místností pro domácnost &ndash; zajímavá volba pro korelaci). To
je pro knihovnu Matplotlib snadný úkol. Užitečné je ovšem vědět, jak
z&nbsp;pole (matice) s&nbsp;rozměry květů získat příslušné sloupce. Navíc
jednotlivé body korelačního diagramu obarvíme podle zjištěné ceny (tuto
informaci máme k&nbsp;dispozici a používá se pro trénink modelů, jak již
víme):</p>

<pre>
import matplotlib.pyplot as plt
&nbsp;
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
&nbsp;
<i># vykresleni korelacniho diagramu pro dvojici vybranych atributu</i>
<i># prvni sloupec: x-ove souradnice</i>
<i># druhy sloupec: y-ove souradnice</i>
plt.scatter(data[:, 0], data[:, 2], c=housings.target, s=2)
plt.title("Classes")
&nbsp;
<i># popisky os</i>
plt.xlabel(housings.feature_names[0])
plt.ylabel(housings.feature_names[2])
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("76.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>

<p>Výsledek by mohl vypadat následovně:</p>

*** image ***
<p><i>Obrázek 1: Korelace (existuje?) mezi mediánem příjmů (MedInc) a průměrným
počtem místností (AveRooms) v&nbsp;domácnosti. Barevně jsou odlišeny ceny
jednotek, které (zdá se) více odpovídají mediánu příjmů. Ovšem to za nás již
zjistí model.</i></p>

<p>Podobně si můžeme zobrazit závislost mezi celkovým počtem místností
v&nbsp;bloku a počtem ložnic. Zde již očekáváme skutečnou korelaci:</p>

*** image ***
<p><i>Obrázek 2: Korelace mezi celkovým počtem místností v&nbsp;bloku a počtem
ložnic (AveRooms, AveBdrms).</i></p>

<p><div class="rs-tip-major">Poznámka: některé hodnoty &bdquo;uletěly&ldquo;
(velký blok), ovšem filtraci můžeme provést později.</div></p>

<pre>
import matplotlib.pyplot as plt
&nbsp;
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
FIRST_DIM = 2
SECOND_DIM = 3
&nbsp;
<i># vykresleni korelacniho diagramu pro dvojici vybranych atributu</i>
<i># prvni sloupec: x-ove souradnice</i>
<i># druhy sloupec: y-ove souradnice</i>
plt.scatter(data[:, FIRST_DIM], data[:, SECOND_DIM], c=housings.target, s=2)
plt.title("Classes")
&nbsp;
<i># popisky os</i>
plt.xlabel(housings.feature_names[FIRST_DIM])
plt.ylabel(housings.feature_names[SECOND_DIM])
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("76_B.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. Korelační diagram pro všechny kombinace dvojic proměnných</h2>

<p>V&nbsp;datové sadě, kterou zpracováváme, je pro každý blok domů uloženo
celkem osm atributů, ovšem v&nbsp;korelačním diagramu dokážeme přiměřeným
způsobem zobrazit vztahy mezi dvěma atributy, maximálně mezi třemi atributy
(když zobrazíme 3D diagram, který ovšem ztrácí přehlednost). Abychom zjistili,
mezi jakou kombinací atributů existuje nějaký vztah (pokud existuje), budeme
muset skutečně zobrazit všechny možné kombinace, což je ukázáno v&nbsp;dalším
skriptu:</p>

<pre>
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># vykresleni mrizky korelacnich diagramu</i>
fig, axes = plt.subplots(nrows=8, ncols=8)
&nbsp;
<i># rozmery vysledneho obrazku</i>
fig.set_figheight(15)
fig.set_figwidth(15)
&nbsp;
<i># vyplneni mrizky</i>
for row in range(8):
    for column in range(8):
        ax = axes[row][column]
        if row == column:
            # na diagonale jsou prazdna mista
            fig.delaxes(ax)
            continue
        <i># pridat korelacni diagram do mrizky</i>
        <i># sloupec row: x-ove souradnice</i>
        <i># sloupec column: y-ove souradnice</i>
        scatter = ax.scatter(data[:, row], data[:, column], c=housings.target, s=1)
        <i># popisky os</i>
        ax.set(xlabel=housings.feature_names[row], ylabel=housings.feature_names[column])
&nbsp;
&nbsp;
<i># zbavit se prazdneho mista okolo bunek mrizky</i>
plt.tight_layout()
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("77.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>

<p>Výsledek může vypadat následovně:</p>

*** image ***
<p><i>Obrázek 3: Všechny kombinace korelací dvou atributů (proměnných).</i></p>

<p><div class="rs-tip-major">Poznámka: tento skript zdánlivě nic nezobrazí,
protože musí vypočítat velké množství diagramů a navíc je ještě datová sada
poměrně rozsáhlá. Je tedy nutné několik sekund počkat &ndash; k&nbsp;vykreslení
diagramů nakonec dojde.</div></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Dvourozměrné hodnoty reprezentované jako dvojice atributů</h2>

<p>Mnohdy se setkáme s&nbsp;tím, že vícerozměrné hodnoty jsou v&nbsp;datové
sadě reprezentované jako dvojice, trojice atd. atributů, protože
<i>scikit-learn</i> každý záznam chápe jako jednorozměrné pole (vektor). To je
ostatně i případ datové sady <i>California housings</i>, protože sedmý a osmý
atribut obsahují souřadnice bloku (zeměpisnou výšku a délku). Ostatně nejlépe
bude význam těchto dvou atributů patrný ve chvíli, kdy si je vykreslíme do
korelačního diagramu. To je snadné:</p>

<pre>
import matplotlib.pyplot as plt
&nbsp;
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
FIRST_DIM = 6
SECOND_DIM = 7
&nbsp;
<i># vykresleni korelacniho diagramu pro dvojici vybranych atributu</i>
<i># prvni sloupec: x-ove souradnice</i>
<i># druhy sloupec: y-ove souradnice</i>
plt.scatter(data[:, FIRST_DIM], data[:, SECOND_DIM], s=2)
plt.title("Classes")
&nbsp;
<i># popisky os</i>
plt.xlabel(housings.feature_names[FIRST_DIM])
plt.ylabel(housings.feature_names[SECOND_DIM])
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("78.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>

<p>Výsledek by přitom měl vypadat následovně:</p>

*** image ***
<p><i>Obrázek 4: Vynesením souřadnic bloků jsme vlastně do určité míry získali
mapu zastavění sledované oblasti.</i></p>



<p><a name="k08"></a></p>
<h2 id="k08">8. Regresní analýza</h2>

<p>Prozatím jsme datovou sadu <i>California housings</i> zkoumali pouze
základními vizualizačními prostředky; nyní ovšem konečně přichází na řadu
použití modelů. V&nbsp;dnešním článku se zaměříme především na model založený
na klasické <i>regresní analýze</i>, konkrétně s&nbsp;využitím <i>lineární
regrese</i>. Jedná se o interně velmi jednoduchý model, což je velká výhoda i
nevýhoda současně. Výhodou je, že po naučení (natrénování) si můžeme zobrazit
koeficienty modelu a mnohdy z&nbsp;nich pochopit, co se model vlastně naučil a
jaké jsou skutečné vztahy mezi atributy (proměnnými) a výslednou hodnotou. To
je mnohdy velmi důležité. Nevýhodou je to, že zdaleka ne všechny závislosti
v&nbsp;reálném světě mají lineární charakter (tedy například že pravděpodobnost
nakažení nějakou přenosnou nemocí závisí lineárně na času stráveného
s&nbsp;nemocným a taktéž lineárně na jeho věku a řekněme váze). Při
nelineárních závislostech je vhodnější použít komplikovanější modely,
k&nbsp;nimž se ostatně ještě později vrátíme.</p>



<p><a name="k09"></a></p>
<h2 id="k09">9. Model <i>LinearRegression</i> nad uměle vytvořenými daty</h2>

<p>Ukažme si nyní použití modelu nazvaného <i>LinearRegression</i> pro
proložení nějakých (pseudo)naměřených dat přímkou, tedy polynomem stupně jedna.
Jedná se o klasickou <i>lineární regresi</i> používanou v&nbsp;mnoha
technických oborech. Povšimněte si, že hodnoty na x-ové ose pravidelně rostou,
zatímco na y-ové ose hodnoty sice taktéž obecně rostou, ale navíc jsou náhodně
modifikovány:</p>

<pre>
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
from sklearn import linear_model
&nbsp;
VALUES = 50
&nbsp;
x = np.linspace(0, 10, VALUES)
y = np.linspace(-1, 1, VALUES) + 0.5*np.random.rand(VALUES)
&nbsp;
<i># konstrukce modelu</i>
lr = <strong>linear_model.LinearRegression()</strong>
&nbsp;
<i># trénink modelu</i>
lr.fit(x.reshape(-1, 1), y)
&nbsp;
<i># predikce modelu</i>
y_pred = lr.predict(x.reshape(-1, 1))
&nbsp;
<i># výpis vypočtených koeficientů modelu</i>
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)
&nbsp;
<i># vykreslení výsledku</i>
plt.scatter(x, y, color="black", s=2)
plt.plot(x, y_pred, color="blue", linewidth=2)
&nbsp;
<i># titulek grafu</i>
plt.title("Linear regression")
&nbsp;
<i># osy</i>
plt.xticks(())
plt.yticks(())
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("79.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>

<p>Skript po svém spuštění nejdříve vypíše koeficient regresního modelu, což je
vlastně směrnice úsečky, kterou jsou data proložena. Dále se vypíše hodnota
odpovídající y-ovému posunu:</p>

<pre>
Coefficients: 
 [0.1991314]
Intercept: 
 -0.7428300973657997
</pre>

<p>A samozřejmě se vykreslí jak body, pro které se lineární regrese počítala a
úsečka vypočtená modelem:</p>

*** image ***
<p><i>Obrázek 5: Proložení bodů úsečkou (lineární regrese) tak, aby čtverec
chyb byl co nejmenší.</i></p>

<p>Pokusme se nyní z&nbsp;dat odstranit náhodnost, což znamená, že všechny body
budou ležet na stejné přímce:</p>

<pre>
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
from sklearn import linear_model
&nbsp;
VALUES = 50
&nbsp;
x = np.linspace(0, 10, VALUES)
y = np.linspace(-1, 1, VALUES)
&nbsp;
<i># konstrukce modelu</i>
lr = <strong>linear_model.LinearRegression()</strong>
&nbsp;
<i># trénink modelu</i>
lr.fit(x.reshape(-1, 1), y)
&nbsp;
<i># predikce modelu</i>
y_pred = lr.predict(x.reshape(-1, 1))
&nbsp;
1# výpis vypočtených koeficientů modelu
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)
&nbsp;
<i># vykreslení výsledku</i>
plt.scatter(x, y, color="black", s=2)
plt.plot(x, y_pred, color="blue", linewidth=2)
&nbsp;
<i># titulek grafu</i>
plt.title("Linear regression")
&nbsp;
<i># osy</i>
plt.xticks(())
plt.yticks(())
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("79.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>

<p>Nyní bude směrnice vypočtené úsečky rovna přesně 0,2 (vypočteno jako 2/10) a
její posun -1 ve směru y-ové osy:</p>

<pre>
Coefficients:
 [0.2]
Intercept:
 -1.0
</pre>

<p>Takovou úsečku lze nakreslit snadno:</p>

*** image ***
<p><i>Obrázek 6: Nyní úsečka přesně prochází všemi body.</i></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Predikce modelu provádějícího lineární regresi</h2>

<p>Ve skutečnosti není model <strong>LinearRegression</strong> používán pouze
pro proložení dat úsečkou, ale můžeme s&nbsp;ním provádět i predikce. Je to ve
skutečnosti velmi snadné a vlastně se nejedná o žádnou novinku, ale naopak o
postup, který již dobře známe &ndash; data rozdělíme na tréninkovou část a
testovací část. Následně model natrénujeme pouze s&nbsp;využitím tréninkových
dat a necháme model předpovědět hodnoty pro testovací data, což v&nbsp;našem
umělém příkladu budou pouze x-ové souřadnice. Model pro každou takovou x-ovou
souřadnici vypočítá souřadnici y-ovou, a to tak, aby ležela na vypočtené úsečce
(model si totiž pamatuje jen směrnici a posun této úsečky):</p>

<pre>
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
&nbsp;
VALUES = 100
&nbsp;
x = np.linspace(0, 10, VALUES)
y = np.linspace(-1, 1, VALUES) + 0.5*np.random.rand(VALUES)
&nbsp;
<i># rozdělení dat na trénovací a testovací část</i>
x_train, x_test, y_train, y_test = <strong>train_test_split(x, y, test_size=0.6)</strong>
&nbsp;
print("Array sizes:")
print(f"x_train: {len(x_train)}")
print(f"y_train: {len(y_train)}")
print(f"x_test:  {len(x_test)}")
print(f"y_test:  {len(y_test)}")
&nbsp;
<i># konstrukce modelu</i>
lr = <strong>linear_model.LinearRegression()</strong>
&nbsp;
<i># trénink modelu</i>
lr.fit(x_train.reshape(-1, 1), y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = lr.predict(x_test.reshape(-1, 1))
&nbsp;
<i># výpis vypočtených koeficientů modelu</i>
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)
&nbsp;
<i># vykreslení výsledku</i>
plt.scatter(x_test, y_test, color="black", s=2)
plt.plot(x_test, y_pred, color="blue", linewidth=2)
&nbsp;
<i># titulek grafu</i>
plt.title("Linear regression")
&nbsp;
<i># osy</i>
plt.xticks(())
plt.yticks(())
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("80.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>

<p>Skript běžným způsobem spustíme:</p>

<pre>
Array sizes:
x_train: 40
y_train: 40
x_test:  60
y_test:  60
Coefficients: 
 [0.20740958]
Intercept: 
 -0.7674754384139917
</pre>

<p>Ve výsledném obrázku se zobrazí testovací body (nikoli body trénovací) i
předpověď modelu, tj.&nbsp;vlastně body ležící na úsečce (tyto body skutečně
úsečkou spojíme):</p>

*** image ***
<p><i>Obrázek 7: Testovací data (body) a odhadnutí výsledků modelem.</i></p>

<p>Model ovšem musíme vhodně natrénovat. Pokud mu předáme jen malé množství dat
pro trénink, může se stál, že vypočtená úsečka &bdquo;ulétne&ldquo;:</p>

*** image ***
<p><i>Obrázek 8: Nyní bylo pro trénink použito jen velmi malé množství dat (bodů).</i></p>

<p>Nyní jsme modelu předali jen minimum dat pro trénink:</p>

<pre>
VALUES = 100
&nbsp;
x = np.linspace(0, 10, VALUES)
y = np.linspace(-1, 1, VALUES) + 0.5*np.random.rand(VALUES)
&nbsp;
x_train, x_test, y_train, y_test = train_test_split(x, y, <strong>test_size=0.97</strong>)
&nbsp;
print("Array sizes:")
print(f"x_train: {len(x_train)}")
print(f"y_train: {len(y_train)}")
print(f"x_test:  {len(x_test)}")
print(f"y_test:  {len(y_test)}")
...
...
...
</pre>

<p>To je ostatně patrné již po spuštění skriptu:</p>

<pre>
Array sizes:
x_train: 3
y_train: 3
x_test:  97
y_test:  97
Coefficients: 
 [0.18461929]
Intercept: 
 -0.6401611268416783
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. Chování modelu pro zcela náhodná data</h2>

<p>Model založený na lineární regresi je interně, jak již ostatně víme, velmi
jednoduchý a nedokáže korektně zpracovat například náhodná data. V&nbsp;takovém
případě bude výpočet směrnice a posunu úsečky, ale výsledná predikce i chyba
budou příliš velké a v&nbsp;praxi prakticky nepoužitelné. Ostatně si to můžeme
opět velmi snadno ověřit. Povšimněte si, jakým způsobem jsou vypočteny y-ové
souřadnice bodů použitých pro trénink i testování:</p>

<pre>
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
from sklearn import linear_model
from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
&nbsp;
VALUES = 100
&nbsp;
x = np.linspace(0, 10, VALUES)
y = <strong>-1 + 2*np.random.rand(VALUES)</strong>
&nbsp;
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)
&nbsp;
print("Array sizes:")
print(f"x_train: {len(x_train)}")
print(f"y_train: {len(y_train)}")
print(f"x_test:  {len(x_test)}")
print(f"y_test:  {len(y_test)}")
&nbsp;
<i># konstrukce modelu</i>
lr = linear_model.LinearRegression()
&nbsp;
<i># trénink modelu</i>
lr.fit(x_train.reshape(-1, 1), y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = lr.predict(x_test.reshape(-1, 1))
&nbsp;
<i># výpis vypočtených koeficientů modelu</i>
print("Coefficients: \n", lr.coef_)
&nbsp;
<i># vykreslení výsledku</i>
plt.scatter(x_test, y_test, color="black", s=2)
plt.plot(x_test, y_pred, color="blue", linewidth=2)
&nbsp;
<i># titulek grafu</i>
plt.title("Linear regression")
&nbsp;
<i># osy</i>
plt.xticks(())
plt.yticks(())
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("81.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>

<p>Vypočtená směrnice a posun úsečky po spuštění a tréninku modelu:</p>

<pre>
Array sizes:
x_train: 40
y_train: 40
x_test:  60
y_test:  60
Coefficients:
 [0.04072739]
Intercept:
 -0.2650716913256721
</pre>

<p>A takto bude vypadat výsledný diagram s&nbsp;testovacími daty a
s&nbsp;odpovědí modelu (modré body pospojované úsečkami):</p>

*** image ***
<p><i>Obrázek 9: Model založený na lineární regresi a náhodná data.</i></p>



<p><a name="k12"></a></p>
<h2 id="k12">12. Výpočet chyby &ndash; základní metriky modelu lineární regrese</h2>

<p>V&nbsp;navazujícím textu se budeme věnovat &bdquo;ladění&ldquo; modelů.
V&nbsp;tomto případě je vhodné zjistit, jak dobrý odhad vlastně model lineární
regrese má. To je poměrně snadné určit, protože nám k&nbsp;tomu knihovna
<i>scikit-learn</i> nabízí prostředky. Jedná se především o výpočet střední
kvadratické chyby (<i>mean squared error</i> neboli <i>MSE</i>). Pro každý bod
odhadnutý modelem se vypočítá čtverec jeho vzdálenosti od skutečné pozice bodu;
z&nbsp;takto získaných výsledků se vypočte střední hodnota. Pro různě
nakonfigurovaný model se <i>stejnými testovacími daty</i> potom můžeme tyto
hodnoty porovnat, přičemž čím menší hodnotu získáme, tím lépe model odpovídal
(pro různá data to není možné, protože výsledkem je hodnota
s&nbsp;rozměrem).</p>

<p>Můžeme taktéž použít výpočet <i>R<sup>2</sup> score</i>, který nám poskytne
relativní skóre (ohodnocení modelu). Nejlepší modely, které odpovídají vždy
přesně, mají skóre rovno 1, horší modely budou mít skóre nižší, klidně i
záporné.</p>

<p>Postup je snadný. Nejdříve model natrénujeme tak, jak to již známe:</p>

<pre>
<i># trénink modelu</i>
lr.fit(x_train.reshape(-1, 1), y_train)
</pre>

<p>Dále necháme model odhadnout výsledky pro trénovací data:</p>

<pre>
<i># predikce modelu</i>
y_pred = lr.predict(x_test.reshape(-1, 1))
</pre>

<p>Naimportujeme dvě výše zmíněné funkce pro hodnocení modelu:</p>

<pre>
from sklearn.metrics import mean_squared_error, r2_score
</pre>

<p>A na základě odhadnutých dat a očekávaných hodnot můžeme model ohodnotit (a
později porovnat):</p>

<pre>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
</pre>



<p><a name="k13"></a></p>
<h2 id="k13">13. Praktický příklad: výpočet chyby a skóre modelu pro čtyři odlišné datové sady</h2>

<p>Ukažme si na praktickém příkladu, jak vlastně probíhá výpočet chyby a skóre
modelu lineární regrese. Použijeme přitom čtyři zcela odlišné datové sady:</p>

<ol>
<li>Body ležící na přímce, ovšem s&nbsp;přidanou náhodností (šumem)</li>
<li>Body ležící přímo na přímce</li>
<li>Náhodně rozmístěné body</li>
<li>Body získané z&nbsp;datové sady <i>California housings</i> (souřadnice bloků)</li>
</ol>

<p>Zdrojový kód příkladu vypadá následovně:</p>

<pre>
import numpy as np
from sklearn import linear_model
from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
&nbsp;
&nbsp;
def <strong>errors_and_score_for_linear_regression</strong>(x_train, x_test, y_train, y_test):
    <i># konstrukce modelu</i>
    lr = linear_model.LinearRegression()
&nbsp;
    <i># trénink modelu</i>
    lr.fit(x_train.reshape(-1, 1), y_train)
&nbsp;
    <i># predikce modelu</i>
    y_pred = lr.predict(x_test.reshape(-1, 1))
&nbsp;
    <i># výpis vypočtených koeficientů modelu</i>
    print("    Coefficients:      ", lr.coef_)
    print("    Intercept:         ", lr.intercept_)
&nbsp;
    <i># chyba predikce</i>
    print("    Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
    <i># 1 = nejlepší predikce modelu</i>
    print("    Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
    print()
&nbsp;
&nbsp;
&nbsp;
<i># ------------------------------------------------------------------------</i>
<i># zcela nenáhodná data</i>
&nbsp;
VALUES = 100
&nbsp;
x = np.linspace(0, 10, VALUES)
y = np.linspace(-1, 1, VALUES)
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)
&nbsp;
print("Non-random data that are on one line:")
errors_and_score_for_linear_regression(x_train, x_test, y_train, y_test)
&nbsp;
&nbsp;
&nbsp;
<i># ------------------------------------------------------------------------</i>
<i># data obsahující náhodné odchylky</i>
&nbsp;
VALUES = 100
&nbsp;
x = np.linspace(0, 10, VALUES)
y = np.linspace(-1, 1, VALUES) + 0.5*np.random.rand(VALUES)
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)
&nbsp;
print("Data with added randomness that are on one line:")
errors_and_score_for_linear_regression(x_train, x_test, y_train, y_test)
&nbsp;
&nbsp;
&nbsp;
<i># ------------------------------------------------------------------------</i>
<i># zcela náhodná data</i>
&nbsp;
VALUES = 100
&nbsp;
x = np.linspace(0, 10, VALUES)
y = -1 + 2*np.random.rand(VALUES)
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.6)
&nbsp;
print("Totally random data:")
errors_and_score_for_linear_regression(x_train, x_test, y_train, y_test)
&nbsp;
&nbsp;
&nbsp;
<i># ------------------------------------------------------------------------</i>
<i># California housings</i>
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
FIRST_DIM = 6
SECOND_DIM = 7
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
x_train, x_test, y_train, y_test = train_test_split(data[:, FIRST_DIM], data[:, SECOND_DIM], test_size=0.6)
&nbsp;
print("California housings data: longitude/lattitude:")
errors_and_score_for_linear_regression(x_train, x_test, y_train, y_test)
</pre>

<p>Výsledky odpovídají očekávání, což se týká výsledného skóre:</p>

<pre>
Non-random data that are on one line:
    Coefficients:       [0.2]
    Intercept:          -0.9999999999999999
    Mean squared error: 0.00
    Coefficient of determination: 1.00
&nbsp;
Data with added randomness that are on one line:
    Coefficients:       [0.19224885]
    Intercept:          -0.7319112328028108
    Mean squared error: 0.02
    Coefficient of determination: 0.94
&nbsp;
Totally random data:
    Coefficients:       [0.05727984]
    Intercept:          -0.32444669595342196
    Mean squared error: 0.46
    Coefficient of determination: -0.13
&nbsp;
California housings data: longitude/lattitude:
    Coefficients:       [-0.87110537]
    Intercept:          -88.54126270759419
    Mean squared error: 0.59
    Coefficient of determination: 0.85
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Predikce modelu pro datovou sadu <i>California housing</i></h2>

<p>Prozatím jsme lineární regresní analýzu používali nad umělými daty. Pokusme
se tedy nyní model natrénovat takovým způsobem, aby dokázal na základě
předaného počtu místností v&nbsp;bloku odhadnout, kolik z&nbsp;těchto místností
je ložnicemi. Dopředu ovšem nevíme, zda se jedná o lineární závislost či
nikoli. Napovědět nám pomůže jak graf s&nbsp;vykreslenými odhady modelu pro
testovací data, tak i výpočet chyby a skóre modelu:</p>

<pre>
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
from sklearn import linear_model
from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
FIRST_DIM = 2
SECOND_DIM = 3
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
x_train, x_test, y_train, y_test = train_test_split(data[:, FIRST_DIM], data[:, SECOND_DIM], test_size=0.6)
&nbsp;
print("Array sizes:")
print(f"x_train: {len(x_train)}")
print(f"y_train: {len(y_train)}")
print(f"x_test:  {len(x_test)}")
print(f"y_test:  {len(y_test)}")
&nbsp;
<i># konstrukce modelu</i>
lr = linear_model.LinearRegression()
&nbsp;
<i># trénink modelu</i>
lr.fit(x_train.reshape(-1, 1), y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = lr.predict(x_test.reshape(-1, 1))
&nbsp;
<i># výpis vypočtených koeficientů modelu</i>
print("Coefficients: \n", lr.coef_)
&nbsp;
<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
&nbsp;
<i># vykreslení výsledku</i>
plt.scatter(x_test, y_test, color="black", s=1)
plt.plot(x_test, y_pred, color="blue", linewidth=3)
&nbsp;
<i># osy</i>
plt.xlabel(housings.feature_names[FIRST_DIM])
plt.ylabel(housings.feature_names[SECOND_DIM])
plt.xticks(())
plt.yticks(())
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("82.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>

<p>Výsledek bude vypadat následovně:</p>

*** image ***
<p><i>Obrázek 10: Odhad počtu ložnic na celkovém počtu místností v&nbsp;bloku.</i></p>



<p><a name="k15"></a></p>
<h2 id="k15">15. Lineární regrese nad daty s&nbsp;nelineární závislostí</h2>

<p>Lineární regrese je sice pro mnoho účelů skvělý nástroj, ovšem (logicky)
nebude příliš funkční nad daty, které nemají interní lineární závislost. To
jsme částečně mohli vidět u náhodných dat, ovšem pojďme si vyzkoušet, co se
stane, když modelu předložíme data, v&nbsp;nichž se navíc nachází i
&bdquo;skok&ldquo; (což je nejlépe patrné z&nbsp;výsledného grafu):</p>

<pre>
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
from sklearn import linear_model
from sklearn.metrics import mean_squared_error, r2_score
&nbsp;
VALUES = 100
&nbsp;
x = np.linspace(0, 10, VALUES)
<strong>y1 = 0.5*np.random.rand(VALUES//2)</strong>
<strong>y2 = 1 + 0.5*np.random.rand(VALUES//2)</strong>
&nbsp;
<i># nelinearita - skok</i>
<strong>y = np.concatenate((y1, y2))</strong>
&nbsp;
<i># konstrukce modelu</i>
lr = linear_model.LinearRegression()
&nbsp;
<i># trénink modelu</i>
lr.fit(x.reshape(-1, 1), y)
&nbsp;
<i># predikce modelu</i>
y_pred = lr.predict(x.reshape(-1, 1))
&nbsp;
<i># výpis vypočtených koeficientů modelu</i>
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)
&nbsp;
<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y, y_pred))
&nbsp;
<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y, y_pred))
&nbsp;
<i># vykreslení výsledku</i>
plt.scatter(x, y, color="black", s=2)
plt.plot(x, y_pred, color="blue", linewidth=2)
&nbsp;
<i># titulek grafu</i>
plt.title("Linear regression")
&nbsp;
<i># osy</i>
plt.xticks()
plt.yticks()
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("88.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>

<p>Výsledky naznačují, že predikce modelu není zcela úspěšná:</p>

<pre>
 [0.14891026]
Intercept: 
 0.018213198056308944
Mean squared error: 0.08
Coefficient of determination: 0.71
</pre>

*** image ***
<p><i>Obrázek 11: Model lineární regrese se snaží proložit úsečkou data, v&nbsp;nichž je skok.</i></p>



<p><a name="k16"></a></p>
<h2 id="k16">16. Polynomická regrese</h2>

<p>V&nbsp;mnoha případech je namísto modelu s&nbsp;interní lineární závislostí
mezi vstupem a výstupem použít polynom vyššího stupně. I to nám knihovna
<i>scikit-learn</i> umožňuje, i když možná poněkud matoucím způsobem (ovšem jen
zdánlivě matoucím):</p>

<pre>
pr = linear_model.LinearRegression()
&nbsp;
poly = PolynomialFeatures(degree=degree)
&nbsp;
poly_features = poly.fit_transform(x.reshape(-1, 1))
&nbsp;
<i># trénink modelu</i>
pr.fit(poly_features, y)
&nbsp;
<i># predikce modelu</i>
y_pred = pr.predict(poly_features)
</pre>

<p>Jedná se vlastně o obecný případ <i>lineární regrese</i>, kdy se jedná o
lineární kombinaci funkcí, v&nbsp;tomto případě funkcí typu
<i>x<sup>n</sup></i> pro nějaké omezené <i>n</i>. Hodnotu <i>n</i> se přitom
snažíme volit co nejmenší, aby bylo možné z&nbsp;nalezených koeficientů
odvodit, co se vlastně model naučil. Na druhou stranu musí být <i>n</i>
dostatečně vysoké na to, aby model dokázal odhadovat výsledky.</p>

<p>Koeficienty modelu s&nbsp;kvadratickým polynomem mohou vypadat následovně:</p>

<pre>
Coefficients: 
 [0.         0.11345465 0.00357484]
Intercept: 
 0.06366079775076627
</pre>

<p>Povšimněte si, že první koeficient je nulový. Jedná se o posun (konstantu),
která je obsažena v&nbsp;<i>intercept</i>. Model však můžeme inicializovat
s&nbsp;parametrem <strong>fit_intercept=False</strong> a poté bude posun
přesunut do prvního koeficientu a atribut <strong>intercept</strong> bude
nulový (což je v&nbsp;tomto případě lepší řešení):</p>

<pre>
Coefficients: 
 [0.02078658 0.1302669  0.0017247 ]
Intercept: 
 0.0
</pre>



<p><a name="k17"></a></p>
<h2 id="k17">17. Polynomická regrese nad daty s&nbsp;nelinearitou</h2>

<p>Pokusme se nyní použít polynomickou regresi s&nbsp;polynomy řádu 1 až 11,
přičemž vždy vykreslíme odhad modelu jakožto lomenou úsečku, která vlastně
aproximuje polynom, jehož koeficienty se model naučil při tréninku:</p>

<pre>
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
from sklearn import linear_model
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
&nbsp;
VALUES = 100
&nbsp;
x = np.linspace(0, 10, VALUES)
y1 = 0.5*np.random.rand(VALUES//2)
y2 = 1 + 0.5*np.random.rand(VALUES//2)
y = np.concatenate((y1, y2))
&nbsp;
for degree in range(1, 12):
    <i># konstrukce modelu</i>
    pr = linear_model.LinearRegression()
&nbsp;
    poly = PolynomialFeatures(degree=degree)
&nbsp;
    poly_features = poly.fit_transform(x.reshape(-1, 1))
&nbsp;
    <i># trénink modelu</i>
    pr.fit(poly_features, y)
&nbsp;
    <i># predikce modelu</i>
    y_pred = pr.predict(poly_features)
&nbsp;
    <i># výpis vypočtených koeficientů modelu</i>
    print("Coefficients: \n", pr.coef_)
    print("Intercept: \n", pr.intercept_)
&nbsp;
    <i># chyba predikce</i>
    print("Mean squared error: %.2f" % mean_squared_error(y, y_pred))
&nbsp;
    <i># 1 = nejlepší predikce modelu</i>
    print("Coefficient of determination: %.2f" % r2_score(y, y_pred))
&nbsp;
    <i># vykreslení výsledku</i>
    plt.scatter(x, y, color="black", s=1)
    plt.plot(x, y_pred, color="blue", linewidth=2)
&nbsp;
    <i># titulek grafu</i>
    plt.title(f"Degree={degree}")
&nbsp;
    <i># osy</i>
    plt.xticks(())
    plt.yticks(())
&nbsp;
    <i># ulozeni diagramu do souboru</i>
    plt.savefig(f"83_{degree}.png")
&nbsp;
    <i># zobrazeni diagramu</i>
    plt.show()
</pre>

<p>Povšimněte si, že v&nbsp;tomto případě je vhodnější použít polynom lichého
stupně, což vlastně velmi dobře odpovídá vstupním datům:</p>

*** image ***
<p><i>Obrázek 12: Polynomická regrese polynomem stupně 1.</i></p>

*** image ***
<p><i>Obrázek 13: Polynomická regrese polynomem stupně 2.</i></p>

*** image ***
<p><i>Obrázek 14: Polynomická regrese polynomem stupně 3.</i></p>

*** image ***
<p><i>Obrázek 15: Polynomická regrese polynomem stupně 4.</i></p>

*** image ***
<p><i>Obrázek 16: Polynomická regrese polynomem stupně 5.</i></p>

*** image ***
<p><i>Obrázek 17: Polynomická regrese polynomem stupně 6.</i></p>

*** image ***
<p><i>Obrázek 18: Polynomická regrese polynomem stupně 7.</i></p>

*** image ***
<p><i>Obrázek 19: Polynomická regrese polynomem stupně 8.</i></p>

*** image ***
<p><i>Obrázek 20: Polynomická regrese polynomem stupně 9.</i></p>

*** image ***
<p><i>Obrázek 21: Polynomická regrese polynomem stupně 10.</i></p>

*** image ***
<p><i>Obrázek 22: Polynomická regrese polynomem stupně 11.</i></p>



<p><a name="k18"></a></p>
<h2 id="k18">18. Vyšší stupeň polynomu = lepší model?</h2>

<p>Obecně ovšem neplatí, že čím vyšší stupeň polynomu zvolíme, tím lépe. Model
se totiž může přeučit a &bdquo;zakmitávat&ldquo;. S&nbsp;tímto problémem se
podrobněji seznámíme příště, ovšem již nyní si můžeme ukázat závislosti mezi
stupněm polynomu a chybou i skóre:</p>

<pre>
import numpy as np
import matplotlib.pyplot as plt
&nbsp;
from sklearn import linear_model
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error, r2_score
&nbsp;
VALUES = 100
&nbsp;
x = np.linspace(0, 10, VALUES)
y1 = 0.5*np.random.rand(VALUES//2)
y2 = 1 + 0.5*np.random.rand(VALUES//2)
y = np.concatenate((y1, y2))
&nbsp;
degrees = []
mses = []
r2_scores = []
&nbsp;
for degree in range(1, 50):
    <i># konstrukce modelu</i>
    pr = linear_model.LinearRegression(fit_intercept=False)
&nbsp;
    poly = PolynomialFeatures(degree=degree)
&nbsp;
    poly_features = poly.fit_transform(x.reshape(-1, 1))
&nbsp;
    <i># trénink modelu</i>
    pr.fit(poly_features, y)
&nbsp;
    <i># predikce modelu</i>
    y_pred = pr.predict(poly_features)
&nbsp;
    degrees.append(degree)
    mse = mean_squared_error(y, y_pred)
    r2 = r2_score(y, y_pred)
    mses.append(mse)
    r2_scores.append(r2)
    print(degree, mse, r2)
&nbsp;
&nbsp;
plt.plot(degrees, mses, degrees, r2_scores)
&nbsp;
<i># titulek grafu</i>
plt.title("Mode prediction")
plt.legend(["MSE", "R2 score"])
&nbsp;
<i># osy</i>
plt.xticks()
plt.yticks()
&nbsp;
<i># ulozeni diagramu do souboru</i>
plt.savefig("89.png")
&nbsp;
<i># zobrazeni diagramu</i>
plt.show()
</pre>

*** image ***
<p><i>Obrázek 23: Chyba a skóre modelů pro různé stupně polynomu.</i></p>

<p>Numerické výsledky:</p>

<pre>
1 0.08854350477181652 0.6727776670574832
2 0.08847105481617644 0.6730454138963645
3 0.06352553393094755 0.7652343504148237
4 0.06352363502305206 0.7652413680393599
5 0.05139097616802354 0.8100789531967275
6 0.051360414474032764 0.8101918973232574
7 0.04282549807457683 0.8417336265883979
8 0.04272801081159937 0.842093901570802
9 0.037628039473641815 0.860941410752273
10 0.03762741402964682 0.8609437221498588
11 0.03654030854048818 0.8649612409417097
12 0.03649603934320596 0.8651248426655122
13 0.033551344371300515 0.8760072892209562
14 0.034587421482685336 0.8721783514533651
15 0.0349144348488055 0.8709698373241697
16 0.03883429903924582 0.8564835448680573
17 0.0439054993310688 0.8377423622755509
18 0.04718657143483762 0.8256167967570557
19 0.06068608267845382 0.775727857143657
20 0.06067219921030257 0.7757791650385669
21 0.060546395766387956 0.7762440856051972
22 0.06054664801379553 0.7762431533969523
23 0.060416619348441204 0.7767236887375885
24 0.06766439714886716 0.7499387227864862
25 0.07517323686503591 0.722188973598805
26 0.08558129686149148 0.6837248346173771
27 0.09850570476460575 0.6359612531230979
28 0.11332248094826584 0.5812042149642964
29 0.1295420132490688 0.5212631361422777
30 0.1465486596302491 0.4584131900200912
31 0.1638999092609902 0.3942897244054083
32 0.1812521964418129 0.33016242440943333
33 0.19844435668492633 0.26662689125461947
34 0.284832041072001 -0.052628368580522444
35 0.29895181099387746 -0.10480954286716115
36 0.31230328573680555 -0.15415139718909043
37 0.32493332104343997 -0.20082709213513872
38 0.33689126278510223 -0.24501899084054113
39 0.34822667356365017 -0.2869102573922446
40 0.3589877377267896 -0.32667896238626026
41 0.36920578835842205 -0.3644409007060072
42 0.3789544071733879 -0.40046800173189534
43 0.38827003463206067 -0.43489493522301825
44 0.3971522552977659 -0.4677201658871135
45 0.4056720613291159 -0.499206053112615
46 0.4138479677051003 -0.5294210210559303
47 0.4217077493464011 -0.558467715014038
48 0.42928089265327807 -0.5864551052463374
49 0.43657927470983254 -0.6134270848331644
</pre>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu Scikit-learn lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady i na (Jupyter) diáře s&nbsp;postupem
výpočtů a analýz:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td>01_show_matrix.py</td><td>kooperace mezi knihovnami Matplotlib a NumPy: vizualizace obsahu 2D matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py</a></td></tr>
<tr><td> 2</td><td>02_get_digits.py</td><td>datová množina obsahující naskenované ručně napsané číslice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py</a></td></tr>
<tr><td> 3</td><td>03_get_features.py</td><td>další atributy datové množiny, které použijeme při trénování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py</a></td></tr>
<tr><td> 4</td><td>04_get_images.py</td><td>přečtení a následné vykreslení jednotlivých ručně nakreslených číslic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py</a></td></tr>
<tr><td> 5</td><td>05_show_grayscale_matrix.py</td><td>odstranění umělé aplikované barvové palety (obrázky ve stupních šedi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py</a></td></tr>
<tr><td> 6</td><td>06_grayscale_images.py</td><td>vykreslení ručně nakreslených číslic ve formě obrázků ve stupních šedi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py</a></td></tr>
<tr><td> 7</td><td>07_multiplot.py</td><td>rozdělení plochy grafu do oblastí; vykreslení více obrázků do jediného grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py</a></td></tr>
<tr><td> 8</td><td>08_model_preperation_1.py</td><td>obrázky s&nbsp;jejich ohodnocením</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py</a></td></tr>
<tr><td> 9</td><td>09_training_set.py</td><td>příprava dat pro trénink</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py</a></td></tr>
<tr><td>10</td><td>10_classification.py</td><td>klasifikace obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py</a></td></tr>
<tr><td>11</td><td>11_results.py</td><td>vykreslení obrázků společně s&nbsp;jejich klasifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py</a></td></tr>
<tr><td>12</td><td>12_change_training_set.py</td><td>změna poměru rozdělení dat na tréninkovou a testovací množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>13</td><td>13_blobs.py</td><td>použití funkce <strong>make_blobs</strong> pro vygenerování sady bodů v&nbsp;rovině sdružených do oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py</a></td></tr>
<tr><td>14</td><td>14_swap_coords.py</td><td>úprava předchozího příkladu: prohození souřadnic na osách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py</a></td></tr>
<tr><td>15</td><td>15_blobs_scatter_plot.py</td><td>základní podoba bodového diagramu (<i>scatter plot</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py</a></td></tr>
<tr><td>16</td><td>16_blobs_scatter_plot.py</td><td>úprava bodového diagramu při zobrazení většího množství bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py</a></td></tr>
<tr><td>17</td><td>17_colorized_blobs.py</td><td>obarvení bodů podle oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py</a></td></tr>
<tr><td>18</td><td>18_k-means.py</td><td>základní použití algoritmu K-means pro clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py</a></td></tr>
<tr><td>19</td><td>19_combination.py</td><td>zobrazení centroidů společně s&nbsp;původními body</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py</a></td></tr>
<tr><td>20</td><td>20_combinations.py</td><td>vizualizace clusteringu původní množiny bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py</a></td></tr>
<tr><td>21</td><td>21_other_settings.py</td><td>vizualizace clusteringu původní množiny bodů pro odlišnou množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py</a></td></tr>
<tr><td>22</td><td>22_random_points.py</td><td>clustering pro náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>23</td><td>23_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, menší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py</a></td></tr>
<tr><td>24</td><td>24_more_noise_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, větší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py</a></td></tr>
<tr><td>25</td><td>25_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, menší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py</a></td></tr>
<tr><td>26</td><td>26_more_noisy_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, větší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py</a></td></tr>
<tr><td>27</td><td>27_circles_kmeans.py</td><td>výsledek clusteringu provedeného algoritmem K-means na &bdquo;kružnice&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/27_circles_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/27_circles_kmeans.py</a></td></tr>
<tr><td>28</td><td>28_moons_kmeans.py</td><td>výsledek clusteringu provedeného algoritmem K-means na &bdquo;půlměsíce&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/28_moons_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/28_moons_kmeans.py</a></td></tr>
<tr><td>29</td><td>29_blobs_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné pomocí <strong>make_blobs</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/29_blobs_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/29_blobs_spectral_clustering.py</a></td></tr>
<tr><td>30</td><td>30_circles_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné do kružnic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/30_circles_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/30_circles_spectral_clustering.py</a></td></tr>
<tr><td>31</td><td>31_moons_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné do půlměsíců </td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/31_moons_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/31_moons_spectral_clustering.py</a></td></tr>
<tr><td>32</td><td>32_moons_spectral_clustering_limits.py</td><td>vyhledání limitů algoritmu spectral clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/32_moons_spectral_clustering_limits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/32_moons_spectral_clustering_limits.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>33</td><td>33_particles_load.py</td><td>načtení souřadnic částic uložených v&nbsp;souboru formátu CSV</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/33_particles_load.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/33_particles_load.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>34</td><td>34_lorenz_attractor.py</td><td>zobrazení Lorenzova atraktoru formou bodů propojených úsečkami</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/34_lorenz_attractor.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/34_lorenz_attractor.py</a></td></tr>
<tr><td>35</td><td>35_lorenz_attractor_points.py</td><td>Lorenzův atraktor vykreslený formou jednotlivých bodů s&nbsp;definovaným stylem zobrazení a velikostí stopy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/35_lorenz_attractor_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/35_lorenz_attractor_points.py</a></td></tr>
<tr><td>36</td><td>36_blobs_3d.py</td><td>vygenerování a zobrazení sady bodů v&nbsp;3D prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/36_blobs_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/36_blobs_3d.py</a></td></tr>
<tr><td>37</td><td>37_spread_blobs_3d.py</td><td>vygenerování a zobrazení sady bodů v&nbsp;3D prostoru, odlišné parametry při generování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/37_spread_blobs_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/37_spread_blobs_3d.py</a></td></tr>
<tr><td>38</td><td>38_views.py</td><td>různé pohledy na 3D graf</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/38_views.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/38_views.py</a></td></tr>
<tr><td>39</td><td>39_colorized_3d_blobs.py</td><td>obarvení bodů v&nbsp;prostoru na základě vstupních dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/39_colorized_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/39_colorized_3d_blobs.py</a></td></tr>
<tr><td>40</td><td>40_kmeans_3d_blobs.py</td><td>shluková analýza v&nbsp;3D prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/40_kmeans_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/40_kmeans_3d_blobs.py</a></td></tr>
<tr><td>41</td><td>41_kmeans_spread_3d_blobs.py</td><td>shluková analýza v&nbsp;3D prostoru pro odlišnou množinu bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/41_kmeans_spread_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/41_kmeans_spread_3d_blobs.py</a></td></tr>
<tr><td>42</td><td>42_kmeans_random_3d.py</td><td>shluková analýza pro body rozmístěné zcela náhodně v&nbsp;omezeném prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/42_kmeans_random_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/42_kmeans_random_3d.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>43</td><td>43_speed_measurements.py</td><td>benchmark pro postupně rostoucí počet bodů tvořících shluky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/43_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/43_speed_measurements.py</a></td></tr>
<tr><td>44</td><td>44_speed_measurements.py</td><td>benchmark pro postupně rostoucí počet bodů rozmístěných náhodně</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/44_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/44_speed_measurements.py</a></td></tr>
<tr><td>45</td><td>45_speed_measurements.py</td><td>benchmark pro stále stejný počet bodů, u jejichž rozmístění v&nbsp;prostoru se používá stále větší směrodatná odchylka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/45_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/45_speed_measurements.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>46</td><td>46_iris_dataset.py</td><td>načtení datové kolekce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/46_iris_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/46_iris_dataset.py</a></td></tr>
<tr><td>47</td><td>47_iris_description.py</td><td>metadata o datové kolekci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/47_iris_description.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/47_iris_description.py</a></td></tr>
<tr><td>48</td><td>48_iris_data.py</td><td>tvar dat &ndash; počet záznamů a počet proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/48_iris_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/48_iris_data.py</a></td></tr>
<tr><td>49</td><td>49_iris_targets.py</td><td>jména atributů, vztah mezi numerickou hodnotou atributu a jeho jménem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/49_iris_targets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/49_iris_targets.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>50</td><td>50_iris_scatter_plot_1.py</td><td>korelační diagram pro dvojici vybraných proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/50_iris_scatter_plot_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/50_iris_scatter_plot_1.py</a></td></tr>
<tr><td>51</td><td>51_iris_scatter_plot_2.py</td><td>příprava pro tvorbu složitějších grafů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/51_iris_scatter_plot_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/51_iris_scatter_plot_2.py</a></td></tr>
<tr><td>52</td><td>52_iris_mutliplot.py</td><td>mřížka obsahující více korelačních diagramů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/52_iris_mutliplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/52_iris_mutliplot.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>53</td><td>53_iris_histograms.py</td><td>zobrazení základního histogramu pro data v&nbsp;sadě Iris</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/53_iris_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/53_iris_histograms.py</a></td></tr>
<tr><td>54</td><td>54_iris_histograms.py</td><td>úprava histogramu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/54_iris_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/54_iris_histograms.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>55</td><td>55_pca.py</td><td>analýza hlavních komponent (PCA), výsledek zobrazený v&nbsp;2D grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/55_pca.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/55_pca.py</a></td></tr>
<tr><td>56</td><td>56_pca_3d.py</td><td>analýza hlavních komponent (PCA), výsledek zobrazený v&nbsp;3D grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/56_pca_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/56_pca_3d.py</a></td></tr>
<tr><td>57</td><td>57_kmeans.py</td><td>základní shluková analýza</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/57_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/57_kmeans.py</a></td></tr>
<tr><td>58</td><td>58_multiple_kmeans.py</td><td>větší množství výsledků shlukové analýzy pro různé atributy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/58_multiple_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/58_multiple_kmeans.py</a></td></tr>
<tr><td>59</td><td>59_kmeans_errors.py</td><td>korektní a nekorektní výsledky základní shlukové analýzy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/59_kmeans_errors.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/59_kmeans_errors.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>60</td><td>60_basic_classifier.py</td><td>aplikace jednoduchého modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/60_basic_classifier.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/60_basic_classifier.py</a></td></tr>
<tr><td>61</td><td>61_changed_model_parameters.py</td><td>změna parametrů modelu pro zjištění druhů rostil</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/61_changed_model_parameters.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/61_changed_model_parameters.py</a></td></tr>
<tr><td>62</td><td>62_different_model.py</td><td>použití odlišného modelu pro zjištění druhů rostlin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/62_different_model.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/62_different_model.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>63</td><td>63_verify_on_whole_data_1.py</td><td>otestování naučeného modelu s&nbsp;využitím tréninkových dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/63_verify_on_whole_data_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/63_verify_on_whole_data_1.py</a></td></tr>
<tr><td>64</td><td>64_verify_on_whole_data_2.py</td><td>využití funkce <strong>metrics.accuracy_score</strong> pro zjištění kvality modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/64_verify_on_whole_data_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/64_verify_on_whole_data_2.py</a></td></tr>
<tr><td>65</td><td>65_basic_comparison.py</td><td>porovnání vlastností různých modelů (prozatím nekorektní řešení)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/65_basic_comparison.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/65_basic_comparison.py</a></td></tr>
<tr><td>66</td><td>66_training_testing_split_1.py</td><td>rozdělení datové sady na trénovací data a testovací data (základní varianta)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/66_training_testing_split_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/66_training_testing_split_1.py</a></td></tr>
<tr><td>67</td><td>67_training_testing_split_2.py</td><td>rozdělení datové sady na trénovací data a testovací data (náhodné rozdělení sady)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/67_training_testing_split_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/67_training_testing_split_2.py</a></td></tr>
<tr><td>68</td><td>68_training_testing_split_3.py</td><td>rozdělení datové sady na trénovací data a testovací data (využití vestavěné funkce)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/68_training_testing_split_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/68_training_testing_split_3.py</a></td></tr>
<tr><td>69</td><td>69_better_comparison.py</td><td>vylepšené porovnání vlastností různých modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/69_better_comparison.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/69_better_comparison.py</a></td></tr>
<tr><td>70</td><td>70_multiple_runs.py</td><td>vliv generátoru náhodných čísel na změřené výsledky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/70_multiple_runs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/70_multiple_runs.py</a></td></tr>
<tr><td>71</td><td>71_stable_multiple_runs.py</td><td>generátor náhodných čísel a použití hodnoty <strong>random_state</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/71_stable_multiple_runs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/71_stable_multiple_runs.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>72</td><td>72_housings_dataset.py</td><td>načtení datové sady <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/72_housings_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/72_housings_dataset.py</a></td></tr>
<tr><td>73</td><td>73_housings_dataset_description.py</td><td>metainformace o datové sadě <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/73_housings_dataset_description.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/73_housings_dataset_description.py</a></td></tr>
<tr><td>74</td><td>74_housings_data.py</td><td>n-rozměrné pole s&nbsp;atributy jednotlivých domů/bloků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/74_housings_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/74_housings_data.py</a></td></tr>
<tr><td>75</td><td>75_housings_targets.py</td><td>jména atributů, ceny domů atd.</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/75_housings_targets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/75_housings_targets.py</a></td></tr>
<tr><td>76</td><td>76_housings_scatter_plot.py</td><td>korelační diagram pro dvojici vybraných proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/76_housings_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/76_housings_scatter_plot.py</a></td></tr>
<tr><td>77</td><td>77_housings_mutliplot.py</td><td>korelační diagram pro všechny kombinace dvojic proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/77_housings_mutliplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/77_housings_mutliplot.py</a></td></tr>
<tr><td>78</td><td>78_scatter.py</td><td>dvourozměrné hodnoty reprezentované jako dvojice atributů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/78_scatter.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/78_scatter.py</a></td></tr>
<tr><td>79</td><td>79_linear_regression_gen_data.py</td><td>model <i>LinearRegression</i> nad uměle vytvořenými daty</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/79_linear_regression_gen_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/79_linear_regression_gen_data.py</a></td></tr>
<tr><td>80</td><td>80_linear_regression_predictions.py</td><td>predikce modelu provádějícího lineární regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/80_linear_regression_predictions.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/80_linear_regression_predictions.py</a></td></tr>
<tr><td>81</td><td>81_linear_regression_random_data.py</td><td>chování modelu pro zcela náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/81_linear_regression_random_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/81_linear_regression_random_data.py</a></td></tr>
<tr><td>82</td><td>82_linear_regression_housings.py</td><td>model <i>LinearRegression</i> pro datovou sadu <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/82_linear_regression_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/82_linear_regression_housings.py</a></td></tr>
<tr><td>83</td><td>83_polynomial_regression_gen_data.py</td><td>polynomiální regrese (základní příklad)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/83_polynomial_regression_gen_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/83_polynomial_regression_gen_data.py</a></td></tr>
<tr><td>84</td><td>84_polynomial_regression_housings.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, první příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/84_polynomial_regression_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/84_polynomial_regression_housings.py</a></td></tr>
<tr><td>85</td><td>85_polynomial_regression_housings_2.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, druhý příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/85_polynomial_regression_housings_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/85_polynomial_regression_housings_2.py</a></td></tr>
<tr><td>86</td><td>86_polynomial_regression_housings_3.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, třetí příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/86_polynomial_regression_housings_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/86_polynomial_regression_housings_3.py</a></td></tr>
<tr><td>87</td><td>87_linear_regression_errors.py</td><td>výpočet chyby a skóre modelu lineární regrese</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/87_linear_regression_errors.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/87_linear_regression_errors.py</a></td></tr>
<tr><td>88</td><td>88_linear_regression_non_linear_data.py</td><td>lineární regrese nad nelineárními daty</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/88_linear_regression_non_linear_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/88_linear_regression_non_linear_data.py</a></td></tr>
<tr><td>89</td><td>89_polynomial_regression_error.py</td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/89_polynomial_regression_error.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/89_polynomial_regression_error.py</a></td></tr>
</table>



<p>V&nbsp;repositáři nalezneme taktéž projektový soubor a Jupyter Notebook
s&nbsp;vysvětlením, jak lze modely využít pro rozpoznávání obsahu rastrových
obrázků:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td>1</td><td>pyproject.toml</td><td>projektový soubor (pro PDM) se všemi závislostmi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>2</td><td>pdm.lock</td><td>lock soubor s&nbsp;konkrétními verzemi všech přímých i tranzitivních závislostí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>3</td><td>Rozpoznání_obrazu_scikit-learn.ipynb</td><td>Jupyter notebook s&nbsp;celým postupem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>4</td><td>particle_life.py</td><td>emergence: příklad vzniku struktury</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py">https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

<li>Rozpoznávání obrázků knihovnou Scikit-learn: první kroky<br />
<a href="https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/">https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/</a>
</li>

<li>scikit-learn: Machine Learning in Python<br />
<a href="https://scikit-learn.org/stable/index.html">https://scikit-learn.org/stable/index.html</a>
</li>

<li>Sklearn-pandas<br />
<a href="https://github.com/scikit-learn-contrib/sklearn-pandas">https://github.com/scikit-learn-contrib/sklearn-pandas</a>
</li>

<li>sklearn-xarray<br />
<a href="https://github.com/phausamann/sklearn-xarray/">https://github.com/phausamann/sklearn-xarray/</a>
</li>

<li>Clustering<br />
<a href="https://scikit-learn.org/stable/modules/clustering.html">https://scikit-learn.org/stable/modules/clustering.html</a>
</li>

<li>Cluster analysis (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Cluster_analysis">https://en.wikipedia.org/wiki/Cluster_analysis</a>
</li>

<li>Shluková analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza">https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza</a>
</li>

<li>K-means<br />
<a href="https://cs.wikipedia.org/wiki/K-means">https://cs.wikipedia.org/wiki/K-means</a>
</li>

<li>k-means clustering<br />
<a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a>
</li>

<li>Spectral clustering<br />
<a href="https://en.wikipedia.org/wiki/Spectral_clustering">https://en.wikipedia.org/wiki/Spectral_clustering</a>
</li>

<li>Emergence<br />
<a href="https://cs.wikipedia.org/wiki/Emergence">https://cs.wikipedia.org/wiki/Emergence</a>
</li>

<li>Particle Life: Vivid structures from rudimentary rules<br />
<a href="https://particle-life.com/">https://particle-life.com/</a>
</li>

<li>Hertzsprungův–Russellův diagram<br />
<a href="https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram">https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram</a>
</li>

<li>Using Machine Learning in an HR Diagram<br />
<a href="https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f">https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f</a>
</li>

<li>Gaia H-R diagrams: Querying Gaia data for one million nearby stars<br />
<a href="https://vlas.dev/post/gaia-dr2-hrd/">https://vlas.dev/post/gaia-dr2-hrd/</a>
</li>

<li>The Hertzsprung–Russell diagram<br />
<a href="https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/">https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/</a>
</li>

<li>Animated Hertzsprung-Russell Diagram with 119,614 datapoints<br />
<a href="https://github.com/zonination/h-r-diagram">https://github.com/zonination/h-r-diagram</a>
</li>

<li>Neuraxle Pipelines<br />
<a href="https://github.com/Neuraxio/Neuraxle">https://github.com/Neuraxio/Neuraxle</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Natural-language processing<br />
<a href="https://en.wikipedia.org/wiki/Natural-language_processing">https://en.wikipedia.org/wiki/Natural-language_processing</a>
</li>

<li>THE MNIST DATABASE of handwritten digits<br />
<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>
</li>

<li>MNIST database (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/MNIST_database">https://en.wikipedia.org/wiki/MNIST_database</a>
</li>

<li>MNIST For ML Beginners<br />
<a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch: Serialization<br />
<a href="https://github.com/torch/torch7/blob/master/doc/serialization.md">https://github.com/torch/torch7/blob/master/doc/serialization.md</a>
</li>

<li>Torch: modul image<br />
<a href="https://github.com/torch/image/blob/master/README.md">https://github.com/torch/image/blob/master/README.md</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>Neural network containres (Torch)<br />
<a href="https://github.com/torch/nn/blob/master/doc/containers.md">https://github.com/torch/nn/blob/master/doc/containers.md</a>
</li>

<li>Simple layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear">https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear</a>
</li>

<li>Transfer Function Layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok">https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>PyTorch<br />
<a href="http://pytorch.org/">http://pytorch.org/</a>
</li>

<li>JupyterLite na PyPi<br />
<a href="https://pypi.org/project/jupyterlite/">https://pypi.org/project/jupyterlite/</a>
</li>

<li>JupyterLite na GitHubu<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Dokumentace k&nbsp;projektu JupyterLite<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Matplotlib Home Page<br />
<a href="http://matplotlib.org/">http://matplotlib.org/</a>
</li>

<li>Matplotlib (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Matplotlib">https://en.wikipedia.org/wiki/Matplotlib</a>
</li>

<li>Popis barvových map modulu matplotlib.cm<br />
<a href="https://gist.github.com/endolith/2719900#id7">https://gist.github.com/endolith/2719900#id7</a>
</li>

<li>Ukázky (palety) barvových map modulu matplotlib.cm<br />
<a href="http://matplotlib.org/examples/color/colormaps_reference.html">http://matplotlib.org/examples/color/colormaps_reference.html</a>
</li>

<li>Galerie grafů vytvořených v&nbsp;Matplotlibu<br />
<a href="https://matplotlib.org/3.2.1/gallery/">https://matplotlib.org/3.2.1/gallery/</a>
</li>

<li>3D rendering<br />
<a href="https://en.wikipedia.org/wiki/3D_rendering">https://en.wikipedia.org/wiki/3D_rendering</a>
</li>

<li>3D computer graphics<br />
<a href="https://en.wikipedia.org/wiki/3D_computer_graphics">https://en.wikipedia.org/wiki/3D_computer_graphics</a>
</li>

<li>Primary 3D view planes<br />
<a href="https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html">https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html</a>
</li>

<li>Getting started in scikit-learn with the famous iris dataset<br />
<a href="https://www.youtube.com/watch?v=hd1W4CyPX58">https://www.youtube.com/watch?v=hd1W4CyPX58</a>
</li>

<li>Training a machine learning model with scikit-learn<br />
<a href="https://www.youtube.com/watch?v=RlQuVL6-qe8">https://www.youtube.com/watch?v=RlQuVL6-qe8</a>
</li>

<li>Iris (plant)<br />
<a href="https://en.wikipedia.org/wiki/Iris_(plant)">https://en.wikipedia.org/wiki/Iris_(plant)</a>
</li>

<li>Kosatec<br />
<a href="https://cs.wikipedia.org/wiki/Kosatec">https://cs.wikipedia.org/wiki/Kosatec</a>
</li>

<li>Iris setosa<br />
<a href="https://en.wikipedia.org/wiki/Iris_setosa">https://en.wikipedia.org/wiki/Iris_setosa</a>
</li>

<li>Iris versicolor<br />
<a href="https://en.wikipedia.org/wiki/Iris_versicolor">https://en.wikipedia.org/wiki/Iris_versicolor</a>
</li>

<li>Iris virginica<br />
<a href="https://en.wikipedia.org/wiki/Iris_virginica">https://en.wikipedia.org/wiki/Iris_virginica</a>
</li>

<li>Druh<br />
<a href="https://cs.wikipedia.org/wiki/Druh">https://cs.wikipedia.org/wiki/Druh</a>
</li>

<li>Iris subg. Limniris<br />
<a href="https://en.wikipedia.org/wiki/Iris_subg._Limniris">https://en.wikipedia.org/wiki/Iris_subg._Limniris</a>
</li>

<li>Iris Dataset Classification with Python: A Tutorial<br />
<a href="https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html">https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html</a>
</li>

<li>Iris flower data set<br />
<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">https://en.wikipedia.org/wiki/Iris_flower_data_set</a>
</li>

<li>List of datasets for machine-learning research<br />
<a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research</a>
</li>

<li>Analýza hlavních komponent<br />
<a href="https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent">https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent</a>
</li>

<li>Principal component analysis<br />
<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">https://en.wikipedia.org/wiki/Principal_component_analysis</a>
</li>

<li>Scikit-learn Crash Course - Machine Learning Library for Python<br />
<a href="https://www.youtube.com/watch?v=0B5eIE_1vpU">https://www.youtube.com/watch?v=0B5eIE_1vpU</a>
</li>

<li>calm-notebooks<br />
<a href="https://github.com/koaning/calm-notebooks">https://github.com/koaning/calm-notebooks</a>
</li>

<li>Should you teach Python or R for data science?<br />
<a href="https://www.dataschool.io/python-or-r-for-data-science/">https://www.dataschool.io/python-or-r-for-data-science/</a>
</li>

<li>nbviewer: A simple way to share Jupyter Notebooks<br />
<a href="https://nbviewer.org/">https://nbviewer.org/</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

<li>Matplotlib vs. seaborn vs. Plotly vs. MATLAB vs. ggplot2 vs. pandas<br />
<a href="https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/">https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/</a>
</li>

<li>Matplotlib, Seaborn or Plotnine?<br />
<a href="https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/">https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/</a>
</li>

<li>@Rabeez: Rabeez/plotting_comparison.ipynb<br />
<a href="https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc">https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc</a>
</li>

<li>Matplotlib, Seaborn, Plotly and Plotnine Comparison<br />
<a href="https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40">https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40</a>
</li>

<li>Data Visualization 101: How to Choose a Python Plotting Library<br />
<a href="https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a">https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a</a>
</li>

<li>Data science in Python: pandas, seaborn, scikit-learn<br />
<a href="https://www.youtube.com/watch?v=3ZWuPVWq7p4">https://www.youtube.com/watch?v=3ZWuPVWq7p4</a>
</li>

<li>7.2. Real world datasets<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>7.2.7. California Housing dataset<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>Comprehensive Guide to Classification Models in Scikit-Learn<br />
<a href="https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/">https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/</a>
</li>

<li>Tidy Data Visualization: ggplot2 vs seaborn<br />
<a href="https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/">https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/</a>
</li>

<li>seaborn: statistical data visualization<br />
<a href="https://seaborn.pydata.org/">https://seaborn.pydata.org/</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

