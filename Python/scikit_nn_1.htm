<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. </a></p>
<p><a href="#k02">*** 2. </a></p>
<p><a href="#k03">*** 3. </a></p>
<p><a href="#k04">*** 4. </a></p>
<p><a href="#k05">*** 5. </a></p>
<p><a href="#k06">*** 6. </a></p>
<p><a href="#k07">*** 7. </a></p>
<p><a href="#k08">*** 8. </a></p>
<p><a href="#k09">*** 9. </a></p>
<p><a href="#k10">*** 10. </a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">*** 20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. </h2>



<p><a name="k02"></a></p>
<h2 id="k02">2. </h2>



<p><a name="k03"></a></p>
<h2 id="k03">3. </h2>

<pre>
from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
import numpy as np
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = KNeighborsClassifier(n_neighbors=1)
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
&nbsp;
<i># trening modelu</i>
classifier.fit(X_train, y_train)
&nbsp;
<i># očekávané výsledky</i>
expexted_labels = y_test
&nbsp;
<i># výsledky modelu (predikované výsledky)</i>
predicted_labels = classifier.predict(X_test)
&nbsp;
<i># jak je náš model úspěšný?</i>
total = 0
same = 0
&nbsp;
<i># porovnání predikce s očekáváním</i>
for (expected, predicted) in zip(expexted_labels, predicted_labels):
    if expected==predicted:
        same+=1
    total+=1
&nbsp;
print(f"total:    {total}")
print(f"same:     {same}")
print(f"accuracy: {100.0*same/total:4.1f}%")
</pre>

<pre>
total:    30
same:     29
accuracy: 96.7%
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. </h2>

<pre>
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = MLPClassifier(max_iter=5000)
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
&nbsp;
<i># trening modelu</i>
classifier.fit(X_train, y_train)
&nbsp;
<i># očekávané výsledky</i>
expexted_labels = y_test
&nbsp;
<i># výsledky modelu (predikované výsledky)</i>
predicted_labels = classifier.predict(X_test)
&nbsp;
<i># jak je náš model úspěšný?</i>
total = 0
same = 0
&nbsp;
<i># porovnání predikce s očekáváním</i>
for (expected, predicted) in zip(expexted_labels, predicted_labels):
    if expected==predicted:
        same+=1
    total+=1
&nbsp;
print(f"total:    {total}")
print(f"same:     {same}")
print(f"accuracy: {100.0*same/total:4.1f}%")
&nbsp;
print(f"Features: {classifier.n_features_in_}")
print(f"Layers:   {classifier.n_layers_}")
print(f"Outputs:  {classifier.n_outputs_}")
print("Weights:")
&nbsp;
for layer, weights in enumerate(classifier.coefs_):
    print("\t", layer, weights.shape)
</pre>

<pre>
total:    30
same:     30
accuracy: 100.0%
</pre>

<pre>
total:    30
same:     28
accuracy: 93.3%
</pre>

<pre>
Features: 4
Layers:   3
Outputs:  3
Weights:
         0 (4, 100)
         1 (100, 3)
</pre>


<p><a name="k05"></a></p>
<h2 id="k05">5. </h2>

<pre>
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
&nbsp;
from sklearn.metrics import accuracy_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = MLPClassifier(max_iter=5000)
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
&nbsp;
<i># trening modelu</i>
classifier.fit(X_train, y_train)
&nbsp;
&nbsp;
<i># výsledky modelu (predikované výsledky)</i>
y_pred = classifier.predict(X_test)
&nbsp;
<i># vypoctena presnost modelu</i>
print(accuracy_score(y_test, y_pred))
&nbsp;
print(f"Features: {classifier.n_features_in_}")
print(f"Layers:   {classifier.n_layers_}")
print(f"Outputs:  {classifier.n_outputs_}")
print("Weights:")
&nbsp;
for layer, weights in enumerate(classifier.coefs_):
    print("\t", layer, weights.shape)
</pre>

<pre>
0.9666666666666667
</pre>

<pre>
1.0
</pre>

<pre>
Features: 4
Layers:   3
Outputs:  3
Weights:
         0 (4, 100)
         1 (100, 3)
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. </h2>

<pre>
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
&nbsp;
from sklearn.metrics import accuracy_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = MLPClassifier(max_iter=5000, hidden_layer_sizes = (10, 10, 10))
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
&nbsp;
<i># trening modelu</i>
classifier.fit(X_train, y_train)
&nbsp;
&nbsp;
<i># výsledky modelu (predikované výsledky)</i>
y_pred = classifier.predict(X_test)
&nbsp;
<i># vypoctena presnost modelu</i>
print(accuracy_score(y_test, y_pred))
&nbsp;
print(f"Features: {classifier.n_features_in_}")
print(f"Layers:   {classifier.n_layers_}")
print(f"Outputs:  {classifier.n_outputs_}")
print("Weights:")
&nbsp;
for layer, weights in enumerate(classifier.coefs_):
    print("\t", layer, weights.shape)
</pre>

<pre>
0.9666666666666667
0.9333333333333333
1.0
</pre>

<pre>
Features: 4
Layers:   5
Outputs:  3
Weights:
         0 (4, 10)
         1 (10, 10)
         2 (10, 10)
         3 (10, 3)
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. </h2>

<pre>
import matplotlib.pyplot as plt
&nbsp;
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
avg_scores = []
&nbsp;
r = range(1, 20)
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for neurons in r:
    <i># konstrukce klasifikatoru</i>
    <i># (s hyperparametrem)</i>
    classifier = MLPClassifier(max_iter=5000, hidden_layer_sizes = (neurons, neurons, neurons))
&nbsp;
    <i># vypocet skore</i>
    scores = cross_val_score(classifier, X, y, cv=10, scoring='accuracy')
&nbsp;
    avg_score = scores.mean()
&nbsp;
    <i># vypsani prumerneho skore do tabulky</i>
    print(neurons, avg_score)
&nbsp;
    avg_scores.append(avg_score)
&nbsp;
plt.plot(r, avg_scores)
plt.xlabel("Změna počtu neuronů ve třech vrstvách")
plt.ylabel("Přesnost modelu")
&nbsp;
<i># ulozeni grafu do souboru</i>
plt.savefig("139.png")
&nbsp;
<i># vykresleni grafu na obrazovku</i>
plt.show()
</pre>

<pre>
1 0.33333333333333337
2 0.6533333333333333
3 0.7533333333333332
4 0.76
5 0.9666666666666668
6 0.9066666666666666
7 0.9466666666666667
8 0.9866666666666667
9 0.9866666666666667
10 0.9866666666666667
11 0.9666666666666668
12 0.9733333333333334
13 0.9666666666666668
14 0.9733333333333334
15 0.9733333333333334
16 0.9733333333333334
17 0.9733333333333334
18 0.9733333333333334
19 0.9733333333333334
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. </h2>

<pre>
import matplotlib.pyplot as plt
&nbsp;
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
avg_scores = []
&nbsp;
r = range(1, 20)
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for neurons in r:
    <i># konstrukce klasifikatoru</i>
    <i># (s hyperparametrem)</i>
    classifier = MLPClassifier(max_iter=5000, hidden_layer_sizes = (neurons, neurons, neurons, neurons, neurons))
&nbsp;
    <i># vypocet skore</i>
    scores = cross_val_score(classifier, X, y, cv=10, scoring='accuracy')
&nbsp;
    avg_score = scores.mean()
&nbsp;
    <i># vypsani prumerneho skore do tabulky</i>
    print(neurons, avg_score)
&nbsp;
    avg_scores.append(avg_score)
&nbsp;
plt.plot(r, avg_scores)
plt.xlabel("Změna počtu neuronů v pěti vrstvách")
plt.ylabel("Přesnost modelu")
&nbsp;
<i># ulozeni grafu do souboru</i>
plt.savefig("140.png")
&nbsp;
<i># vykresleni grafu na obrazovku</i>
plt.show()
</pre>

<pre>
1 0.33333333333333337
2 0.4666666666666666
3 0.7133333333333333
4 0.7
5 0.9066666666666666
6 0.9733333333333334
7 0.9866666666666667
8 0.9133333333333333
9 0.9133333333333333
10 0.9733333333333334
11 0.9866666666666667
12 0.9866666666666667
13 0.9733333333333334
14 0.9733333333333334
15 0.9800000000000001
16 0.9733333333333334
17 0.9800000000000001
18 0.9800000000000001
19 0.9733333333333334
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>

<pre>
import matplotlib.pyplot as plt
&nbsp;
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
avg_scores = []
&nbsp;
NEURONS = 5
r = range(1, 40)
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for layers in r:
    <i># konstrukce klasifikatoru</i>
    <i># (s hyperparametrem)</i>
    layer_sizes = (NEURONS, ) * layers
    classifier = MLPClassifier(max_iter=5000, hidden_layer_sizes = layer_sizes)
&nbsp;
    <i># vypocet skore</i>
    scores = cross_val_score(classifier, X, y, cv=10, scoring='accuracy')
&nbsp;
    avg_score = scores.mean()
&nbsp;
    <i># vypsani prumerneho skore do tabulky</i>
    print(layers, avg_score)
&nbsp;
    avg_scores.append(avg_score)
&nbsp;
plt.plot(r, avg_scores)
plt.xlabel("Změna počtu vrstev")
plt.ylabel("Přesnost modelu")
&nbsp;
<i># ulozeni grafu do souboru</i>
plt.savefig("141.png")
&nbsp;
<i># vykresleni grafu na obrazovku</i>
plt.show()

</pre>

<pre>
1 0.9666666666666668
2 0.9800000000000001
3 0.8466666666666667
4 0.9733333333333334
5 0.9733333333333334
6 0.7133333333333333
7 0.8733333333333334
8 0.8866666666666667
9 0.5999999999999999
10 0.7466666666666667
11 0.7333333333333333
12 0.6799999999999999
13 0.5866666666666667
14 0.8066666666666666
15 0.4666666666666666
16 0.4666666666666666
17 0.4533333333333333
18 0.4333333333333333
19 0.39333333333333337
20 0.4
21 0.33333333333333337
22 0.33333333333333337
23 0.44666666666666666
24 0.33333333333333337
25 0.42000000000000004
26 0.4
27 0.33333333333333337
28 0.33333333333333337
29 0.33333333333333337
30 0.33333333333333337
31 0.33333333333333337
32 0.33333333333333337
33 0.33333333333333337
34 0.33333333333333337
35 0.33333333333333337
36 0.33333333333333337
37 0.33333333333333337
38 0.33333333333333337
39 0.33333333333333337
</pre>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>

<pre>
from sklearn import linear_model
from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># ceny bloku</i>
targets = housings["target"]
&nbsp;
<i># X je matice, y je vektor</i>
X = data
y = targets
&nbsp;
<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6)
&nbsp;
<i># konstrukce modelu</i>
lr = linear_model.LinearRegression()
&nbsp;
<i># trénink modelu</i>
lr.fit(X_train, y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = lr.predict(X_test)
&nbsp;
<i># výpis vypočtených koeficientů modelu</i>
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)
&nbsp;
<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
</pre>

<pre>
Coefficients:
 [ 4.45786809e-01  9.72953693e-03 -1.35720128e-01  8.20514635e-01
 -1.33231372e-06 -2.84786314e-03 -4.16735165e-01 -4.31811104e-01]
Intercept:
 -36.869534449989914
Mean squared error: 0.53
Coefficient of determination: 0.61
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>

<pre>
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor

from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

<i># nacteni datove sady</i>
housings = fetch_california_housing()

<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]

<i># ceny bloku</i>
targets = housings["target"]

<i># X je matice, y je vektor</i>
X = data
y = targets

<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)

<i># konstrukce modelu</i>
nn = MLPRegressor(max_iter=5000)

<i># trénink modelu</i>
nn.fit(X_train, y_train)

<i># predikce modelu</i>
y_pred = nn.predict(X_test)

<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))

<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))

print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")

for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
</pre>

<pre>
Mean squared error: 0.61
Coefficient of determination: 0.55
Features: 8
Layers:   3
Outputs:  1
Weights:
         0 (8, 100)
         1 (100, 1)
</pre>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>

<pre>
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor

from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split

<i># nacteni datove sady</i>
housings = fetch_california_housing()

<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]

<i># ceny bloku</i>
targets = housings["target"]

<i># X je matice, y je vektor</i>
X = data
y = targets

<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)

neurons = 1000

<i># konstrukce modelu</i>
nn = MLPRegressor(max_iter=5000, hidden_layer_sizes = (neurons, neurons, ))

<i># trénink modelu</i>
nn.fit(X_train, y_train)

<i># predikce modelu</i>
y_pred = nn.predict(X_test)

<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))

<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))

print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")

for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
</pre>

<pre>
Mean squared error: 1.07
Coefficient of determination: 0.19
Features: 8
Layers:   4
Outputs:  1
Weights:
         0 (8, 1000)
         1 (1000, 1000)
         2 (1000, 1)
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>

<pre>
import matplotlib.pyplot as plt

# model zalozeny na neuronove siti
from sklearn.neural_network import MLPRegressor

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score

# nacteni datove sady
housings = fetch_california_housing()

# precteni dat z datove sady
# urcenych pro trenink, validaci atd.
data = housings["data"]

# ceny bloku
targets = housings["target"]

# X je matice, y je vektor
X = data
y = targets

r = range(1, 12)
avg_scores = []

# hledani optimalniho poctu neuronu ve vrstvach
for i in r:
    # konstrukce modelu
    neurons = 2**i
    nn = MLPRegressor(max_iter=5000, hidden_layer_sizes = (neurons, ))

    scores = cross_val_score(nn, X, y, cv=10, scoring='r2')

    # vypsani prumerneho skore do tabulky
    avg_score = scores.mean()
    print(neurons, avg_score)

    avg_scores.append(avg_score)

plt.plot(r, avg_scores)
plt.xlabel("Změna počtu neuronů v jedné vrstvě")
plt.ylabel("R2")

# ulozeni grafu do souboru
plt.savefig("144.png")

# vykresleni grafu na obrazovku
#plt.show()
</pre>

<pre>
2 -0.1454302734588354
4 -0.03707952396388188
8 0.024029461721653787
16 0.15975633333410563
32 0.0019421990876153927
64 0.2831746308829118
128 0.30220876727407814
256 -0.08924552002434508
512 -0.0007001958806893916
1024 -5.531109632506313
2048 -20.041735587898025
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>

<pre>
import matplotlib.pyplot as plt

# model zalozeny na neuronove siti
from sklearn.neural_network import MLPRegressor

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score

# nacteni datove sady
housings = fetch_california_housing()

# precteni dat z datove sady
# urcenych pro trenink, validaci atd.
data = housings["data"]

# ceny bloku
targets = housings["target"]

# X je matice, y je vektor
X = data
y = targets

r = range(1, 12)
avg_scores = []

# hledani optimalniho poctu neuronu ve vrstvach
for i in r:
    # konstrukce modelu
    neurons = 2**i
    nn = MLPRegressor(max_iter=5000, hidden_layer_sizes = (neurons, neurons, neurons))

    scores = cross_val_score(nn, X, y, cv=10, scoring='r2')

    # vypsani prumerneho skore do tabulky
    avg_score = scores.mean()
    print(neurons, avg_score)

    avg_scores.append(avg_score)

plt.plot(r, avg_scores)
plt.xlabel("Změna počtu neuronů ve třech vrstvách")
plt.ylabel("R2")

# ulozeni grafu do souboru
plt.savefig("145.png")

# vykresleni grafu na obrazovku
#plt.show()

</pre>

<pre>
2 -0.283005105231359
4 0.148825137624293
8 0.3334395444819797
16 0.14779810169991886
32 -0.14617386521960413
64 0.17143912954224527
128 -0.35915114561290196
256 0.028327261438945373
512 -0.5219569442908789
1024 0.22234451593419272
2048 0.32266508344685396
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>

<pre>
import matplotlib.pyplot as plt

# model zalozeny na neuronove siti
from sklearn.neural_network import MLPRegressor

from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score

# nacteni datove sady
housings = fetch_california_housing()

# precteni dat z datove sady
# urcenych pro trenink, validaci atd.
data = housings["data"]

# ceny bloku
targets = housings["target"]

# X je matice, y je vektor
X = data
y = targets

r = range(1, 12)
avg_scores = []

# hledani optimalniho poctu neuronu ve vrstvach
for i in r:
    # konstrukce modelu
    neurons = 2**i
    nn = MLPRegressor(max_iter=5000, hidden_layer_sizes = (neurons, neurons, neurons, neurons, neurons))

    scores = cross_val_score(nn, X, y, cv=10, scoring='r2', n_jobs=-1)

    # vypsani prumerneho skore do tabulky
    avg_score = scores.mean()
    print(neurons, avg_score)

    avg_scores.append(avg_score)

plt.plot(r, avg_scores)
plt.xlabel("Změna počtu neuronů v pěti vrstvách")
plt.ylabel("R2")

# ulozeni grafu do souboru
plt.savefig("146.png")

# vykresleni grafu na obrazovku
#plt.show()
</pre>

<pre>
2 -0.0754384824557155
4 -0.14798990918251986
8 0.3995421626439365
16 0.010342881370922475
32 0.19336159679802659
64 0.17877679646955416
128 0.2820772221907199
256 0.5288142058348293
512 0.44223558072990465
1024 0.44861141341888383
2048 0.40412403628968663
</pre>


<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu Scikit-learn lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady i na (Jupyter) diáře s&nbsp;postupem
výpočtů a analýz:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td>01_show_matrix.py</td><td>kooperace mezi knihovnami Matplotlib a NumPy: vizualizace obsahu 2D matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py</a></td></tr>
<tr><td> 2</td><td>02_get_digits.py</td><td>datová množina obsahující naskenované ručně napsané číslice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py</a></td></tr>
<tr><td> 3</td><td>03_get_features.py</td><td>další atributy datové množiny, které použijeme při trénování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py</a></td></tr>
<tr><td> 4</td><td>04_get_images.py</td><td>přečtení a následné vykreslení jednotlivých ručně nakreslených číslic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py</a></td></tr>
<tr><td> 5</td><td>05_show_grayscale_matrix.py</td><td>odstranění umělé aplikované barvové palety (obrázky ve stupních šedi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py</a></td></tr>
<tr><td> 6</td><td>06_grayscale_images.py</td><td>vykreslení ručně nakreslených číslic ve formě obrázků ve stupních šedi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py</a></td></tr>
<tr><td> 7</td><td>07_multiplot.py</td><td>rozdělení plochy grafu do oblastí; vykreslení více obrázků do jediného grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py</a></td></tr>
<tr><td> 8</td><td>08_model_preperation_1.py</td><td>obrázky s&nbsp;jejich ohodnocením</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py</a></td></tr>
<tr><td> 9</td><td>09_training_set.py</td><td>příprava dat pro trénink</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py</a></td></tr>
<tr><td>10</td><td>10_classification.py</td><td>klasifikace obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py</a></td></tr>
<tr><td>11</td><td>11_results.py</td><td>vykreslení obrázků společně s&nbsp;jejich klasifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py</a></td></tr>
<tr><td>12</td><td>12_change_training_set.py</td><td>změna poměru rozdělení dat na tréninkovou a testovací množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>13</td><td>13_blobs.py</td><td>použití funkce <strong>make_blobs</strong> pro vygenerování sady bodů v&nbsp;rovině sdružených do oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py</a></td></tr>
<tr><td>14</td><td>14_swap_coords.py</td><td>úprava předchozího příkladu: prohození souřadnic na osách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py</a></td></tr>
<tr><td>15</td><td>15_blobs_scatter_plot.py</td><td>základní podoba bodového diagramu (<i>scatter plot</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py</a></td></tr>
<tr><td>16</td><td>16_blobs_scatter_plot.py</td><td>úprava bodového diagramu při zobrazení většího množství bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py</a></td></tr>
<tr><td>17</td><td>17_colorized_blobs.py</td><td>obarvení bodů podle oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py</a></td></tr>
<tr><td>18</td><td>18_k-means.py</td><td>základní použití algoritmu K-means pro clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py</a></td></tr>
<tr><td>19</td><td>19_combination.py</td><td>zobrazení centroidů společně s&nbsp;původními body</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py</a></td></tr>
<tr><td>20</td><td>20_combinations.py</td><td>vizualizace clusteringu původní množiny bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py</a></td></tr>
<tr><td>21</td><td>21_other_settings.py</td><td>vizualizace clusteringu původní množiny bodů pro odlišnou množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py</a></td></tr>
<tr><td>22</td><td>22_random_points.py</td><td>clustering pro náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>23</td><td>23_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, menší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py</a></td></tr>
<tr><td>24</td><td>24_more_noise_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, větší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py</a></td></tr>
<tr><td>25</td><td>25_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, menší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py</a></td></tr>
<tr><td>26</td><td>26_more_noisy_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, větší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py</a></td></tr>
</table>

<p>V&nbsp;repositáři nalezneme taktéž projektový soubor a Jupyter Notebook
s&nbsp;vysvětlením, jak lze modely využít pro rozpoznávání obsahu rastrových
obrázků:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td>1</td><td>pyproject.toml</td><td>projektový soubor (pro PDM) se všemi závislostmi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>2</td><td>pdm.lock</td><td>lock soubor s&nbsp;konkrétními verzemi všech přímých i tranzitivních závislostí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>3</td><td>Rozpoznání_obrazu_scikit-learn.ipynb</td><td>Jupyter notebook s&nbsp;celým postupem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>4</td><td>particle_life.py</td><td>emergence: příklad vzniku struktury</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py">https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

<li>Rozpoznávání obrázků knihovnou Scikit-learn: první kroky<br />
<a href="https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/">https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/</a>
</li>

<li>scikit-learn: Machine Learning in Python<br />
<a href="https://scikit-learn.org/stable/index.html">https://scikit-learn.org/stable/index.html</a>
</li>

<li>Sklearn-pandas<br />
<a href="https://github.com/scikit-learn-contrib/sklearn-pandas">https://github.com/scikit-learn-contrib/sklearn-pandas</a>
</li>

<li>sklearn-xarray<br />
<a href="https://github.com/phausamann/sklearn-xarray/">https://github.com/phausamann/sklearn-xarray/</a>
</li>

<li>Clustering<br />
<a href="https://scikit-learn.org/stable/modules/clustering.html">https://scikit-learn.org/stable/modules/clustering.html</a>
</li>

<li>Cluster analysis (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Cluster_analysis">https://en.wikipedia.org/wiki/Cluster_analysis</a>
</li>

<li>Shluková analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza">https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza</a>
</li>

<li>K-means<br />
<a href="https://cs.wikipedia.org/wiki/K-means">https://cs.wikipedia.org/wiki/K-means</a>
</li>

<li>k-means clustering<br />
<a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a>
</li>

<li>Spectral clustering<br />
<a href="https://en.wikipedia.org/wiki/Spectral_clustering">https://en.wikipedia.org/wiki/Spectral_clustering</a>
</li>

<li>Emergence<br />
<a href="https://cs.wikipedia.org/wiki/Emergence">https://cs.wikipedia.org/wiki/Emergence</a>
</li>

<li>Particle Life: Vivid structures from rudimentary rules<br />
<a href="https://particle-life.com/">https://particle-life.com/</a>
</li>

<li>Hertzsprungův–Russellův diagram<br />
<a href="https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram">https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram</a>
</li>

<li>Using Machine Learning in an HR Diagram<br />
<a href="https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f">https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f</a>
</li>

<li>Gaia H-R diagrams: Querying Gaia data for one million nearby stars<br />
<a href="https://vlas.dev/post/gaia-dr2-hrd/">https://vlas.dev/post/gaia-dr2-hrd/</a>
</li>

<li>The Hertzsprung–Russell diagram<br />
<a href="https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/">https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/</a>
</li>

<li>Animated Hertzsprung-Russell Diagram with 119,614 datapoints<br />
<a href="https://github.com/zonination/h-r-diagram">https://github.com/zonination/h-r-diagram</a>
</li>

<li>Neuraxle Pipelines<br />
<a href="https://github.com/Neuraxio/Neuraxle">https://github.com/Neuraxio/Neuraxle</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Natural-language processing<br />
<a href="https://en.wikipedia.org/wiki/Natural-language_processing">https://en.wikipedia.org/wiki/Natural-language_processing</a>
</li>

<li>THE MNIST DATABASE of handwritten digits<br />
<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>
</li>

<li>MNIST database (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/MNIST_database">https://en.wikipedia.org/wiki/MNIST_database</a>
</li>

<li>MNIST For ML Beginners<br />
<a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch: Serialization<br />
<a href="https://github.com/torch/torch7/blob/master/doc/serialization.md">https://github.com/torch/torch7/blob/master/doc/serialization.md</a>
</li>

<li>Torch: modul image<br />
<a href="https://github.com/torch/image/blob/master/README.md">https://github.com/torch/image/blob/master/README.md</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>Neural network containres (Torch)<br />
<a href="https://github.com/torch/nn/blob/master/doc/containers.md">https://github.com/torch/nn/blob/master/doc/containers.md</a>
</li>

<li>Simple layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear">https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear</a>
</li>

<li>Transfer Function Layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok">https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>PyTorch<br />
<a href="http://pytorch.org/">http://pytorch.org/</a>
</li>

<li>JupyterLite na PyPi<br />
<a href="https://pypi.org/project/jupyterlite/">https://pypi.org/project/jupyterlite/</a>
</li>

<li>JupyterLite na GitHubu<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Dokumentace k&nbsp;projektu JupyterLite<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Matplotlib Home Page<br />
<a href="http://matplotlib.org/">http://matplotlib.org/</a>
</li>

<li>Matplotlib (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Matplotlib">https://en.wikipedia.org/wiki/Matplotlib</a>
</li>

<li>Popis barvových map modulu matplotlib.cm<br />
<a href="https://gist.github.com/endolith/2719900#id7">https://gist.github.com/endolith/2719900#id7</a>
</li>

<li>Ukázky (palety) barvových map modulu matplotlib.cm<br />
<a href="http://matplotlib.org/examples/color/colormaps_reference.html">http://matplotlib.org/examples/color/colormaps_reference.html</a>
</li>

<li>Galerie grafů vytvořených v&nbsp;Matplotlibu<br />
<a href="https://matplotlib.org/3.2.1/gallery/">https://matplotlib.org/3.2.1/gallery/</a>
</li>

<li>3D rendering<br />
<a href="https://en.wikipedia.org/wiki/3D_rendering">https://en.wikipedia.org/wiki/3D_rendering</a>
</li>

<li>3D computer graphics<br />
<a href="https://en.wikipedia.org/wiki/3D_computer_graphics">https://en.wikipedia.org/wiki/3D_computer_graphics</a>
</li>

<li>Primary 3D view planes<br />
<a href="https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html">https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html</a>
</li>

<li>Getting started in scikit-learn with the famous iris dataset<br />
<a href="https://www.youtube.com/watch?v=hd1W4CyPX58">https://www.youtube.com/watch?v=hd1W4CyPX58</a>
</li>

<li>Training a machine learning model with scikit-learn<br />
<a href="https://www.youtube.com/watch?v=RlQuVL6-qe8">https://www.youtube.com/watch?v=RlQuVL6-qe8</a>
</li>

<li>Iris (plant)<br />
<a href="https://en.wikipedia.org/wiki/Iris_(plant)">https://en.wikipedia.org/wiki/Iris_(plant)</a>
</li>

<li>Kosatec<br />
<a href="https://cs.wikipedia.org/wiki/Kosatec">https://cs.wikipedia.org/wiki/Kosatec</a>
</li>

<li>Iris setosa<br />
<a href="https://en.wikipedia.org/wiki/Iris_setosa">https://en.wikipedia.org/wiki/Iris_setosa</a>
</li>

<li>Iris versicolor<br />
<a href="https://en.wikipedia.org/wiki/Iris_versicolor">https://en.wikipedia.org/wiki/Iris_versicolor</a>
</li>

<li>Iris virginica<br />
<a href="https://en.wikipedia.org/wiki/Iris_virginica">https://en.wikipedia.org/wiki/Iris_virginica</a>
</li>

<li>Druh<br />
<a href="https://cs.wikipedia.org/wiki/Druh">https://cs.wikipedia.org/wiki/Druh</a>
</li>

<li>Iris subg. Limniris<br />
<a href="https://en.wikipedia.org/wiki/Iris_subg._Limniris">https://en.wikipedia.org/wiki/Iris_subg._Limniris</a>
</li>

<li>Iris Dataset Classification with Python: A Tutorial<br />
<a href="https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html">https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html</a>
</li>

<li>Iris flower data set<br />
<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">https://en.wikipedia.org/wiki/Iris_flower_data_set</a>
</li>

<li>List of datasets for machine-learning research<br />
<a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research</a>
</li>

<li>Analýza hlavních komponent<br />
<a href="https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent">https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent</a>
</li>

<li>Principal component analysis<br />
<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">https://en.wikipedia.org/wiki/Principal_component_analysis</a>
</li>

<li>Scikit-learn Crash Course - Machine Learning Library for Python<br />
<a href="https://www.youtube.com/watch?v=0B5eIE_1vpU">https://www.youtube.com/watch?v=0B5eIE_1vpU</a>
</li>

<li>calm-notebooks<br />
<a href="https://github.com/koaning/calm-notebooks">https://github.com/koaning/calm-notebooks</a>
</li>

<li>Should you teach Python or R for data science?<br />
<a href="https://www.dataschool.io/python-or-r-for-data-science/">https://www.dataschool.io/python-or-r-for-data-science/</a>
</li>

<li>nbviewer: A simple way to share Jupyter Notebooks<br />
<a href="https://nbviewer.org/">https://nbviewer.org/</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

<li>Matplotlib vs. seaborn vs. Plotly vs. MATLAB vs. ggplot2 vs. pandas<br />
<a href="https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/">https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/</a>
</li>

<li>Matplotlib, Seaborn or Plotnine?<br />
<a href="https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/">https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/</a>
</li>

<li>@Rabeez: Rabeez/plotting_comparison.ipynb<br />
<a href="https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc">https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc</a>
</li>

<li>Matplotlib, Seaborn, Plotly and Plotnine Comparison<br />
<a href="https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40">https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40</a>
</li>

<li>Data Visualization 101: How to Choose a Python Plotting Library<br />
<a href="https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a">https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a</a>
</li>

<li>Data science in Python: pandas, seaborn, scikit-learn<br />
<a href="https://www.youtube.com/watch?v=3ZWuPVWq7p4">https://www.youtube.com/watch?v=3ZWuPVWq7p4</a>
</li>

<li>7.2. Real world datasets<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>7.2.7. California Housing dataset<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>Comprehensive Guide to Classification Models in Scikit-Learn<br />
<a href="https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/">https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/</a>
</li>

<li>Tidy Data Visualization: ggplot2 vs seaborn<br />
<a href="https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/">https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/</a>
</li>

<li>seaborn: statistical data visualization<br />
<a href="https://seaborn.pydata.org/">https://seaborn.pydata.org/</a>
</li>

<li>Linear regression (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Linear_regression">https://en.wikipedia.org/wiki/Linear_regression</a>
</li>

<li>Lineární regrese (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese">https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese</a>
</li>

<li>Iris Flower Classification with MLP Classifier<br />
<a href="https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier">https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

