<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Neuronové sítě v knihovně scikit-learn</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Neuronové sítě v knihovně scikit-learn</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>V dnešní části seriálu o balíčku scikit-learn si ukážeme, jakým způsobem je možné vytvořit neuronovou síť s volitelným počtem skrytých vrstev, naučit tuto síť řešit zvolený problém s využitím sady trénovacích dat a následně tuto síť použít nad další sadou (validačních) dat.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Neuronové sítě v&nbsp;knihovně <i>scikit-learn</i></a></p>
<p><a href="#k02">2. Idealizovaný model neuronu používaný v&nbsp;umělých neuronových sítích</a></p>
<p><a href="#k03">3. Role biasu</a></p>
<p><a href="#k04">4. Aktivační funkce</a></p>
<p><a href="#k05">5. Vytvoření feed-forward sítě z&nbsp;jednotlivých neuronů</a></p>
<p><a href="#k06">6. Vstupní vrstva, výstupní vrstva a skryté vrstvy neuronů</a></p>
<p><a href="#k07">7. Trénink (učení) sítě s&nbsp;využitím trénovacích dat</a></p>
<p><a href="#k08">8. Neuronová síť jako další typ modelu ve <i>scikit-learn</i></a></p>
<p><a href="#k09">9. Konstrukce neuronové sítě, její trénink a následné použití</a></p>
<p><a href="#k10">10. Zobrazení vah neuronů v&nbsp;jednotlivých vrstvách</a></p>
<p><a href="#k11">11. Zjištění přesnosti modelu vytvořeného neuronovou sítí, pomocí funkce <strong>accuracy_score</strong></a></p>
<p><a href="#k12">12. Konfigurace topologie neuronové sítě &ndash; počty neuronů ve skrytých vrstvách</a></p>
<p><a href="#k13">13. Vliv počtu neuronů ve skrytých vrstvách na predikce neuronové sítě</a></p>
<p><a href="#k14">14. Výsledky pro neuronovou síť s&nbsp;pěti skrytými vrstvami</a></p>
<p><a href="#k15">15. Má další zvyšování počtu skrytých vrstev význam?</a></p>
<p><a href="#k16">16. Lineární model provádějící regresi</a></p>
<p><a href="#k17">17. Neuronová síť provádějící regresi</a></p>
<p><a href="#k18">18. Změna počtu skrytých vrstev a neuronů v&nbsp;těchto vrstvách</a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Neuronové sítě v&nbsp;knihovně <i>scikit-learn</i></h2>

<p>V&nbsp;dnešním článku o knihovně <i>scikit-learn</i> se budeme zabývat
problematikou vytvoření jednoduchých umělých neuronových sítí (zkráceně jen
neuronových sítí neboli <i>neural network</i> popř.&nbsp;<i>nn</i>) a taktéž
způsobem tréninku (učení) těchto sítí s&nbsp;jejich následnou křížovou
validací. Již na začátku je nutné říct, že se sice jedná o dosti rozsáhlou
problematiku, pro jejíž pochopení se navíc očekává alespoň základní znalost
teorie neuronových sítí, na druhou stranu je však použití těchto sítí (ve
funkci blackboxu) ve <i>scikit-learn</i> až triviálně jednoduché, vlastně
stejně jednoduché, jako použití jiných modelů.</p>

<p>Zpočátku se zaměříme na neuronové sítě typu <i>feed-forward</i>
s&nbsp;volitelným počtem vrstev neuronů, přičemž neurony na sousedních vrstvách
budou propojeny (synapsemi) systémem &bdquo;každý s&nbsp;každým&ldquo; a
informace mezi neurony potečou pouze jedním směrem (<i>forward</i>).
V&nbsp;dalších částech tohoto seriálu si popíšeme i další typy sítí,
v&nbsp;nichž bude použito více vrstev neuronů, neurony budou propojeny odlišným
způsobem, budou použity jiné <i>aktivační funkce</i> atd. (což již ovšem
částečně přesahuje možnosti <i>scikit-learn</i> a sáhneme tedy například po
<i>pytorchi</i> atd.</p>

<p>Neuronové sítě se používají zejména v&nbsp;těch projektech, v&nbsp;nichž je
zapotřebí vytvořit funkční systém už ve chvíli, kdy ještě neznáme všechny možné
kombinace vstupů a výstupů, popř.&nbsp;když je chování systému, který se
implementuje, tak složité, že klasický návrh a implementace algoritmů by byl
příliš zdlouhavý nebo s&nbsp;danými prostředky (čas, počet vývojářů a testerů)
neefektivní. Jednou z&nbsp;nevýhod neuronových sítí může být to, že je někdy
velmi obtížné zjistit, jaký problém jsme vlastně neuronovou síť naučili řešit.
Výsledná síť se totiž (pokud se nebudeme hodně snažit zjisti více) chová jako
<i>blackbox</i>, o němž není snadné říct, jaké konkrétní rozhodování ten který
neuron provádí (v&nbsp;některých případech to ovšem možné je). Kritickou úlohu
zde sehrává výběr vhodné množiny trénovacích dat. K&nbsp;tomu se však dostaneme
až v&nbsp;dalších částech seriálu, v&nbsp;nichž se zmíníme o již existujících
trénovacích datech.</p>

<p><div class="rs-tip-major">Poznámka: již na úvod si však řekněme, že
neuronové sítě jsou pro mnoho problémů příliš složitými modely, takže bývá
snazší (a rychlejší) nejprve použít modely jednodušší.</div></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Idealizovaný model neuronu používaný v&nbsp;umělých neuronových sítích</h2>

<p>Při práci s&nbsp;umělými neuronovými sítěmi je vhodné vědět, jak je vlastně
taková síť zkonstruována a z&nbsp;jakých prvků se skládá. Základním stavebním
prvkem je umělý neuron, resp.&nbsp;velmi zjednodušený a idealizovaný model
skutečného neuronu. Původní model neuronu byl navržen Warrenem McCullochem a
Walterem Pittsem (MCP) již ve čtyřicátých letech minulého století, z&nbsp;čehož
plyne, že neuronové sítě nejsou jen módním výstřelkem poslední doby (naopak,
moderní GPU umožňují jejich nasazení i tam, kde to dříve nebylo možné, to je
však téma na samostatný článek.). Na dalším obrázku jsou naznačeny prvky modelu
neuronu:</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-1.png" class="image-312261" alt="&#160;" width="459" height="140" />
<p><i>Obrázek 1: Idealizovaný model neuronu.</i></p>

<p>Vidíme, že neuron může mít libovolný počet vstupů (na obrázku jsou tři
vstupy <strong>x<sub>1</sub></strong>, <strong>x<sub>2</sub></strong> a
<strong>x<sub>3</sub></strong>, ovšem může to být jen jeden vstup nebo i sto
vstupů) a má pouze jeden výstup <strong>y</strong>. Vstupem a výstupem jsou
reálná čísla; typicky bývá výstup upraven aktivační funkcí tak, že leží
v&nbsp;rozsahu &lt;-1..1&gt; nebo &lt;0..1&gt;.</p>

<p>Dále na schématu vidíme váhy <strong>w<sub>1</sub></strong>,
<strong>w<sub>2</sub></strong> a <strong>w<sub>3</sub></strong>. Těmito váhami
jsou vynásobeny vstupní hodnoty. Váhy vlastně představují stav neuronu,
tj.&nbsp;o funkci, na kterou byl neuron natrénován (naučen). Vstupní hodnoty
<strong>x<sub>1</sub></strong> až <strong>x<sub>n</sub></strong> jsou tedy
postupně vynásobeny váhami <strong>w<sub>1</sub></strong> až
<strong>w<sub>n</sub></strong> a výsledky součinu jsou v&nbsp;neuronu sečteny,
takže získáme jediné reálné číslo. Toto číslo je zpracováno <i>aktivační
funkcí</i> (ta již většinou žádný stav nemá, ostatně stejně jako funkce pro
výpočet sumy) výsledek této funkce je poslán na výstup neuronu.</p>

<p>Neuron tedy provádí tento výpočet:</p>

<p>
y = f(w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + ... + w<sub>n</sub>x<sub>n</sub>)
</p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Role biasu</h2>

<p>Ve skutečnosti není stav neuronu pro <i>n</i> vstupů
<strong>x<sub>1</sub></strong> až <strong>x<sub>n</sub></strong> určen pouze
<i>n</i> vahami <strong>w<sub>1</sub></strong> až
<strong>w<sub>n</sub></strong>. Musíme přidat ještě váhu
<strong>w<sub>0</sub></strong>, na kterou je připojena konstanta 1 (někdy se
proto můžeme setkat s&nbsp;nákresem neuronové sítě, v&nbsp;níž se nachází
speciální neurony bez vstupů a s&nbsp;jedničkou na výstupu). Model neuronu se
přidáním nového vstupu nepatrně zkomplikuje:</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-2.png" class="image-312262" alt="&#160;" width="465" height="145" />
<p><i>Obrázek 2: Idealizovaný model neuronu s&nbsp;biasem.</i></p>

<p>I výpočet bude vypadat (nepatrně) odlišně, neboť do něho přidáme nový
člen:</p>

<p>
y = f(<strong>w<sub>0</sub></strong> + w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + ... + w<sub>n</sub>x<sub>n</sub>)
</p>

<p>Tato přidaná váha se někdy nazývá <i>bias</i>, protože vlastně umožňuje
posouvat <a
href="https://stackoverflow.com/questions/2480650/role-of-bias-in-neural-networks">průběh
aktivační funkce nalevo a napravo</a>, v&nbsp;závislosti na jeho hodnotě.</p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Aktivační funkce</h2>

<p>Bez aktivační funkce by se neuron choval jednoduše &ndash; spočítal by
vážený součet vstupů a výsledek by poslal na výstup. Aktivační funkce, kterou
jsme v&nbsp;předchozích dvou kapitolách označovali symbolem <i>f</i>, do celého
výpočtu vnáší nelinearitu (ta je velmi důležitá). Nejjednodušší aktivační
funkce může pro vstupní hodnoty &lt;0 vracet -1 a pro hodnoty &ge;0 vracet 1,
což vlastně říká, že je nutné dosáhnout určité hraniční hodnoty váženého součtu
vstupů, aby byl neuron aktivován (tj.&nbsp;na výstup vyslal jedničku a nikoli
-1). Ostatně právě zde znovu vidíme význam biasu, který onu hraniční hodnotu
posunuje.</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-3.png" class="image-312263" alt="&#160;" width="640" height="480" />
<p><i>Obrázek 3: Aktivační funkce ReLU.</i></p>

<p>V&nbsp;praxi je však aktivační funkce složitější, než zmíněný jednotkový
skok. Často se používá <i>ReLU</i>, <i>sigmoid</i> nebo <i>hyperbolický
tangent</i>. Pro specializovanější účely se však používají i další funkce,
které dokonce nemusí mít monotonní průběh. S&nbsp;dalšími podporovanými
funkcemi se seznámíme příště.</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-4.png" class="image-312264" alt="&#160;" width="640" height="480" />
<p><i>Obrázek 4: Aktivační funkce Tanh.</i></p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Vytvoření feed-forward sítě z&nbsp;jednotlivých neuronů</h2>

<p>Samostatné neurony i s&nbsp;aktivační funkcí stále provádí velmi jednoduchou
činnost, ovšem aby se mohly stát součástí složitějšího systému (řekněme
automatického řízení auta), musíme z&nbsp;nich vytvořit síť. Jedna
z&nbsp;nejjednodušších forem umělé neuronové sítě se nazývá
<i>feed-forward</i>, a to z&nbsp;toho důvodu, že informace (tedy vstupní
hodnoty, mezihodnoty i hodnoty výstupní) touto sítí tečou jen jedním směrem
(při učení je tomu jinak). Neurony jsou uspořádány pravidelně do vrstev:</p>

<img src="https://i.iinfo.cz/images/329/torch-nn1-5.png" class="image-312265" alt="&#160;" width="600" height="400" />
<p><i>Obrázek 5: Uspořádání neuronů do vrstev ve feed-forward síti.</i></p>

<p>Kolečka na obrázku představují jednotlivé neurony, přičemž žlutě jsou
označeny neurony na vstupu, zeleně &bdquo;interní&ldquo; (skryté) neurony a
červeně neurony, které produkují kýžený výstup neuronové sítě.</p>

<p>Zcela nalevo jsou šipkami naznačeny vstupy. Jejich počet je prakticky zcela
závislý na řešeném problému. Může se jednat jen o několik vstupů (viz naše
testovací síť popsaná níže), ovšem pokud například budeme tvořit síť určenou
pro rozpoznání objektů v&nbsp;rastrovém obrázku, může být počet vstupů roven
počtu pixelů (což ovšem v&nbsp;praxi realizujeme odlišně &ndash; konvolučními
sítěmi).</p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Vstupní vrstva, výstupní vrstva a skryté vrstvy neuronů</h2>

<p>Vraťme se ještě jednou k&nbsp;obrázku číslo 5.</p>

<p>Povšimněte si, že vstupní neurony mají vlastně zjednodušenou funkci, protože
mají jen jeden vstup. V&nbsp;mnoha typech sítí tyto neurony jen rozesílají
vstup na další neurony a neprovádí žádný složitější výpočet, například u nich
není použita aktivační funkce, ovšem to již záleží na konkrétní konfiguraci
sítě. Dále stojí za povšimnutí, že neurony posílají svůj výstup neuronům na
nejbližší další vrstvě; nejsou zde tedy žádné zkratky, žádné zpětné vazby
atd.</p>

<p>Existují samozřejmě složitější typy sítí, těmi se teď ale nebudeme zabývat.
Dále tato síť propojuje neurony na sousedních vrstvách systémem &bdquo;každý
s&nbsp;každým&ldquo;. V&nbsp;našem konkrétním příkladu mají neurony na
prostřední vrstvě dva vstupy, protože předchozí vrstva má jen dva neurony.
Ovšem neurony na poslední vrstvě již musí mít tři vstupy.</p>

<p><div class="rs-tip-major">Poznámka: může se stát, že síť bude po naučení
obsahovat neurony, jejichž váhy na vstupu budou nulové. To vlastně značí, že ze
sítě některé spoje (šipky) zmizí, protože vynásobením jakéhokoli vstupu nulou
dostaneme zase jen nulu.</div></p>

<p>První vrstva s&nbsp;jednoduchými (&bdquo;hloupými&ldquo;) neurony se nazývá
<i>vstupní vrstva</i>, poslední vrstva je <i>vrstva výstupní</i>. Vrstvy mezi
vrstvou vstupní a výstupní, kterých může být teoreticky libovolné množství, se
nazývají <i>skryté vrstvy</i>.</p>

<p>&bdquo;Paměť&ldquo; neuronové sítě je tvořena vahami na vstupech
neuronů (včetně biasu):</p>

<table>
<tr><th>Vrstva</th><th>Neuronů</th><th>Počet vstupů/neuron</th><th>Počet vah/neuron</th><th>Celkem</th></tr>
<tr><td>1</td><td>2</td><td>1</td><td>2</td><td>4</td></tr>
<tr><td>2</td><td>3</td><td>2</td><td>3</td><td>9</td></tr>
<tr><td>3</td><td>2</td><td>3</td><td>4</td><td>8</td></tr>
<tr><td>&sum;</td><td>7</td><td>&nbsp;</td><td>&nbsp;</td><td>21</td></tr>
</table>

<p>V&nbsp;praxi se používají sítě s&nbsp;více vrstvami a především
s&nbsp;větším počtem neuronů v&nbsp;každé vrstvě. Stavový prostor a tím i
schopnosti sítě se tak prudce rozšiřují (viz již zmíněná problematika
rozpoznávání objektů v&nbsp;rastrových obrázcích).</p>

<p><div class="rs-tip-major">Poznámka: někdy se počet neuronů v&nbsp;umělých
sítích porovnává s&nbsp;počtem neuronů v&nbsp;mozku, ale to je ve skutečnosti
dost zavádějící, neboť záleží spíše na uspořádání sítě, složitosti neuronů
(více výstupů) atd. A pravděpodobně mnoho věcí o mozku ještě neznáme.</div></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Trénink (učení) sítě s&nbsp;využitím trénovacích dat</h2>

<p>Nejzajímavější je proces tréninku (učení) sítě. Ten může probíhat několika
způsoby, ovšem nejčastější je učení založené na tom, že na vstup sítě přivedeme
data, u nichž dopředu známe očekávaný výsledek. Síť pro tato vstupní data
provede svůj odhad a na základě rozdílů mezi odhadem sítě a očekávaným
výsledkem se více či méně sofistikovanými algoritmy nepatrně pozmění váhy
<strong>w<sub>i</sub></strong> na vstupech do neuronů (včetně biasu, tedy
<strong>w<sub>0</sub></strong>).</p>

<p>Konkrétní míra změn váhy na vstupech neuronů je globálně řízena dalším
parametrem či parametry, z&nbsp;nichž ten nejdůležitější ovlivňuje rychlost
učení. Ta by neměla být příliš nízká (to vyžaduje objemná trénovací data nebo
jejich opakování), ale ani příliš vysoká. Základní algoritmus učení sítě se
jmenuje <i>backpropagation</i>, protože se váhy skutečně mění v&nbsp;opačném
směru &ndash; od výstupů (na něž se přivede vypočtená chyba) ke vstupům. Asi
nejlépe je tento koncept popsán v&nbsp;článku dostupném na adrese <a
href="https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/">https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/</a>,
tuto část za nás však vykoná knihovna <i>scikit-learn</i> zcela
automaticky.</p>



<p><a name="k08"></a></p>
<h2 id="k08">8. Neuronová síť jako další typ modelu ve <i>scikit-learn</i></h2>

<p>V&nbsp;knihovně <i>scikit-learn</i> se s&nbsp;neuronovými sítěmi pracuje
prakticky stejným způsobem, jako s&nbsp;dalšími typy modelů. Implementace
neuronových sítí tedy dělíme na klasifikátory a na sítě/modely provádějící
regresi. Připomeňme si tedy, jakým způsobem se vytvoří model (NEzaložený na
neuronové síti), který bude provádět klasifikaci, tj.&nbsp;na základě vstupu
oznámí, že výstupní hodnota spadá do určité kategorie. V&nbsp;našem konkrétním
případě se bude jednat o datovou sadu <i>Iris</i> a budeme rozlišovat čtyři
možné druhy květin. Použijeme model <strong>KNeighborsClassifier</strong>:</p>

<pre>
from sklearn.datasets import load_iris
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
import numpy as np
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = KNeighborsClassifier(n_neighbors=1)
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
&nbsp;
<i># trening modelu</i>
classifier.fit(X_train, y_train)
&nbsp;
<i># očekávané výsledky</i>
expexted_labels = y_test
&nbsp;
<i># výsledky modelu (predikované výsledky)</i>
predicted_labels = classifier.predict(X_test)
&nbsp;
<i># jak je náš model úspěšný?</i>
total = 0
same = 0
&nbsp;
<i># porovnání predikce s očekáváním</i>
for (expected, predicted) in zip(expexted_labels, predicted_labels):
    if expected==predicted:
        same+=1
    total+=1
&nbsp;
print(f"total:    {total}")
print(f"same:     {same}")
print(f"accuracy: {100.0*same/total:4.1f}%")
</pre>

<p>Po spuštění tohoto skriptu se zobrazí, že z&nbsp;třiceti vstupů (20% ze
vstupní datové sady se 150 záznamy) se dobře klasifikovalo 29 vstupů a přesnost
modelu je tedy 96,7%:</p>

<pre>
total:    30
same:     29
accuracy: 96.7%
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Konstrukce neuronové sítě, její trénink a následné použití</h2>

<p>Nyní provedeme jednoduchou záměnu &ndash; namísto modelu
<strong>KNeighborsClassifier</strong> použijeme model
<strong>MLPClassifier</strong>, což je model založený na neuronové síti (MLP
znamená <i>MultiLayer Perceptron</i>). Model natrénujeme naprosto stejným
způsobem, jako model <a href="#k08">z&nbsp;předchozí kapitoly</a>, a následně
jej i naprosto stejným způsobem otestujeme:</p>

<pre>
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = MLPClassifier(max_iter=5000)
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
&nbsp;
<i># trening modelu</i>
classifier.fit(X_train, y_train)
&nbsp;
<i># očekávané výsledky</i>
expexted_labels = y_test
&nbsp;
<i># výsledky modelu (predikované výsledky)</i>
predicted_labels = classifier.predict(X_test)
&nbsp;
<i># jak je náš model úspěšný?</i>
total = 0
same = 0
&nbsp;
<i># porovnání predikce s očekáváním</i>
for (expected, predicted) in zip(expexted_labels, predicted_labels):
    if expected==predicted:
        same+=1
    total+=1
&nbsp;
print(f"total:    {total}")
print(f"same:     {same}")
print(f"accuracy: {100.0*same/total:4.1f}%")
&nbsp;
print(f"Features: {classifier.n_features_in_}")
print(f"Layers:   {classifier.n_layers_}")
print(f"Outputs:  {classifier.n_outputs_}")
print("Weights:")
&nbsp;
for layer, weights in enumerate(classifier.coefs_):
    print("\t", layer, weights.shape)
&nbsp;
print("Biases:")
&nbsp;
for layer, biases in enumerate(classifier.intercepts_):
    print("\t", layer, biases.shape)
</pre>

<p>Výsledky pro několik běhů naznačují, že se při tréninku sítě používají
náhodné hodnoty a tudíž výsledky nebudou vždy totožné:</p>

<pre>
total:    30
same:     30
accuracy: 100.0%
</pre>

<p>Další běh:</p>

<pre>
total:    30
same:     28
accuracy: 93.3%
</pre>

<p><div class="rs-tip-major">Poznámka: neuronová síť tedy nemusí být (a ani
nebývá) &bdquo;chytřejší&ldquo;, než jiné typy modelů!</div></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Zobrazení vah neuronů v&nbsp;jednotlivých vrstvách</h2>

<p>Povšimněte si, že na konci předchozího skriptu (po zjištění přesnosti
modelu) si ještě necháme vypsat základní informace o neuronové síti. Zejména se
vypíšou informace o počtu vstupů (<i>features</i>), počtu hladin
(<i>layers</i>) i o počtu výstupů (<i>outputs</i>):</p>

<pre>
print(f"Features: {classifier.n_features_in_}")
print(f"Layers:   {classifier.n_layers_}")
print(f"Outputs:  {classifier.n_outputs_}")
print("Weights:")
</pre>

<p>Pro datovou sadu <i>Iris</i> se vypíše:</p>

<pre>
Features: 4
Layers:   3
Outputs:  3
</pre>

<p>Tj.&nbsp;bude se jednat o neuronovou síť, kde vstupní vrstva má čtyři
neurony, výstupní vrstva má tři neurony (rozlišujeme tři druhy květin) a
celkový počet vrstev bude roven třem (tedy k&nbsp;dispozici je jen jedna skrytá
vrstva).</p>

<p>Dále si můžeme vypsat váhy vstupů jednotlivých neuronů i hodnoty
<i>bias</i>:</p>

<pre>
&nbsp;
for layer, weights in enumerate(classifier.coefs_):
    print("\t", layer, weights.shape)
&nbsp;
print("Biases:")
&nbsp;
for layer, biases in enumerate(classifier.intercepts_):
    print("\t", layer, biases.shape)
</pre>

<p>Výsledky:</p>

<pre>
Weights:
         0 (4, 100)
         1 (100, 3)
Biases:
         0 (100,)
         1 (3,)
</pre>

<p>Jak tyto údaje číst? Skrytá vrstva má sto neuronů, takže se propojuje stylem
4:100:3. Váhy jsou uloženy ve formě dvourozměrných matic s&nbsp;hodnotami typu
<i>float</i>. A hodnoty <i>bias</i> jsou uloženy pro každou vrstvu formou
vektorů (není zde realizováno propojení &bdquo;každý s&nbsp;každým&ldquo;, jde
jen o vstup konstant do neuronů.</p>

<p>Pro neuronovou síť se třemi skrytými vrstvami, z&nbsp;nich každá má 10
neuronů, bude výstup vypadat následovně:</p>

<pre>
Features: 4
Layers:   5
Outputs:  3
Weights:
         0 (4, 10)
         1 (10, 10)
         2 (10, 10)
         3 (10, 3)
Biases:
         0 (10,)
         1 (10,)
         2 (10,)
         3 (3,)
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. Zjištění přesnosti modelu vytvořeného neuronovou sítí, pomocí funkce <strong>accuracy_score</strong></h2>

<p>Podobně jako u dalších typů modelů pochopitelně můžeme i u neuronových sítí
zjistit přesnost modelu kombinací funkcí <strong>train_test_split</strong> a
<strong>accuracy_score</strong>. Výsledkem by měly být podobné hodnoty, jaké
jsme dostali v&nbsp;předchozím skriptu:</p>

<pre>
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
&nbsp;
from sklearn.metrics import accuracy_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = MLPClassifier(max_iter=5000)
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
&nbsp;
<i># trening modelu</i>
classifier.fit(X_train, y_train)
&nbsp;
&nbsp;
<i># výsledky modelu (predikované výsledky)</i>
y_pred = classifier.predict(X_test)
&nbsp;
<i># vypoctena presnost modelu</i>
print(accuracy_score(y_test, y_pred))
&nbsp;
print(f"Features: {classifier.n_features_in_}")
print(f"Layers:   {classifier.n_layers_}")
print(f"Outputs:  {classifier.n_outputs_}")
print("Weights:")
&nbsp;
for layer, weights in enumerate(classifier.coefs_):
    print("\t", layer, weights.shape)
&nbsp;
print("Biases:")
&nbsp;
for layer, biases in enumerate(classifier.intercepts_):
    print("\t", layer, biases.shape)
</pre>

<p>Skóre při prvním spuštění:</p>

<pre>
0.9666666666666667
</pre>

<p>Při dalším spuštění může být skóre vyšší (nebo nižší). Já měl štěstí &ndash;
vyšel mi 100% korektní model:</p>

<pre>
1.0
</pre>

<p>A nakonec se opět vypíše konfigurace naučené neuronové sítě:</p>

<pre>
Features: 4
Layers:   3
Outputs:  3
Weights:
         0 (4, 100)
         1 (100, 3)
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Konfigurace topologie neuronové sítě &ndash; počty neuronů ve skrytých vrstvách</h2>

<p>Knihovna <i>scikit-learn</i> umožňuje částečnou konfiguraci topologie
neuronové sítě. Volit totiž můžeme počty neuronů v&nbsp;jednotlivých skrytých
vrstvách (nikoli ve vrstvě vstupní ani ve vrstvě výstupní &ndash; což je
logické). Dosáhneme toho následujícím konstruktorem:</p>

<pre>
classifier = MLPClassifier(max_iter=5000, hidden_layer_sizes = (počet_neuronů_ve_vrstvě1, počet_neuronů_ve_vrstvě2, ...))
</pre>

<p>To tedy znamená, že se počet neuronů předává ve formě n-tice, kde počet
členů určí počet skrytých vrstev.</p>

<p>Ukažme si celý postup na jednoduchém demonstračním příkladu, v&nbsp;němž
vytvoříme neuronovou síť se třemi skrytými vrstvami, přičemž každá vrstva bude
obsahovat deset neuronů:</p>

<pre>
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
&nbsp;
from sklearn.metrics import accuracy_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># konstrukce klasifikatoru</i>
<i># (s hyperparametrem)</i>
classifier = <strong>MLPClassifier(max_iter=5000, hidden_layer_sizes = (10, 10, 10))</strong>
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
<i># rozdělení na trénovací a testovací data</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
&nbsp;
<i># trening modelu</i>
classifier.fit(X_train, y_train)
&nbsp;
&nbsp;
<i># výsledky modelu (predikované výsledky)</i>
y_pred = classifier.predict(X_test)
&nbsp;
<i># vypoctena presnost modelu</i>
print(accuracy_score(y_test, y_pred))
&nbsp;
print(f"Features: {classifier.n_features_in_}")
print(f"Layers:   {classifier.n_layers_}")
print(f"Outputs:  {classifier.n_outputs_}")
print("Weights:")
&nbsp;
for layer, weights in enumerate(classifier.coefs_):
    print("\t", layer, weights.shape)
&nbsp;
print("Biases:")
&nbsp;
for layer, biases in enumerate(nn.intercepts_):
    print("\t", layer, biases.shape)
</pre>

<p>Postupně získávané výsledky (přesnosti predikce modelu):</p>

<pre>
0.9666666666666667
0.9333333333333333
1.0
</pre>

<p>Zajímavá bude informace o samotné neuronové síti. Povšimněte si, že nyní je
počet vrstev roven 1+3+1=5 a že váhy odpovídají tomu, že skryté vrstvy budou
mít každá deset neuronů:</p>

<pre>
Features: 4
Layers:   5
Outputs:  3
Weights:
         0 (4, 10)
         1 (10, 10)
         2 (10, 10)
         3 (10, 3)
Biases:
         0 (10,)
         1 (10,)
         2 (10,)
         3 (3,)
</pre>



<p><a name="k13"></a></p>
<h2 id="k13">13. Vliv počtu neuronů ve skrytých vrstvách na predikce neuronové sítě</h2>

<p>Mohlo by se zdát, že větší neuronová síť (tedy více neuronů) může znamenat,
že dostaneme i kvalitnější model a lepší výsledky. Ovšem v&nbsp;praxi můžeme
narazit na úplný opak, a to ve chvíli, kdy se neuronová síť nedokáže správně
zaučit &ndash; datová sada je buď příliš malá, nebo je neuronů tolik, že
<i>gradient</i> při změně jejich vah je příliš malý nebo dokonce nulový.  Ovšem
zaměřme se nejdříve na případ, kdy vyšší počet neuronů má dobrý vliv na kvalitu
modelu. Ostatně si to můžeme snadno ukázat &ndash; pro naši síť se třemi
skrytými vrstvami budeme postupně zvyšovat počet neuronů v&nbsp;těchto vrstvách
od 1 do 19 a budeme počítat úspěšnost takového modelu:</p>

<pre>
import matplotlib.pyplot as plt
&nbsp;
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
avg_scores = []
&nbsp;
r = range(1, 20)
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for neurons in r:
    <i># konstrukce klasifikatoru</i>
    <i># (s hyperparametrem)</i>
    classifier = MLPClassifier(max_iter=5000, hidden_layer_sizes = (neurons, neurons, neurons))
&nbsp;
    <i># vypocet skore</i>
    scores = cross_val_score(classifier, X, y, cv=10, scoring='accuracy')
&nbsp;
    avg_score = scores.mean()
&nbsp;
    <i># vypsani prumerneho skore do tabulky</i>
    print(neurons, avg_score)
&nbsp;
    avg_scores.append(avg_score)
&nbsp;
plt.plot(r, avg_scores)
plt.xlabel("Změna počtu neuronů ve třech vrstvách")
plt.ylabel("Přesnost modelu")
&nbsp;
<i># ulozeni grafu do souboru</i>
plt.savefig("139.png")
&nbsp;
<i># vykresleni grafu na obrazovku</i>
plt.show()
</pre>

<p>Numerické výsledky ukazují, že pro cca 8 neuronů ve vrstvě jsme dosáhli
optimálního bodu:</p>

<pre>
1 0.33333333333333337
2 0.6533333333333333
3 0.7533333333333332
4 0.76
5 0.9666666666666668
6 0.9066666666666666
7 0.9466666666666667
8 0.9866666666666667
9 0.9866666666666667
10 0.9866666666666667
11 0.9666666666666668
12 0.9733333333333334
13 0.9666666666666668
14 0.9733333333333334
15 0.9733333333333334
16 0.9733333333333334
17 0.9733333333333334
18 0.9733333333333334
19 0.9733333333333334
</pre>

<p>Ještě lépe je to vidět na vykresleném grafu:</p>

<img src="https://i.iinfo.cz/images/79/scikit-nn-1-1.webp" class="image-1137533" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 6: Vliv počtu neuronů na kvalitu modelu.</i></p>



<p><a name="k14"></a></p>
<h2 id="k14">14. Výsledky pro neuronovou síť s&nbsp;pěti skrytými vrstvami</h2>

<p>Pokusme se nyní zvýšit počet skrytých vrstev ze tří na pět. Skript bude
prakticky stejný, jako tomu bylo <a href="#k13">v&nbsp;předchozí kapitole</a>,
pouze se změní n-tice předávaná do konstruktoru <strong>MLPClassifier</strong>.
Nyní budeme specifikovat pět vrstev (hodnot v&nbsp;n-tici) a nikoli vrstvy
tři:</p>

<pre>
import matplotlib.pyplot as plt
&nbsp;
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
avg_scores = []
&nbsp;
r = range(1, 20)
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for neurons in r:
    <i># konstrukce klasifikatoru</i>
    <i># (s hyperparametrem)</i>
    classifier = MLPClassifier(max_iter=5000, hidden_layer_sizes = (neurons, neurons, neurons, neurons, neurons))
&nbsp;
    <i># vypocet skore</i>
    scores = cross_val_score(classifier, X, y, cv=10, scoring='accuracy')
&nbsp;
    avg_score = scores.mean()
&nbsp;
    <i># vypsani prumerneho skore do tabulky</i>
    print(neurons, avg_score)
&nbsp;
    avg_scores.append(avg_score)
&nbsp;
plt.plot(r, avg_scores)
plt.xlabel("Změna počtu neuronů v pěti vrstvách")
plt.ylabel("Přesnost modelu")
&nbsp;
<i># ulozeni grafu do souboru</i>
plt.savefig("140.png")
&nbsp;
<i># vykresleni grafu na obrazovku</i>
plt.show()
</pre>

<p>Výsledky nyní budou (na první pohled možná poněkud paradoxně) nepatrně
horší, než tomu bylo v&nbsp;předchozím příkladu:</p>

<pre>
1 0.33333333333333337
2 0.4666666666666666
3 0.7133333333333333
4 0.7
5 0.9066666666666666
6 0.9733333333333334
7 0.9866666666666667
8 0.9133333333333333
9 0.9133333333333333
10 0.9733333333333334
11 0.9866666666666667
12 0.9866666666666667
13 0.9733333333333334
14 0.9733333333333334
15 0.9800000000000001
16 0.9733333333333334
17 0.9800000000000001
18 0.9800000000000001
19 0.9733333333333334
</pre>

<p>Grafické znázornění výsledků:</p>

<img src="https://i.iinfo.cz/images/79/scikit-nn-1-2.webp" class="image-1137536" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 7: Vliv počtu neuronů na kvalitu modelu.</i></p>



<p><a name="k15"></a></p>
<h2 id="k15">15. Má další zvyšování počtu skrytých vrstev význam?</h2>

<p>Zajímavé bude taktéž zjistit, jestli má vůbec smysl zvyšovat počet skrytých
vrstev nad určitou ideální hodnotu. Opět si to můžeme vyzkoušet, a to tak, že
budeme měnit počet prvků v&nbsp;n-tici <strong>hidden_layer_sizes</strong>:</p>

<pre>
NEURONS = 5
r = range(1, 40)
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for layers in r:
    <i># konstrukce klasifikatoru</i>
    <i># (s hyperparametrem)</i>
    layer_sizes = (NEURONS, ) * layers
    classifier = MLPClassifier(max_iter=5000, hidden_layer_sizes = layer_sizes)
</pre>

<p><div class="rs-tip-major">Poznámka: pozor &ndash; tento skript bude běžet
velmi dlouho, i několik hodin:</div></p>

<pre>
import matplotlib.pyplot as plt
&nbsp;
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPClassifier
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
avg_scores = []
&nbsp;
NEURONS = 5
r = range(1, 40)
&nbsp;
<i># hledani optimalniho poctu neuronu ve vrstvach</i>
for layers in r:
    <i># konstrukce klasifikatoru</i>
    <i># (s hyperparametrem)</i>
    layer_sizes = (NEURONS, ) * layers
    classifier = MLPClassifier(max_iter=5000, hidden_layer_sizes = layer_sizes)
&nbsp;
    <i># vypocet skore</i>
    scores = cross_val_score(classifier, X, y, cv=10, scoring='accuracy')
&nbsp;
    avg_score = scores.mean()
&nbsp;
    <i># vypsani prumerneho skore do tabulky</i>
    print(layers, avg_score)
&nbsp;
    avg_scores.append(avg_score)
&nbsp;
plt.plot(r, avg_scores)
plt.xlabel("Změna počtu vrstev")
plt.ylabel("Přesnost modelu")
&nbsp;
<i># ulozeni grafu do souboru</i>
plt.savefig("141.png")
&nbsp;
<i># vykresleni grafu na obrazovku</i>
plt.show()
</pre>

<p>Nyní jsou výsledky dosti odlišné od předchozích dvou výsledků, protože se
model nejenom přestane zlepšovat, ale od cca 4-5 skrytých vrstev se naopak
začíná zhoršovat, a to dosti podstatným způsobem (až k&nbsp;tomu, že začne
hádat &ndash; což přesně odpovídá hodnotě 1/3, protože klasifikujeme jen tři
druhy rostlin, a na hádání nám stačí funkce RND a nikoli neuronová síť):</p>

<pre>
1 0.9666666666666668
2 0.9800000000000001
3 0.8466666666666667
4 0.9733333333333334
5 0.9733333333333334
6 0.7133333333333333
7 0.8733333333333334
8 0.8866666666666667
9 0.5999999999999999
10 0.7466666666666667
11 0.7333333333333333
12 0.6799999999999999
13 0.5866666666666667
14 0.8066666666666666
15 0.4666666666666666
16 0.4666666666666666
17 0.4533333333333333
18 0.4333333333333333
19 0.39333333333333337
20 0.4
21 0.33333333333333337
22 0.33333333333333337
23 0.44666666666666666
24 0.33333333333333337
25 0.42000000000000004
26 0.4
27 0.33333333333333337
28 0.33333333333333337
29 0.33333333333333337
30 0.33333333333333337
31 0.33333333333333337
32 0.33333333333333337
33 0.33333333333333337
34 0.33333333333333337
35 0.33333333333333337
36 0.33333333333333337
37 0.33333333333333337
38 0.33333333333333337
39 0.33333333333333337
</pre>

<p>Grafické znázornění výsledků:</p>

<img src="https://i.iinfo.cz/images/79/scikit-nn-1-3.webp" class="image-1137539" width="640" height="480" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 8: Vliv počtu skrytých vrstev na kvalitu modelu.</i></p>



<p><a name="k16"></a></p>
<h2 id="k16">16. Lineární model provádějící regresi</h2>

<p>V&nbsp;první části článku jsme si ukázali, jak podobné je použití
libovolného modelu pro klasifikaci s&nbsp;neuronovou sítí, která taktéž provádí
klasifikaci. Ovšem prakticky totéž platí i pro vztah mezi modely pro regresi a
neuronovou sítí provádějící taktéž regresi (tedy zjednodušeně řečeno odhad
numerické hodnoty z&nbsp;nějakého intervalu). Zopakujme si tedy, jak lze použít
jednoduchý model pro lineární regresi a následně zjistit jeho (ne)přesnost.
Použijeme přitom naši známou datovou sadu <i>California Housings</i>:</p>

<pre>
from sklearn import linear_model
from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># ceny bloku</i>
targets = housings["target"]
&nbsp;
<i># X je matice, y je vektor</i>
X = data
y = targets
&nbsp;
<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.6)
&nbsp;
<i># konstrukce modelu</i>
lr = <strong>linear_model.LinearRegression()</strong>
&nbsp;
<i># trénink modelu</i>
lr.fit(X_train, y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = lr.predict(X_test)
&nbsp;
<i># výpis vypočtených koeficientů modelu</i>
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)
&nbsp;
<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
</pre>

<p>Po spuštění tohoto skriptu se zobrazí koeficienty lineárního modelu a
následně i přesnost (zde spíše nepatrná nepřesnost) odhadu výsledků:</p>

<pre>
Coefficients:
 [ 4.45786809e-01  9.72953693e-03 -1.35720128e-01  8.20514635e-01
 -1.33231372e-06 -2.84786314e-03 -4.16735165e-01 -4.31811104e-01]
Intercept:
 -36.869534449989914
Mean squared error: 0.53
Coefficient of determination: 0.61
</pre>



<p><a name="k17"></a></p>
<h2 id="k17">17. Neuronová síť provádějící regresi</h2>

<p>Nyní namísto modelu <strong>LinearRegression</strong> použijeme model
nazvaný <strong>MLPRegressor</strong>. Jedná se o model založený na neuronové
síti, který dokáže provádět regresi. A navíc do skriptu přidáme i (nyní známou)
část, která vypíše základní parametry zkonstruované a natrénované neuronové
sítě:</p>

<pre>
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># ceny bloku</i>
targets = housings["target"]
&nbsp;
<i># X je matice, y je vektor</i>
X = data
y = targets
&nbsp;
<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)
&nbsp;
<i># konstrukce modelu</i>
nn = <strong>MLPRegressor(max_iter=5000)</strong>
&nbsp;
<i># trénink modelu</i>
nn.fit(X_train, y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = nn.predict(X_test)
&nbsp;
<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
&nbsp;
print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")
&nbsp;
for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
&nbsp;
print("Biases:")
&nbsp;
for layer, biases in enumerate(nn.intercepts_):
    print("\t", layer, biases.shape)
</pre>

<p>Po spuštění tohoto skriptu se opět nejdříve zobrazí výsledek validace modelu
(s&nbsp;nepříliš lichotivými výsledky):</p>

<pre>
Mean squared error: 1.34
Coefficient of determination: -0.01
</pre>

<p>Posléze se zobrazí informace o neuronové síti. Ve vstupní vrstvě je osm
neuronů, což odpovídá počtu atributů, na které byla síť natrénována. Výstupní
vrstva má jeden neuron, což je opět pochopitelné, protože výstupem má být
jediné reálné číslo. A celkový počet vrstev je roven třem &ndash; tedy kromě
vstupní vrstvy a vrstvy výstupní máme jedinou skrytou vrstvu:</p>

<pre>
Features: 8
Layers:   3
Outputs:  1
</pre>

<p>Posledními údaji, které skript uvedený v&nbsp;této kapitole zobrazí, jsou
tvary (<i>shape</i>) polí s&nbsp;váhami neuronů a taktéž pole s&nbsp;hodnotami
<i>bias</i>. Tvary těchto polí plně odpovídají očekávané topologii neuronové
sítě (tedy vazby 8:100:1 atd.):</p>

<pre>
Weights:
	 0 (8, 100)
	 1 (100, 1)
Biases:
	 0 (100,)
	 1 (1,)
</pre>



<p><a name="k18"></a></p>
<h2 id="k18">18. Změna počtu skrytých vrstev a neuronů v&nbsp;těchto vrstvách</h2>

<p>Podobně jako u neuronové sítě tvořící základ modelu
<strong>MLPClassifier</strong> můžeme i u neuronové sítě v&nbsp;modelu
<strong>MLPRegressor</strong> měnit jak počet skrytých vrstev, tak i počty
neuronů v&nbsp;těchto vrstvách. K&nbsp;tomuto účelu se používá stejný nepovinný
parametr <strong>hidden_layer_sizes</strong>, kterému se předává n-tice
obsahující počty neuronů v&nbsp;jednotlivých vrstvách:</p>

<pre>
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
from sklearn.datasets import fetch_california_housing
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># ceny bloku</i>
targets = housings["target"]
&nbsp;
<i># X je matice, y je vektor</i>
X = data
y = targets
&nbsp;
<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)
&nbsp;
neurons = 1000
&nbsp;
<i># konstrukce modelu</i>
nn = MLPRegressor(max_iter=5000, <strong>hidden_layer_sizes = (neurons, neurons, )</strong>)
&nbsp;
<i># trénink modelu</i>
nn.fit(X_train, y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = nn.predict(X_test)
&nbsp;
<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
&nbsp;
print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")
&nbsp;
for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
</pre>

<p>Na výsledky nyní budeme čekat delší dobu, a to kvůli pomalejšímu tréninku
neuronové sítě:</p>

<pre>
Mean squared error: 0.65
Coefficient of determination: 0.51
Features: 8
Layers:   4
Outputs:  1
Weights:
         0 (8, 1000)
         1 (1000, 1000)
         2 (1000, 1)
Biases:
         0 (1000,)
         1 (1000,)
         2 (1,)
</pre>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu Scikit-learn lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady i na (Jupyter) diáře s&nbsp;postupem
výpočtů a analýz:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td>01_show_matrix.py</td><td>kooperace mezi knihovnami Matplotlib a NumPy: vizualizace obsahu 2D matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py</a></td></tr>
<tr><td> 2</td><td>02_get_digits.py</td><td>datová množina obsahující naskenované ručně napsané číslice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py</a></td></tr>
<tr><td> 3</td><td>03_get_features.py</td><td>další atributy datové množiny, které použijeme při trénování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py</a></td></tr>
<tr><td> 4</td><td>04_get_images.py</td><td>přečtení a následné vykreslení jednotlivých ručně nakreslených číslic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py</a></td></tr>
<tr><td> 5</td><td>05_show_grayscale_matrix.py</td><td>odstranění umělé aplikované barvové palety (obrázky ve stupních šedi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py</a></td></tr>
<tr><td> 6</td><td>06_grayscale_images.py</td><td>vykreslení ručně nakreslených číslic ve formě obrázků ve stupních šedi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py</a></td></tr>
<tr><td> 7</td><td>07_multiplot.py</td><td>rozdělení plochy grafu do oblastí; vykreslení více obrázků do jediného grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py</a></td></tr>
<tr><td> 8</td><td>08_model_preperation_1.py</td><td>obrázky s&nbsp;jejich ohodnocením</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py</a></td></tr>
<tr><td> 9</td><td>09_training_set.py</td><td>příprava dat pro trénink</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py</a></td></tr>
<tr><td>10</td><td>10_classification.py</td><td>klasifikace obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py</a></td></tr>
<tr><td>11</td><td>11_results.py</td><td>vykreslení obrázků společně s&nbsp;jejich klasifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py</a></td></tr>
<tr><td>12</td><td>12_change_training_set.py</td><td>změna poměru rozdělení dat na tréninkovou a testovací množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>13</td><td>13_blobs.py</td><td>použití funkce <strong>make_blobs</strong> pro vygenerování sady bodů v&nbsp;rovině sdružených do oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py</a></td></tr>
<tr><td>14</td><td>14_swap_coords.py</td><td>úprava předchozího příkladu: prohození souřadnic na osách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py</a></td></tr>
<tr><td>15</td><td>15_blobs_scatter_plot.py</td><td>základní podoba bodového diagramu (<i>scatter plot</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py</a></td></tr>
<tr><td>16</td><td>16_blobs_scatter_plot.py</td><td>úprava bodového diagramu při zobrazení většího množství bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py</a></td></tr>
<tr><td>17</td><td>17_colorized_blobs.py</td><td>obarvení bodů podle oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py</a></td></tr>
<tr><td>18</td><td>18_k-means.py</td><td>základní použití algoritmu K-means pro clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py</a></td></tr>
<tr><td>19</td><td>19_combination.py</td><td>zobrazení centroidů společně s&nbsp;původními body</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py</a></td></tr>
<tr><td>20</td><td>20_combinations.py</td><td>vizualizace clusteringu původní množiny bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py</a></td></tr>
<tr><td>21</td><td>21_other_settings.py</td><td>vizualizace clusteringu původní množiny bodů pro odlišnou množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py</a></td></tr>
<tr><td>22</td><td>22_random_points.py</td><td>clustering pro náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>23</td><td>23_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, menší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py</a></td></tr>
<tr><td>24</td><td>24_more_noise_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, větší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py</a></td></tr>
<tr><td>25</td><td>25_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, menší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py</a></td></tr>
<tr><td>26</td><td>26_more_noisy_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, větší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py</a></td></tr>
<tr><td>27</td><td>27_circles_kmeans.py</td><td>výsledek clusteringu provedeného algoritmem K-means na &bdquo;kružnice&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/27_circles_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/27_circles_kmeans.py</a></td></tr>
<tr><td>28</td><td>28_moons_kmeans.py</td><td>výsledek clusteringu provedeného algoritmem K-means na &bdquo;půlměsíce&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/28_moons_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/28_moons_kmeans.py</a></td></tr>
<tr><td>29</td><td>29_blobs_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné pomocí <strong>make_blobs</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/29_blobs_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/29_blobs_spectral_clustering.py</a></td></tr>
<tr><td>30</td><td>30_circles_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné do kružnic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/30_circles_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/30_circles_spectral_clustering.py</a></td></tr>
<tr><td>31</td><td>31_moons_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné do půlměsíců </td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/31_moons_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/31_moons_spectral_clustering.py</a></td></tr>
<tr><td>32</td><td>32_moons_spectral_clustering_limits.py</td><td>vyhledání limitů algoritmu spectral clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/32_moons_spectral_clustering_limits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/32_moons_spectral_clustering_limits.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>33</td><td>33_particles_load.py</td><td>načtení souřadnic částic uložených v&nbsp;souboru formátu CSV</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/33_particles_load.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/33_particles_load.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>34</td><td>34_lorenz_attractor.py</td><td>zobrazení Lorenzova atraktoru formou bodů propojených úsečkami</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/34_lorenz_attractor.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/34_lorenz_attractor.py</a></td></tr>
<tr><td>35</td><td>35_lorenz_attractor_points.py</td><td>Lorenzův atraktor vykreslený formou jednotlivých bodů s&nbsp;definovaným stylem zobrazení a velikostí stopy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/35_lorenz_attractor_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/35_lorenz_attractor_points.py</a></td></tr>
<tr><td>36</td><td>36_blobs_3d.py</td><td>vygenerování a zobrazení sady bodů v&nbsp;3D prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/36_blobs_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/36_blobs_3d.py</a></td></tr>
<tr><td>37</td><td>37_spread_blobs_3d.py</td><td>vygenerování a zobrazení sady bodů v&nbsp;3D prostoru, odlišné parametry při generování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/37_spread_blobs_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/37_spread_blobs_3d.py</a></td></tr>
<tr><td>38</td><td>38_views.py</td><td>různé pohledy na 3D graf</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/38_views.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/38_views.py</a></td></tr>
<tr><td>39</td><td>39_colorized_3d_blobs.py</td><td>obarvení bodů v&nbsp;prostoru na základě vstupních dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/39_colorized_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/39_colorized_3d_blobs.py</a></td></tr>
<tr><td>40</td><td>40_kmeans_3d_blobs.py</td><td>shluková analýza v&nbsp;3D prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/40_kmeans_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/40_kmeans_3d_blobs.py</a></td></tr>
<tr><td>41</td><td>41_kmeans_spread_3d_blobs.py</td><td>shluková analýza v&nbsp;3D prostoru pro odlišnou množinu bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/41_kmeans_spread_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/41_kmeans_spread_3d_blobs.py</a></td></tr>
<tr><td>42</td><td>42_kmeans_random_3d.py</td><td>shluková analýza pro body rozmístěné zcela náhodně v&nbsp;omezeném prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/42_kmeans_random_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/42_kmeans_random_3d.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>43</td><td>43_speed_measurements.py</td><td>benchmark pro postupně rostoucí počet bodů tvořících shluky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/43_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/43_speed_measurements.py</a></td></tr>
<tr><td>44</td><td>44_speed_measurements.py</td><td>benchmark pro postupně rostoucí počet bodů rozmístěných náhodně</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/44_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/44_speed_measurements.py</a></td></tr>
<tr><td>45</td><td>45_speed_measurements.py</td><td>benchmark pro stále stejný počet bodů, u jejichž rozmístění v&nbsp;prostoru se používá stále větší směrodatná odchylka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/45_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/45_speed_measurements.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>46</td><td>46_iris_dataset.py</td><td>načtení datové kolekce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/46_iris_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/46_iris_dataset.py</a></td></tr>
<tr><td>47</td><td>47_iris_description.py</td><td>metadata o datové kolekci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/47_iris_description.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/47_iris_description.py</a></td></tr>
<tr><td>48</td><td>48_iris_data.py</td><td>tvar dat &ndash; počet záznamů a počet proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/48_iris_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/48_iris_data.py</a></td></tr>
<tr><td>49</td><td>49_iris_targets.py</td><td>jména atributů, vztah mezi numerickou hodnotou atributu a jeho jménem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/49_iris_targets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/49_iris_targets.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>50</td><td>50_iris_scatter_plot_1.py</td><td>korelační diagram pro dvojici vybraných proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/50_iris_scatter_plot_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/50_iris_scatter_plot_1.py</a></td></tr>
<tr><td>51</td><td>51_iris_scatter_plot_2.py</td><td>příprava pro tvorbu složitějších grafů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/51_iris_scatter_plot_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/51_iris_scatter_plot_2.py</a></td></tr>
<tr><td>52</td><td>52_iris_mutliplot.py</td><td>mřížka obsahující více korelačních diagramů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/52_iris_mutliplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/52_iris_mutliplot.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>53</td><td>53_iris_histograms.py</td><td>zobrazení základního histogramu pro data v&nbsp;sadě Iris</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/53_iris_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/53_iris_histograms.py</a></td></tr>
<tr><td>54</td><td>54_iris_histograms.py</td><td>úprava histogramu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/54_iris_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/54_iris_histograms.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>55</td><td>55_pca.py</td><td>analýza hlavních komponent (PCA), výsledek zobrazený v&nbsp;2D grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/55_pca.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/55_pca.py</a></td></tr>
<tr><td>56</td><td>56_pca_3d.py</td><td>analýza hlavních komponent (PCA), výsledek zobrazený v&nbsp;3D grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/56_pca_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/56_pca_3d.py</a></td></tr>
<tr><td>57</td><td>57_kmeans.py</td><td>základní shluková analýza</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/57_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/57_kmeans.py</a></td></tr>
<tr><td>58</td><td>58_multiple_kmeans.py</td><td>větší množství výsledků shlukové analýzy pro různé atributy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/58_multiple_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/58_multiple_kmeans.py</a></td></tr>
<tr><td>59</td><td>59_kmeans_errors.py</td><td>korektní a nekorektní výsledky základní shlukové analýzy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/59_kmeans_errors.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/59_kmeans_errors.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>60</td><td>60_basic_classifier.py</td><td>aplikace jednoduchého modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/60_basic_classifier.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/60_basic_classifier.py</a></td></tr>
<tr><td>61</td><td>61_changed_model_parameters.py</td><td>změna parametrů modelu pro zjištění druhů rostil</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/61_changed_model_parameters.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/61_changed_model_parameters.py</a></td></tr>
<tr><td>62</td><td>62_different_model.py</td><td>použití odlišného modelu pro zjištění druhů rostlin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/62_different_model.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/62_different_model.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>63</td><td>63_verify_on_whole_data_1.py</td><td>otestování naučeného modelu s&nbsp;využitím tréninkových dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/63_verify_on_whole_data_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/63_verify_on_whole_data_1.py</a></td></tr>
<tr><td>64</td><td>64_verify_on_whole_data_2.py</td><td>využití funkce <strong>metrics.accuracy_score</strong> pro zjištění kvality modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/64_verify_on_whole_data_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/64_verify_on_whole_data_2.py</a></td></tr>
<tr><td>65</td><td>65_basic_comparison.py</td><td>porovnání vlastností různých modelů (prozatím nekorektní řešení)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/65_basic_comparison.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/65_basic_comparison.py</a></td></tr>
<tr><td>66</td><td>66_training_testing_split_1.py</td><td>rozdělení datové sady na trénovací data a testovací data (základní varianta)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/66_training_testing_split_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/66_training_testing_split_1.py</a></td></tr>
<tr><td>67</td><td>67_training_testing_split_2.py</td><td>rozdělení datové sady na trénovací data a testovací data (náhodné rozdělení sady)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/67_training_testing_split_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/67_training_testing_split_2.py</a></td></tr>
<tr><td>68</td><td>68_training_testing_split_3.py</td><td>rozdělení datové sady na trénovací data a testovací data (využití vestavěné funkce)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/68_training_testing_split_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/68_training_testing_split_3.py</a></td></tr>
<tr><td>69</td><td>69_better_comparison.py</td><td>vylepšené porovnání vlastností různých modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/69_better_comparison.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/69_better_comparison.py</a></td></tr>
<tr><td>70</td><td>70_multiple_runs.py</td><td>vliv generátoru náhodných čísel na změřené výsledky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/70_multiple_runs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/70_multiple_runs.py</a></td></tr>
<tr><td>71</td><td>71_stable_multiple_runs.py</td><td>generátor náhodných čísel a použití hodnoty <strong>random_state</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/71_stable_multiple_runs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/71_stable_multiple_runs.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>72</td><td>72_housings_dataset.py</td><td>načtení datové sady <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/72_housings_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/72_housings_dataset.py</a></td></tr>
<tr><td>73</td><td>73_housings_dataset_description.py</td><td>metainformace o datové sadě <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/73_housings_dataset_description.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/73_housings_dataset_description.py</a></td></tr>
<tr><td>74</td><td>74_housings_data.py</td><td>n-rozměrné pole s&nbsp;atributy jednotlivých domů/bloků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/74_housings_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/74_housings_data.py</a></td></tr>
<tr><td>75</td><td>75_housings_targets.py</td><td>jména atributů, ceny domů atd.</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/75_housings_targets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/75_housings_targets.py</a></td></tr>
<tr><td>76</td><td>76_housings_scatter_plot.py</td><td>korelační diagram pro dvojici vybraných proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/76_housings_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/76_housings_scatter_plot.py</a></td></tr>
<tr><td>77</td><td>77_housings_mutliplot.py</td><td>korelační diagram pro všechny kombinace dvojic proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/77_housings_mutliplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/77_housings_mutliplot.py</a></td></tr>
<tr><td>78</td><td>78_scatter.py</td><td>dvourozměrné hodnoty reprezentované jako dvojice atributů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/78_scatter.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/78_scatter.py</a></td></tr>
<tr><td>79</td><td>79_linear_regression_gen_data.py</td><td>model <i>LinearRegression</i> nad uměle vytvořenými daty</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/79_linear_regression_gen_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/79_linear_regression_gen_data.py</a></td></tr>
<tr><td>80</td><td>80_linear_regression_predictions.py</td><td>predikce modelu provádějícího lineární regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/80_linear_regression_predictions.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/80_linear_regression_predictions.py</a></td></tr>
<tr><td>81</td><td>81_linear_regression_random_data.py</td><td>chování modelu pro zcela náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/81_linear_regression_random_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/81_linear_regression_random_data.py</a></td></tr>
<tr><td>82</td><td>82_linear_regression_housings.py</td><td>model <i>LinearRegression</i> pro datovou sadu <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/82_linear_regression_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/82_linear_regression_housings.py</a></td></tr>
<tr><td>83</td><td>83_polynomial_regression_gen_data.py</td><td>polynomiální regrese (základní příklad)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/83_polynomial_regression_gen_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/83_polynomial_regression_gen_data.py</a></td></tr>
<tr><td>84</td><td>84_polynomial_regression_housings.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, první příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/84_polynomial_regression_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/84_polynomial_regression_housings.py</a></td></tr>
<tr><td>85</td><td>85_polynomial_regression_housings_2.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, druhý příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/85_polynomial_regression_housings_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/85_polynomial_regression_housings_2.py</a></td></tr>
<tr><td>86</td><td>86_polynomial_regression_housings_3.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, třetí příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/86_polynomial_regression_housings_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/86_polynomial_regression_housings_3.py</a></td></tr>
<tr><td>87</td><td>87_linear_regression_errors.py</td><td>výpočet chyby a skóre modelu lineární regrese</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/87_linear_regression_errors.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/87_linear_regression_errors.py</a></td></tr>
<tr><td>88</td><td>88_linear_regression_non_linear_data.py</td><td>lineární regrese nad nelineárními daty</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/88_linear_regression_non_linear_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/88_linear_regression_non_linear_data.py</a></td></tr>
<tr><td>89</td><td>89_polynomial_regression_error.py</td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/89_polynomial_regression_error.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/89_polynomial_regression_error.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>90</td><td>90_housings_prediction_1.py</td><td>regresní analýza nad daty <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/90_housings_prediction_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/90_housings_prediction_1.py</a></td></tr>
<tr><td>91</td><td>91_housings_prediction_2.py</td><td>korektní natrénování modelu pro regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/91_housings_prediction_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/91_housings_prediction_2.py</a></td></tr>
<tr><td>92</td><td>92_housings_prediction_3.py</td><td>omezení množství atributů (proměnných), na kterých je model natrénován</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/92_housings_prediction_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/92_housings_prediction_3.py</a></td></tr>
<tr><td>93</td><td>93_housings_prediction_errors_1.py</td><td>chybně natrénovaný model při náhodné volbě dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/93_housings_prediction_errors_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/93_housings_prediction_errors_1.py</a></td></tr>
<tr><td>94</td><td>94_housings_prediction_errors_2.py</td><td>omezení atributů + chybně natrénovaný model</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/94_housings_prediction_errors_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/94_housings_prediction_errors_2.py</a></td></tr>
<tr><td>95</td><td>95_housings_histograms.py</td><td>histogramy pro jednotlivé atributy (proměnné)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/95_housings_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/95_housings_histograms.py</a></td></tr>
<tr><td>96</td><td>96_housings_statistic.py</td><td>statistické údaje pro jednotlivé atributy (proměnné)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/96_housings_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/96_housings_statistic.py</a></td></tr>
<tr><td>97</td><td>97_housings_statistic_normalized.py</td><td>statistické údaje získané po normalizaci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/97_housings_statistic_normalized.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/97_housings_statistic_normalized.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 98</td><td>98_k_fold_help.py</td><td>zobrazení nápovědy ke třídě s&nbsp;realizací k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/98_k_fold_help.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/98_k_fold_help.py</a></td></tr>
<tr><td> 99</td><td>99_k_fold_old.py</td><td>původní (nepodporovaná) varianta provedení k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/99_k_fold_old.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/99_k_fold_old.py</a></td></tr>
<tr><td>100</td><td>100_k_fold_1.py</td><td>interní chování algoritmu k-foldingu (základní parametry)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/100_k_fold_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/100_k_fold_1.py</a></td></tr>
<tr><td>101</td><td>101_k_fold_2.py</td><td>interní chování algoritmu k-foldingu (odlišné parametry)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/101_k_fold_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/101_k_fold_2.py</a></td></tr>
<tr><td>102</td><td>102_k_fold_selection.py</td><td>k-folding a výběr dat pro otestování modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/102_k_fold_selection.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/102_k_fold_selection.py</a></td></tr>
<tr><td>103</td><td>103_average_score.py</td><td>realizace výpočtu průměrného skóre pro otestování modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/103_average_score.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/103_average_score.py</a></td></tr>
<tr><td>104</td><td>104_hyperparams_score.py</td><td>změna hyperparametrů s&nbsp;výpočtem průměrného skóre (tabulka)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/104_hyperparams_score.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/104_hyperparams_score.py</a></td></tr>
<tr><td>105</td><td>105_hyperparams_score_plot.py</td><td>změna hyperparametrů s&nbsp;výpočtem průměrného skóre (graf)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/105_hyperparams_score_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/105_hyperparams_score_plot.py</a></td></tr>
<tr><td>106</td><td>106_model_selection.py</td><td>výběr nejlepšího modelu s&nbsp;využitím k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/106_model_selection.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/106_model_selection.py</a></td></tr>
<tr><td>107</td><td>107_features_selection_basic.py</td><td>výběr atributů (proměnných) pro trénink modelu (základní varianta)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/107_features_selection_basic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/107_features_selection_basic.py</a></td></tr>
<tr><td>108</td><td>108_features_selection_iris.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada Iris)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/108_features_selection_iris.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/108_features_selection_iris.py</a></td></tr>
<tr><td>109</td><td>109_features_selection_houses.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada California Housings)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/109_features_selection_houses.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/109_features_selection_houses.py</a></td></tr>
<tr><td>110</td><td>110_best_features_selection_houses.py</td><td>získání nejlepší sady atributů (proměnných)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/110_best_features_selection_houses.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/110_best_features_selection_houses.py</a></td></tr>
<tr><td>111</td><td>111_features_selection_graphical.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada Iris), grafický výstup</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/111_features_selection_graphical.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/111_features_selection_graphical.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>112</td><td>112_simplest_linear_regression.py</td><td>lineární regrese bodů ležících v&nbsp;rovině</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/112_simplest_linear_regression.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/112_simplest_linear_regression.py</a></td></tr>
<tr><td>113</td><td>113_linear_regression_no_intercept.py</td><td>lineární regrese při vynucení <i>w<sub>0</sub>=0</i> pro obecná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/113_linear_regression_no_intercept.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/113_linear_regression_no_intercept.py</a></td></tr>
<tr><td>114</td><td>114_linear_regression_from_0_0.py</td><td>lineární regrese při vynucení <i>w<sub>0</sub>=0</i> v&nbsp;případě, že vstupní body obsahují počátek souřadného systému</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/114_linear_regression_from_0_0.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/114_linear_regression_from_0_0.py</a></td></tr>
<tr><td>115</td><td>115_linear_regression_multiple_y.py</td><td>model předpovídající pro každou vstupní hodnotu dvě výstupní hodnoty (odpovědi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/115_linear_regression_multiple_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/115_linear_regression_multiple_y.py</a></td></tr>
<tr><td>116</td><td>116_grid_operations.py</td><td>konstrukce matice obsahující souřadnice bodů v&nbsp;mřížce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/116_grid_operations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/116_grid_operations.py</a></td></tr>
<tr><td>117</td><td>117_linear_regression_multiple_x.py</td><td>proložení bodů v&nbsp;prostoru rovinou</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/117_linear_regression_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/117_linear_regression_multiple_x.py</a></td></tr>
<tr><td>118</td><td>118_linear_regression_multiple_x.py</td><td>proložení bodů s&nbsp;náhodnou výškou rovinou</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/118_linear_regression_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/118_linear_regression_multiple_x.py</a></td></tr>
<tr><td>119</td><td>119_linear_regression_multiple_x_and_y.py</td><td>proložení dvou sad bodů dvojicí rovin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/119_linear_regression_multiple_x_and_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/119_linear_regression_multiple_x_and_y.py</a></td></tr>
<tr><td>120</td><td>120_linear_regression_multiple_x_and_y.py</td><td>proložení dvou sad bodů dvojicí rovin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/120_linear_regression_multiple_x_and_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/120_linear_regression_multiple_x_and_y.py</a></td></tr>
<tr><td>121</td><td>121_linear_regression_poly.py</td><td>základní polynomická regrese</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/121_linear_regression_poly.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/121_linear_regression_poly.py</a></td></tr>
<tr><td>122</td><td>122_linear_regression_poly_multiple_x.py</td><td>polynomická regrese a body v&nbsp;prostoru, první příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/122_linear_regression_poly_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/122_linear_regression_poly_multiple_x.py</a></td></tr>
<tr><td>123</td><td>123_linear_regression_poly_multiple_x.py</td><td>polynomická regrese a body v&nbsp;prostoru, druhý příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/123_linear_regression_poly_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/123_linear_regression_poly_multiple_x.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>124</td><td>124_iris_set_statistic.py</td><td>získání statistických informací o datové sadě <i>Iris</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/124_iris_set_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/124_iris_set_statistic.py</a></td></tr>
<tr><td>125</td><td>125_california_housings_statistic.py</td><td>získání statistických informací o datové sadě <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/125_california_housings_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/125_california_housings_statistic.py</a></td></tr>
<tr><td>126</td><td>126_variance_threshold_1.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/126_variance_threshold_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/126_variance_threshold_1.py</a></td></tr>
<tr><td>127</td><td>127_variance_threshold_2.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/127_variance_threshold_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/127_variance_threshold_2.py</a></td></tr>
<tr><td>128</td><td>128_variance_threshold_3.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/128_variance_threshold_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/128_variance_threshold_3.py</a></td></tr>
<tr><td>129</td><td>129_select_best_iris.py</td><td>výběr nejvhodnějších atributů pro datovou sadu <i>Iris</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/129_select_best_iris.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/129_select_best_iris.py</a></td></tr>
<tr><td>130</td><td>130_select_best_housings.py</td><td>výběr nejvhodnějších atributů pro datovou sadu <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/130_select_best_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/130_select_best_housings.py</a></td></tr>
<tr><td>131</td><td>131_select_k_best_housings.py</td><td>výběr K nejvhodnějších atributů pro datovou sadu <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/131_select_k_best_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/131_select_k_best_housings.py</a></td></tr>
<tr><td>132</td><td>132_select_from_model.py</td><td>výběr atributů na základě k&nbsp;tomu určeného modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/132_select_from_model.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/132_select_from_model.py</a></td></tr>
<tr><td>133</td><td>133_cross_validation_1.py</td><td>křížová validace po výběru (filtraci) modelů (datová sada <i>Iris</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/133_cross_validation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/133_cross_validation_1.py</a></td></tr>
<tr><td>134</td><td>134_cross_validation_2.py</td><td>křížová validace po výběru (filtraci) modelů (datová sada <i>California Housings</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/134_cross_validation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/134_cross_validation_2.py</a></td></tr>
<tr><td>135</td><td>135_cross_validation_3.py</td><td>křížová validace po výběru (filtraci) modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/135_cross_validation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/135_cross_validation_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>136</td><td>136_mlp_classifier_01.py</td><td>použití neuronové sítě pro klasifikaci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/136_mlp_classifier_01.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/136_mlp_classifier_01.py</a></td></tr>
<tr><td>137</td><td>137_mlp_classifier_02.py</td><td>výpočet úspěšnosti modelu založeného na neuronové síti</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/137_mlp_classifier_02.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/137_mlp_classifier_02.py</a></td></tr>
<tr><td>138</td><td>138_mlp_classifier_03.py</td><td>konfigurace vrstev neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/138_mlp_classifier_03.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/138_mlp_classifier_03.py</a></td></tr>
<tr><td>139</td><td>139_mlp_classifier_04.py</td><td>proměnný počet neuronů ve vrstvách neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/139_mlp_classifier_04.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/139_mlp_classifier_04.py</a></td></tr>
<tr><td>140</td><td>140_mlp_classifier_05.py</td><td>proměnný počet neuronů ve více vrstvách neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/140_mlp_classifier_05.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/140_mlp_classifier_05.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>141</td><td>141_mlp_regression_1.py</td><td>použití neuronové sítě pro regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/141_mlp_regression_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/141_mlp_regression_1.py</a></td></tr>
<tr><td>142</td><td>142_mlp_regression_2.py</td><td>modifikace parametrů neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/142_mlp_regression_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/142_mlp_regression_2.py</a></td></tr>
</table>

<p>V&nbsp;repositáři nalezneme taktéž projektový soubor a Jupyter Notebook
s&nbsp;vysvětlením, jak lze modely využít pro rozpoznávání obsahu rastrových
obrázků:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td>1</td><td>pyproject.toml</td><td>projektový soubor (pro PDM) se všemi závislostmi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>2</td><td>pdm.lock</td><td>lock soubor s&nbsp;konkrétními verzemi všech přímých i tranzitivních závislostí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>3</td><td>Rozpoznání_obrazu_scikit-learn.ipynb</td><td>Jupyter notebook s&nbsp;celým postupem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>4</td><td>particle_life.py</td><td>emergence: příklad vzniku struktury</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py">https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

<li>Rozpoznávání obrázků knihovnou Scikit-learn: první kroky<br />
<a href="https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/">https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/</a>
</li>

<li>scikit-learn: Machine Learning in Python<br />
<a href="https://scikit-learn.org/stable/index.html">https://scikit-learn.org/stable/index.html</a>
</li>

<li>Sklearn-pandas<br />
<a href="https://github.com/scikit-learn-contrib/sklearn-pandas">https://github.com/scikit-learn-contrib/sklearn-pandas</a>
</li>

<li>sklearn-xarray<br />
<a href="https://github.com/phausamann/sklearn-xarray/">https://github.com/phausamann/sklearn-xarray/</a>
</li>

<li>Clustering<br />
<a href="https://scikit-learn.org/stable/modules/clustering.html">https://scikit-learn.org/stable/modules/clustering.html</a>
</li>

<li>Cluster analysis (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Cluster_analysis">https://en.wikipedia.org/wiki/Cluster_analysis</a>
</li>

<li>Shluková analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza">https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza</a>
</li>

<li>K-means<br />
<a href="https://cs.wikipedia.org/wiki/K-means">https://cs.wikipedia.org/wiki/K-means</a>
</li>

<li>k-means clustering<br />
<a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a>
</li>

<li>Spectral clustering<br />
<a href="https://en.wikipedia.org/wiki/Spectral_clustering">https://en.wikipedia.org/wiki/Spectral_clustering</a>
</li>

<li>Emergence<br />
<a href="https://cs.wikipedia.org/wiki/Emergence">https://cs.wikipedia.org/wiki/Emergence</a>
</li>

<li>Particle Life: Vivid structures from rudimentary rules<br />
<a href="https://particle-life.com/">https://particle-life.com/</a>
</li>

<li>Hertzsprungův–Russellův diagram<br />
<a href="https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram">https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram</a>
</li>

<li>Using Machine Learning in an HR Diagram<br />
<a href="https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f">https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f</a>
</li>

<li>Gaia H-R diagrams: Querying Gaia data for one million nearby stars<br />
<a href="https://vlas.dev/post/gaia-dr2-hrd/">https://vlas.dev/post/gaia-dr2-hrd/</a>
</li>

<li>The Hertzsprung–Russell diagram<br />
<a href="https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/">https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/</a>
</li>

<li>Animated Hertzsprung-Russell Diagram with 119,614 datapoints<br />
<a href="https://github.com/zonination/h-r-diagram">https://github.com/zonination/h-r-diagram</a>
</li>

<li>Neuraxle Pipelines<br />
<a href="https://github.com/Neuraxio/Neuraxle">https://github.com/Neuraxio/Neuraxle</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Natural-language processing<br />
<a href="https://en.wikipedia.org/wiki/Natural-language_processing">https://en.wikipedia.org/wiki/Natural-language_processing</a>
</li>

<li>THE MNIST DATABASE of handwritten digits<br />
<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>
</li>

<li>MNIST database (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/MNIST_database">https://en.wikipedia.org/wiki/MNIST_database</a>
</li>

<li>MNIST For ML Beginners<br />
<a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch: Serialization<br />
<a href="https://github.com/torch/torch7/blob/master/doc/serialization.md">https://github.com/torch/torch7/blob/master/doc/serialization.md</a>
</li>

<li>Torch: modul image<br />
<a href="https://github.com/torch/image/blob/master/README.md">https://github.com/torch/image/blob/master/README.md</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>Neural network containres (Torch)<br />
<a href="https://github.com/torch/nn/blob/master/doc/containers.md">https://github.com/torch/nn/blob/master/doc/containers.md</a>
</li>

<li>Simple layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear">https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear</a>
</li>

<li>Transfer Function Layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok">https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>PyTorch<br />
<a href="http://pytorch.org/">http://pytorch.org/</a>
</li>

<li>JupyterLite na PyPi<br />
<a href="https://pypi.org/project/jupyterlite/">https://pypi.org/project/jupyterlite/</a>
</li>

<li>JupyterLite na GitHubu<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Dokumentace k&nbsp;projektu JupyterLite<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Matplotlib Home Page<br />
<a href="http://matplotlib.org/">http://matplotlib.org/</a>
</li>

<li>Matplotlib (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Matplotlib">https://en.wikipedia.org/wiki/Matplotlib</a>
</li>

<li>Popis barvových map modulu matplotlib.cm<br />
<a href="https://gist.github.com/endolith/2719900#id7">https://gist.github.com/endolith/2719900#id7</a>
</li>

<li>Ukázky (palety) barvových map modulu matplotlib.cm<br />
<a href="http://matplotlib.org/examples/color/colormaps_reference.html">http://matplotlib.org/examples/color/colormaps_reference.html</a>
</li>

<li>Galerie grafů vytvořených v&nbsp;Matplotlibu<br />
<a href="https://matplotlib.org/3.2.1/gallery/">https://matplotlib.org/3.2.1/gallery/</a>
</li>

<li>3D rendering<br />
<a href="https://en.wikipedia.org/wiki/3D_rendering">https://en.wikipedia.org/wiki/3D_rendering</a>
</li>

<li>3D computer graphics<br />
<a href="https://en.wikipedia.org/wiki/3D_computer_graphics">https://en.wikipedia.org/wiki/3D_computer_graphics</a>
</li>

<li>Primary 3D view planes<br />
<a href="https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html">https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html</a>
</li>

<li>Getting started in scikit-learn with the famous iris dataset<br />
<a href="https://www.youtube.com/watch?v=hd1W4CyPX58">https://www.youtube.com/watch?v=hd1W4CyPX58</a>
</li>

<li>Training a machine learning model with scikit-learn<br />
<a href="https://www.youtube.com/watch?v=RlQuVL6-qe8">https://www.youtube.com/watch?v=RlQuVL6-qe8</a>
</li>

<li>Iris (plant)<br />
<a href="https://en.wikipedia.org/wiki/Iris_(plant)">https://en.wikipedia.org/wiki/Iris_(plant)</a>
</li>

<li>Kosatec<br />
<a href="https://cs.wikipedia.org/wiki/Kosatec">https://cs.wikipedia.org/wiki/Kosatec</a>
</li>

<li>Iris setosa<br />
<a href="https://en.wikipedia.org/wiki/Iris_setosa">https://en.wikipedia.org/wiki/Iris_setosa</a>
</li>

<li>Iris versicolor<br />
<a href="https://en.wikipedia.org/wiki/Iris_versicolor">https://en.wikipedia.org/wiki/Iris_versicolor</a>
</li>

<li>Iris virginica<br />
<a href="https://en.wikipedia.org/wiki/Iris_virginica">https://en.wikipedia.org/wiki/Iris_virginica</a>
</li>

<li>Druh<br />
<a href="https://cs.wikipedia.org/wiki/Druh">https://cs.wikipedia.org/wiki/Druh</a>
</li>

<li>Iris subg. Limniris<br />
<a href="https://en.wikipedia.org/wiki/Iris_subg._Limniris">https://en.wikipedia.org/wiki/Iris_subg._Limniris</a>
</li>

<li>Iris Dataset Classification with Python: A Tutorial<br />
<a href="https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html">https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html</a>
</li>

<li>Iris flower data set<br />
<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">https://en.wikipedia.org/wiki/Iris_flower_data_set</a>
</li>

<li>List of datasets for machine-learning research<br />
<a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research</a>
</li>

<li>Analýza hlavních komponent<br />
<a href="https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent">https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent</a>
</li>

<li>Principal component analysis<br />
<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">https://en.wikipedia.org/wiki/Principal_component_analysis</a>
</li>

<li>Scikit-learn Crash Course - Machine Learning Library for Python<br />
<a href="https://www.youtube.com/watch?v=0B5eIE_1vpU">https://www.youtube.com/watch?v=0B5eIE_1vpU</a>
</li>

<li>calm-notebooks<br />
<a href="https://github.com/koaning/calm-notebooks">https://github.com/koaning/calm-notebooks</a>
</li>

<li>Should you teach Python or R for data science?<br />
<a href="https://www.dataschool.io/python-or-r-for-data-science/">https://www.dataschool.io/python-or-r-for-data-science/</a>
</li>

<li>nbviewer: A simple way to share Jupyter Notebooks<br />
<a href="https://nbviewer.org/">https://nbviewer.org/</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

<li>Matplotlib vs. seaborn vs. Plotly vs. MATLAB vs. ggplot2 vs. pandas<br />
<a href="https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/">https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/</a>
</li>

<li>Matplotlib, Seaborn or Plotnine?<br />
<a href="https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/">https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/</a>
</li>

<li>@Rabeez: Rabeez/plotting_comparison.ipynb<br />
<a href="https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc">https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc</a>
</li>

<li>Matplotlib, Seaborn, Plotly and Plotnine Comparison<br />
<a href="https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40">https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40</a>
</li>

<li>Data Visualization 101: How to Choose a Python Plotting Library<br />
<a href="https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a">https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a</a>
</li>

<li>Data science in Python: pandas, seaborn, scikit-learn<br />
<a href="https://www.youtube.com/watch?v=3ZWuPVWq7p4">https://www.youtube.com/watch?v=3ZWuPVWq7p4</a>
</li>

<li>7.2. Real world datasets<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>7.2.7. California Housing dataset<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>Comprehensive Guide to Classification Models in Scikit-Learn<br />
<a href="https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/">https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/</a>
</li>

<li>Tidy Data Visualization: ggplot2 vs seaborn<br />
<a href="https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/">https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/</a>
</li>

<li>seaborn: statistical data visualization<br />
<a href="https://seaborn.pydata.org/">https://seaborn.pydata.org/</a>
</li>

<li>Linear regression (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Linear_regression">https://en.wikipedia.org/wiki/Linear_regression</a>
</li>

<li>Lineární regrese (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese">https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese</a>
</li>

<li>Iris Flower Classification with MLP Classifier<br />
<a href="https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier">https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

