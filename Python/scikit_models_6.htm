<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. </a></p>
<p><a href="#k02">*** 2. </a></p>
<p><a href="#k03">*** 3. </a></p>
<p><a href="#k04">*** 4. </a></p>
<p><a href="#k05">*** 5. </a></p>
<p><a href="#k06">*** 6. </a></p>
<p><a href="#k07">*** 7. </a></p>
<p><a href="#k08">*** 8. </a></p>
<p><a href="#k09">*** 9. </a></p>
<p><a href="#k10">*** 10. </a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">*** 20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. </h2>



<p><a name="k02"></a></p>
<h2 id="k02">2. </h2>

<pre>
import numpy as np

# import funkce pro nacteni datove sady, kterou pouzijeme
from sklearn.datasets import load_iris

# nacteni datove sady
iris = load_iris()

# precteni dat z datove sady
data = iris["data"]

# nadpis tabulky
print("Feature                     Min          Max          Avg         Std          Var")

# zakladni statisticke informace o jednotlivych atributech
for i in range(len(iris["feature_names"])):
    column = data[:, i]
    feature = iris.feature_names[i]
    print(f"{feature:20}   {column.min():10.3f}   {column.max():10.3f}   {np.mean(column):10.3f}  {np.std(column):10.3f}  {np.var(column):11.3f}")
</pre>

<pre>
import numpy as np

# import funkce pro nacteni datove sady, kterou pouzijeme
from sklearn.datasets import fetch_california_housing

# nacteni datove sady
housings = fetch_california_housing()

# precteni dat z datove sady
data = housings["data"]

# nadpis tabulky
print("Feature              Min         Max           Avg         Std         Var")

# zakladni statisticke informace o jednotlivych atributech
for i in range(len(housings["feature_names"])):
    column = data[:, i]
    feature = housings.feature_names[i]
    print(f"{feature:12}   {column.min():10.3f}   {column.max():10.3f}   {np.mean(column):10.3f}  {np.std(column):10.3f}  {np.var(column):11.3f}")
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. </h2>

<pre>
Feature                     Min          Max          Avg         Std          Var
sepal length (cm)           4.300        7.900        5.843       0.825        0.681
sepal width (cm)            2.000        4.400        3.057       0.434        0.189
petal length (cm)           1.000        6.900        3.758       1.759        3.096
petal width (cm)            0.100        2.500        1.199       0.760        0.577
</pre>

<pre>
Feature              Min         Max           Avg         Std         Var
MedInc              0.500       15.000        3.871       1.900        3.609
HouseAge            1.000       52.000       28.639      12.585      158.389
AveRooms            0.846      141.909        5.429       2.474        6.121
AveBedrms           0.333       34.067        1.097       0.474        0.225
Population          3.000    35682.000     1425.477    1132.435  1282408.322
AveOccup            0.692     1243.333        3.071      10.386      107.865
Latitude           32.540       41.950       35.632       2.136        4.562
Longitude        -124.350     -114.310     -119.570       2.003        4.014
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. </h2>

<pre>
# import tridy realizujici vyber atributu
from sklearn.feature_selection import VarianceThreshold

# import funkce pro nacteni datove sady, kterou pouzijeme
from sklearn.datasets import fetch_california_housing

# nacteni datove sady
housings = fetch_california_housing()

# precteni dat z datove sady
# urcenych pro trenink, validaci atd.
data = housings["data"]

# tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem
print("Data shape before selection:")
print(data.shape)

# provest filtering dat
sel = VarianceThreshold(threshold=0.6)
selected = sel.fit_transform(data)

# tvar upravene datove sady (pocet zaznamu a atributu)
print("Data shape after selection:")
print(selected.shape)
</pre>

<pre>
Data shape before selection:
(20640, 8)
Data shape after selection:
(20640, 7)
</pre>

<pre>
# import tridy realizujici vyber atributu
from sklearn.feature_selection import VarianceThreshold

# import funkce pro nacteni datove sady, kterou pouzijeme
from sklearn.datasets import fetch_california_housing

# nacteni datove sady
housings = fetch_california_housing()

# precteni dat z datove sady
# urcenych pro trenink, validaci atd.
data = housings["data"]

# jmena jednotlivych atributu
feature_names = housings["feature_names"]

# tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem
print("Data shape before selection:")
print(data.shape)

# jmena vsech puvodnich atributu
print("Features before selection:")
print(feature_names)

print()

sel = VarianceThreshold(threshold=0.6)
selected = sel.fit_transform(data)

# tvar upravene datove sady (pocet zaznamu a atributu)
print("Data shape after selection:")
print(selected.shape)

# jmena vybranych atributu
print("Features after selection:")
print(sel.get_feature_names_out(input_features=housings["feature_names"]))
</pre>

<pre>
Data shape before selection:
(20640, 8)
Features before selection:
['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']

Data shape after selection:
(20640, 7)
Features after selection:
['MedInc' 'HouseAge' 'AveRooms' 'Population' 'AveOccup' 'Latitude'
 'Longitude']
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. </h2>

<pre>
import numpy as np

# import tridy realizujici vyber atributu
from sklearn.feature_selection import VarianceThreshold

# import funkce pro nacteni datove sady, kterou pouzijeme
from sklearn.datasets import load_iris

# nacteni datove sady
iris = load_iris()

# precteni dat z datove sady
# urcenych pro trenink, validaci atd.
data = iris["data"]

# jmena jednotlivych atributu
feature_names = iris["feature_names"]

# tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem
print("Data shape before selection:")
print(data.shape)

# jmena vsech puvodnich atributu
print("Features before selection:")
print(feature_names)

print()

for threshold in np.linspace(0.0, 1.0, 11):
    sel = VarianceThreshold(threshold=threshold)

    selected = sel.fit_transform(data)

    print(threshold, selected.shape, sel.get_feature_names_out(input_features=feature_names))
</pre>

<pre>
Data shape before selection:
(150, 4)
Features before selection:
['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']

0.0 (150, 4) ['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)' 'petal width (cm)']
0.1 (150, 4) ['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)' 'petal width (cm)']
0.2 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)'] 0.30000000000000004 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)']
0.4 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)'] 0.5 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)']
0.6 (150, 2) ['sepal length (cm)' 'petal length (cm)']
0.7 (150, 1) ['petal length (cm)']
0.8 (150, 1) ['petal length (cm)']
0.9 (150, 1) ['petal length (cm)']
1.0 (150, 1) ['petal length (cm)']
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. </h2>

<pre>
# import tridy realizujici vyber atributu
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

# import funkce pro nacteni datove sady, kterou pouzijeme
from sklearn.datasets import load_iris

# nacteni datove sady
iris = load_iris()

# precteni dat z datove sady
# urcenych pro trenink, validaci atd.
data = iris["data"]

# jmena jednotlivych atributu
feature_names = iris["feature_names"]

# tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem
print("Data shape before selection:")
print(data.shape)

# provest filtering dat
sel = SelectKBest(f_classif, k=2)
selected = sel.fit_transform(data, iris["target"])

# tvar upravene datove sady (pocet zaznamu a atributu)
print("Data shape after selection:")
print(selected.shape)
print(sel.get_feature_names_out(input_features=iris["feature_names"]))
</pre>

<pre>
Data shape before selection:
(150, 4)
Data shape after selection:
(150, 2)
['petal length (cm)' 'petal width (cm)']
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. </h2>

<pre>
# import tridy realizujici vyber atributu
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

# import funkce pro nacteni datove sady, kterou pouzijeme
from sklearn.datasets import fetch_california_housing

# nacteni datove sady
housings = fetch_california_housing()

# precteni dat z datove sady
# urcenych pro trenink, validaci atd.
data = housings["data"]

# jmena jednotlivych atributu
feature_names = housings["feature_names"]

# tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem
print("Data shape before selection:")
print(data.shape)

# provest filtering dat
sel = SelectKBest(f_classif, k=4)
selected = sel.fit_transform(data, housings["target"])

# tvar upravene datove sady (pocet zaznamu a atributu)
print("Data shape after selection:")
print(selected.shape)
print(sel.get_feature_names_out(input_features=housings["feature_names"]))
</pre>

<pre>
Data shape before selection:
(20640, 8)
Data shape after selection:
(20640, 4)
['MedInc' 'HouseAge' 'Population' 'Latitude']
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. </h2>

<pre>
# import tridy realizujici vyber atributu
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

# import funkce pro nacteni datove sady, kterou pouzijeme
from sklearn.datasets import fetch_california_housing

# nacteni datove sady
housings = fetch_california_housing()

# precteni dat z datove sady
# urcenych pro trenink, validaci atd.
data = housings["data"]

# jmena jednotlivych atributu
feature_names = housings["feature_names"]

# tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem
print("Data shape before selection:")
print(data.shape)

for k_best in range(0, len(feature_names)+1):
    # provest filtering dat
    sel = SelectKBest(f_classif, k=k_best)
    selected = sel.fit_transform(data, housings["target"])

    print(k_best, selected.shape, sel.get_feature_names_out(input_features=feature_names))
</pre>

<pre>
0 (20640, 0) []
1 (20640, 1) ['MedInc']
2 (20640, 2) ['MedInc' 'Latitude']
3 (20640, 3) ['MedInc' 'Population' 'Latitude']
4 (20640, 4) ['MedInc' 'HouseAge' 'Population' 'Latitude']
5 (20640, 5) ['MedInc' 'HouseAge' 'Population' 'Latitude' 'Longitude']
6 (20640, 6) ['MedInc' 'HouseAge' 'AveRooms' 'Population' 'Latitude' 'Longitude']
7 (20640, 7) ['MedInc' 'HouseAge' 'AveRooms' 'AveBedrms' 'Population' 'Latitude' 'Longitude']
8 (20640, 8) ['MedInc' 'HouseAge' 'AveRooms' 'AveBedrms' 'Population' 'AveOccup' 'Latitude' 'Longitude']
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

<li>Rozpoznávání obrázků knihovnou Scikit-learn: první kroky<br />
<a href="https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/">https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/</a>
</li>

<li>scikit-learn: Machine Learning in Python<br />
<a href="https://scikit-learn.org/stable/index.html">https://scikit-learn.org/stable/index.html</a>
</li>

<li>Sklearn-pandas<br />
<a href="https://github.com/scikit-learn-contrib/sklearn-pandas">https://github.com/scikit-learn-contrib/sklearn-pandas</a>
</li>

<li>sklearn-xarray<br />
<a href="https://github.com/phausamann/sklearn-xarray/">https://github.com/phausamann/sklearn-xarray/</a>
</li>

<li>Clustering<br />
<a href="https://scikit-learn.org/stable/modules/clustering.html">https://scikit-learn.org/stable/modules/clustering.html</a>
</li>

<li>Cluster analysis (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Cluster_analysis">https://en.wikipedia.org/wiki/Cluster_analysis</a>
</li>

<li>Shluková analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza">https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza</a>
</li>

<li>K-means<br />
<a href="https://cs.wikipedia.org/wiki/K-means">https://cs.wikipedia.org/wiki/K-means</a>
</li>

<li>k-means clustering<br />
<a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a>
</li>

<li>Spectral clustering<br />
<a href="https://en.wikipedia.org/wiki/Spectral_clustering">https://en.wikipedia.org/wiki/Spectral_clustering</a>
</li>

<li>Emergence<br />
<a href="https://cs.wikipedia.org/wiki/Emergence">https://cs.wikipedia.org/wiki/Emergence</a>
</li>

<li>Particle Life: Vivid structures from rudimentary rules<br />
<a href="https://particle-life.com/">https://particle-life.com/</a>
</li>

<li>Hertzsprungův–Russellův diagram<br />
<a href="https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram">https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram</a>
</li>

<li>Using Machine Learning in an HR Diagram<br />
<a href="https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f">https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f</a>
</li>

<li>Gaia H-R diagrams: Querying Gaia data for one million nearby stars<br />
<a href="https://vlas.dev/post/gaia-dr2-hrd/">https://vlas.dev/post/gaia-dr2-hrd/</a>
</li>

<li>The Hertzsprung–Russell diagram<br />
<a href="https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/">https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/</a>
</li>

<li>Animated Hertzsprung-Russell Diagram with 119,614 datapoints<br />
<a href="https://github.com/zonination/h-r-diagram">https://github.com/zonination/h-r-diagram</a>
</li>

<li>Neuraxle Pipelines<br />
<a href="https://github.com/Neuraxio/Neuraxle">https://github.com/Neuraxio/Neuraxle</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Natural-language processing<br />
<a href="https://en.wikipedia.org/wiki/Natural-language_processing">https://en.wikipedia.org/wiki/Natural-language_processing</a>
</li>

<li>THE MNIST DATABASE of handwritten digits<br />
<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>
</li>

<li>MNIST database (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/MNIST_database">https://en.wikipedia.org/wiki/MNIST_database</a>
</li>

<li>MNIST For ML Beginners<br />
<a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch: Serialization<br />
<a href="https://github.com/torch/torch7/blob/master/doc/serialization.md">https://github.com/torch/torch7/blob/master/doc/serialization.md</a>
</li>

<li>Torch: modul image<br />
<a href="https://github.com/torch/image/blob/master/README.md">https://github.com/torch/image/blob/master/README.md</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>Neural network containres (Torch)<br />
<a href="https://github.com/torch/nn/blob/master/doc/containers.md">https://github.com/torch/nn/blob/master/doc/containers.md</a>
</li>

<li>Simple layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear">https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear</a>
</li>

<li>Transfer Function Layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok">https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

