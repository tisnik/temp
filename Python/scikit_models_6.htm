<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. </a></p>
<p><a href="#k02">*** 2. </a></p>
<p><a href="#k03">*** 3. </a></p>
<p><a href="#k04">*** 4. </a></p>
<p><a href="#k05">*** 5. </a></p>
<p><a href="#k06">*** 6. </a></p>
<p><a href="#k07">*** 7. </a></p>
<p><a href="#k08">*** 8. </a></p>
<p><a href="#k09">*** 9. </a></p>
<p><a href="#k10">*** 10. </a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">*** 20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. </h2>



<p><a name="k02"></a></p>
<h2 id="k02">2. </h2>

<pre>
import numpy as np

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import load_iris

<i># nacteni datove sady</i>
iris = load_iris()

<i># precteni dat z datove sady</i>
data = iris["data"]

<i># nadpis tabulky</i>
print("Feature                     Min          Max          Avg         Std          Var")

<i># zakladni statisticke informace o jednotlivych atributech</i>
for i in range(len(iris["feature_names"])):
    column = data[:, i]
    feature = iris.feature_names[i]
    print(f"{feature:20}   {column.min():10.3f}   {column.max():10.3f}   {np.mean(column):10.3f}  {np.std(column):10.3f}  {np.var(column):11.3f}")
</pre>

<pre>
import numpy as np

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing

<i># nacteni datove sady</i>
housings = fetch_california_housing()

<i># precteni dat z datove sady</i>
data = housings["data"]

<i># nadpis tabulky</i>
print("Feature              Min         Max           Avg         Std         Var")

<i># zakladni statisticke informace o jednotlivych atributech</i>
for i in range(len(housings["feature_names"])):
    column = data[:, i]
    feature = housings.feature_names[i]
    print(f"{feature:12}   {column.min():10.3f}   {column.max():10.3f}   {np.mean(column):10.3f}  {np.std(column):10.3f}  {np.var(column):11.3f}")
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. </h2>

<pre>
Feature                     Min          Max          Avg         Std          Var
sepal length (cm)           4.300        7.900        5.843       0.825        0.681
sepal width (cm)            2.000        4.400        3.057       0.434        0.189
petal length (cm)           1.000        6.900        3.758       1.759        3.096
petal width (cm)            0.100        2.500        1.199       0.760        0.577
</pre>

<pre>
Feature              Min         Max           Avg         Std         Var
MedInc              0.500       15.000        3.871       1.900        3.609
HouseAge            1.000       52.000       28.639      12.585      158.389
AveRooms            0.846      141.909        5.429       2.474        6.121
AveBedrms           0.333       34.067        1.097       0.474        0.225
Population          3.000    35682.000     1425.477    1132.435  1282408.322
AveOccup            0.692     1243.333        3.071      10.386      107.865
Latitude           32.540       41.950       35.632       2.136        4.562
Longitude        -124.350     -114.310     -119.570       2.003        4.014
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. </h2>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import VarianceThreshold

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing

<i># nacteni datove sady</i>
housings = fetch_california_housing()

<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]

<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)

<i># provest filtering dat</i>
sel = VarianceThreshold(threshold=0.6)
selected = sel.fit_transform(data)

<i># tvar upravene datove sady (pocet zaznamu a atributu)</i>
print("Data shape after selection:")
print(selected.shape)
</pre>

<pre>
Data shape before selection:
(20640, 8)
Data shape after selection:
(20640, 7)
</pre>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import VarianceThreshold

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing

<i># nacteni datove sady</i>
housings = fetch_california_housing()

<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]

<i># jmena jednotlivych atributu</i>
feature_names = housings["feature_names"]

<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)

<i># jmena vsech puvodnich atributu</i>
print("Features before selection:")
print(feature_names)

print()

sel = VarianceThreshold(threshold=0.6)
selected = sel.fit_transform(data)

<i># tvar upravene datove sady (pocet zaznamu a atributu)</i>
print("Data shape after selection:")
print(selected.shape)

<i># jmena vybranych atributu</i>
print("Features after selection:")
print(sel.get_feature_names_out(input_features=housings["feature_names"]))
</pre>

<pre>
Data shape before selection:
(20640, 8)
Features before selection:
['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']

Data shape after selection:
(20640, 7)
Features after selection:
['MedInc' 'HouseAge' 'AveRooms' 'Population' 'AveOccup' 'Latitude'
 'Longitude']
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. </h2>

<pre>
import numpy as np

<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import VarianceThreshold

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import load_iris

<i># nacteni datove sady</i>
iris = load_iris()

<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = iris["data"]

<i># jmena jednotlivych atributu</i>
feature_names = iris["feature_names"]

<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)

<i># jmena vsech puvodnich atributu</i>
print("Features before selection:")
print(feature_names)

print()

for threshold in np.linspace(0.0, 1.0, 11):
    sel = VarianceThreshold(threshold=threshold)

    selected = sel.fit_transform(data)

    print(threshold, selected.shape, sel.get_feature_names_out(input_features=feature_names))
</pre>

<pre>
Data shape before selection:
(150, 4)
Features before selection:
['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']

0.0 (150, 4) ['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)' 'petal width (cm)']
0.1 (150, 4) ['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)' 'petal width (cm)']
0.2 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)'] 0.30000000000000004 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)']
0.4 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)'] 0.5 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)']
0.6 (150, 2) ['sepal length (cm)' 'petal length (cm)']
0.7 (150, 1) ['petal length (cm)']
0.8 (150, 1) ['petal length (cm)']
0.9 (150, 1) ['petal length (cm)']
1.0 (150, 1) ['petal length (cm)']
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. </h2>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import load_iris

<i># nacteni datove sady</i>
iris = load_iris()

<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = iris["data"]

<i># jmena jednotlivych atributu</i>
feature_names = iris["feature_names"]

<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)

<i># provest filtering dat</i>
sel = SelectKBest(f_classif, k=2)
selected = sel.fit_transform(data, iris["target"])

<i># tvar upravene datove sady (pocet zaznamu a atributu)</i>
print("Data shape after selection:")
print(selected.shape)
print(sel.get_feature_names_out(input_features=iris["feature_names"]))
</pre>

<pre>
Data shape before selection:
(150, 4)
Data shape after selection:
(150, 2)
['petal length (cm)' 'petal width (cm)']
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. </h2>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing

<i># nacteni datove sady</i>
housings = fetch_california_housing()

<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]

<i># jmena jednotlivych atributu</i>
feature_names = housings["feature_names"]

<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)

<i># provest filtering dat</i>
sel = SelectKBest(f_classif, k=4)
selected = sel.fit_transform(data, housings["target"])

<i># tvar upravene datove sady (pocet zaznamu a atributu)</i>
print("Data shape after selection:")
print(selected.shape)
print(sel.get_feature_names_out(input_features=housings["feature_names"]))
</pre>

<pre>
Data shape before selection:
(20640, 8)
Data shape after selection:
(20640, 4)
['MedInc' 'HouseAge' 'Population' 'Latitude']
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. </h2>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing

<i># nacteni datove sady</i>
housings = fetch_california_housing()

<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]

<i># jmena jednotlivych atributu</i>
feature_names = housings["feature_names"]

<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)

for k_best in range(0, len(feature_names)+1):
    <i># provest filtering dat</i>
    sel = SelectKBest(f_classif, k=k_best)
    selected = sel.fit_transform(data, housings["target"])

    print(k_best, selected.shape, sel.get_feature_names_out(input_features=feature_names))
</pre>

<pre>
0 (20640, 0) []
1 (20640, 1) ['MedInc']
2 (20640, 2) ['MedInc' 'Latitude']
3 (20640, 3) ['MedInc' 'Population' 'Latitude']
4 (20640, 4) ['MedInc' 'HouseAge' 'Population' 'Latitude']
5 (20640, 5) ['MedInc' 'HouseAge' 'Population' 'Latitude' 'Longitude']
6 (20640, 6) ['MedInc' 'HouseAge' 'AveRooms' 'Population' 'Latitude' 'Longitude']
7 (20640, 7) ['MedInc' 'HouseAge' 'AveRooms' 'AveBedrms' 'Population' 'Latitude' 'Longitude']
8 (20640, 8) ['MedInc' 'HouseAge' 'AveRooms' 'AveBedrms' 'Population' 'AveOccup' 'Latitude' 'Longitude']
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>

<pre>
from sklearn.svm import LinearSVC

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import load_iris
from sklearn.feature_selection import SelectFromModel

<i># nacteni datove sady</i>
iris = load_iris()

<i># ziskani atributu a ocekavanych vysledku</i>
X = iris["data"]
y = iris["target"]

<i># jmena jednotlivych atributu</i>
feature_names = iris["feature_names"]

<i># "odhadovac" vysledku</i>
lsvc = LinearSVC(C=0.01, penalty="l1", dual=False).fit(X, y)

<i># vyber modelu</i>
model = SelectFromModel(lsvc, prefit=True)

<i># tisk modelu</i>
print(model)

<i># transformace dat</i>
X_new = model.transform(X)

<i># natrenovani modelu</i>
model.fit(X, y)

<i># vysledek + ziskani jmen atributu, ktere se pouzily</i>
print(X_new.shape)
print(model.get_feature_names_out(input_features=feature_names))
</pre>

<pre>
SelectFromModel(estimator=LinearSVC(C=0.01, dual=False, penalty='l1'),
                prefit=True)
(150, 3)
['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)']
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

from sklearn.neighbors import KNeighborsClassifier

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score


<i># nacteni datove sady</i>
iris = load_iris()

<i># jmena jednotlivych atributu</i>
feature_names = iris["feature_names"]

<i># X je matice (feature matrix)</i>
X = iris.data

<i># y je vektor (response vector)</i>
y = iris.target

for k_best in range(1, len(feature_names)+1):
    <i># provest filtering dat</i>
    sel = SelectKBest(f_classif, k=k_best)
    X_new = sel.fit_transform(X, y)

    print(k_best, X_new.shape, sel.get_feature_names_out(input_features=feature_names))
    <i># konstrukce klasifikatoru</i>
    knn = KNeighborsClassifier(n_neighbors=5)
    scores = cross_val_score(knn, X_new, y, cv=10, scoring='accuracy')
    print("Average score:", scores.mean())
</pre>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>

<pre>
1 (150, 1) ['petal length (cm)']
Average score: 0.9533333333333334
2 (150, 2) ['petal length (cm)' 'petal width (cm)']
Average score: 0.9666666666666666
3 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)']
Average score: 0.96
4 (150, 4) ['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)'
 'petal width (cm)']
Average score: 0.9666666666666668
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif

from sklearn import linear_model

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score

<i># nacteni datove sady</i>
housings = fetch_california_housing()

<i># jmena jednotlivych atributu</i>
feature_names = housings["feature_names"]

<i># X je matice (feature matrix)</i>
X = housings.data

<i># y je vektor (response vector)</i>
y = housings.target

for k_best in range(1, len(feature_names)+1):
    <i># provest filtering dat</i>
    sel = SelectKBest(f_classif, k=k_best)
    X_new = sel.fit_transform(X, y)

    <i># konstrukce modelu pro regresi</i>
    lr = linear_model.LinearRegression()
    scores = cross_val_score(lr, X_new, y, cv=10, scoring='r2')

    print(k_best, X_new.shape, sel.get_feature_names_out(input_features=feature_names), scores.mean())
</pre>

<pre>
1 (20640, 1) ['MedInc'] 0.3483800124754965
2 (20640, 2) ['MedInc' 'Latitude'] 0.34861270211722617
3 (20640, 3) ['MedInc' 'Population' 'Latitude'] 0.34993815052254296
4 (20640, 4) ['MedInc' 'HouseAge' 'Population' 'Latitude'] 0.3903572524665514
5 (20640, 5) ['MedInc' 'HouseAge' 'Population' 'Latitude' 'Longitude'] 0.5021339726461409
6 (20640, 6) ['MedInc' 'HouseAge' 'AveRooms' 'Population' 'Latitude' 'Longitude'] 0.5034342766060689
7 (20640, 7) ['MedInc' 'HouseAge' 'AveRooms' 'AveBedrms' 'Population' 'Latitude'
 'Longitude'] 0.5100561354984194
8 (20640, 8) ['MedInc' 'HouseAge' 'AveRooms' 'AveBedrms' 'Population' 'AveOccup'
 'Latitude' 'Longitude'] 0.5110068610523775
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import VarianceThreshold

from sklearn import linear_model

<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score

<i># nacteni datove sady</i>
housings = fetch_california_housing()

<i># jmena jednotlivych atributu</i>
feature_names = housings["feature_names"]

<i># X je matice (feature matrix)</i>
X = housings.data

<i># y je vektor (response vector)</i>
y = housings.target

sel = VarianceThreshold(threshold=0.6)
X_new = sel.fit_transform(X, y)

<i># konstrukce modelu pro regresi</i>
lr = linear_model.LinearRegression()
scores = cross_val_score(lr, X_new, y, cv=10, scoring='r2')

print(X_new.shape, sel.get_feature_names_out(input_features=feature_names), scores.mean())
</pre>

<pre>
20640, 7) ['MedInc' 'HouseAge' 'AveRooms' 'Population' 'AveOccup' 'Latitude' 'Longitude'] 0.503734153650471
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

<li>Rozpoznávání obrázků knihovnou Scikit-learn: první kroky<br />
<a href="https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/">https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/</a>
</li>

<li>scikit-learn: Machine Learning in Python<br />
<a href="https://scikit-learn.org/stable/index.html">https://scikit-learn.org/stable/index.html</a>
</li>

<li>Sklearn-pandas<br />
<a href="https://github.com/scikit-learn-contrib/sklearn-pandas">https://github.com/scikit-learn-contrib/sklearn-pandas</a>
</li>

<li>sklearn-xarray<br />
<a href="https://github.com/phausamann/sklearn-xarray/">https://github.com/phausamann/sklearn-xarray/</a>
</li>

<li>Clustering<br />
<a href="https://scikit-learn.org/stable/modules/clustering.html">https://scikit-learn.org/stable/modules/clustering.html</a>
</li>

<li>Cluster analysis (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Cluster_analysis">https://en.wikipedia.org/wiki/Cluster_analysis</a>
</li>

<li>Shluková analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza">https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza</a>
</li>

<li>K-means<br />
<a href="https://cs.wikipedia.org/wiki/K-means">https://cs.wikipedia.org/wiki/K-means</a>
</li>

<li>k-means clustering<br />
<a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a>
</li>

<li>Spectral clustering<br />
<a href="https://en.wikipedia.org/wiki/Spectral_clustering">https://en.wikipedia.org/wiki/Spectral_clustering</a>
</li>

<li>Emergence<br />
<a href="https://cs.wikipedia.org/wiki/Emergence">https://cs.wikipedia.org/wiki/Emergence</a>
</li>

<li>Particle Life: Vivid structures from rudimentary rules<br />
<a href="https://particle-life.com/">https://particle-life.com/</a>
</li>

<li>Hertzsprungův–Russellův diagram<br />
<a href="https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram">https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram</a>
</li>

<li>Using Machine Learning in an HR Diagram<br />
<a href="https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f">https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f</a>
</li>

<li>Gaia H-R diagrams: Querying Gaia data for one million nearby stars<br />
<a href="https://vlas.dev/post/gaia-dr2-hrd/">https://vlas.dev/post/gaia-dr2-hrd/</a>
</li>

<li>The Hertzsprung–Russell diagram<br />
<a href="https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/">https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/</a>
</li>

<li>Animated Hertzsprung-Russell Diagram with 119,614 datapoints<br />
<a href="https://github.com/zonination/h-r-diagram">https://github.com/zonination/h-r-diagram</a>
</li>

<li>Neuraxle Pipelines<br />
<a href="https://github.com/Neuraxio/Neuraxle">https://github.com/Neuraxio/Neuraxle</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Natural-language processing<br />
<a href="https://en.wikipedia.org/wiki/Natural-language_processing">https://en.wikipedia.org/wiki/Natural-language_processing</a>
</li>

<li>THE MNIST DATABASE of handwritten digits<br />
<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>
</li>

<li>MNIST database (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/MNIST_database">https://en.wikipedia.org/wiki/MNIST_database</a>
</li>

<li>MNIST For ML Beginners<br />
<a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch: Serialization<br />
<a href="https://github.com/torch/torch7/blob/master/doc/serialization.md">https://github.com/torch/torch7/blob/master/doc/serialization.md</a>
</li>

<li>Torch: modul image<br />
<a href="https://github.com/torch/image/blob/master/README.md">https://github.com/torch/image/blob/master/README.md</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>Neural network containres (Torch)<br />
<a href="https://github.com/torch/nn/blob/master/doc/containers.md">https://github.com/torch/nn/blob/master/doc/containers.md</a>
</li>

<li>Simple layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear">https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear</a>
</li>

<li>Transfer Function Layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok">https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>PyTorch<br />
<a href="http://pytorch.org/">http://pytorch.org/</a>
</li>

<li>JupyterLite na PyPi<br />
<a href="https://pypi.org/project/jupyterlite/">https://pypi.org/project/jupyterlite/</a>
</li>

<li>JupyterLite na GitHubu<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Dokumentace k&nbsp;projektu JupyterLite<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Matplotlib Home Page<br />
<a href="http://matplotlib.org/">http://matplotlib.org/</a>
</li>

<li>Matplotlib (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Matplotlib">https://en.wikipedia.org/wiki/Matplotlib</a>
</li>

<li>Popis barvových map modulu matplotlib.cm<br />
<a href="https://gist.github.com/endolith/2719900#id7">https://gist.github.com/endolith/2719900#id7</a>
</li>

<li>Ukázky (palety) barvových map modulu matplotlib.cm<br />
<a href="http://matplotlib.org/examples/color/colormaps_reference.html">http://matplotlib.org/examples/color/colormaps_reference.html</a>
</li>

<li>Galerie grafů vytvořených v&nbsp;Matplotlibu<br />
<a href="https://matplotlib.org/3.2.1/gallery/">https://matplotlib.org/3.2.1/gallery/</a>
</li>

<li>3D rendering<br />
<a href="https://en.wikipedia.org/wiki/3D_rendering">https://en.wikipedia.org/wiki/3D_rendering</a>
</li>

<li>3D computer graphics<br />
<a href="https://en.wikipedia.org/wiki/3D_computer_graphics">https://en.wikipedia.org/wiki/3D_computer_graphics</a>
</li>

<li>Primary 3D view planes<br />
<a href="https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html">https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html</a>
</li>

<li>Getting started in scikit-learn with the famous iris dataset<br />
<a href="https://www.youtube.com/watch?v=hd1W4CyPX58">https://www.youtube.com/watch?v=hd1W4CyPX58</a>
</li>

<li>Training a machine learning model with scikit-learn<br />
<a href="https://www.youtube.com/watch?v=RlQuVL6-qe8">https://www.youtube.com/watch?v=RlQuVL6-qe8</a>
</li>

<li>Iris (plant)<br />
<a href="https://en.wikipedia.org/wiki/Iris_(plant)">https://en.wikipedia.org/wiki/Iris_(plant)</a>
</li>

<li>Kosatec<br />
<a href="https://cs.wikipedia.org/wiki/Kosatec">https://cs.wikipedia.org/wiki/Kosatec</a>
</li>

<li>Iris setosa<br />
<a href="https://en.wikipedia.org/wiki/Iris_setosa">https://en.wikipedia.org/wiki/Iris_setosa</a>
</li>

<li>Iris versicolor<br />
<a href="https://en.wikipedia.org/wiki/Iris_versicolor">https://en.wikipedia.org/wiki/Iris_versicolor</a>
</li>

<li>Iris virginica<br />
<a href="https://en.wikipedia.org/wiki/Iris_virginica">https://en.wikipedia.org/wiki/Iris_virginica</a>
</li>

<li>Druh<br />
<a href="https://cs.wikipedia.org/wiki/Druh">https://cs.wikipedia.org/wiki/Druh</a>
</li>

<li>Iris subg. Limniris<br />
<a href="https://en.wikipedia.org/wiki/Iris_subg._Limniris">https://en.wikipedia.org/wiki/Iris_subg._Limniris</a>
</li>

<li>Iris Dataset Classification with Python: A Tutorial<br />
<a href="https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html">https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html</a>
</li>

<li>Iris flower data set<br />
<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">https://en.wikipedia.org/wiki/Iris_flower_data_set</a>
</li>

<li>List of datasets for machine-learning research<br />
<a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

