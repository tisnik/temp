<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Redukce atributů v datových sadách před tréninkem modelů</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Redukce atributů v datových sadách před tréninkem modelů</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">1. Redukce atributů v&nbsp;datových sadách před tréninkem modelů</a></p>
<p><a href="#k02">2. Získání základních statistických informací o atributech v&nbsp;datových sadách Iris i California Housings</a></p>
<p><a href="#k03">3. Získané statistické informace</a></p>
<p><a href="#k04">4. Výběr atributů pro trénink modelu s&nbsp;využitím filtru <strong>VarianceThreshold</strong></a></p>
<p><a href="#k05">5. Získání jmen atributů původní datové sady a datové sady redukované</a></p>
<p><a href="#k06">6. Výběr (filtrace) atributů pro různé mezní hodnoty (<i>threshold</i>)</a></p>
<p><a href="#k07">7. Výběr K nejvhodnějších atributů pro trénink</a></p>
<p><a href="#k08">8. Výběr čtyř nejvhodnějších atributů datové sady <i>California Housings</i></a></p>
<p><a href="#k09">9. Výběr atributů pro postupně rostoucí hodnotu K</a></p>
<p><a href="#k10">*** 10. Použití modelu pro výběr atributů</a></p>
<p><a href="#k11">11. Ukázka využití modelu pro výběr atributů</a></p>
<p><a href="#k12">*** 12. Křížová validace modelu naučeného s&nbsp;využitím vyfiltrované skupiny atributů</a></p>
<p><a href="#k13">*** 13. Křížová validace pro model natrénovaný na datovou sadu <i>Iris</i></a></p>
<p><a href="#k14">14. Výsledky křížové validace pro datovou sadu <i>Iris</i></a></p>
<p><a href="#k15">15. Křížová validace pro model natrénovaný na datovou sadu <i>California Housings</i></a></p>
<p><a href="#k16">16. Výsledky křížové validace pro datovou sadu <i>California housings</i></a></p>
<p><a href="#k17">*** 17. Výsledky křížové validace pro filtraci pomocí <strong>VarianceThreshold</strong></a></p>
<p><a href="#k18">*** 18. Obsah navazujícího článku &ndash; neuronové sítě</a></p>
<p><a href="#k19">19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Redukce atributů v&nbsp;datových sadách před tréninkem modelů</h2>

<p>Poměrně často se setkáme s&nbsp;daty (resp.&nbsp;přesněji řečeno
s&nbsp;datovými sadami), které obsahují velké množství atributů. Příkladem může
být například datová sada s&nbsp;parametry různých typů vín, která pro každé
víno obsahuje jednu hodnotu s&nbsp;odpovědí a třináct dalších atributů, které
je možné (nikoli nutné) použít pro trénink:</p>

<pre>
Variable Name                 Role
class                         Target
Alcohol                       Feature
Malicacid                     Feature
Ash                           Feature
Alcalinity_of_ash             Feature
Magnesium                     Feature
Total_phenols                 Feature
Flavanoids                    Feature
Nonflavanoid_phenols          Feature
Proanthocyanins               Feature
Color_intensity               Feature
Hue                           Feature
0D280_0D315_of_diluted_wines  Feature
Proline                       Feature
</pre>

<p>Většinou ovšem dopředu nevíme, které z&nbsp;těchto atributů má smysl použít
pro trénink modelu a které atributy jsou naopak zbytečné či dokonce nevhodné
(příliš náhodné atd.). Dnes si tedy ukážeme několik způsobů filtrace vhodných a
nevhodných atributů. Opět pochopitelně použijeme knihovnu
<i>scikit-learn</i>.</p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Získání základních statistických informací o atributech v&nbsp;datových sadách Iris i California Housings</h2>

<p>Nejprve si ukažme resp.&nbsp;přesněji řečeno připomeňme, jakým způsobem
můžeme získat základní statistické informace o atributech v&nbsp;datových
sadách. Podobně jako v&nbsp;předchozích částech tohoto seriálu i dnes použijeme
datové sady <i>Iris</i> (čtyři atributy se stejnými jednotkami i měřítkem) a
<i>California Housings</i> (osm atributů z&nbsp;různými jednotkami a samozřejmě
i s&nbsp;rozdílným měřítkem).</p>

<p>Získání a výpočet statistických informací pro datovou sadu <i>Iris</i>:</p>

<pre>
import numpy as np
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import load_iris
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># precteni dat z datove sady</i>
data = iris["data"]
&nbsp;
<i># nadpis tabulky</i>
print("Feature                     Min          Max          Avg         Std          Var")
&nbsp;
<i># zakladni statisticke informace o jednotlivych atributech</i>
for i in range(len(iris["feature_names"])):
    column = data[:, i]
    feature = iris.feature_names[i]
    print(f"{feature:20}   {column.min():10.3f}   {column.max():10.3f}   {np.mean(column):10.3f}  {np.std(column):10.3f}  {np.var(column):11.3f}")
</pre>

<p>Získání a výpočet statistických informací pro datovou sadu <i>California
Housings</i>:</p>

<pre>
import numpy as np
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
data = housings["data"]
&nbsp;
<i># nadpis tabulky</i>
print("Feature              Min         Max           Avg         Std         Var")
&nbsp;
<i># zakladni statisticke informace o jednotlivych atributech</i>
for i in range(len(housings["feature_names"])):
    column = data[:, i]
    feature = housings.feature_names[i]
    print(f"{feature:12}   {column.min():10.3f}   {column.max():10.3f}   {np.mean(column):10.3f}  {np.std(column):10.3f}  {np.var(column):11.3f}")
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. Získané statistické informace</h2>

<p>Výše uvedené skripty vypočítaly pro každý z&nbsp;atributů nejmenší a
největší hodnotu atributu, průměrnou hodnotu, směrodatnou odchylku a
rozptyl:</p>

<pre>
Feature                     Min          Max          Avg         Std          Var
sepal length (cm)           4.300        7.900        5.843       0.825        0.681
sepal width (cm)            2.000        4.400        3.057       0.434        0.189
petal length (cm)           1.000        6.900        3.758       1.759        3.096
petal width (cm)            0.100        2.500        1.199       0.760        0.577
</pre>

<p><div class="rs-tip-major">Poznámka: rozptyl i směrodatné odchylky jsou
v&nbsp;tomto případě pro všechny atributy relativně malé.</div></p>

<p>Pro datovou sadu <i>California Housings</i> dostaneme značně odlišné
hodnoty. Především stojí za pozornost velká odchylka a rozptyl pro atribut
<i>Population</i>:</p>

<pre>
Feature              Min         Max           Avg         Std         Var
MedInc              0.500       15.000        3.871       1.900        3.609
HouseAge            1.000       52.000       28.639      12.585      158.389
AveRooms            0.846      141.909        5.429       2.474        6.121
AveBedrms           0.333       34.067        1.097       0.474        0.225
Population          3.000    35682.000     1425.477    1132.435  1282408.322
AveOccup            0.692     1243.333        3.071      10.386      107.865
Latitude           32.540       41.950       35.632       2.136        4.562
Longitude        -124.350     -114.310     -119.570       2.003        4.014
</pre>

<p><div class="rs-tip-major">Poznámka: připomeňme si, že právě odstraněním
atributu <i>Population</i> jsme získali nejlepší předpověď modelu (nejmenší
chyba resp.&nbsp;největší skóre):</div></p>

<pre>
Ignored attribute       MSE     r2 score
MedInc                  0.805   0.392
HouseAge                0.535   0.601
AveRooms                0.536   0.596
AveBedrms               0.541   0.598
Population              0.525   0.605
AveOccup                0.539   0.596
Latitude                0.617   0.535
Longitude               0.619   0.538
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. Výběr atributů pro trénink modelu s&nbsp;využitím filtru <strong>VarianceThreshold</strong></h2>

<p>Jedním z&nbsp;filtrů sloužících pro snížení počtu atributů, se kterými se
bude model trénovat, je filtr nazvaný <strong>VarianceThreshold</strong>. Tento
filtr odstraní atribut či atributy s&nbsp;nejmenším (nikoli největším)
rozptylem. Filtr přímo vrací novou datovou sadu. Podívejme se na jeho použití,
přičemž vstupem bude datová sada <i>California Housings</i>:</p>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import VarianceThreshold
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)
&nbsp;
<i># provest filtering dat</i>
sel = VarianceThreshold(threshold=0.6)
selected = sel.fit_transform(data)
&nbsp;
<i># tvar upravene datove sady (pocet zaznamu a atributu)</i>
print("Data shape after selection:")
print(selected.shape)
</pre>

<p>Tento skript po svém spuštění zobrazí tvar původní datové sady (20640
záznamů, každý s&nbsp;osmi atributy) a nově redukované datové sady (stejný
počet záznamů, ale jen sedm atributů):</p>

<pre>
Data shape before selection:
(20640, 8)
Data shape after selection:
(20640, 7)
</pre>

<p><div class="rs-tip-major">Poznámka: důvodem pro existenci tohoto filtru je
fakt, že atribut s&nbsp;velmi malým rozptylem je vlastně pro trénink modelu
zbytečný až nadbytečný. Extrémním případem je atribut s&nbsp;konstantní
hodnotou, který způsobuje menší citlivost modelu.</div></p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Získání jmen atributů původní datové sady a datové sady redukované</h2>

<p>V&nbsp;praxi je pochopitelně vhodné zjistit nejenom to, kolik atributů má
nově vyfiltrovaná datová sada, ale i to, o jaké atributy se jedná. I tuto
informaci lze velmi snadno zjistit pomocí
<strong>get_feature_names_out</strong>:</p>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import VarianceThreshold
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># jmena jednotlivych atributu</i>
feature_names = housings["feature_names"]
&nbsp;
<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)
&nbsp;
<i># jmena vsech puvodnich atributu</i>
print("Features before selection:")
print(feature_names)
&nbsp;
print()
&nbsp;
sel = VarianceThreshold(threshold=0.6)
selected = sel.fit_transform(data)
&nbsp;
<i># tvar upravene datove sady (pocet zaznamu a atributu)</i>
print("Data shape after selection:")
print(selected.shape)
&nbsp;
<i># jmena vybranych atributu</i>
print("Features after selection:")
print(sel.get_feature_names_out(input_features=housings["feature_names"]))
</pre>

<p>A takto bude vypadat výsledek běhu tohoto skriptu:</p>

<pre>
Data shape before selection:
(20640, 8)
Features before selection:
['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']
&nbsp;
Data shape after selection:
(20640, 7)
Features after selection:
['MedInc' 'HouseAge' 'AveRooms' 'Population' 'AveOccup' 'Latitude' 'Longitude']
</pre>

<p><div class="rs-tip-major">Poznámka: dostali jsme předpokládaný výsledek,
který odpovídá tabulce <a href="#k03">ze třetí kapitoly</a>.</div></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Výběr (filtrace) atributů pro různé mezní hodnoty (<i>threshold</i>)</h2>

<p>Pokusme se pro zajímavost manipulovat s&nbsp;hodnotou předávanou
v&nbsp;parametru <i>threshold</i>. Jedná se o mezní hodnotu pro filtraci
atributů na základě jejich rozptylu. Čím větší bude mezní hodnota, tím větší
počet atributů bude obecně odstraněn. Vyzkoušejme si nyní proměnnou hodnotu
<i>threshold</i> použít společně s&nbsp;datovou sadou <i>Iris</i>:</p>

<pre>
import numpy as np
&nbsp;
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import VarianceThreshold
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import load_iris
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = iris["data"]
&nbsp;
<i># jmena jednotlivych atributu</i>
feature_names = iris["feature_names"]
&nbsp;
<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)
&nbsp;
<i># jmena vsech puvodnich atributu</i>
print("Features before selection:")
print(feature_names)
&nbsp;
print()
&nbsp;
for threshold in np.linspace(0.0, 1.0, 11):
    sel = VarianceThreshold(threshold=threshold)
&nbsp;
    selected = sel.fit_transform(data)
&nbsp;
    print(threshold, selected.shape, sel.get_feature_names_out(input_features=feature_names))
</pre>

<p>Po spuštění skriptu se budou vypisovat tvary datové sady po filtraci,
pochopitelně společně s&nbsp;názvy atributů, které v&nbsp;nově sadě
zůstaly:</p>

<pre>
Data shape before selection:
(150, 4)
&nbsp;
Features before selection:
['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']
&nbsp;
0.0 (150, 4) ['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)' 'petal width (cm)']
0.1 (150, 4) ['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)' 'petal width (cm)']
0.2 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)']
0.3 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)']
0.4 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)']
0.5 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)']
0.6 (150, 2) ['sepal length (cm)' 'petal length (cm)']
0.7 (150, 1) ['petal length (cm)']
0.8 (150, 1) ['petal length (cm)']
0.9 (150, 1) ['petal length (cm)']
1.0 (150, 1) ['petal length (cm)']
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. Výběr K nejvhodnějších atributů pro trénink</h2>

<p>Dalším typem filtrů, který je možné použít pro výběr nejvhodnějších
atributů, je filtr nazvaný <strong>SelectKBest</strong>. Jak již název tohoto
filtru naznačuje, bude se vracet K nejlepších atributů, přičemž ona konstanta K
je volitelná uživatelem. Ukažme si nejdříve použití tohoto filtru nad datovou
sadou <i>Iris</i>, z&nbsp;níž se pokusíme vybrat dva nejlepší atributy:</p>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import load_iris
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = iris["data"]
&nbsp;
<i># jmena jednotlivych atributu</i>
feature_names = iris["feature_names"]
&nbsp;
<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)
&nbsp;
<i># provest filtering dat</i>
sel = SelectKBest(f_classif, k=2)
selected = sel.fit_transform(data, iris["target"])
&nbsp;
<i># tvar upravene datove sady (pocet zaznamu a atributu)</i>
print("Data shape after selection:")
print(selected.shape)
print(sel.get_feature_names_out(input_features=iris["feature_names"]))
</pre>

<p>Nejdříve se opět zobrazí tvar (<i>shape</i>) původní datové sady a posléze
tvar sady vyfiltrované. A nakonec se vypíše dvojice atributů, která je podle
tohoto filtru nejlepší:</p>

<pre>
Data shape before selection:
(150, 4)
Data shape after selection:
(150, 2)
['petal length (cm)' 'petal width (cm)']
</pre>

<p><div class="rs-tip-major">Poznámka: povšimněte si, že výsledek vlastně
neodpovídá předchozímu filtru, který pro vhodný <i>threshold</i> doporučil tyto
dva atributy:</div></p>

<pre>
0.6 (150, 2) ['sepal length (cm)' 'petal length (cm)']
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. Výběr čtyř nejvhodnějších atributů datové sady <i>California Housings</i></h2>

<p>Stejný filtr, pouze s&nbsp;odlišnou hodnotou K, nyní použijeme pro výběr
atributů z&nbsp;datové sady <i>California Housings</i>. Skript, který tento
výběr provede, vypadá následovně:</p>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># jmena jednotlivych atributu</i>
feature_names = housings["feature_names"]
&nbsp;
<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)
&nbsp;
<i># provest filtering dat</i>
sel = SelectKBest(f_classif, k=4)
selected = sel.fit_transform(data, housings["target"])
&nbsp;
<i># tvar upravene datove sady (pocet zaznamu a atributu)</i>
print("Data shape after selection:")
print(selected.shape)
print(sel.get_feature_names_out(input_features=housings["feature_names"]))
</pre>

<p>Výsledkem bude doporučení čtyř atributů vypsaných na posledním řádku:</p>

<pre>
Data shape before selection:
(20640, 8)
Data shape after selection:
(20640, 4)
['MedInc' 'HouseAge' 'Population' 'Latitude']
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Výběr atributů pro postupně rostoucí hodnotu K</h2>

<p>Samozřejmě si můžeme otestovat, jaké konkrétní atributy budou vybrány
v&nbsp;případě, že K předávané do konstruktoru třídy
<strong>SelectKBest</strong> postupně poroste od nuly do maximálního počtu
atributů (tedy v&nbsp;našem případě pro osm atributů). Samotný test chování
<strong>SelectKBest</strong> pro proměnné K lze naprogramovat velmi snadno:</p>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># precteni dat z datove sady</i>
<i># urcenych pro trenink, validaci atd.</i>
data = housings["data"]
&nbsp;
<i># jmena jednotlivych atributu</i>
feature_names = housings["feature_names"]
&nbsp;
<i># tvar puvodni datove sady (pocet zaznamu a atributu) pred vyberem</i>
print("Data shape before selection:")
print(data.shape)
&nbsp;
for k_best in range(0, len(feature_names)+1):
    <i># provest filtering dat</i>
    sel = SelectKBest(f_classif, k=k_best)
    selected = sel.fit_transform(data, housings["target"])
&nbsp;
    print(k_best, selected.shape, sel.get_feature_names_out(input_features=feature_names))
</pre>

<p>Podívejme se nyní na výsledky, od &bdquo;nejlepší malé skupiny&ldquo;
atributů až po všechny dostupné atributy:</p>

<pre>
0 (20640, 0) []
1 (20640, 1) ['MedInc']
2 (20640, 2) ['MedInc' 'Latitude']
3 (20640, 3) ['MedInc' 'Population' 'Latitude']
4 (20640, 4) ['MedInc' 'HouseAge' 'Population' 'Latitude']
5 (20640, 5) ['MedInc' 'HouseAge' 'Population' 'Latitude' 'Longitude']
6 (20640, 6) ['MedInc' 'HouseAge' 'AveRooms' 'Population' 'Latitude' 'Longitude']
7 (20640, 7) ['MedInc' 'HouseAge' 'AveRooms' 'AveBedrms' 'Population' 'Latitude' 'Longitude']
8 (20640, 8) ['MedInc' 'HouseAge' 'AveRooms' 'AveBedrms' 'Population' 'AveOccup' 'Latitude' 'Longitude']
</pre>

<p><div class="rs-tip-major">Poznámka: opět stojí za povšimnutí, že atribut
<i>AveBedrms</i>, který byl podle filtru <strong>VarianceThreshold</strong>
nejhorší (adept na odstranění), zde nejhorší není (konkrétně je druhý
nejhorší). Nyní je nejhorším atributem <strong>AveOccup</strong> a nejlepším
atributeb <strong>MedInc</strong>. To může být na dobře fungujícím trhu
s&nbsp;byty logické &ndash; hodnota domů koreluje s&nbsp;mediánem
příjmů.</div></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Použití modelu pro výběr atributů</h2>

<p></p>



<p><a name="k11"></a></p>
<h2 id="k11">11. Ukázka využití modelu pro výběr atributů</h2>

<p>Opět si na praktickém příkladu vyzkoušejme, jakým způsobem je možné použít
model pro výběr atributů. Konkrétně využijeme třídy <strong>LinearSVC</strong>
a <strong>SelectFromModel</strong>. Instance třídy <strong>LinearSVC</strong>
bude využita pro odhad výsledků, návratová hodnota bude použita modelem pro
výběr atributů. Model následně ztransformuje původní datovou sadu na sadu
novou:</p>

<pre>
from sklearn.svm import LinearSVC
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import load_iris
from sklearn.feature_selection import SelectFromModel
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># ziskani atributu a ocekavanych vysledku</i>
X = iris["data"]
y = iris["target"]
&nbsp;
<i># jmena jednotlivych atributu</i>
feature_names = iris["feature_names"]
&nbsp;
<i># "odhadovac" vysledku</i>
lsvc = LinearSVC(C=0.01, penalty="l1", dual=False).fit(X, y)
&nbsp;
<i># vyber modelu</i>
model = SelectFromModel(lsvc, prefit=True)
&nbsp;
<i># tisk modelu</i>
print(model)
&nbsp;
<i># transformace dat</i>
X_new = model.transform(X)
&nbsp;
<i># natrenovani modelu</i>
model.fit(X, y)
&nbsp;
<i># vysledek + ziskani jmen atributu, ktere se pouzily</i>
print(X_new.shape)
print(model.get_feature_names_out(input_features=feature_names))
</pre>

<p>Zkontrolujeme výsledky vyprodukované tímto skriptem. Nyní byly pro trénink
modelu vybrány tři atributy, které jsou vypsány na posledním řádku:</p>

<pre>
SelectFromModel(estimator=LinearSVC(C=0.01, dual=False, penalty='l1'),
                prefit=True)
(150, 3)
['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)']
</pre>

<p><div class="rs-tip-major">Poznámka: za povšimnutí stojí odlišné výsledky
oproti filtru <strong>VarianceThreshold</strong>.</div></p>



<p><a name="k12"></a></p>
<h2 id="k12">12. Křížová validace modelu naučeného s&nbsp;využitím vyfiltrované skupiny atributů</h2>



<p><a name="k13"></a></p>
<h2 id="k13">13. Křížová validace pro model natrénovaný na datovou sadu <i>Iris</i></h2>

<p></p>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
&nbsp;
from sklearn.neighbors import KNeighborsClassifier
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import load_iris
from sklearn.model_selection import cross_val_score
&nbsp;
&nbsp;
<i># nacteni datove sady</i>
iris = load_iris()
&nbsp;
<i># jmena jednotlivych atributu</i>
feature_names = iris["feature_names"]
&nbsp;
<i># X je matice (feature matrix)</i>
X = iris.data
&nbsp;
<i># y je vektor (response vector)</i>
y = iris.target
&nbsp;
for k_best in range(1, len(feature_names)+1):
    <i># provest filtering dat</i>
    sel = SelectKBest(f_classif, k=k_best)
    X_new = sel.fit_transform(X, y)
&nbsp;
    print(k_best, X_new.shape, sel.get_feature_names_out(input_features=feature_names))
    <i># konstrukce klasifikatoru</i>
    knn = KNeighborsClassifier(n_neighbors=5)
    scores = cross_val_score(knn, X_new, y, cv=10, scoring='accuracy')
    print("Average score:", scores.mean())
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Výsledky křížové validace pro datovou sadu <i>Iris</i></h2>

<p>Výsledky získané skriptem uvedeným <a href="#k14">v&nbsp;předchozí
kapitole</a> by měly vypadat následovně:</p>

<pre>
1 (150, 1) ['petal length (cm)']
Average score: 0.9533333333333334
&nbsp;
2 (150, 2) ['petal length (cm)' 'petal width (cm)']
Average score: 0.9666666666666666
&nbsp;
3 (150, 3) ['sepal length (cm)' 'petal length (cm)' 'petal width (cm)']
Average score: 0.96
4 (150, 4) ['sepal length (cm)' 'sepal width (cm)' 'petal length (cm)' 'petal width (cm)']
&nbsp;
Average score: 0.9666666666666668
</pre>

<p><div class="rs-tip-major">Poznámka: to jsou ve skutečnosti velmi zajímavé
výsledky, protože vlastně říkají, že jediným skutečně rozhodujícím atributem je
&bdquo;petal length&ldquo;</div>, přičemž další atributy model pouze nepatrně
&bdquo;doladí&ldquo;. To ostatně odpovídá výsledkům, které jsme získali
v&nbsp;rámci <a href="#k06">šesté kapitoly</a> a vlastně i <a
href="#k07">kapitoly sedmé</a>.</p>



<p><a name="k15"></a></p>
<h2 id="k15">15. Křížová validace pro model natrénovaný na datovou sadu <i>California Housings</i></h2>

<p>Prakticky totožným způsobem lze zkombinovat výběr atributů s&nbsp;využitím
<strong>SelectKBest</strong> a s&nbsp;ověřením natrénovaného modelu
<strong>LinearRegression</strong> křížovou validací. Jak je již z&nbsp;názvu
modelu patrné, použijeme nyní datovou sadu <i>California Housings</i> a necháme
model odhadovat cenu nemovitosti:</p>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
&nbsp;
from sklearn import linear_model
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># jmena jednotlivych atributu</i>
feature_names = housings["feature_names"]
&nbsp;
<i># X je matice (feature matrix)</i>
X = housings.data
&nbsp;
<i># y je vektor (response vector)</i>
y = housings.target
&nbsp;
for k_best in range(1, len(feature_names)+1):
    <i># provest filtering dat</i>
    sel = SelectKBest(f_classif, k=k_best)
    X_new = sel.fit_transform(X, y)
&nbsp;
    <i># konstrukce modelu pro regresi</i>
    lr = linear_model.LinearRegression()
    scores = cross_val_score(lr, X_new, y, cv=10, scoring='r2')
&nbsp;
    print(k_best, X_new.shape, sel.get_feature_names_out(input_features=feature_names), scores.mean())
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. Výsledky křížové validace pro datovou sadu <i>California housings</i></h2>

<p>Pro datovou sadu <i>California Housings</i> a pro proměnný počet atributů
použitých pro trénink modelu vypadají výsledky křížové validace následovně:</p>

<pre>
1 (20640, 1) ['MedInc'] 0.3483800124754965
2 (20640, 2) ['MedInc' 'Latitude'] 0.34861270211722617
3 (20640, 3) ['MedInc' 'Population' 'Latitude'] 0.34993815052254296
4 (20640, 4) ['MedInc' 'HouseAge' 'Population' 'Latitude'] 0.3903572524665514
5 (20640, 5) ['MedInc' 'HouseAge' 'Population' 'Latitude' 'Longitude'] 0.5021339726461409
6 (20640, 6) ['MedInc' 'HouseAge' 'AveRooms' 'Population' 'Latitude' 'Longitude'] 0.5034342766060689
7 (20640, 7) ['MedInc' 'HouseAge' 'AveRooms' 'AveBedrms' 'Population' 'Latitude' 'Longitude'] 0.5100561354984194
8 (20640, 8) ['MedInc' 'HouseAge' 'AveRooms' 'AveBedrms' 'Population' 'AveOccup' 'Latitude' 'Longitude'] 0.5110068610523775
</pre>

<p><div class="rs-tip-major">Poznámka: můžeme zde vidět poměrně velký skok
v&nbsp;úspěšnosti modelu při přidání atributu <strong>Longitude</strong>. Před
přidáním tohoto atributu dosahovalo skóre přibližné hodnoty 0,4, poté již
překročilo hodnotu 0,5. A přidávání dalších atributů již kvalitě modelu příliš
nepomohlo. A pochopitelně by bylo možné dosáhnout lepších výsledků přechodem na
jiný model, než je jednoduchý <i>LinearRegression</i></div>.</p>



<p><a name="k17"></a></p>
<h2 id="k17">17. Výsledky křížové validace pro filtraci pomocí <strong>VarianceThreshold</strong></h2>

<p></p>

<pre>
<i># import tridy realizujici vyber atributu</i>
from sklearn.feature_selection import VarianceThreshold
&nbsp;
from sklearn import linear_model
&nbsp;
<i># import funkce pro nacteni datove sady, kterou pouzijeme</i>
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import cross_val_score
&nbsp;
<i># nacteni datove sady</i>
housings = fetch_california_housing()
&nbsp;
<i># jmena jednotlivych atributu</i>
feature_names = housings["feature_names"]
&nbsp;
<i># X je matice (feature matrix)</i>
X = housings.data
&nbsp;
<i># y je vektor (response vector)</i>
y = housings.target
&nbsp;
sel = VarianceThreshold(threshold=0.6)
X_new = sel.fit_transform(X, y)
&nbsp;
<i># konstrukce modelu pro regresi</i>
lr = linear_model.LinearRegression()
scores = cross_val_score(lr, X_new, y, cv=10, scoring='r2')
&nbsp;
print(X_new.shape, sel.get_feature_names_out(input_features=feature_names), scores.mean())
</pre>

<pre>
20640, 7) ['MedInc' 'HouseAge' 'AveRooms' 'Population' 'AveOccup' 'Latitude' 'Longitude'] 0.503734153650471
</pre>



<p><a name="k18"></a></p>
<h2 id="k18">18. Obsah navazujícího článku &ndash; neuronové sítě</h2>

<p></p>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu Scikit-learn lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady i na (Jupyter) diáře s&nbsp;postupem
výpočtů a analýz:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td>01_show_matrix.py</td><td>kooperace mezi knihovnami Matplotlib a NumPy: vizualizace obsahu 2D matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py</a></td></tr>
<tr><td> 2</td><td>02_get_digits.py</td><td>datová množina obsahující naskenované ručně napsané číslice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py</a></td></tr>
<tr><td> 3</td><td>03_get_features.py</td><td>další atributy datové množiny, které použijeme při trénování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py</a></td></tr>
<tr><td> 4</td><td>04_get_images.py</td><td>přečtení a následné vykreslení jednotlivých ručně nakreslených číslic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py</a></td></tr>
<tr><td> 5</td><td>05_show_grayscale_matrix.py</td><td>odstranění umělé aplikované barvové palety (obrázky ve stupních šedi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py</a></td></tr>
<tr><td> 6</td><td>06_grayscale_images.py</td><td>vykreslení ručně nakreslených číslic ve formě obrázků ve stupních šedi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py</a></td></tr>
<tr><td> 7</td><td>07_multiplot.py</td><td>rozdělení plochy grafu do oblastí; vykreslení více obrázků do jediného grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py</a></td></tr>
<tr><td> 8</td><td>08_model_preperation_1.py</td><td>obrázky s&nbsp;jejich ohodnocením</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py</a></td></tr>
<tr><td> 9</td><td>09_training_set.py</td><td>příprava dat pro trénink</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py</a></td></tr>
<tr><td>10</td><td>10_classification.py</td><td>klasifikace obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py</a></td></tr>
<tr><td>11</td><td>11_results.py</td><td>vykreslení obrázků společně s&nbsp;jejich klasifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py</a></td></tr>
<tr><td>12</td><td>12_change_training_set.py</td><td>změna poměru rozdělení dat na tréninkovou a testovací množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>13</td><td>13_blobs.py</td><td>použití funkce <strong>make_blobs</strong> pro vygenerování sady bodů v&nbsp;rovině sdružených do oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py</a></td></tr>
<tr><td>14</td><td>14_swap_coords.py</td><td>úprava předchozího příkladu: prohození souřadnic na osách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py</a></td></tr>
<tr><td>15</td><td>15_blobs_scatter_plot.py</td><td>základní podoba bodového diagramu (<i>scatter plot</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py</a></td></tr>
<tr><td>16</td><td>16_blobs_scatter_plot.py</td><td>úprava bodového diagramu při zobrazení většího množství bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py</a></td></tr>
<tr><td>17</td><td>17_colorized_blobs.py</td><td>obarvení bodů podle oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py</a></td></tr>
<tr><td>18</td><td>18_k-means.py</td><td>základní použití algoritmu K-means pro clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py</a></td></tr>
<tr><td>19</td><td>19_combination.py</td><td>zobrazení centroidů společně s&nbsp;původními body</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py</a></td></tr>
<tr><td>20</td><td>20_combinations.py</td><td>vizualizace clusteringu původní množiny bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py</a></td></tr>
<tr><td>21</td><td>21_other_settings.py</td><td>vizualizace clusteringu původní množiny bodů pro odlišnou množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py</a></td></tr>
<tr><td>22</td><td>22_random_points.py</td><td>clustering pro náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>23</td><td>23_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, menší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py</a></td></tr>
<tr><td>24</td><td>24_more_noise_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, větší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py</a></td></tr>
<tr><td>25</td><td>25_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, menší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/25_moons.py</a></td></tr>
<tr><td>26</td><td>26_more_noisy_moons.py</td><td>pseudonáhodné rozmístění bodů do tvaru dvou půlměsíců, větší náhodnost</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/26_more_noisy_moons.py</a></td></tr>
<tr><td>27</td><td>27_circles_kmeans.py</td><td>výsledek clusteringu provedeného algoritmem K-means na &bdquo;kružnice&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/27_circles_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/27_circles_kmeans.py</a></td></tr>
<tr><td>28</td><td>28_moons_kmeans.py</td><td>výsledek clusteringu provedeného algoritmem K-means na &bdquo;půlměsíce&ldquo;</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/28_moons_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/28_moons_kmeans.py</a></td></tr>
<tr><td>29</td><td>29_blobs_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné pomocí <strong>make_blobs</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/29_blobs_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/29_blobs_spectral_clustering.py</a></td></tr>
<tr><td>30</td><td>30_circles_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné do kružnic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/30_circles_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/30_circles_spectral_clustering.py</a></td></tr>
<tr><td>31</td><td>31_moons_spectral_clustering.py</td><td>spectral clustering pro body rozmístěné do půlměsíců </td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/31_moons_spectral_clustering.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/31_moons_spectral_clustering.py</a></td></tr>
<tr><td>32</td><td>32_moons_spectral_clustering_limits.py</td><td>vyhledání limitů algoritmu spectral clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/32_moons_spectral_clustering_limits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/32_moons_spectral_clustering_limits.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>33</td><td>33_particles_load.py</td><td>načtení souřadnic částic uložených v&nbsp;souboru formátu CSV</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/33_particles_load.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/33_particles_load.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>34</td><td>34_lorenz_attractor.py</td><td>zobrazení Lorenzova atraktoru formou bodů propojených úsečkami</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/34_lorenz_attractor.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/34_lorenz_attractor.py</a></td></tr>
<tr><td>35</td><td>35_lorenz_attractor_points.py</td><td>Lorenzův atraktor vykreslený formou jednotlivých bodů s&nbsp;definovaným stylem zobrazení a velikostí stopy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/35_lorenz_attractor_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/35_lorenz_attractor_points.py</a></td></tr>
<tr><td>36</td><td>36_blobs_3d.py</td><td>vygenerování a zobrazení sady bodů v&nbsp;3D prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/36_blobs_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/36_blobs_3d.py</a></td></tr>
<tr><td>37</td><td>37_spread_blobs_3d.py</td><td>vygenerování a zobrazení sady bodů v&nbsp;3D prostoru, odlišné parametry při generování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/37_spread_blobs_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/37_spread_blobs_3d.py</a></td></tr>
<tr><td>38</td><td>38_views.py</td><td>různé pohledy na 3D graf</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/38_views.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/38_views.py</a></td></tr>
<tr><td>39</td><td>39_colorized_3d_blobs.py</td><td>obarvení bodů v&nbsp;prostoru na základě vstupních dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/39_colorized_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/39_colorized_3d_blobs.py</a></td></tr>
<tr><td>40</td><td>40_kmeans_3d_blobs.py</td><td>shluková analýza v&nbsp;3D prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/40_kmeans_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/40_kmeans_3d_blobs.py</a></td></tr>
<tr><td>41</td><td>41_kmeans_spread_3d_blobs.py</td><td>shluková analýza v&nbsp;3D prostoru pro odlišnou množinu bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/41_kmeans_spread_3d_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/41_kmeans_spread_3d_blobs.py</a></td></tr>
<tr><td>42</td><td>42_kmeans_random_3d.py</td><td>shluková analýza pro body rozmístěné zcela náhodně v&nbsp;omezeném prostoru</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/42_kmeans_random_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/42_kmeans_random_3d.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>43</td><td>43_speed_measurements.py</td><td>benchmark pro postupně rostoucí počet bodů tvořících shluky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/43_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/43_speed_measurements.py</a></td></tr>
<tr><td>44</td><td>44_speed_measurements.py</td><td>benchmark pro postupně rostoucí počet bodů rozmístěných náhodně</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/44_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/44_speed_measurements.py</a></td></tr>
<tr><td>45</td><td>45_speed_measurements.py</td><td>benchmark pro stále stejný počet bodů, u jejichž rozmístění v&nbsp;prostoru se používá stále větší směrodatná odchylka</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/45_speed_measurements.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/45_speed_measurements.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>46</td><td>46_iris_dataset.py</td><td>načtení datové kolekce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/46_iris_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/46_iris_dataset.py</a></td></tr>
<tr><td>47</td><td>47_iris_description.py</td><td>metadata o datové kolekci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/47_iris_description.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/47_iris_description.py</a></td></tr>
<tr><td>48</td><td>48_iris_data.py</td><td>tvar dat &ndash; počet záznamů a počet proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/48_iris_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/48_iris_data.py</a></td></tr>
<tr><td>49</td><td>49_iris_targets.py</td><td>jména atributů, vztah mezi numerickou hodnotou atributu a jeho jménem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/49_iris_targets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/49_iris_targets.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>50</td><td>50_iris_scatter_plot_1.py</td><td>korelační diagram pro dvojici vybraných proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/50_iris_scatter_plot_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/50_iris_scatter_plot_1.py</a></td></tr>
<tr><td>51</td><td>51_iris_scatter_plot_2.py</td><td>příprava pro tvorbu složitějších grafů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/51_iris_scatter_plot_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/51_iris_scatter_plot_2.py</a></td></tr>
<tr><td>52</td><td>52_iris_mutliplot.py</td><td>mřížka obsahující více korelačních diagramů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/52_iris_mutliplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/52_iris_mutliplot.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>53</td><td>53_iris_histograms.py</td><td>zobrazení základního histogramu pro data v&nbsp;sadě Iris</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/53_iris_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/53_iris_histograms.py</a></td></tr>
<tr><td>54</td><td>54_iris_histograms.py</td><td>úprava histogramu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/54_iris_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/54_iris_histograms.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>55</td><td>55_pca.py</td><td>analýza hlavních komponent (PCA), výsledek zobrazený v&nbsp;2D grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/55_pca.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/55_pca.py</a></td></tr>
<tr><td>56</td><td>56_pca_3d.py</td><td>analýza hlavních komponent (PCA), výsledek zobrazený v&nbsp;3D grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/56_pca_3d.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/56_pca_3d.py</a></td></tr>
<tr><td>57</td><td>57_kmeans.py</td><td>základní shluková analýza</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/57_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/57_kmeans.py</a></td></tr>
<tr><td>58</td><td>58_multiple_kmeans.py</td><td>větší množství výsledků shlukové analýzy pro různé atributy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/58_multiple_kmeans.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/58_multiple_kmeans.py</a></td></tr>
<tr><td>59</td><td>59_kmeans_errors.py</td><td>korektní a nekorektní výsledky základní shlukové analýzy</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/59_kmeans_errors.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/59_kmeans_errors.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>60</td><td>60_basic_classifier.py</td><td>aplikace jednoduchého modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/60_basic_classifier.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/60_basic_classifier.py</a></td></tr>
<tr><td>61</td><td>61_changed_model_parameters.py</td><td>změna parametrů modelu pro zjištění druhů rostil</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/61_changed_model_parameters.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/61_changed_model_parameters.py</a></td></tr>
<tr><td>62</td><td>62_different_model.py</td><td>použití odlišného modelu pro zjištění druhů rostlin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/62_different_model.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/62_different_model.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>63</td><td>63_verify_on_whole_data_1.py</td><td>otestování naučeného modelu s&nbsp;využitím tréninkových dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/63_verify_on_whole_data_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/63_verify_on_whole_data_1.py</a></td></tr>
<tr><td>64</td><td>64_verify_on_whole_data_2.py</td><td>využití funkce <strong>metrics.accuracy_score</strong> pro zjištění kvality modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/64_verify_on_whole_data_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/64_verify_on_whole_data_2.py</a></td></tr>
<tr><td>65</td><td>65_basic_comparison.py</td><td>porovnání vlastností různých modelů (prozatím nekorektní řešení)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/65_basic_comparison.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/65_basic_comparison.py</a></td></tr>
<tr><td>66</td><td>66_training_testing_split_1.py</td><td>rozdělení datové sady na trénovací data a testovací data (základní varianta)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/66_training_testing_split_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/66_training_testing_split_1.py</a></td></tr>
<tr><td>67</td><td>67_training_testing_split_2.py</td><td>rozdělení datové sady na trénovací data a testovací data (náhodné rozdělení sady)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/67_training_testing_split_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/67_training_testing_split_2.py</a></td></tr>
<tr><td>68</td><td>68_training_testing_split_3.py</td><td>rozdělení datové sady na trénovací data a testovací data (využití vestavěné funkce)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/68_training_testing_split_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/68_training_testing_split_3.py</a></td></tr>
<tr><td>69</td><td>69_better_comparison.py</td><td>vylepšené porovnání vlastností různých modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/69_better_comparison.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/69_better_comparison.py</a></td></tr>
<tr><td>70</td><td>70_multiple_runs.py</td><td>vliv generátoru náhodných čísel na změřené výsledky</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/70_multiple_runs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/70_multiple_runs.py</a></td></tr>
<tr><td>71</td><td>71_stable_multiple_runs.py</td><td>generátor náhodných čísel a použití hodnoty <strong>random_state</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/71_stable_multiple_runs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/71_stable_multiple_runs.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>72</td><td>72_housings_dataset.py</td><td>načtení datové sady <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/72_housings_dataset.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/72_housings_dataset.py</a></td></tr>
<tr><td>73</td><td>73_housings_dataset_description.py</td><td>metainformace o datové sadě <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/73_housings_dataset_description.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/73_housings_dataset_description.py</a></td></tr>
<tr><td>74</td><td>74_housings_data.py</td><td>n-rozměrné pole s&nbsp;atributy jednotlivých domů/bloků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/74_housings_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/74_housings_data.py</a></td></tr>
<tr><td>75</td><td>75_housings_targets.py</td><td>jména atributů, ceny domů atd.</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/75_housings_targets.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/75_housings_targets.py</a></td></tr>
<tr><td>76</td><td>76_housings_scatter_plot.py</td><td>korelační diagram pro dvojici vybraných proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/76_housings_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/76_housings_scatter_plot.py</a></td></tr>
<tr><td>77</td><td>77_housings_mutliplot.py</td><td>korelační diagram pro všechny kombinace dvojic proměnných</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/77_housings_mutliplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/77_housings_mutliplot.py</a></td></tr>
<tr><td>78</td><td>78_scatter.py</td><td>dvourozměrné hodnoty reprezentované jako dvojice atributů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/78_scatter.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/78_scatter.py</a></td></tr>
<tr><td>79</td><td>79_linear_regression_gen_data.py</td><td>model <i>LinearRegression</i> nad uměle vytvořenými daty</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/79_linear_regression_gen_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/79_linear_regression_gen_data.py</a></td></tr>
<tr><td>80</td><td>80_linear_regression_predictions.py</td><td>predikce modelu provádějícího lineární regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/80_linear_regression_predictions.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/80_linear_regression_predictions.py</a></td></tr>
<tr><td>81</td><td>81_linear_regression_random_data.py</td><td>chování modelu pro zcela náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/81_linear_regression_random_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/81_linear_regression_random_data.py</a></td></tr>
<tr><td>82</td><td>82_linear_regression_housings.py</td><td>model <i>LinearRegression</i> pro datovou sadu <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/82_linear_regression_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/82_linear_regression_housings.py</a></td></tr>
<tr><td>83</td><td>83_polynomial_regression_gen_data.py</td><td>polynomiální regrese (základní příklad)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/83_polynomial_regression_gen_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/83_polynomial_regression_gen_data.py</a></td></tr>
<tr><td>84</td><td>84_polynomial_regression_housings.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, první příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/84_polynomial_regression_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/84_polynomial_regression_housings.py</a></td></tr>
<tr><td>85</td><td>85_polynomial_regression_housings_2.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, druhý příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/85_polynomial_regression_housings_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/85_polynomial_regression_housings_2.py</a></td></tr>
<tr><td>86</td><td>86_polynomial_regression_housings_3.py</td><td>polynomiální regrese a datová sada <i>California housings</i>, třetí příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/86_polynomial_regression_housings_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/86_polynomial_regression_housings_3.py</a></td></tr>
<tr><td>87</td><td>87_linear_regression_errors.py</td><td>výpočet chyby a skóre modelu lineární regrese</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/87_linear_regression_errors.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/87_linear_regression_errors.py</a></td></tr>
<tr><td>88</td><td>88_linear_regression_non_linear_data.py</td><td>lineární regrese nad nelineárními daty</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/88_linear_regression_non_linear_data.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/88_linear_regression_non_linear_data.py</a></td></tr>
<tr><td>89</td><td>89_polynomial_regression_error.py</td><td></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/89_polynomial_regression_error.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/89_polynomial_regression_error.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>90</td><td>90_housings_prediction_1.py</td><td>regresní analýza nad daty <i>California housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/90_housings_prediction_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/90_housings_prediction_1.py</a></td></tr>
<tr><td>91</td><td>91_housings_prediction_2.py</td><td>korektní natrénování modelu pro regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/91_housings_prediction_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/91_housings_prediction_2.py</a></td></tr>
<tr><td>92</td><td>92_housings_prediction_3.py</td><td>omezení množství atributů (proměnných), na kterých je model natrénován</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/92_housings_prediction_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/92_housings_prediction_3.py</a></td></tr>
<tr><td>93</td><td>93_housings_prediction_errors_1.py</td><td>chybně natrénovaný model při náhodné volbě dat</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/93_housings_prediction_errors_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/93_housings_prediction_errors_1.py</a></td></tr>
<tr><td>94</td><td>94_housings_prediction_errors_2.py</td><td>omezení atributů + chybně natrénovaný model</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/94_housings_prediction_errors_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/94_housings_prediction_errors_2.py</a></td></tr>
<tr><td>95</td><td>95_housings_histograms.py</td><td>histogramy pro jednotlivé atributy (proměnné)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/95_housings_histograms.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/95_housings_histograms.py</a></td></tr>
<tr><td>96</td><td>96_housings_statistic.py</td><td>statistické údaje pro jednotlivé atributy (proměnné)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/96_housings_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/96_housings_statistic.py</a></td></tr>
<tr><td>97</td><td>97_housings_statistic_normalized.py</td><td>statistické údaje získané po normalizaci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/97_housings_statistic_normalized.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/97_housings_statistic_normalized.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 98</td><td>98_k_fold_help.py</td><td>zobrazení nápovědy ke třídě s&nbsp;realizací k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/98_k_fold_help.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/98_k_fold_help.py</a></td></tr>
<tr><td> 99</td><td>99_k_fold_old.py</td><td>původní (nepodporovaná) varianta provedení k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/99_k_fold_old.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/99_k_fold_old.py</a></td></tr>
<tr><td>100</td><td>100_k_fold_1.py</td><td>interní chování algoritmu k-foldingu (základní parametry)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/100_k_fold_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/100_k_fold_1.py</a></td></tr>
<tr><td>101</td><td>101_k_fold_2.py</td><td>interní chování algoritmu k-foldingu (odlišné parametry)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/101_k_fold_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/101_k_fold_2.py</a></td></tr>
<tr><td>102</td><td>102_k_fold_selection.py</td><td>k-folding a výběr dat pro otestování modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/102_k_fold_selection.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/102_k_fold_selection.py</a></td></tr>
<tr><td>103</td><td>103_average_score.py</td><td>realizace výpočtu průměrného skóre pro otestování modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/103_average_score.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/103_average_score.py</a></td></tr>
<tr><td>104</td><td>104_hyperparams_score.py</td><td>změna hyperparametrů s&nbsp;výpočtem průměrného skóre (tabulka)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/104_hyperparams_score.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/104_hyperparams_score.py</a></td></tr>
<tr><td>105</td><td>105_hyperparams_score_plot.py</td><td>změna hyperparametrů s&nbsp;výpočtem průměrného skóre (graf)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/105_hyperparams_score_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/105_hyperparams_score_plot.py</a></td></tr>
<tr><td>106</td><td>106_model_selection.py</td><td>výběr nejlepšího modelu s&nbsp;využitím k-foldingu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/106_model_selection.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/106_model_selection.py</a></td></tr>
<tr><td>107</td><td>107_features_selection_basic.py</td><td>výběr atributů (proměnných) pro trénink modelu (základní varianta)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/107_features_selection_basic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/107_features_selection_basic.py</a></td></tr>
<tr><td>108</td><td>108_features_selection_iris.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada Iris)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/108_features_selection_iris.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/108_features_selection_iris.py</a></td></tr>
<tr><td>109</td><td>109_features_selection_houses.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada California Housings)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/109_features_selection_houses.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/109_features_selection_houses.py</a></td></tr>
<tr><td>110</td><td>110_best_features_selection_houses.py</td><td>získání nejlepší sady atributů (proměnných)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/110_best_features_selection_houses.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/110_best_features_selection_houses.py</a></td></tr>
<tr><td>111</td><td>111_features_selection_graphical.py</td><td>výběr atributů (proměnných) pro trénink modelu (datová sada Iris), grafický výstup</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/111_features_selection_graphical.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/111_features_selection_graphical.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>112</td><td>112_simplest_linear_regression.py</td><td>lineární regrese bodů ležících v&nbsp;rovině</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/112_simplest_linear_regression.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/112_simplest_linear_regression.py</a></td></tr>
<tr><td>113</td><td>113_linear_regression_no_intercept.py</td><td>lineární regrese při vynucení <i>w<sub>0</sub>=0</i> pro obecná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/113_linear_regression_no_intercept.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/113_linear_regression_no_intercept.py</a></td></tr>
<tr><td>114</td><td>114_linear_regression_from_0_0.py</td><td>lineární regrese při vynucení <i>w<sub>0</sub>=0</i> v&nbsp;případě, že vstupní body obsahují počátek souřadného systému</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/114_linear_regression_from_0_0.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/114_linear_regression_from_0_0.py</a></td></tr>
<tr><td>115</td><td>115_linear_regression_multiple_y.py</td><td>model předpovídající pro každou vstupní hodnotu dvě výstupní hodnoty (odpovědi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/115_linear_regression_multiple_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/115_linear_regression_multiple_y.py</a></td></tr>
<tr><td>116</td><td>116_grid_operations.py</td><td>konstrukce matice obsahující souřadnice bodů v&nbsp;mřížce</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/116_grid_operations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/116_grid_operations.py</a></td></tr>
<tr><td>117</td><td>117_linear_regression_multiple_x.py</td><td>proložení bodů v&nbsp;prostoru rovinou</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/117_linear_regression_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/117_linear_regression_multiple_x.py</a></td></tr>
<tr><td>118</td><td>118_linear_regression_multiple_x.py</td><td>proložení bodů s&nbsp;náhodnou výškou rovinou</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/118_linear_regression_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/118_linear_regression_multiple_x.py</a></td></tr>
<tr><td>119</td><td>119_linear_regression_multiple_x_and_y.py</td><td>proložení dvou sad bodů dvojicí rovin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/119_linear_regression_multiple_x_and_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/119_linear_regression_multiple_x_and_y.py</a></td></tr>
<tr><td>120</td><td>120_linear_regression_multiple_x_and_y.py</td><td>proložení dvou sad bodů dvojicí rovin</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/120_linear_regression_multiple_x_and_y.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/120_linear_regression_multiple_x_and_y.py</a></td></tr>
<tr><td>121</td><td>121_linear_regression_poly.py</td><td>základní polynomická regrese</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/121_linear_regression_poly.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/121_linear_regression_poly.py</a></td></tr>
<tr><td>122</td><td>122_linear_regression_poly_multiple_x.py</td><td>polynomická regrese a body v&nbsp;prostoru, první příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/122_linear_regression_poly_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/122_linear_regression_poly_multiple_x.py</a></td></tr>
<tr><td>123</td><td>123_linear_regression_poly_multiple_x.py</td><td>polynomická regrese a body v&nbsp;prostoru, druhý příklad</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/123_linear_regression_poly_multiple_x.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/123_linear_regression_poly_multiple_x.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>124</td><td>124_iris_set_statistic.py</td><td>získání statistických informací o datové sadě <i>Iris</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/124_iris_set_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/124_iris_set_statistic.py</a></td></tr>
<tr><td>125</td><td>125_california_housings_statistic.py</td><td>získání statistických informací o datové sadě <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/125_california_housings_statistic.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/125_california_housings_statistic.py</a></td></tr>
<tr><td>126</td><td>126_variance_threshold_1.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/126_variance_threshold_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/126_variance_threshold_1.py</a></td></tr>
<tr><td>127</td><td>127_variance_threshold_2.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/127_variance_threshold_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/127_variance_threshold_2.py</a></td></tr>
<tr><td>128</td><td>128_variance_threshold_3.py</td><td>výběr atributů pro trénink modelu pomocí <strong>VarianceThreshold</strong></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/128_variance_threshold_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/128_variance_threshold_3.py</a></td></tr>
<tr><td>129</td><td>129_select_best_iris.py</td><td>výběr nejvhodnějších atributů pro datovou sadu <i>Iris</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/129_select_best_iris.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/129_select_best_iris.py</a></td></tr>
<tr><td>130</td><td>130_select_best_housings.py</td><td>výběr nejvhodnějších atributů pro datovou sadu <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/130_select_best_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/130_select_best_housings.py</a></td></tr>
<tr><td>131</td><td>131_select_k_best_housings.py</td><td>výběr K nejvhodnějších atributů pro datovou sadu <i>California Housings</i></td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/131_select_k_best_housings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/131_select_k_best_housings.py</a></td></tr>
<tr><td>132</td><td>132_select_from_model.py</td><td>výběr atributů na základě k&nbsp;tomu určeného modelu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/132_select_from_model.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/132_select_from_model.py</a></td></tr>
<tr><td>133</td><td>133_cross_validation_1.py</td><td>křížová validace po výběru (filtraci) modelů (datová sada <i>Iris</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/133_cross_validation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/133_cross_validation_1.py</a></td></tr>
<tr><td>134</td><td>134_cross_validation_2.py</td><td>křížová validace po výběru (filtraci) modelů (datová sada <i>California Housings</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/134_cross_validation_2.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/134_cross_validation_2.py</a></td></tr>
<tr><td>135</td><td>135_cross_validation_3.py</td><td>křížová validace po výběru (filtraci) modelů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/135_cross_validation_3.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/135_cross_validation_3.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>136</td><td>136_mlp_classifier_01.py</td><td>použití neuronové sítě pro klasifikaci</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/136_mlp_classifier_01.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/136_mlp_classifier_01.py</a></td></tr>
<tr><td>137</td><td>137_mlp_classifier_02.py</td><td>výpočet úspěšnosti modelu založeného na neuronové síti</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/137_mlp_classifier_02.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/137_mlp_classifier_02.py</a></td></tr>
<tr><td>138</td><td>138_mlp_classifier_03.py</td><td>konfigurace vrstev neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/138_mlp_classifier_03.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/138_mlp_classifier_03.py</a></td></tr>
<tr><td>139</td><td>139_mlp_classifier_04.py</td><td>proměnný počet neuronů ve vrstvách neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/139_mlp_classifier_04.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/139_mlp_classifier_04.py</a></td></tr>
<tr><td>140</td><td>140_mlp_classifier_05.py</td><td>proměnný počet neuronů ve více vrstvách neuronové sítě</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/140_mlp_classifier_05.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/140_mlp_classifier_05.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>141</td><td>141_mlp_regression_1.py</td><td>použití neuronové sítě pro regresi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/141_mlp_regression_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/141_mlp_regression_1.py</a></td></tr>
</table>

<p>V&nbsp;repositáři nalezneme taktéž projektový soubor a Jupyter Notebook
s&nbsp;vysvětlením, jak lze modely využít pro rozpoznávání obsahu rastrových
obrázků:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td>1</td><td>pyproject.toml</td><td>projektový soubor (pro PDM) se všemi závislostmi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>2</td><td>pdm.lock</td><td>lock soubor s&nbsp;konkrétními verzemi všech přímých i tranzitivních závislostí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>3</td><td>Rozpoznání_obrazu_scikit-learn.ipynb</td><td>Jupyter notebook s&nbsp;celým postupem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>4</td><td>particle_life.py</td><td>emergence: příklad vzniku struktury</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py">https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

<li>Rozpoznávání obrázků knihovnou Scikit-learn: první kroky<br />
<a href="https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/">https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/</a>
</li>

<li>scikit-learn: Machine Learning in Python<br />
<a href="https://scikit-learn.org/stable/index.html">https://scikit-learn.org/stable/index.html</a>
</li>

<li>Sklearn-pandas<br />
<a href="https://github.com/scikit-learn-contrib/sklearn-pandas">https://github.com/scikit-learn-contrib/sklearn-pandas</a>
</li>

<li>sklearn-xarray<br />
<a href="https://github.com/phausamann/sklearn-xarray/">https://github.com/phausamann/sklearn-xarray/</a>
</li>

<li>Clustering<br />
<a href="https://scikit-learn.org/stable/modules/clustering.html">https://scikit-learn.org/stable/modules/clustering.html</a>
</li>

<li>Cluster analysis (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Cluster_analysis">https://en.wikipedia.org/wiki/Cluster_analysis</a>
</li>

<li>Shluková analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza">https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza</a>
</li>

<li>K-means<br />
<a href="https://cs.wikipedia.org/wiki/K-means">https://cs.wikipedia.org/wiki/K-means</a>
</li>

<li>k-means clustering<br />
<a href="https://en.wikipedia.org/wiki/K-means_clustering">https://en.wikipedia.org/wiki/K-means_clustering</a>
</li>

<li>Spectral clustering<br />
<a href="https://en.wikipedia.org/wiki/Spectral_clustering">https://en.wikipedia.org/wiki/Spectral_clustering</a>
</li>

<li>Emergence<br />
<a href="https://cs.wikipedia.org/wiki/Emergence">https://cs.wikipedia.org/wiki/Emergence</a>
</li>

<li>Particle Life: Vivid structures from rudimentary rules<br />
<a href="https://particle-life.com/">https://particle-life.com/</a>
</li>

<li>Hertzsprungův–Russellův diagram<br />
<a href="https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram">https://cs.wikipedia.org/wiki/Hertzsprung%C5%AFv%E2%80%93Russell%C5%AFv_diagram</a>
</li>

<li>Using Machine Learning in an HR Diagram<br />
<a href="https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f">https://cocalc.com/share/public_paths/08b6e03583cbdef3cdb9813a54ec68ff773c747f</a>
</li>

<li>Gaia H-R diagrams: Querying Gaia data for one million nearby stars<br />
<a href="https://vlas.dev/post/gaia-dr2-hrd/">https://vlas.dev/post/gaia-dr2-hrd/</a>
</li>

<li>The Hertzsprung–Russell diagram<br />
<a href="https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/">https://scipython.com/book2/chapter-9-data-analysis-with-pandas/problems/p92/the-hertzsprung-russell-diagram/</a>
</li>

<li>Animated Hertzsprung-Russell Diagram with 119,614 datapoints<br />
<a href="https://github.com/zonination/h-r-diagram">https://github.com/zonination/h-r-diagram</a>
</li>

<li>Neuraxle Pipelines<br />
<a href="https://github.com/Neuraxio/Neuraxle">https://github.com/Neuraxio/Neuraxle</a>
</li>

<li>scikit-learn: Getting Started<br />
<a href="https://scikit-learn.org/stable/getting_started.html">https://scikit-learn.org/stable/getting_started.html</a>
</li>

<li>Support Vector Machines<br />
<a href="https://scikit-learn.org/stable/modules/svm.html">https://scikit-learn.org/stable/modules/svm.html</a>
</li>

<li>Use Deep Learning to Detect Programming Languages<br />
<a href="http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/">http://searene.me/2017/11/26/use-neural-networks-to-detect-programming-languages/</a>
</li>

<li>Natural-language processing<br />
<a href="https://en.wikipedia.org/wiki/Natural-language_processing">https://en.wikipedia.org/wiki/Natural-language_processing</a>
</li>

<li>THE MNIST DATABASE of handwritten digits<br />
<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>
</li>

<li>MNIST database (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/MNIST_database">https://en.wikipedia.org/wiki/MNIST_database</a>
</li>

<li>MNIST For ML Beginners<br />
<a href="https://www.tensorflow.org/get_started/mnist/beginners">https://www.tensorflow.org/get_started/mnist/beginners</a>
</li>

<li>Stránka projektu Torch<br />
<a href="http://torch.ch/">http://torch.ch/</a>
</li>

<li>Torch: Serialization<br />
<a href="https://github.com/torch/torch7/blob/master/doc/serialization.md">https://github.com/torch/torch7/blob/master/doc/serialization.md</a>
</li>

<li>Torch: modul image<br />
<a href="https://github.com/torch/image/blob/master/README.md">https://github.com/torch/image/blob/master/README.md</a>
</li>

<li>Data pro neuronové sítě<br />
<a href="http://archive.ics.uci.edu/ml/index.php">http://archive.ics.uci.edu/ml/index.php</a>
</li>

<li>Torch na GitHubu (několik repositářů)<br />
<a href="https://github.com/torch">https://github.com/torch</a>
</li>

<li>Torch (machine learning), Wikipedia<br />
<a href="https://en.wikipedia.org/wiki/Torch_%28machine_learning%29">https://en.wikipedia.org/wiki/Torch_%28machine_learning%29</a>
</li>

<li>Torch Package Reference Manual<br />
<a href="https://github.com/torch/torch7/blob/master/README.md">https://github.com/torch/torch7/blob/master/README.md</a>
</li>

<li>Torch Cheatsheet<br />
<a href="https://github.com/torch/torch7/wiki/Cheatsheet">https://github.com/torch/torch7/wiki/Cheatsheet</a>
</li>

<li>Neural network containres (Torch)<br />
<a href="https://github.com/torch/nn/blob/master/doc/containers.md">https://github.com/torch/nn/blob/master/doc/containers.md</a>
</li>

<li>Simple layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear">https://github.com/torch/nn/blob/master/doc/simple.md#nn.Linear</a>
</li>

<li>Transfer Function Layers<br />
<a href="https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok">https://github.com/torch/nn/blob/master/doc/transfer.md#nn.transfer.dok</a>
</li>

<li>Feedforward neural network<br />
<a href="https://en.wikipedia.org/wiki/Feedforward_neural_network">https://en.wikipedia.org/wiki/Feedforward_neural_network</a>
</li>

<li>Biologické algoritmy (4) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-4-neuronove-site/</a>
</li>

<li>Biologické algoritmy (5) - Neuronové sítě<br />
<a href="https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/">https://www.root.cz/clanky/biologicke-algoritmy-5-neuronove-site/</a>
</li>

<li>Umělá neuronová síť (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5">https://cs.wikipedia.org/wiki/Um%C4%9Bl%C3%A1_neuronov%C3%A1_s%C3%AD%C5%A5</a>
</li>

<li>PyTorch<br />
<a href="http://pytorch.org/">http://pytorch.org/</a>
</li>

<li>JupyterLite na PyPi<br />
<a href="https://pypi.org/project/jupyterlite/">https://pypi.org/project/jupyterlite/</a>
</li>

<li>JupyterLite na GitHubu<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Dokumentace k&nbsp;projektu JupyterLite<br />
<a href="https://github.com/jupyterlite/jupyterlite">https://github.com/jupyterlite/jupyterlite</a>
</li>

<li>Matplotlib Home Page<br />
<a href="http://matplotlib.org/">http://matplotlib.org/</a>
</li>

<li>Matplotlib (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Matplotlib">https://en.wikipedia.org/wiki/Matplotlib</a>
</li>

<li>Popis barvových map modulu matplotlib.cm<br />
<a href="https://gist.github.com/endolith/2719900#id7">https://gist.github.com/endolith/2719900#id7</a>
</li>

<li>Ukázky (palety) barvových map modulu matplotlib.cm<br />
<a href="http://matplotlib.org/examples/color/colormaps_reference.html">http://matplotlib.org/examples/color/colormaps_reference.html</a>
</li>

<li>Galerie grafů vytvořených v&nbsp;Matplotlibu<br />
<a href="https://matplotlib.org/3.2.1/gallery/">https://matplotlib.org/3.2.1/gallery/</a>
</li>

<li>3D rendering<br />
<a href="https://en.wikipedia.org/wiki/3D_rendering">https://en.wikipedia.org/wiki/3D_rendering</a>
</li>

<li>3D computer graphics<br />
<a href="https://en.wikipedia.org/wiki/3D_computer_graphics">https://en.wikipedia.org/wiki/3D_computer_graphics</a>
</li>

<li>Primary 3D view planes<br />
<a href="https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html">https://matplotlib.org/stable/gallery/mplot3d/view_planes_3d.html</a>
</li>

<li>Getting started in scikit-learn with the famous iris dataset<br />
<a href="https://www.youtube.com/watch?v=hd1W4CyPX58">https://www.youtube.com/watch?v=hd1W4CyPX58</a>
</li>

<li>Training a machine learning model with scikit-learn<br />
<a href="https://www.youtube.com/watch?v=RlQuVL6-qe8">https://www.youtube.com/watch?v=RlQuVL6-qe8</a>
</li>

<li>Iris (plant)<br />
<a href="https://en.wikipedia.org/wiki/Iris_(plant)">https://en.wikipedia.org/wiki/Iris_(plant)</a>
</li>

<li>Kosatec<br />
<a href="https://cs.wikipedia.org/wiki/Kosatec">https://cs.wikipedia.org/wiki/Kosatec</a>
</li>

<li>Iris setosa<br />
<a href="https://en.wikipedia.org/wiki/Iris_setosa">https://en.wikipedia.org/wiki/Iris_setosa</a>
</li>

<li>Iris versicolor<br />
<a href="https://en.wikipedia.org/wiki/Iris_versicolor">https://en.wikipedia.org/wiki/Iris_versicolor</a>
</li>

<li>Iris virginica<br />
<a href="https://en.wikipedia.org/wiki/Iris_virginica">https://en.wikipedia.org/wiki/Iris_virginica</a>
</li>

<li>Druh<br />
<a href="https://cs.wikipedia.org/wiki/Druh">https://cs.wikipedia.org/wiki/Druh</a>
</li>

<li>Iris subg. Limniris<br />
<a href="https://en.wikipedia.org/wiki/Iris_subg._Limniris">https://en.wikipedia.org/wiki/Iris_subg._Limniris</a>
</li>

<li>Iris Dataset Classification with Python: A Tutorial<br />
<a href="https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html">https://www.pycodemates.com/2022/05/iris-dataset-classification-with-python.html</a>
</li>

<li>Iris flower data set<br />
<a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">https://en.wikipedia.org/wiki/Iris_flower_data_set</a>
</li>

<li>List of datasets for machine-learning research<br />
<a href="https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research">https://en.wikipedia.org/wiki/List_of_datasets_for_machine-learning_research</a>
</li>

<li>Analýza hlavních komponent<br />
<a href="https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent">https://cs.wikipedia.org/wiki/Anal%C3%BDza_hlavn%C3%ADch_komponent</a>
</li>

<li>Principal component analysis<br />
<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">https://en.wikipedia.org/wiki/Principal_component_analysis</a>
</li>

<li>Scikit-learn Crash Course - Machine Learning Library for Python<br />
<a href="https://www.youtube.com/watch?v=0B5eIE_1vpU">https://www.youtube.com/watch?v=0B5eIE_1vpU</a>
</li>

<li>calm-notebooks<br />
<a href="https://github.com/koaning/calm-notebooks">https://github.com/koaning/calm-notebooks</a>
</li>

<li>Should you teach Python or R for data science?<br />
<a href="https://www.dataschool.io/python-or-r-for-data-science/">https://www.dataschool.io/python-or-r-for-data-science/</a>
</li>

<li>nbviewer: A simple way to share Jupyter Notebooks<br />
<a href="https://nbviewer.org/">https://nbviewer.org/</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

<li>Matplotlib vs. seaborn vs. Plotly vs. MATLAB vs. ggplot2 vs. pandas<br />
<a href="https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/">https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/</a>
</li>

<li>Matplotlib, Seaborn or Plotnine?<br />
<a href="https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/">https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/</a>
</li>

<li>@Rabeez: Rabeez/plotting_comparison.ipynb<br />
<a href="https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc">https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc</a>
</li>

<li>Matplotlib, Seaborn, Plotly and Plotnine Comparison<br />
<a href="https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40">https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40</a>
</li>

<li>Data Visualization 101: How to Choose a Python Plotting Library<br />
<a href="https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a">https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a</a>
</li>

<li>Data science in Python: pandas, seaborn, scikit-learn<br />
<a href="https://www.youtube.com/watch?v=3ZWuPVWq7p4">https://www.youtube.com/watch?v=3ZWuPVWq7p4</a>
</li>

<li>7.2. Real world datasets<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>7.2.7. California Housing dataset<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>Comprehensive Guide to Classification Models in Scikit-Learn<br />
<a href="https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/">https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/</a>
</li>

<li>Tidy Data Visualization: ggplot2 vs seaborn<br />
<a href="https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/">https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/</a>
</li>

<li>seaborn: statistical data visualization<br />
<a href="https://seaborn.pydata.org/">https://seaborn.pydata.org/</a>
</li>

<li>Linear regression (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Linear_regression">https://en.wikipedia.org/wiki/Linear_regression</a>
</li>

<li>Lineární regrese (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese">https://cs.wikipedia.org/wiki/Line%C3%A1rn%C3%AD_regrese</a>
</li>

<li>Iris Flower Classification with MLP Classifier<br />
<a href="https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier">https://www.metriccoders.com/post/iris-flower-classification-with-mlp-classifier</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

