<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. </a></p>
<p><a href="#k02">*** 2. </a></p>
<p><a href="#k03">*** 3. </a></p>
<p><a href="#k04">*** 4. </a></p>
<p><a href="#k05">*** 5. </a></p>
<p><a href="#k06">*** 6. </a></p>
<p><a href="#k07">*** 7. </a></p>
<p><a href="#k08">*** 8. </a></p>
<p><a href="#k09">*** 9. </a></p>
<p><a href="#k10">*** 10. </a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">*** 20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. </h2>



<p><a name="k02"></a></p>
<h2 id="k02">2. </h2>

<pre>
import numpy as np

import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# model zalozeny na neuronove siti
from sklearn.neural_network import MLPRegressor

# velikost vstupu
MAX_N = 10

# X je matice, y je vektor
X = np.zeros( (MAX_N, 2) )   # kombinace vstupu
y = np.zeros( (MAX_N, ))     # vektor vysledku

for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]

# rozdeleni dat na treninkovou a testovaci mnozinu
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# konstrukce modelu
nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=())

# trénink modelu
nn.fit(X_train, y_train)

# predikce modelu
y_pred = nn.predict(X_test)

# chyba predikce
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))

# 1 = nejlepší predikce modelu
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))

# zobrazit parametry neuronove site
print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")

# vahy neuronu
for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
    print(weights)
print()

# posuny (dalsi vstup do neuronu)
print("Biases:")
for layer, biases in enumerate(nn.intercepts_):
    print("\t", layer, biases.shape)
    print(biases)
print()

# nezname vstupy
inputs = []
for i in range(0, MAX_N):
    for j in range(0, MAX_N):
        inputs.append([i, j])
predicted = nn.predict(inputs)

print()

# odhady neuronove site po zaokrouhleni
all = 0
wrong = 0

for i, p in zip(inputs, predicted):
    if i[1] != round(p):
        print(f"{i[0]:2}, {i[1]:2} = {round(p):2}")
        wrong += 1
    all += 1

# vysledna statisticka
print(f"{wrong}/{all}")
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. </h2>

<pre>
Mean squared error: 0.10
Coefficient of determination: 0.00
Features: 2
Layers:   2
Outputs:  1
Weights:
	 0 (2, 1)
[[-0.00311307]
 [ 0.96168339]]

Biases:
	 0 (1,)
[-0.08298607]


rounded:
0/100
</pre>

<pre>
Mean squared error: 0.49
Coefficient of determination: 0.92
Features: 2
Layers:   2
Outputs:  1
Weights:
	 0 (2, 1)
[[0.04786446]
 [0.95183809]]

Biases:
	 0 (1,)
[0.47868983]


rounded:
 1,  0 =  1
 2,  0 =  1
 2,  1 =  2
 3,  0 =  1
 3,  1 =  2
 3,  2 =  3
 4,  0 =  1
 4,  1 =  2
 4,  2 =  3
 4,  3 =  4
 5,  0 =  1
 5,  1 =  2
 5,  2 =  3
 5,  3 =  4
 5,  4 =  5
 6,  0 =  1
 6,  1 =  2
 6,  2 =  3
 6,  3 =  4
 6,  4 =  5
 6,  5 =  6
 7,  0 =  1
 7,  1 =  2
 7,  2 =  3
 7,  3 =  4
 7,  4 =  5
 7,  5 =  6
 7,  6 =  7
 8,  0 =  1
 8,  1 =  2
 8,  2 =  3
 8,  3 =  4
 8,  4 =  5
 8,  5 =  6
 8,  6 =  7
 8,  7 =  8
 9,  0 =  1
 9,  1 =  2
 9,  2 =  3
 9,  3 =  4
 9,  4 =  5
 9,  5 =  6
 9,  6 =  7
 9,  7 =  8
 9,  8 =  9
45/100
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. </h2>



<p><a name="k05"></a></p>
<h2 id="k05">5. </h2>

<pre>
import numpy as np

import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# model zalozeny na neuronove siti
from sklearn.neural_network import MLPRegressor

# velikost vstupu
MAX_N = 20

# X je matice, y je vektor
X = np.zeros( (MAX_N, 2) )   # kombinace vstupu
y = np.zeros( (MAX_N, ))     # vektor vysledku

random.seed(19)

for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]


# rozdeleni dat na treninkovou a testovaci mnozinu
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# konstrukce modelu
nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(), random_state=1000)

# trénink modelu
nn.fit(X_train, y_train)

# predikce modelu
y_pred = nn.predict(X_test)

# chyba predikce
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))

# 1 = nejlepší predikce modelu
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))

# zobrazit parametry neuronove site
print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")

# vahy neuronu
for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
    print(weights)
print()

# posuny (dalsi vstup do neuronu)
print("Biases:")
for layer, biases in enumerate(nn.intercepts_):
    print("\t", layer, biases.shape)
    print(biases)
print()

# nezname vstupy
inputs = []
for i in range(0, MAX_N):
    for j in range(0, MAX_N):
        inputs.append([i, j])
predicted = nn.predict(inputs)

print()

# odhady neuronove site po zaokrouhleni
all = 0
wrong = 0

for i, p in zip(inputs, predicted):
    if i[1] != round(p):
        print(f"{i[0]:2}, {i[1]:2} = {round(p):2}")
        wrong += 1
    all += 1

# vysledna statisticka
print(f"{wrong}/{all}")
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. </h2>

<pre>
Mean squared error: 0.08
Coefficient of determination: 1.00
Features: 2
Layers:   2
Outputs:  1
Weights:
	 0 (2, 1)
[[0.01515987]
 [0.96449027]]

Biases:
	 0 (1,)
[0.08740665]


 0, 17 = 16
 0, 18 = 17
 0, 19 = 18
 1, 17 = 16
 1, 18 = 17
 1, 19 = 18
 2, 18 = 17
 2, 19 = 18
 3, 18 = 17
 3, 19 = 18
 4, 19 = 18
 5, 19 = 18
12/400
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. </h2>



<p><a name="k08"></a></p>
<h2 id="k08">8. </h2>

<pre>
import numpy as np

import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

# model zalozeny na neuronove siti
from sklearn.neural_network import MLPRegressor

# velikost vstupu
MAX_N = 40

# X je matice, y je vektor
X = np.zeros( (MAX_N, 2) )   # kombinace vstupu
y = np.zeros( (MAX_N, ))     # vektor vysledku

random.seed(19)

for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]


# rozdeleni dat na treninkovou a testovaci mnozinu
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


def train_and_test_nn(size):
    X_train_ = X_train[:size]
    y_train_ = y_train[:size]

    # konstrukce modelu
    nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(), random_state=1000)

    # trénink modelu
    nn.fit(X_train_, y_train_)

    # predikce modelu
    y_pred = nn.predict(X_test)

    # chyba predikce
    # 1 = nejlepší predikce modelu
    print("%2d" % size, "%.2f" % mean_squared_error(y_test, y_pred), "%.2f" % r2_score(y_test, y_pred))


for i in range(1, MAX_N+1):
    train_and_test_nn(i)
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu Scikit-learn lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady i na (Jupyter) diáře s&nbsp;postupem
výpočtů a analýz:</p>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>
</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

