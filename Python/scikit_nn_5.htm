<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">1. Nejjednodušší prakticky použitelná neuronová síť: výběr jednoho vstupu ze dvou dostupných</a></p>
<p><a href="#k02">2. Výsledky získané otestování jednoduché neuronové sítě</a></p>
<p><a href="#k03">3. Odstranění náhody z&nbsp;procesu tréninku a testování neuronové sítě</a></p>
<p><a href="#k04">4. Skript pro trénink a otestování neuronové sítě se stabilními výsledky</a></p>
<p><a href="#k05">5. Stabilní výsledky získané předchozím skriptem</a></p>
<p><a href="#k06">*** 6. </a></p>
<p><a href="#k07">*** 7. </a></p>
<p><a href="#k08">*** 8. </a></p>
<p><a href="#k09">*** 9. </a></p>
<p><a href="#k10">*** 10. </a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">*** 20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Nejjednodušší prakticky použitelná neuronová síť: výběr jednoho vstupu ze dvou dostupných</h2>

<p>Pro pochopení toho, jaký vliv mají hyperparametry modelu na výslednou
neuronovou síť si vytvoříme tu nejjednodušší ještě prakticky použitelnou síť,
která bude mít dva vstupy a jediný výstup. Bude se jednat o regresní síť, která
bude natrénována tak, aby z&nbsp;obou vstupů vybrala vždy hodnotu
z&nbsp;jednoho předem určeného vstupu (určení, o který vstup se jedná, se
provádí tréninkem). Například síť natrénujeme takovým způsobem, aby vždy
vybrala hodnotu druhého vstupu a tu poslala na výstup (jedná se o
&bdquo;analogovou&ldquo; hodnotu, ne o logické hradlo
resp.&nbsp;demultiplexor). A navíc síť zjednodušíme do nejmenší možné
velikosti, protože bude mít pouze dva neurony ve vstupní vrstvě a jediný neuron
ve vrstvě výstupní. Skryté vrstvy nebudou existovat. To tedy znamená, že
namísto relativně složité sítě typu:</p>

*** image ***
<p><i>Obrázek 1: Neuronová síť s&nbsp;více skrytými vrstvami.</i></p>

<p>Budeme mít síť s&nbsp;celkem pouze třemi neurony:</p>

*** image ***
<p><i>Obrázek 2: Neuronová síť bez skrytých vrstev; vstupní vrstva má dva
neurony, výstupní vrstva neuron jediný.</i></p>

<p>Skript, který si připraví data pro trénink a testování (začneme na 10
záznamech), zkonstruuje síť a následně ověří její (ne)funkčnost, může vypadat
následovně. Naprostou většinu konceptů použitých v&nbsp;tomto skriptu již
známe:</p>

<pre>
import numpy as np
&nbsp;
import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
<i># velikost vstupu</i>
MAX_N = 10
&nbsp;
<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N, 2) )   <i># kombinace vstupu</i>
y = np.zeros( (MAX_N, ))     <i># vektor vysledku</i>
&nbsp;
<i># priprava dat pro trenink i otestovani neuronove site</i>
for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]
&nbsp;
<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
&nbsp;
<i># konstrukce modelu</i>
nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=())
&nbsp;
<i># trénink modelu</i>
nn.fit(X_train, y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = nn.predict(X_test)
&nbsp;
<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
&nbsp;
<i># zobrazit parametry neuronove site</i>
print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")
&nbsp;
<i># vahy neuronu</i>
for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
    print(weights)
print()
&nbsp;
<i># posuny (dalsi vstup do neuronu)</i>
print("Biases:")
for layer, biases in enumerate(nn.intercepts_):
    print("\t", layer, biases.shape)
    print(biases)
print()
&nbsp;
<i># test neuronove site na (potencialne) nezname vstupy</i>
inputs = []
for i in range(0, MAX_N):
    for j in range(0, MAX_N):
        inputs.append([i, j])
predicted = nn.predict(inputs)
&nbsp;
print()
&nbsp;
<i># odhady neuronove site po zaokrouhleni</i>
all = 0
wrong = 0
&nbsp;
<i># projit vsemi odhady a najit spatne vystupy site</i>
for i, p in zip(inputs, predicted):
    <i># spatny odhad?</i>
    if i[1] != round(p):
        print(f"{i[0]:2}, {i[1]:2} = {round(p):2}")
        wrong += 1
    all += 1
&nbsp;
<i># vysledna statistika</i>
print(f"{wrong}/{all}")
</pre>



<p><a name="k02"></a></p>
<h2 id="k02">2. Výsledky získané otestování jednoduché neuronové sítě</h2>

<p>Užitečné bude zjistit, jak se bude výše nakonfigurovaná neuronová síť
chovat. Ovšem vzhledem k&nbsp;tomu, že se v&nbsp;průběhu tréninku používají
náhodná čísla, nebudou výsledky vždy totožné. Ovšem poměrně často je síť
natrénována tak vhodným způsobem, že má prakticky stoprocentní odpovědi:</p>

<pre>
Mean squared error: 0.10
Coefficient of determination: 0.00
</pre>

<p>Interní struktura takové sítě vypadá následovně:</p>

<pre>
Features: 2
Layers:   2
Outputs:  1
Weights:
	 0 (2, 1)
[[-0.00311307]
 [ 0.96168339]]
&nbsp;
Biases:
	 0 (1,)
[-0.08298607]
</pre>

<p>Povšimněte si toho, že váhy na vstupu neuronu ve výstupní vrstvě jsou
poměrně blízko hodnotám 0,0 a 1,0, což odpovídá požadované funkci sítě. A bias
(tedy váha pro posuny hodnot na vstupu tohoto neuronu) je taky prakticky
nulový.  Neuron tedy skutečně vybere druhou vstupní hodnotu, kterou předá do
aktivační funkce. Ta je pro kladné hodnoty funkcí lineární, takže ji můžeme
ignorovat. Ze vztahu:</p>

<p>
y = f(<strong>w<sub>0</sub></strong> + w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub> + ... + w<sub>n</sub>x<sub>n</sub>)
</p>

<p>Tedy získáme tento výpočet, který neuron provádí:</p>

<p>
y = <strong>w<sub>0</sub></strong> + w<sub>1</sub>x<sub>1</sub> + w<sub>2</sub>x<sub>2</sub>
</p>

<p>A po dosazení ideálních hodnot:</p>

<p>
y = 0x<sub>1</sub> + 1x<sub>2</sub> = x<sub>2</sub>
</p>

<p>Ideálně natrénované neuronové síti odpovídá tento výsledek:</p>

<pre>
rounded:
0/100
</pre>

<p><div class="rs-tip-major">Poznámka: naše síť sice není natrénována ideálně,
ale pro zvolenou testovací sadu jsme tuto vlastnost (zatím)
neodhalili.</div></p>

<p>Ovšem v&nbsp;některých případech dopadne trénink odlišně, a to opět kvůli
(pseudo)náhodným hodnotám, které do celého procesu vstupují. Povšimněte si
odlišných vah a o snahu sítě vše &bdquo;vyvážit&ldquo; vyšším biasem:</p>

<pre>
Mean squared error: 0.49
Coefficient of determination: 0.92
Features: 2
Layers:   2
Outputs:  1
Weights:
	 0 (2, 1)
[[0.04786446]
 [0.95183809]]
&nbsp;
Biases:
	 0 (1,)
[0.47868983]
&nbsp;
&nbsp;
rounded:
 1,  0 =  1
 2,  0 =  1
 2,  1 =  2
 3,  0 =  1
 3,  1 =  2
 3,  2 =  3
 4,  0 =  1
 4,  1 =  2
 4,  2 =  3
 4,  3 =  4
 5,  0 =  1
 5,  1 =  2
 5,  2 =  3
 5,  3 =  4
 5,  4 =  5
 6,  0 =  1
 6,  1 =  2
 6,  2 =  3
 6,  3 =  4
 6,  4 =  5
 6,  5 =  6
 7,  0 =  1
 7,  1 =  2
 7,  2 =  3
 7,  3 =  4
 7,  4 =  5
 7,  5 =  6
 7,  6 =  7
 8,  0 =  1
 8,  1 =  2
 8,  2 =  3
 8,  3 =  4
 8,  4 =  5
 8,  5 =  6
 8,  6 =  7
 8,  7 =  8
 9,  0 =  1
 9,  1 =  2
 9,  2 =  3
 9,  3 =  4
 9,  4 =  5
 9,  5 =  6
 9,  6 =  7
 9,  7 =  8
 9,  8 =  9
45/100
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. Odstranění náhody z&nbsp;procesu tréninku a testování neuronové sítě</h2>

<p>Abychom se vyhnuli tomu, že po každém spuštění procesu tréninku a testování
získáme poněkud odlišné hodnoty, pokusíme se odstranit všechny náhody (náhodná
čísla), která jsou používána. Nejprve nastavíme konstantní
&bdquo;semínko&ldquo; (<i>seed</i>) použité pro inicializaci generátoru
pseudonáhodných čísel. Tím zajistíme, že stejné pořadí volání funkce
<strong>random.randint()</strong> bude vracet stejné pořadí výsledků:</p>

<pre>
<i># zadne skutecne nahodne hodnoty</i>
<strong>random.seed(19)</strong>
&nbsp;
<i># priprava dat pro trenink i otestovani neuronove site</i>
for i in range(0, MAX_N):
    X[i, 0] = <strong>random.randint(-10, 10)</strong>
    X[i, 1] = <strong>random.randint(-10, 10)</strong>
    y[i] = X[i, 1]
</pre>

<p>Náhodu odstraníme i z&nbsp;procesu rozdělení datové sady na trénovací a
validační data:</p>

<pre>
<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, <strong>random_state=42</strong>)
</pre>

<p>A konečně předáme &bdquo;náhodný stav&ldquo;, který ovšem evidentně náhodný
není, i jako hyperparametr modelu:</p>

<pre>
<i># konstrukce modelu</i>
nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(), <strong>random_state=1000</strong>)
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. Skript pro trénink a otestování neuronové sítě se stabilními výsledky</h2>

<p>Po úpravě zdrojového kódu tak, aby se v&nbsp;něm nevyskytovaly žádné náhodné
hodnoty, dojdeme k&nbsp;následujícímu skriptu, jenž by měl při každém spuštění
vždy odpovědět stejně:</p>

<pre>
import numpy as np
&nbsp;
import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
&nbsp;
<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor
&nbsp;
<i># velikost vstupu</i>
MAX_N = 20
&nbsp;
<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N, 2) )   <i># kombinace vstupu</i>
y = np.zeros( (MAX_N, ))     <i># vektor vysledku</i>
&nbsp;
<i># zadne skutecne nahodne hodnoty</i>
random.seed(19)
&nbsp;
<i># priprava dat pro trenink i otestovani neuronove site</i>
for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]
&nbsp;
&nbsp;
<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
&nbsp;
<i># konstrukce modelu</i>
nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(), random_state=1000)
&nbsp;
<i># trénink modelu</i>
nn.fit(X_train, y_train)
&nbsp;
<i># predikce modelu</i>
y_pred = nn.predict(X_test)
&nbsp;
<i># chyba predikce</i>
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
&nbsp;
<i># 1 = nejlepší predikce modelu</i>
print("Coefficient of determination: %.2f" % r2_score(y_test, y_pred))
&nbsp;
<i># zobrazit parametry neuronove site</i>
print(f"Features: {nn.n_features_in_}")
print(f"Layers:   {nn.n_layers_}")
print(f"Outputs:  {nn.n_outputs_}")
print("Weights:")
&nbsp;
<i># vahy neuronu</i>
for layer, weights in enumerate(nn.coefs_):
    print("\t", layer, weights.shape)
    print(weights)
print()
&nbsp;
<i># posuny (dalsi vstup do neuronu)</i>
print("Biases:")
for layer, biases in enumerate(nn.intercepts_):
    print("\t", layer, biases.shape)
    print(biases)
print()
&nbsp;
<i># test neuronove site na (potencialne) nezname vstupy</i>
inputs = []
for i in range(0, MAX_N):
    for j in range(0, MAX_N):
        inputs.append([i, j])
predicted = nn.predict(inputs)
&nbsp;
print()
&nbsp;
<i># odhady neuronove site po zaokrouhleni</i>
all = 0
wrong = 0
&nbsp;
for i, p in zip(inputs, predicted):
    <i># spatny odhad?</i>
    if i[1] != round(p):
        print(f"{i[0]:2}, {i[1]:2} = {round(p):2}")
        wrong += 1
    all += 1
&nbsp;
<i># vysledna statistika</i>
print(f"{wrong}/{all}")
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Stabilní výsledky získané předchozím skriptem</h2>

<p>Výsledky, které získáme po <i>každém</i> spuštění skriptu popsaného <a
href="#k04">v&nbsp;předchozí kapitole</a>, vypadají na mém počítači následovně
(teoreticky se totiž mohou výsledky na jiném počítači odlišovat, pokud je
použitý jiný algoritmus generování náhodných čísel):</p>

<pre>
Mean squared error: 0.08
Coefficient of determination: 1.00
Features: 2
Layers:   2
Outputs:  1
Weights:
	 0 (2, 1)
[[0.01515987]
 [0.96449027]]
&nbsp;
Biases:
	 0 (1,)
[0.08740665]
</pre>

<p>Povšimněte si, že síť nebyla natrénována zcela ideálně, protože váha u
druhého vstupu neuronu by mohla být blíže jedničce a naopak bias by mohl být
blíže k&nbsp;nule. Ne zcela ideálnímu natrénovaní odpovídá i několik chybných
odhadů nalezených při testování, ovšem není jich příliš mnoho &ndash; tři
procenta:</p>

<pre>
 0, 17 = 16
 0, 18 = 17
 0, 19 = 18
 1, 17 = 16
 1, 18 = 17
 1, 19 = 18
 2, 18 = 17
 2, 19 = 18
 3, 18 = 17
 3, 19 = 18
 4, 19 = 18
 5, 19 = 18
12/400
</pre>



<p><a name="k06"></a></p>
<h2 id="k06">6. </h2>



<p><a name="k07"></a></p>
<h2 id="k07">7. </h2>

<pre>
import numpy as np

import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor

<i># velikost vstupu</i>
MAX_N = 40

<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N, 2) )   <i># kombinace vstupu</i>
y = np.zeros( (MAX_N, ))     <i># vektor vysledku</i>

random.seed(19)

for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]


<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


def train_and_test_nn(size):
    X_train_ = X_train[:size]
    y_train_ = y_train[:size]

    <i># konstrukce modelu</i>
    nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(), random_state=1000)

    <i># trénink modelu</i>
    nn.fit(X_train_, y_train_)

    <i># predikce modelu</i>
    y_pred = nn.predict(X_test)

    <i># chyba predikce</i>
    <i># 1 = nejlepší predikce modelu</i>
    print("%2d" % size, "%.2f" % mean_squared_error(y_test, y_pred), "%.2f" % r2_score(y_test, y_pred))


for i in range(1, MAX_N+1):
    train_and_test_nn(i)
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. </h2>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>

<pre>
from types import NoneType
import matplotlib.pyplot as plt
import numpy as np

import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor

<i># velikost vstupu</i>
MAX_N = 50

<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N, 2) )   <i># kombinace vstupu</i>
y = np.zeros( (MAX_N, ))     <i># vektor vysledku</i>

random.seed(19)

for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]


<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


def train_and_test_nn(size: int):
    X_train_ = X_train[:size]
    y_train_ = y_train[:size]

    <i># konstrukce modelu</i>
    nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(), random_state=1000)

    <i># trénink modelu</i>
    nn.fit(X_train_, y_train_)

    <i># predikce modelu</i>
    y_pred = nn.predict(X_test)

    <i># chyba predikce</i>
    <i># 1 = nejlepší predikce modelu</i>
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print("%2d" % size, "%.2f" % mse, "%.2f" % r2)

    <i># vahy na vstupu neuronu ve vystupni vrstve</i>
    w = nn.coefs_[0]

    <i># bias na vstupu neuronu ve vystupni vrstve</i>
    b = nn.intercepts_[0]

    <i># vratit obe vahy i bias</i>
    return mse, r2, w[0][0], w[1][0], b[0]


<i># trening site az do poctu prvku MAX_N</i>
r = range(1, MAX_N+1)

weights1 = []
weights2 = []
biases = []
mses = []
r2s = []

<i># postupne provest treing site, vyplneni poli s vahami a biasy</i>
for i in r:
    mse, r2, weight1, weight2, bias = train_and_test_nn(i)
    mses.append(mse)
    r2s.append(r2)
    weights1.append(weight1)
    weights2.append(weight2)
    biases.append(bias)

print(weights1)
print(weights2)
print(biases)

plt.plot(r, mses, r, r2s)
plt.legend(["MSE", "R2 score"])
plt.savefig("mse_r2.png")
plt.show()

plt.plot(r, weights1, r, weights2)
plt.legend(["weight1", "weight2"])
plt.savefig("weights.png")
plt.show()

plt.plot(r, biases)
plt.legend(["bias"])
plt.savefig("biases.png")
plt.show()
</pre>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>

<pre>
from types import NoneType
import matplotlib.pyplot as plt
import numpy as np

import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor

<i># velikost vstupu</i>
MAX_N = 50

<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N, 2) )   <i># kombinace vstupu</i>
y = np.zeros( (MAX_N, ))     <i># vektor vysledku</i>

random.seed(19)

for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]


<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


def train_and_test_nn(size: int):
    X_train_ = X_train[:size]
    y_train_ = y_train[:size]

    <i># konstrukce modelu</i>
    nn = MLPRegressor(max_iter=1000, hidden_layer_sizes=(), random_state=1000)

    <i># trénink modelu</i>
    nn.fit(X_train_, y_train_)

    <i># predikce modelu</i>
    y_pred = nn.predict(X_test)

    <i># chyba predikce</i>
    <i># 1 = nejlepší predikce modelu</i>
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print("%2d" % size, "%.2f" % mse, "%.2f" % r2)

    <i># vahy na vstupu neuronu ve vystupni vrstve</i>
    w = nn.coefs_[0]

    <i># bias na vstupu neuronu ve vystupni vrstve</i>
    b = nn.intercepts_[0]

    <i># vratit obe vahy i bias</i>
    return mse, r2, w[0][0], w[1][0], b[0]


<i># trening site az do poctu prvku MAX_N</i>
r = range(1, MAX_N+1)

weights1 = []
weights2 = []
biases = []
mses = []
r2s = []

<i># postupne provest treing site, vyplneni poli s vahami a biasy</i>
for i in r:
    mse, r2, weight1, weight2, bias = train_and_test_nn(i)
    mses.append(mse)
    r2s.append(r2)
    weights1.append(weight1)
    weights2.append(weight2)
    biases.append(bias)

print(weights1)
print(weights2)
print(biases)

plt.plot(r, mses, r, r2s)
plt.legend(["MSE", "R2 score"])
plt.savefig("mse_r2.png")
plt.show()

plt.plot(r, weights1, r, weights2)
plt.legend(["weight1", "weight2"])
plt.savefig("weights.png")
plt.show()

plt.plot(r, biases)
plt.legend(["bias"])
plt.savefig("biases.png")
plt.show()
</pre>


<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>

<pre>
from types import NoneType
import matplotlib.pyplot as plt
import numpy as np

import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor

<i># velikost vstupu</i>
MAX_N = 50

<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N, 2) )   <i># kombinace vstupu</i>
y = np.zeros( (MAX_N, ))     <i># vektor vysledku</i>

random.seed(19)

for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]


<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


def train_and_test_nn(size: int):
    X_train_ = X_train[:size]
    y_train_ = y_train[:size]

    <i># konstrukce modelu</i>
    nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(), random_state=1000, learning_rate_init=0.05)

    <i># trénink modelu</i>
    nn.fit(X_train_, y_train_)

    <i># predikce modelu</i>
    y_pred = nn.predict(X_test)

    <i># chyba predikce</i>
    <i># 1 = nejlepší predikce modelu</i>
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print("%2d" % size, "%.2f" % mse, "%.2f" % r2)

    <i># vahy na vstupu neuronu ve vystupni vrstve</i>
    w = nn.coefs_[0]

    <i># bias na vstupu neuronu ve vystupni vrstve</i>
    b = nn.intercepts_[0]

    <i># vratit obe vahy i bias</i>
    return mse, r2, w[0][0], w[1][0], b[0]


<i># trening site az do poctu prvku MAX_N</i>
r = range(1, MAX_N+1)

weights1 = []
weights2 = []
biases = []
mses = []
r2s = []

<i># postupne provest treing site, vyplneni poli s vahami a biasy</i>
for i in r:
    mse, r2, weight1, weight2, bias = train_and_test_nn(i)
    mses.append(mse)
    r2s.append(r2)
    weights1.append(weight1)
    weights2.append(weight2)
    biases.append(bias)

print(weights1)
print(weights2)
print(biases)

plt.plot(r, mses, r, r2s)
plt.legend(["MSE", "R2 score"])
plt.savefig("mse_r2.png")
plt.show()

plt.plot(r, weights1, r, weights2)
plt.legend(["weight1", "weight2"])
plt.savefig("weights.png")
plt.show()

plt.plot(r, biases)
plt.legend(["bias"])
plt.savefig("biases.png")
plt.show()
</pre>


<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>

<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>

<pre>
from types import NoneType
import matplotlib.pyplot as plt
import numpy as np

import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor

<i># velikost vstupu</i>
MAX_N = 50

<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N, 2) )   <i># kombinace vstupu</i>
y = np.zeros( (MAX_N, ))     <i># vektor vysledku</i>

random.seed(19)

for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]


<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


def train_and_test_nn(size: int):
    X_train_ = X_train[:size]
    y_train_ = y_train[:size]

    <i># konstrukce modelu</i>
    nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(), random_state=1000, learning_rate_init=0.2)

    <i># trénink modelu</i>
    nn.fit(X_train_, y_train_)

    <i># predikce modelu</i>
    y_pred = nn.predict(X_test)

    <i># chyba predikce</i>
    <i># 1 = nejlepší predikce modelu</i>
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print("%2d" % size, "%.2f" % mse, "%.2f" % r2)

    <i># vahy na vstupu neuronu ve vystupni vrstve</i>
    w = nn.coefs_[0]

    <i># bias na vstupu neuronu ve vystupni vrstve</i>
    b = nn.intercepts_[0]

    <i># vratit obe vahy i bias</i>
    return mse, r2, w[0][0], w[1][0], b[0]


<i># trening site az do poctu prvku MAX_N</i>
r = range(1, MAX_N+1)

weights1 = []
weights2 = []
biases = []
mses = []
r2s = []

<i># postupne provest treing site, vyplneni poli s vahami a biasy</i>
for i in r:
    mse, r2, weight1, weight2, bias = train_and_test_nn(i)
    mses.append(mse)
    r2s.append(r2)
    weights1.append(weight1)
    weights2.append(weight2)
    biases.append(bias)

print(weights1)
print(weights2)
print(biases)

plt.plot(r, mses, r, r2s)
plt.legend(["MSE", "R2 score"])
plt.savefig("mse_r2.png")
plt.show()

plt.plot(r, weights1, r, weights2)
plt.legend(["weight1", "weight2"])
plt.savefig("weights.png")
plt.show()

plt.plot(r, biases)
plt.legend(["bias"])
plt.savefig("biases.png")
plt.show()
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>

<pre>
from types import NoneType
import matplotlib.pyplot as plt
import numpy as np

import random
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score

<i># model zalozeny na neuronove siti</i>
from sklearn.neural_network import MLPRegressor

<i># velikost vstupu</i>
MAX_N = 50

<i># X je matice, y je vektor</i>
X = np.zeros( (MAX_N, 2) )   <i># kombinace vstupu</i>
y = np.zeros( (MAX_N, ))     <i># vektor vysledku</i>

random.seed(19)

for i in range(0, MAX_N):
    X[i, 0] = random.randint(-10, 10)
    X[i, 1] = random.randint(-10, 10)
    y[i] = X[i, 1]


<i># rozdeleni dat na treninkovou a testovaci mnozinu</i>
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


def train_and_test_nn(size: int):
    X_train_ = X_train[:size]
    y_train_ = y_train[:size]

    <i># konstrukce modelu</i>
    nn = MLPRegressor(max_iter=5000, hidden_layer_sizes=(), random_state=1000, learning_rate_init=0.0001)

    <i># trénink modelu</i>
    nn.fit(X_train_, y_train_)

    <i># predikce modelu</i>
    y_pred = nn.predict(X_test)

    <i># chyba predikce</i>
    <i># 1 = nejlepší predikce modelu</i>
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print("%2d" % size, "%.2f" % mse, "%.2f" % r2)

    <i># vahy na vstupu neuronu ve vystupni vrstve</i>
    w = nn.coefs_[0]

    <i># bias na vstupu neuronu ve vystupni vrstve</i>
    b = nn.intercepts_[0]

    <i># vratit obe vahy i bias</i>
    return mse, r2, w[0][0], w[1][0], b[0]


<i># trening site az do poctu prvku MAX_N</i>
r = range(1, MAX_N+1)

weights1 = []
weights2 = []
biases = []
mses = []
r2s = []

<i># postupne provest treing site, vyplneni poli s vahami a biasy</i>
for i in r:
    mse, r2, weight1, weight2, bias = train_and_test_nn(i)
    mses.append(mse)
    r2s.append(r2)
    weights1.append(weight1)
    weights2.append(weight2)
    biases.append(bias)

print(weights1)
print(weights2)
print(biases)

plt.plot(r, mses, r, r2s)
plt.legend(["MSE", "R2 score"])
plt.savefig("mse_r2.png")
plt.show()

plt.plot(r, weights1, r, weights2)
plt.legend(["weight1", "weight2"])
plt.savefig("weights.png")
plt.show()

plt.plot(r, biases)
plt.legend(["bias"])
plt.savefig("biases.png")
plt.show()
</pre>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu Scikit-learn lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady i na (Jupyter) diáře s&nbsp;postupem
výpočtů a analýz:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td> 1</td><td>01_show_matrix.py</td><td>kooperace mezi knihovnami Matplotlib a NumPy: vizualizace obsahu 2D matice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/01_show_matrix.py</a></td></tr>
<tr><td> 2</td><td>02_get_digits.py</td><td>datová množina obsahující naskenované ručně napsané číslice</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/02_get_digits.py</a></td></tr>
<tr><td> 3</td><td>03_get_features.py</td><td>další atributy datové množiny, které použijeme při trénování</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/03_get_features.py</a></td></tr>
<tr><td> 4</td><td>04_get_images.py</td><td>přečtení a následné vykreslení jednotlivých ručně nakreslených číslic</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/04_get_images.py</a></td></tr>
<tr><td> 5</td><td>05_show_grayscale_matrix.py</td><td>odstranění umělé aplikované barvové palety (obrázky ve stupních šedi)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/05_show_grayscale_matrix.py</a></td></tr>
<tr><td> 6</td><td>06_grayscale_images.py</td><td>vykreslení ručně nakreslených číslic ve formě obrázků ve stupních šedi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/06_grayscale_images.py</a></td></tr>
<tr><td> 7</td><td>07_multiplot.py</td><td>rozdělení plochy grafu do oblastí; vykreslení více obrázků do jediného grafu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/07_multiplot.py</a></td></tr>
<tr><td> 8</td><td>08_model_preperation_1.py</td><td>obrázky s&nbsp;jejich ohodnocením</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/08_model_preperation_1.py</a></td></tr>
<tr><td> 9</td><td>09_training_set.py</td><td>příprava dat pro trénink</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/09_training_set.py</a></td></tr>
<tr><td>10</td><td>10_classification.py</td><td>klasifikace obrázků</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/10_classification.py</a></td></tr>
<tr><td>11</td><td>11_results.py</td><td>vykreslení obrázků společně s&nbsp;jejich klasifikací</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/11_results.py</a></td></tr>
<tr><td>12</td><td>12_change_training_set.py</td><td>změna poměru rozdělení dat na tréninkovou a testovací množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/12_change_training_set.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>13</td><td>13_blobs.py</td><td>použití funkce <strong>make_blobs</strong> pro vygenerování sady bodů v&nbsp;rovině sdružených do oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/13_blobs.py</a></td></tr>
<tr><td>14</td><td>14_swap_coords.py</td><td>úprava předchozího příkladu: prohození souřadnic na osách</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/14_swap_coords.py</a></td></tr>
<tr><td>15</td><td>15_blobs_scatter_plot.py</td><td>základní podoba bodového diagramu (<i>scatter plot</i>)</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/15_blobs_scatter_plot.py</a></td></tr>
<tr><td>16</td><td>16_blobs_scatter_plot.py</td><td>úprava bodového diagramu při zobrazení většího množství bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/16_blobs_scatter_plot.py</a></td></tr>
<tr><td>17</td><td>17_colorized_blobs.py</td><td>obarvení bodů podle oblastí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/17_colorized_blobs.py</a></td></tr>
<tr><td>18</td><td>18_k-means.py</td><td>základní použití algoritmu K-means pro clustering</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/18_k-means.py</a></td></tr>
<tr><td>19</td><td>19_combination.py</td><td>zobrazení centroidů společně s&nbsp;původními body</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/19_combination.py</a></td></tr>
<tr><td>20</td><td>20_combinations.py</td><td>vizualizace clusteringu původní množiny bodů</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/20_combinations.py</a></td></tr>
<tr><td>21</td><td>21_other_settings.py</td><td>vizualizace clusteringu původní množiny bodů pro odlišnou množinu</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/21_other_settings.py</a></td></tr>
<tr><td>22</td><td>22_random_points.py</td><td>clustering pro náhodná data</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/22_random_points.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>23</td><td>23_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, menší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/23_circles.py</a></td></tr>
<tr><td>24</td><td>24_more_noise_circles.py</td><td>pseudonáhodné rozmístění bodů do kružnic, větší náhodnost výsledku</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/24_more_noise_circles.py</a></td></tr>
</table>

<p>V&nbsp;repositáři nalezneme taktéž projektový soubor a Jupyter Notebook
s&nbsp;vysvětlením, jak lze modely využít pro rozpoznávání obsahu rastrových
obrázků:</p>

<table>
<tr><th>#<th>Příklad</th><th>Stručný popis</th><th>Adresa příkladu</th></tr></i>
<tr><td>1</td><td>pyproject.toml</td><td>projektový soubor (pro PDM) se všemi závislostmi</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pyproject.toml</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>2</td><td>pdm.lock</td><td>lock soubor s&nbsp;konkrétními verzemi všech přímých i tranzitivních závislostí</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/pdm.lock</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>3</td><td>Rozpoznání_obrazu_scikit-learn.ipynb</td><td>Jupyter notebook s&nbsp;celým postupem</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb">https://github.com/tisnik/most-popular-python-libs/blob/master/sklearn/Rozpoznání_obrazu_scikit-learn.ipynb</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>4</td><td>particle_life.py</td><td>emergence: příklad vzniku struktury</td><td><a href="https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py">https://github.com/tisnik/most-popular-python-libs/blob/master/particles/particle_life.py</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

