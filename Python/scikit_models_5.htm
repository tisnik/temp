<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. </a></p>
<p><a href="#k02">*** 2. </a></p>
<p><a href="#k03">*** 3. </a></p>
<p><a href="#k04">*** 4. </a></p>
<p><a href="#k05">*** 5. </a></p>
<p><a href="#k06">*** 6. </a></p>
<p><a href="#k07">*** 7. </a></p>
<p><a href="#k08">*** 8. </a></p>
<p><a href="#k09">*** 9. </a></p>
<p><a href="#k10">*** 10. </a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k20">*** 20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. </h2>



<p><a name="k02"></a></p>
<h2 id="k02">2. </h2>

<pre>
import numpy as np
import matplotlib.pyplot as plt

from sklearn import linear_model

# počet vzorků ve vektorech x i y
VALUES = 50

# x je vektor
x = np.linspace(0, 10, VALUES)

# y je vektor
y = np.linspace(-1, 1, VALUES) + 0.5*np.random.rand(VALUES)

# převod vektoru na 2D matici
X = x.reshape(-1, 1)

# tvar matice X a vektoru y
print("X shape:", X.shape)
print("y shape:", y.shape)

# konstrukce modelu
lr = linear_model.LinearRegression()

# trénink modelu (X musí být maticí)
lr.fit(X, y)

# predikce modelu
y_pred = lr.predict(X)

# výpis vypočtených koeficientů modelu
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)

# vykreslení výsledku
plt.scatter(x, y, color="black", s=2)
plt.plot(x, y_pred, color="blue", linewidth=2)

# titulek grafu
plt.title("Linear regression")

# osy
plt.xticks()
plt.yticks()

# ulozeni diagramu do souboru
plt.savefig("112.png")

# zobrazeni diagramu
plt.show()
</pre>

*** image ***
<p><i>Obrázek 1: </i></p>



<p><a name="k03"></a></p>
<h2 id="k03">3. </h2>



<p><a name="k04"></a></p>
<h2 id="k04">4. </h2>

<pre>
import numpy as np
import matplotlib.pyplot as plt

from sklearn import linear_model

# počet vzorků ve vektorech x i y
VALUES = 50

# x je vektor
x = np.linspace(0, 10, VALUES)

# y je vektor
y = np.linspace(-1, 1, VALUES) + 0.5*np.random.rand(VALUES)

# převod vektoru na 2D matici
X = x.reshape(-1, 1)

# tvar matice X a vektoru y
print("X shape:", X.shape)
print("y shape:", y.shape)

# konstrukce modelu
lr = linear_model.LinearRegression(fit_intercept=False)

# trénink modelu (X musí být maticí)
lr.fit(X, y)

# predikce modelu
y_pred = lr.predict(X)

# výpis vypočtených koeficientů modelu
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)

# vykreslení výsledku
plt.scatter(x, y, color="black", s=2)
plt.plot(x, y_pred, color="blue", linewidth=2)

# titulek grafu
plt.title("Linear regression")

# osy
plt.xticks()
plt.yticks()

# ulozeni diagramu do souboru
plt.savefig("113.png")

# zobrazeni diagramu
plt.show()
</pre>

*** image ***
<p><i>Obrázek 2:</i></p>



<p><a name="k05"></a></p>
<h2 id="k05">5. </h2>

<pre>
import numpy as np
import matplotlib.pyplot as plt

from sklearn import linear_model

# počet vzorků ve vektorech x i y
VALUES = 50

# x je vektor
x = np.linspace(0, 10, VALUES)

# y je vektor
y = np.linspace(0, 2, VALUES) + 0.5*np.random.rand(VALUES)

# převod vektoru na 2D matici
X = x.reshape(-1, 1)

# tvar matice X a vektoru y
print("X shape:", X.shape)
print("y shape:", y.shape)

# konstrukce modelu
lr = linear_model.LinearRegression(fit_intercept=False)

# trénink modelu (X musí být maticí)
lr.fit(X, y)

# predikce modelu
y_pred = lr.predict(X)

# výpis vypočtených koeficientů modelu
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)

# vykreslení výsledku
plt.scatter(x, y, color="black", s=2)
plt.plot(x, y_pred, color="blue", linewidth=2)

# titulek grafu
plt.title("Linear regression")

# osy
plt.xticks()
plt.yticks()

# ulozeni diagramu do souboru
plt.savefig("114.png")

# zobrazeni diagramu
plt.show()
</pre>

*** image ***
<p><i>Obrázek 3:</i></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. </h2>



<p><a name="k07"></a></p>
<h2 id="k07">7. </h2>

<pre>
import numpy as np
import matplotlib.pyplot as plt

from sklearn import linear_model

# počet vzorků ve vektorech x i y
VALUES = 50

# x je vektor
x = np.linspace(0, 10, VALUES)

# Y je matice vytvořená ze dvou vektorů
y1 = np.linspace(-1, 1, VALUES) + 0.5*np.random.rand(VALUES)
y2 = np.linspace(1, -1, VALUES) + 0.5*np.random.rand(VALUES)

# konstrukce matice se dvěma sloupci
Y= np.column_stack((y1, y2))

# převod vektoru na 2D matici
X = x.reshape(-1, 1)

# tvar matic X a Y
print("X shape:", X.shape)
print("Y shape:", Y.shape)

# konstrukce modelu
lr = linear_model.LinearRegression()

# trénink modelu
lr.fit(X, Y)

# predikce modelu
y_pred = lr.predict(X)

# výpis vypočtených koeficientů modelu
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)

for dimension in range(0, 2):
    # vykreslení výsledku
    plt.scatter(x, Y[:, dimension], color="black", s=2)
    plt.plot(x, y_pred[:, dimension], color="blue", linewidth=2)

    # titulek grafu
    plt.title(f"Linear regression in dimension {dimension}")

    # osy
    plt.xticks()
    plt.yticks()

    # ulozeni diagramu do souboru
    plt.savefig(f"115_{dimension}.png")

    # zobrazeni diagramu
    plt.show()

    # druhy diagram
    plt.close()
</pre>

*** image ***
<p><i>Obrázek 4: </i></p>

*** image ***
<p><i>Obrázek 5: </i></p>



<p><a name="k08"></a></p>
<h2 id="k08">8. </h2>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>

<pre>
import numpy as np

# počet vzorků v mřížce
VALUES = 5

# X je matice vytvořená z mřížky
# dvojice vektorů pro konstrukci mřížky
x1 = np.linspace(0, 100, VALUES)
x2 = np.linspace(0, 100, VALUES)

print("x1:", x1)
print("x2:", x2)
print()

# konstrukce mřížky
grid = np.meshgrid(x1, x2)

print("grid #1:\n", grid[0])
print()
print("grid #2:\n", grid[1])
print()

# změna tvaru na matici se dvěma sloupci
X = np.vstack([grid[0].flatten(), grid[1].flatten()]).T

print("X shape:", X.shape)
print(X)
print()

# y je vektor
y = (grid[0] + grid[1]).flatten()

print("y shape:", y.shape)
print(y)
</pre>

<pre>
x1: [  0.  25.  50.  75. 100.]
x2: [  0.  25.  50.  75. 100.]

grid #1:
 [[  0.  25.  50.  75. 100.]
 [  0.  25.  50.  75. 100.]
 [  0.  25.  50.  75. 100.]
 [  0.  25.  50.  75. 100.]
 [  0.  25.  50.  75. 100.]]

grid #2:
 [[  0.   0.   0.   0.   0.]
 [ 25.  25.  25.  25.  25.]
 [ 50.  50.  50.  50.  50.]
 [ 75.  75.  75.  75.  75.]
 [100. 100. 100. 100. 100.]]

X shape: (25, 2)
[[  0.   0.]
 [ 25.   0.]
 [ 50.   0.]
 [ 75.   0.]
 [100.   0.]
 [  0.  25.]
 [ 25.  25.]
 [ 50.  25.]
 [ 75.  25.]
 [100.  25.]
 [  0.  50.]
 [ 25.  50.]
 [ 50.  50.]
 [ 75.  50.]
 [100.  50.]
 [  0.  75.]
 [ 25.  75.]
 [ 50.  75.]
 [ 75.  75.]
 [100.  75.]
 [  0. 100.]
 [ 25. 100.]
 [ 50. 100.]
 [ 75. 100.]
 [100. 100.]]

y shape: (25,)
[  0.  25.  50.  75. 100.  25.  50.  75. 100. 125.  50.  75. 100. 125.
 150.  75. 100. 125. 150. 175. 100. 125. 150. 175. 200.]
</pre>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>

<pre>
import numpy as np
import matplotlib.pyplot as plt

from sklearn import linear_model

# počet vzorků v mřížce
VALUES = 20

# X je matice vytvořená z mřížky
# dvojice vektorů pro konstrukci mřížky
x1 = np.linspace(1, 100, VALUES)
x2 = np.linspace(1, 100, VALUES)

# konstrukce mřížky
grid = np.meshgrid(x1, x2)

# změna tvaru na matici se dvěma sloupci
X = np.vstack([grid[0].flatten(), grid[1].flatten()]).T

# y je vektor
y = (grid[0] + grid[1]).flatten()

# tvar matice X a vektoru y
print("X shape:", X.shape)
print("y shape:", y.shape)

# konstrukce modelu
lr = linear_model.LinearRegression()

# trénink modelu
lr.fit(X, y)

# predikce modelu
y_pred = lr.predict(X).reshape((VALUES, VALUES))
print(y_pred)

# výpis vypočtených koeficientů modelu
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)

# vykreslení výsledku do 3D grafu
fig = plt.figure(figsize=(8, 8))
ax = fig.add_subplot(projection='3d')

# body ze vstupní datové sady
ax.scatter(X[:, 0], X[:, 1], y, color="black", s=2)

# výsledkem modelu je rovina
ax.plot_surface(grid[0], grid[1], y_pred, alpha = 0.5)

# ulozeni diagramu do souboru
plt.savefig("117_.png")

# zobrazeni diagramu
plt.show()
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>

<pre>
import numpy as np
import matplotlib.pyplot as plt

from sklearn import linear_model

# počet vzorků v mřížce
VALUES = 20

# X je matice vytvořená z mřížky
# dvojice vektorů pro konstrukci mřížky
x1 = np.linspace(1, 100, VALUES)
x2 = np.linspace(1, 100, VALUES)

# konstrukce mřížky
grid = np.meshgrid(x1, x2)

# změna tvaru na matici se dvěma sloupci
X = np.vstack([grid[0].flatten(), grid[1].flatten()]).T

# y je vektor
y = (grid[0] + grid[1]).flatten() + 50*np.random.rand(VALUES**2)

# tvar matice X a vektoru y
print("X shape:", X.shape)
print("y shape:", y.shape)

# konstrukce modelu
lr = linear_model.LinearRegression()

# trénink modelu
lr.fit(X, y)

# predikce modelu
y_pred = lr.predict(X).reshape((VALUES, VALUES))
print(y_pred)

# výpis vypočtených koeficientů modelu
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)

# vykreslení výsledku do 3D grafu
fig = plt.figure(figsize=(8, 8))
ax = fig.add_subplot(projection='3d')

# body ze vstupní datové sady
ax.scatter(X[:, 0], X[:, 1], y, color="black", s=2)

# výsledkem modelu je rovina
ax.plot_surface(grid[0], grid[1], y_pred, alpha = 0.5)

# ulozeni diagramu do souboru
plt.savefig("118_.png")

# zobrazeni diagramu
plt.show()
</pre>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>

<pre>
import numpy as np
import matplotlib.pyplot as plt

from sklearn import linear_model

# počet vzorků v mřížce
VALUES = 20

# X je matice vytvořená z mřížky
# dvojice vektorů pro konstrukci mřížky
x1 = np.linspace(1, 100, VALUES)
x2 = np.linspace(1, 100, VALUES)

# konstrukce mřížky
grid = np.meshgrid(x1, x2)

# změna tvaru na matici se dvěma sloupci
X = np.vstack([grid[0].flatten(), grid[1].flatten()]).T

# Y je matice vytvořená ze dvou vektorů
y1 = (grid[0] + grid[1]).flatten() + 0*np.random.rand(VALUES**2) 
y2 = (grid[0] - grid[1]).flatten() + 0*np.random.rand(VALUES**2)

# konstrukce matice se dvěma sloupci
Y= np.column_stack((y1, y2))

# tvar matic X a Y
print("X shape:", X.shape)
print("Y shape:", Y.shape)

# konstrukce modelu
lr = linear_model.LinearRegression()

# trénink modelu
lr.fit(X, Y)

# predikce modelu
y_pred = lr.predict(X).reshape((VALUES, VALUES, 2))

# výpis vypočtených koeficientů modelu
print("Coefficients: \n", lr.coef_)
print("Intercept: \n", lr.intercept_)

for dimension in range(0, 2):
    # vykreslení výsledku do 3D grafu
    fig = plt.figure(figsize=(8, 8))
    ax = fig.add_subplot(projection='3d')

    # body ze vstupní datové sady
    ax.scatter(X[:, 0], X[:, 1], Y[:, dimension], color="black", s=2)

    # výsledkem modelu je rovina
    ax.plot_surface(grid[0], grid[1], y_pred[:, :, dimension], alpha = 0.5)

    # ulozeni diagramu do souboru
    plt.savefig(f"119_{dimension}.png")

    # zobrazeni diagramu
    plt.show()
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>

<p>Všechny demonstrační příklady využívající knihovnu Scikit-learn lze nalézt
v&nbsp;repositáři <a
href="https://github.com/tisnik/most-popular-python-libs">https://github.com/tisnik/most-popular-python-libs</a>.
Následují odkazy na jednotlivé příklady i na (Jupyter) diáře s&nbsp;postupem
výpočtů a analýz:</p>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Shluková analýza (clustering) a knihovna Scikit-learn<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (2)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-2/</a>
</li>

<li>Shluková analýza (clustering) a knihovna Scikit-learn (z plochy do 3D prostoru)<br />
<a href="https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/">https://www.root.cz/clanky/shlukova-analyza-clustering-a-knihovna-scikit-learn-z-plochy-do-3d-prostoru/</a>
</li>

<li>Rozpoznávání obrázků knihovnou Scikit-learn: první kroky<br />
<a href="https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/">https://www.root.cz/clanky/rozpoznavani-obrazku-knihovnou-scikit-learn-prvni-kroky/</a>
</li>

<li>scikit-learn: Machine Learning in Python<br />
<a href="https://scikit-learn.org/stable/index.html">https://scikit-learn.org/stable/index.html</a>
</li>

<li>Sklearn-pandas<br />
<a href="https://github.com/scikit-learn-contrib/sklearn-pandas">https://github.com/scikit-learn-contrib/sklearn-pandas</a>
</li>

<li>sklearn-xarray<br />
<a href="https://github.com/phausamann/sklearn-xarray/">https://github.com/phausamann/sklearn-xarray/</a>
</li>

<li>Clustering<br />
<a href="https://scikit-learn.org/stable/modules/clustering.html">https://scikit-learn.org/stable/modules/clustering.html</a>
</li>

<li>Cluster analysis (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Cluster_analysis">https://en.wikipedia.org/wiki/Cluster_analysis</a>
</li>

<li>Shluková analýza (Wikipedia)<br />
<a href="https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza">https://cs.wikipedia.org/wiki/Shlukov%C3%A1_anal%C3%BDza</a>
</li>

<li>Principal component analysis<br />
<a href="https://en.wikipedia.org/wiki/Principal_component_analysis">https://en.wikipedia.org/wiki/Principal_component_analysis</a>
</li>

<li>Scikit-learn Crash Course - Machine Learning Library for Python<br />
<a href="https://www.youtube.com/watch?v=0B5eIE_1vpU">https://www.youtube.com/watch?v=0B5eIE_1vpU</a>
</li>

<li>calm-notebooks<br />
<a href="https://github.com/koaning/calm-notebooks">https://github.com/koaning/calm-notebooks</a>
</li>

<li>Should you teach Python or R for data science?<br />
<a href="https://www.dataschool.io/python-or-r-for-data-science/">https://www.dataschool.io/python-or-r-for-data-science/</a>
</li>

<li>nbviewer: A simple way to share Jupyter Notebooks<br />
<a href="https://nbviewer.org/">https://nbviewer.org/</a>
</li>

<li>AI vs Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=4RixMPF4xis">https://www.youtube.com/watch?v=4RixMPF4xis</a>
</li>

<li>Machine Learning | What Is Machine Learning? | Introduction To Machine Learning | 2024 | Simplilearn (Youtube)<br />
<a href="https://www.youtube.com/watch?v=ukzFI9rgwfU">https://www.youtube.com/watch?v=ukzFI9rgwfU</a>
</li>

<li>A Gentle Introduction to Machine Learning (Youtube)<br />
<a href="https://www.youtube.com/watch?v=Gv9_4yMHFhI">https://www.youtube.com/watch?v=Gv9_4yMHFhI</a>
</li>

<li>Machine Learning vs Deep Learning<br />
<a href="https://www.youtube.com/watch?v=q6kJ71tEYqM">https://www.youtube.com/watch?v=q6kJ71tEYqM</a>
</li>

<li>Umělá inteligence (slajdy)<br />
<a href="https://slideplayer.cz/slide/12119218/">https://slideplayer.cz/slide/12119218/</a>
</li>

<li>Úvod do umělé inteligence<br />
<a href="https://slideplayer.cz/slide/2505525/">https://slideplayer.cz/slide/2505525/</a>
</li>

<li>Umělá inteligence I / Artificial Intelligence I<br />
<a href="https://ktiml.mff.cuni.cz/~bartak/ui/">https://ktiml.mff.cuni.cz/~bartak/ui/</a>
</li>

<li>Matplotlib vs. seaborn vs. Plotly vs. MATLAB vs. ggplot2 vs. pandas<br />
<a href="https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/">https://ritza.co/articles/matplotlib-vs-seaborn-vs-plotly-vs-MATLAB-vs-ggplot2-vs-pandas/</a>
</li>

<li>Matplotlib, Seaborn or Plotnine?<br />
<a href="https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/">https://www.reddit.com/r/datascience/comments/jvrqxt/matplotlib_seaborn_or_plotnine/</a>
</li>

<li>@Rabeez: Rabeez/plotting_comparison.ipynb<br />
<a href="https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc">https://gist.github.com/Rabeez/ffc0b59d4a41e20fa8d944c44a96adbc</a>
</li>

<li>Matplotlib, Seaborn, Plotly and Plotnine Comparison<br />
<a href="https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40">https://python.plainenglish.io/matplotlib-seaborn-plotly-and-plotnine-comparison-baf2db5a9c40</a>
</li>

<li>Data Visualization 101: How to Choose a Python Plotting Library<br />
<a href="https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a">https://towardsdatascience.com/data-visualization-101-how-to-choose-a-python-plotting-library-853460a08a8a</a>
</li>

<li>Data science in Python: pandas, seaborn, scikit-learn<br />
<a href="https://www.youtube.com/watch?v=3ZWuPVWq7p4">https://www.youtube.com/watch?v=3ZWuPVWq7p4</a>
</li>

<li>7.2. Real world datasets<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>7.2.7. California Housing dataset<br />
<a href="https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset">https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset</a>
</li>

<li>Comprehensive Guide to Classification Models in Scikit-Learn<br />
<a href="https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/">https://www.geeksforgeeks.org/comprehensive-guide-to-classification-models-in-scikit-learn/</a>
</li>

<li>Tidy Data Visualization: ggplot2 vs seaborn<br />
<a href="https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/">https://blog.tidy-intelligence.com/posts/ggplot2-vs-seaborn/</a>
</li>

<li>seaborn: statistical data visualization<br />
<a href="https://seaborn.pydata.org/">https://seaborn.pydata.org/</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2024</small></p>
</body>
</html>

