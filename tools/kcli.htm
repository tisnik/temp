<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Práce s Kafkou z příkazové řádky: nástroje Kafkacat a Kcli</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Práce s Kafkou z příkazové řádky: nástroje Kafkacat a Kcli</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>V několika předchozích článcích jsme si ukázali, jakým způsobem lze využívat služeb Apache Kafky z několika programovacích jazyků. Ve skutečnosti lze ovšem s Kafkou pracovat i přímo z příkazové řádky. K tomu slouží dvojice užitečných aplikací nazvaných Kafkacat a poněkud méně známý nástroj Kcli.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Práce s Kafkou z&nbsp;příkazové řádky: nástroje Kafkacat a Kcli</a></p>
<p><a href="#k02">2. Instalace Kafky</a></p>
<p><a href="#k03">3. Spuštění služby ZooKeeper a jedné instance brokera</a></p>
<p><a href="#k04">4. Uložení logů na ramdisk pro vývojový počítač</a></p>
<p><a href="#k05">5. Konfigurace většího množství brokerů</a></p>
<p><a href="#k06">6. Nástroj <strong>kafkacat</strong></a></p>
<p><a href="#k07">7. Instalace nástroje <strong>kafkacat</strong></a></p>
<p><a href="#k08">8. Nástroj <strong>kcli</strong></a></p>
<p><a href="#k09">9. Instalace nástroje <strong>kcli</strong></a></p>
<p><a href="#k10">*** 10. Připojení <strong>kcli</strong> k&nbsp;brokeru</a></p>
<p><a href="#k11">*** 11. Příprava dat &ndash; zpráv poslaných do témat</a></p>
<p><a href="#k12">*** 12. Prohlížení témat nástrojem <strong>kcli</strong></a></p>
<p><a href="#k13">*** 13. Zápis a prohlížení strukturovaných dat</a></p>
<p><a href="#k14">*** 14. Vytvoření tématu s&nbsp;více oddíly</a></p>
<p><a href="#k15">*** 15. Zápis dat se specifikací oddílů</a></p>
<p><a href="#k16">*** 16. Výběr oddílu v&nbsp;nástroji <strong>kcli</strong></a></p>
<p><a href="#k17">*** 17. Vyhledávání zpráv, přesun na zvolený offset a další možnosti nástroje <strong>kcli</strong></a></p>
<p><a href="#k18">18. Repositář s&nbsp;použitými datovými soubory i skripty</a></p>
<p><a href="#k19">19. Odkazy na relevantní články na Rootu</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Práce s Kafkou z&nbsp;příkazové řádky: nástroje Kafkacat a Kcli</h2>

<p>Na stránkách Roota jsme se již několikrát setkali s&nbsp;užitečnou službou
<i>Apache Kafka</i>, která se v&nbsp;současnosti používá v&nbsp;relativně
velkém množství aplikačních oblastí, od zpracování dat, přes klasické pipeliny,
mikroslužby až po využití Kafky ve funkci <i>message brokera</i>
popř.&nbsp;v&nbsp;architekturách <a
href="https://en.wikipedia.org/wiki/Lambda_architecture">lambda</a> a <a
href="https://www.root.cz/clanky/zpusoby-ulozeni-dat-v-aplikacich-zalozenych-na-mikrosluzbach/#k14">kappa</a>
(resp.&nbsp;spíše <a
href="http://milinda.pathirage.org/kappa-architecture.com/">původní stránka o
tomto tématu</a>). Typicky se s&nbsp;Kafkou komunikuje přímo z&nbsp;aplikací,
které mohou být vyvinuty v&nbsp;různých programovacích jazycích (víme již, jak
vytvořit klienta pro Python, Go a jazyk Clojure). Jedinou podmínkou je, aby pro
daný jazyk (resp.&nbsp;přesněji řečeno pro ekosystém postavený okolo tohoto
jazyka) existovala knihovna poskytující rozhraní ke komunikačnímu protokolu
využívaného Apache Kafkou.</p>

<img src="https://i.iinfo.cz/images/447/microservices2-3.png" class="image-361670" alt="&#160;" width="450" height="134" />
<p><i>Obrázek 1: Logo nástroje Apache Kafka, kterému se budeme dnes
věnovat.</i></p>

<p>Existuje ovšem i poněkud odlišný přístup k&nbsp;práci s&nbsp;Kafkou, který
oceníme při učení, testování, hledání problémů při posílání či příjmu zpráv,
popř.&nbsp;při administrativních úkonech, které s&nbsp;Kafkou souvisí. Tento
přístup je založen na využití příkazového řádku a nástrojů, které jsou
z&nbsp;něj spouštěny a dokážou s&nbsp;Kafkou pracovat (a to pochopitelně i
vzdáleně). Nejedná se vlastně o žádnou žhavou novinku, protože i pro databáze
(relační i postrelační) existují nástroje ovládané z&nbsp;příkazové řádky,
které tvoří alternativu k&nbsp;databázovým ovladačům využívaných
v&nbsp;aplikacích (<strong>psql</strong>, <strong>sqlite3</strong>,
<strong>redis-cli</strong> atd.). V&nbsp;případě Apache Kafky se
s&nbsp;úspěchem používá nástroj nazvaný <i>Kafkacat</i>, který může být
s&nbsp;mnoha výhodami doplněn o poněkud méně známý nástroj pojmenovaný
přímočaře <i>Kcli</i>. Se základními možnostmi poskytovanými oběma zmíněnými
nástroji se seznámíme v&nbsp;navazujících kapitolách.</p>

<img src="https://i.iinfo.cz/images/138/microservices4-2.png" class="image-362665" alt="&#160;" width="309" height="277" />
<p><i>Obrázek 2: Příklad rozdělení témat (topic) v&nbsp;clusteru.</i></p>

<p><div class="rs-tip-major">Poznámka: s&nbsp;nástrojem <i>Kafkacat</i> jsme se
již na stránkách Roota ve stručnosti seznámili &ndash; viz odkazy na příslušné
články uvedené <a href="#k19">v&nbsp;devatenácté kapitole</a>. Ovšem pro
úplnost si některé informace o <i>Kafkacatu</i> znovu popíšeme dnes, aby byly
všechny důležité a (doufejme že) užitečné informace dostupné v&nbsp;jediném
přehledovém článku.</div></p>

<a href="https://www.root.cz/obrazek/362664/"><img src="https://i.iinfo.cz/images/138/microservices4-1-prev.png" class="image-362664" alt="&#160;" width="370" height="237" /></a>
<p><i>Obrázek 3: Příklad použití ekosystému Kafky (Kafka Streams, konektory pro databáze atd.).</i></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Instalace Kafky</h2>

<p>Popišme si nyní ve stručnosti způsob lokální instalace Apache Kafky.
V&nbsp;případě, že je na počítači nainstalováno JRE (tedy běhové prostředí
Javy), je instalace Kafky pro testovací a vývojové účely triviální. Tarball
s&nbsp;instalací Kafky lze získat z&nbsp;adresy <a
href="https://www.apache.org/dyn/closer.cgi?path=/kafka/2.8.0/kafka_2.12-2.8.0.tgz">https://www.apache.org/dyn/closer.cgi?path=/kafka/2.8.0/kafka_2.12-2.8.0.tgz</a>
(verze platná v&nbsp;době vydání dnešního článku). Stažení a rozbalení tarballu
se provede následovně:</p>

<pre>
$ <strong>wget http://apache.miloslavbrada.cz/kafka/2.8.0/kafka_2.12-2.8.0.tgz</strong>
$ <strong>tar -xzf kafka_2.12-2.8.0.tgz</strong>
$ <strong>cd kafka_2.12-2.8.0</strong>
</pre>

<p>Po rozbalení stáhnutého tarballu získáme adresář, v&nbsp;němž se nachází
všechny potřebné Java archivy (JAR), konfigurační soubory (v&nbsp;podadresáři
<strong>config</strong>) a několik pomocných skriptů (v&nbsp;podadresáři
<strong>bin</strong>). Pro spuštění <i>Zookeepera</i> a brokerů je zapotřebí
mít nainstalovánu JRE (neboli již zmíněný <i>Java Runtime Environment</i>) a
samozřejmě též nějaký shell (BASH, cmd, ...).</p>

<a href="https://www.root.cz/obrazek/401919/"><img src="https://i.iinfo.cz/images/303/kafka-jconsole-1-prev.png" class="image-401919" alt="&#160;" width="324" height="270" /></a>
<p><i>Obrázek 4: Sledování činnosti brokeru přes standardní nástroj JConsole.</i></p>

<p>Prozatím nebudeme žádné další nastavení ani žádné další nástroje potřebovat,
pochopitelně s&nbsp;výjimkou dále popsaných nástrojů <i>Kafkacat</i> a
<i>Kcli</i>.</p>

<a href="https://www.root.cz/obrazek/401920/"><img src="https://i.iinfo.cz/images/303/kafka-jconsole-2-prev.png" class="image-401920" alt="&#160;" width="324" height="270" /></a>
<p><i>Obrázek 5: Sledování činnosti brokeru přes standardní nástroj JConsole.</i></p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Spuštění služby ZooKeeper a jedné instance brokera</h2>

<p>Po (doufejme že úspěšné a bezproblémové) instalaci Kafky již můžeme spustit
<i>ZooKeeper</i> a jednu instanci brokera (a to přesně v&nbsp;tomto pořadí!
&ndash; tedy nejdříve ZooKeeper a posléze broker). Konfigurace ZooKeepera je
uložena v&nbsp;souboru <strong>config/zookeeper.properties</strong> a zajímat
nás budou především tyto volby &ndash; adresář, kam ZooKeeper ukládá svoje
data, port, který použijí brokeři a omezení počtu připojení jednoho klienta
v&nbsp;daný okamžik:</p>

<pre>
dataDir=/tmp/zookeeper
clientPort=2181
maxClientCnxns=0
</pre>

<p><div class="rs-tip-major">Poznámka: hodnota <strong>maxClientCnxns</strong>
uložená v&nbsp;konfiguračním souboru v&nbsp;tomto případě neznamená, že by se
nemohly připojit žádní klienti, ale je že vypnutý mechanismus, který
zabezpečuje infrastrukturu Kafky před některými typy DOS útoků. Na disku, kde
je adresář <strong>dataDir</strong> by také mělo být dostatek místa, protože
ZooKeeper v&nbsp;některých případech mívá větší nároky. Další informace lze
nalézt na stránce <a
href="https://zookeeper.apache.org/doc/r3.5.6/">https://zookeeper.apache.org/doc/r3.5.6/</a>.</div></p>

<p>Nyní již můžeme Zookeepera spustit z&nbsp;příkazové řádky (ideálně ve
vyhrazeném terminálu):</p>

<pre>
$ <strong>bin/zookeeper-server-start.sh config/zookeeper.properties</strong>
[2020-01-20 17:00:07,823] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-20 17:00:07,825] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-20 17:00:07,827] INFO clientPortAddress is 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
...
...
[2020-01-20 17:00:07,947] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-01-20 17:00:26,978] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
</pre>

<p>Konfigurace jednoho brokera je uložená v&nbsp;souboru
<strong>config/server.properties</strong>. Samotný konfigurační soubor obsahuje
několik sekcí:</p>

<ol>
<li>Port, na kterém broker naslouchá, jeho ID, počet použitých vláken pro IO operace a počet vláken pro komunikaci.</li>
<li>Velikost bufferů, maximální povolená velikost požadavků (což omezuje velikost zprávy) atd.</li>
<li>Nastavení počtu <i>partitions</i></li>
<li>Nastavení <i>retence</i> dat</li>
<li>Připojení k&nbsp;Zookeeperovi</li>
</ol>

<pre>
broker.id=0
listeners=PLAINTEXT://:9092
num.network.threads=3
num.io.threads=8
&nbsp;
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
&nbsp;
log.dirs=/tmp/kafka-logs
num.partitions=1
num.recovery.threads.per.data.dir=1
log.retention.hours=168
log.segment.bytes=1073741824
&nbsp;
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=6000
</pre>

<p><div class="rs-tip-major">Poznámka: i velikost adresáře
<strong>log.dirs</strong> roste, a to mnohdy velmi rychle, takže se vyplatí
sledovat příslušné metriky.</div></p>

<p>Spuštění jednoho brokera z&nbsp;příkazové řádky vypadá jednoduše:</p>

<pre>
$ <strong>bin/kafka-server-start.sh config/server.properties</strong>
</pre>

<p>Alternativně je možné Zookeepera i Kafku (jednu instanci brokera) spustit
v&nbsp;Dockeru:</p>

<pre>
$ <strong>docker run -p 2181:2181 -p 9092:9092 --env ADVERTISED_HOST=`docker-machine ip \`docker-machine active\`` --env ADVERTISED_PORT=9092 spotify/kafka</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: předchozí nastavení předpokládá, že
současně na stejném stroji nepoběží žádná další instance Kafky ani Zookeepera.
Pokud budete potřebovat spustit větší množství brokerů, je nutné minimálně
změnit mapování portů (přepínače <strong>-p</strong>).</div></p>

<a href="https://www.root.cz/obrazek/361674/"><img src="https://i.iinfo.cz/images/447/microservices2-7-prev.png" class="image-361674" alt="kappa" height="270" width="279"></a>
<p><i>Obrázek 6: Schéma aplikace založené na architektuře kappa.</i></p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Uložení logů na ramdisk pro vývojový počítač</h2>

<p><div class="rs-tip-major">Poznámka: tyto informace byly uvedeny i <a
href="https://www.root.cz/clanky/vyvoj-sluzeb-postavenych-na-systemu-apache-kafka-v-jazyku-go/">v&nbsp;předchozím
článku</a>.</div></p>

<p>Jak broker Apache Kafka, tak i ZooKeeper zapisují poměrně velké množství dat
na disk. Pokud Kafku spouštíte lokálně pouze pro účely vývoje (a tedy bez
reálných dat, které je zapotřebí zachovat), může být užitečné všechny zápisy
provádět na <i>ramdisk</i> &ndash; výsledkem bude jak rychlejší start obou
procesů (cca 2&times; urychleno), tak i menší &bdquo;opotřebování&ldquo; SSD.
Konkrétně na mém vývojovém počítači mám vytvořen ramdisk o velikosti jednoho
gigabajtu, který je připojen do adresáře <strong>/tmp/ramdisk</strong>.
Konfigurace Apache Kafky i ZooKeepera je nutné nepatrně pozměnit, aby se
pracovní data ukládala do tohoto adresáře (resp.&nbsp;přesněji řečeno do
podadresářů). Konkrétní nastavení je ukázáno v&nbsp;dalším odstavci.</p>

<p>Konfigurace ZooKeepera je uložena v&nbsp;souboru
<strong>config/zookeeper.properties</strong>:</p>

<pre>
...
...
...
# the directory where the snapshot is stored.
<strong>dataDir=/tmp/ramdisk/zookeeper</strong>
# the port at which the clients will connect
clientPort=2181
# disable the per-ip limit on the number of connections since this is a non-production config
maxClientCnxns=0
# Disable the adminserver by default to avoid port conflicts.
# Set the port to something non-conflicting if choosing to enable this
admin.enableServer=false
# admin.serverPort=8080
&nbsp;
# Enable snapshot.trust.empty config if the ZK upgrade from 3.4.X to 3.5.6 is failing
# with "java.io.IOException: No snapshot found, but there are log entries" error.
# Check upgrade docs for more details.
# snapshot.trust.empty=true
...
...
...
</pre>

<p>Konfigurace brokera je uložena v&nbsp;souboru <strong></strong>:</p>

<pre>
...
...
...
############################# Log Basics #############################
&nbsp;
# A comma separated list of directories under which to store log files
<strong>log.dirs=/tmp/ramdisk/kafka-logs</strong>
&nbsp;
# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
num.partitions=1
&nbsp;
# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
num.recovery.threads.per.data.dir=1
&nbsp;
############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
...
...
...
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Konfigurace většího množství brokerů</h2>

<p>Spuštění většího množství brokerů je možné a v&nbsp;praxi i velmi časté.
Postačuje pouze zkopírovat soubor <strong>config/server.properties</strong> do
několika podobných souborů nazvaných například
<strong>config/server0.properties</strong>,
<strong>config/server1.properties</strong> atd. Dále je nutné provést
následující úpravy v&nbsp;každém z&nbsp;těchto konfiguračních souborů:</p>

<ol>

<li><strong>broker.id</strong> musí být unikátní hodnota (každý broker je nutné
jednoznačně identifikovat), takže postačuje ID postupně zvyšovat: 0, 1, 2,
atd.</li>

<li><strong>listeners</strong> musí obsahovat unikátní číslo portu, takže
například 9092, 9192, 9292 atd. (ale můžete použít jakýkoli volný port větší
než 1024 &ndash; porty s&nbsp;menším číslem jsou vyhrazeny pro roota).</li>

<li><strong>log.dirs</strong> by taktéž mělo ukazovat na unikátní adresář
<i>nesdílený</i> s&nbsp;ostatními instancemi brokera. Pokud půjde o sdílený
adresář, mohou sice brokeři zdánlivě pracovat, ovšem nikoli bezproblémově.</li>

</ol>

<p>Po splnění těchto podmínek je možné brokery běžným způsobem spustit &ndash;
každý broker jako samostatný proces:</p>

<pre>
$ <strong>nohup bin/kafka-server-start.sh config/server1.properties &amp;</strong>
$ <strong>nohup bin/kafka-server-start.sh config/server2.properties &amp;</strong>
$ <strong>nohup bin/kafka-server-start.sh config/server3.properties &amp;</strong>
...
...
...
</pre>

<a href="https://www.root.cz/obrazek/401920/"><img src="https://i.iinfo.cz/images/303/kafka-jconsole-2-prev.png" class="image-401920" alt="&#160;" width="324" height="270" /></a>
<p><i>Obrázek 7: Sledování činnosti brokeru přes standardní nástroj JConsole.</i></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Nástroj <strong>kafkacat</strong></h2>

<p>Součástí stále se rozšiřujícího a vylepšujícího se ekosystému vytvořeného
okolo Apache Kafky je i užitečný nástroj nazvaný <strong>kafkacat</strong>
(autoři ho taktéž označují jako &bdquo;netcat for Kafka&ldquo;, v&nbsp;kontextu
REST API by se hodilo i &bdquo;curl for Kafka&ldquo;). Tento nástroj, který
naleznete na adrese <a
href="https://github.com/edenhill/kafkacat">https://github.com/edenhill/kafkacat</a>
slouží pro komunikaci s&nbsp;lokálními i vzdáleně běžícími brokery přímo
z&nbsp;příkazové řádky. Pochopitelně se s&nbsp;velkou pravděpodobností nebude
jednat o řešení používané v&nbsp;produkčním kódu, ovšem možnost vytvořit
producenta zpráv či jejich konzumenta přímo z&nbsp;příkazového řádku je
použitelná jak při vývoji, tak i při řešení problémů, které mohou při běhu
aplikace nastat. Tento nástroj budeme používat později, při ukázkách nasazení
Apache Kafky, takže se v&nbsp;této kapitole krátce zmiňme o příkladech použití
převzatých z&nbsp;oficiální dokumentace. Všechny ukázky předpokládají, že
broker běží na lokálním počítači (<i>localhost</i>) na portu 9092.</p>

<p><div class="rs-tip-major">Poznámka: jedná se o nativní aplikaci, což je
velmi dobré řešení, protože se <strong>kafkacat</strong> spouští poměrně často.
To je v&nbsp;ostrém kontrastu se samotnou Kafkou, která sice startuje (jako
každá aplikace pod JVM) pomaleji, ovšem doba provozu se počítá spíše
v&nbsp;měsících a nikoli v&nbsp;sekundách tak, jak je tomu u nástrojů
spouštěných z&nbsp;interaktivní příkazové řádky.</div></p>

<p>Výpis informací o všech dostupných tématech (<i>topic</i>) a jejich
konfigurace:</p>

<pre>
$ <strong>kafkacat -L -b localhost:9092</strong>
</pre>

<p>Spuštění nového producenta zpráv čtených ze souborů specifikovaných na
příkazové řádce:</p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t filedrop -p 0 file1.bin file2.txt /etc/motd dalsi_soubor.tgz</strong>
</pre>

<p>Producent zpráv zapisovaných na standardní vstup uživatelem (co zpráva, to
jeden řádek):</p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t "upload"</strong>
</pre>

<p>Dtto, ale u každé zprávy lze specifikovat i klíč oddělený od těla zprávy
dvojtečkou:</p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t "upload" -K:</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: v&nbsp;tomto případě musí být každá
zpráva zapsána na jeden řádek ve formátu &bdquo;klíč:hodnota&ldquo;. Zadávání
se ukončuje klasicky stiskem klávesové zkratky
<strong>Ctrl+D</strong>.</div></p>

<p>Konzument zpráv posílaných do tématu &bdquo;upload&ldquo;:</p>

<pre>
$ <strong>kafkacat -C -b localhost:9092 -t "upload"</strong>
</pre>

<p>Přečtení posledních 1000 zpráv z&nbsp;tématu s&nbsp;názvem
&bdquo;téma1&ldquo;. Po této operaci se konzument automaticky ukončí,
tj.&nbsp;nebude čekat na další zprávy:</p>

<pre>
$ <strong>kafkacat -C -b localhost:9092 -t téma1 -p 0 -o -1000 -e</strong>
</pre>

<p>Spuštění konzumentů, kteří jsou přihlášení k&nbsp;tématu
&bdquo;téma1&ldquo;:</p>

<pre>
$ <strong>kafkacat -b localhost:9092 -G skupina_konzumentů téma1</strong>
</pre>

<p>Přihlásit se lze i k&nbsp;odběru většího množství témat:</p>

<pre>
$ <strong>kafkacat -b localhost:9092 -G skupina_konzumentů téma1 téma2</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: možnosti nástroje
<strong>kafkacat</strong> jsou pochopitelně mnohem větší; některé z&nbsp;nich
si ještě popíšeme v&nbsp;dalším textu.</div></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Instalace nástroje <strong>kafkacat</strong></h2>

<p>Nástroj <strong>kafkacat</strong> se skládá z&nbsp;několika komponent, které
jsou většinou naprogramovány v&nbsp;jazyku C popř.&nbsp;v&nbsp;C++. Překlad a
slinkování lze provést takovým způsobem, že výsledkem bude jediný spustitelný
soubor nazvaný též &bdquo;kafkacat&ldquo;, který bude obsahovat i všechny
potřebné (tedy staticky slinkované) knihovny, což zjednodušuje nasazení této
utility. Na druhou stranu však nebude možné použít běžné prostředky operačního
systému při updatu knihoven, například při opravách CVE atd.</p>

<p>Napřed se provede naklonování repositáře se zdrojovými kódy Kafkacatu:</p>

<pre>
$ <strong>git clone git@github.com:edenhill/kafkacat.git</strong>
</pre>

<p>po přesunu do naklonovaného repositáře:</p>

<pre>
$ <strong>cd kafkacat</strong>
</pre>

<p>se překlad provede běžnou trojkombinací příkazů
<strong>configure</strong>+<strong>make</strong>+<strong>make
install</strong>:</p>

<pre>
$ <strong>./configure</strong>
$ <strong>make</strong>
$ <strong>sudo make install</strong>
</pre>

<p>Alternativně je ovšem možné použít připravený skript
<strong>bootstrap.sh</strong>, který zajistí stažení všech potřebných knihoven
(crypto atd.) s&nbsp;jejich překladem:</p>

<pre>
$ <strong>./bootstrap.sh</strong>
</pre>

<p>Výsledkem je potom skutečně &bdquo;tlustý&ldquo; binární soubor o velikosti
přibližně dvaceti megabajtů:</p>

<pre>
$ <strong>ls -l ~/bin/kafkacat</strong>
-rwxrwxr-x. 1 ptisnovs ptisnovs <strong>20987784</strong> 17. led 14.34 /home/ptisnovs/bin/kafkacat
</pre>

<p>Některé linuxové distribuce obsahují přímo ve svých repositářích balíček
<strong>kafkacat</strong>, což samozřejmě celý proces instalace (a případných
updatů) značně zjednodušuje. Například na systémech založených na Debianu
postačuje použít:</p>

<pre>
$ <strong>apt-get install kafkacat</strong>
</pre>

<pre>
$ <strong>kafkacat </strong>
Error: -b &lt;broker,..&gt; missing
&nbsp;
Usage: kafkacat &lt;options&gt; [file1 file2 .. | topic1 topic2 ..]]
kafkacat - Apache Kafka producer and consumer tool
https://github.com/edenhill/kafkacat
Copyright (c) 2014-2019, Magnus Edenhill
Version 1.5.0-4-ge461fb (JSON, Avro, librdkafka 1.1.0 builtin.features=gzip,snappy,ssl,sasl,regex,lz4,sasl_plain,sasl_scram,plugins,zstd,sasl_oauthbearer)
...
...
...
</pre>

<p>K&nbsp;dispozici je pochopitelně i vestavěná nápověda:</p>

<pre>
Usage: kafkacat &lt;options&gt; [file1 file2 .. | topic1 topic2 ..]]
kafkacat - Apache Kafka producer and consumer tool
https://github.com/edenhill/kafkacat
Copyright (c) 2014-2019, Magnus Edenhill
Version 1.5.0-4-ge461fb (JSON, Avro, librdkafka 1.1.0 builtin.features=gzip,snappy,ssl,sasl,regex,lz4,sasl_plain,sasl_scram,plugins,zstd,sasl_oauthbearer)
&nbsp;
&nbsp;
General options:
  -C | -P | -L | -Q  Mode: Consume, Produce, Metadata List, Query mode
  -G &lt;group-id&gt;      Mode: High-level KafkaConsumer (Kafka &gt;=0.9 balanced consumer groups)
                     Expects a list of topics to subscribe to
  -t &lt;topic&gt;         Topic to consume from, produce to, or list
  -p &lt;partition&gt;     Partition
  -b &lt;brokers,..&gt;    Bootstrap broker(s) (host[:port])
  -D &lt;delim&gt;         Message delimiter character:
                     a-z.. | \r | \n | \t | \xNN
                     Default: \n
  -E                 Do not exit on non fatal error
  -K &lt;delim&gt;         Key delimiter (same format as -D)
  -c &lt;cnt&gt;           Limit message count
  -F &lt;config-file&gt;   Read configuration properties from file,
  ...
  ...
  ...
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. Nástroj <strong>kcli</strong></h2>

<p>Ve druhé části článku se zaměříme na popis nástroje nazvaného <i>Kcli</i>.
Tento nástroj slouží k&nbsp;interaktivnímu prohlížení zpráv uložených
v&nbsp;jednotlivých tématech (<i>topic</i>) Kafky. <i>Kcli</i> se tedy snaží o
to, aby data byla přístupná nikoli pouze ve formě proudu (<i>streamu</i>) údajů
(to již zajišťuje <i>Kafkacat</i>), ale v&nbsp;ucelené formě, podobně, jako je
tomu v&nbsp;databázích. Navíc je podporováno i vyhledávání zpráv podle zadaných
vzorů. Sice se v&nbsp;žádném případě nejedná o ten nejrychlejší možný způsob
práce s&nbsp;Kafkou, ovšem na druhé straně je tento přístup v&nbsp;mnoha
případech velmi užitečný &ndash; a do jisté míry zahlazuje <i>dualitu</i>
pohledu na to, co vlastně data reprezentují: buď se jedná o uložení konkrétního
stavu modelovaného světa, nebo naopak o sérii změn stavu tohoto světa &ndash;
oba přístupy jsou přitom relevantní a mají své výhody, ale i zápory. Toto téma
je rozpracováno například <a
href="https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854">zde</a>
v&nbsp;souvislosti s&nbsp;technologiemi <i>Kafka Streams</i> a
<i>KTable</i>.</p>

*** image ***
<p><i>Obrázek 8: Nápověda ke klávesovým zkratkám nástroje
<strong>kcli</strong>.</i></p>



<p><a name="k09"></a></p>
<h2 id="k09">9. Instalace nástroje <strong>kcli</strong></h2>

<p>Nástroj <i>Kcli</i> je kompletně naprogramován <a
href="https://www.root.cz/serialy/programovaci-jazyk-go/">v&nbsp;jazyku Go</a>,
takže jeho instalace je velmi jednoduchá &ndash; v&nbsp;Go se totiž snadno
tvoří staticky slinkované spustitelné binární soubory. Ty jsou pro všechny
kombinace nejpoužívanější operační systém + nejpoužívanější architektura
dostupné na adrese <a
href="https://github.com/cswank/kcli/releases">https://github.com/cswank/kcli/releases</a>,
odkud lze stáhnout tarball, rozbalit ho a ihned začít používat.</p>

<p>Alternativně je možné získat a přeložit poslední vývojářskou verzi nástroje
<i>Kcli</i>. Pro tuto operaci je nutné mít nainstalován jazyk Go, a to
minimálně ve verzi 1.11 (vyzkoušeno s&nbsp;Go 1.13, starší verze již nemám
k&nbsp;dispozici). Stažení zdrojových kódů, jejich překlad a instalace
výsledného spustitelného souboru se provede příkazem:</p>

<pre>
$ <strong>go get -u github.com/cswank/kcli</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: v&nbsp;tomto případě je výsledný
spustitelný binární soubor uložen v&nbsp;adresáři, na který ukazuje
<strong>$GOPATH/bin</strong>. Pokud je například proměnná prostředí
<strong>GOPATH</strong> nastavena na <strong>/home/UŽIVATEL/go</strong>, bude
výsledný spustitelný soubor nazvaný <strong>kcli</strong> uložen
v&nbsp;adresáři <strong>/home/UŽIVATEL/go/bin</strong>. Buď si tedy nastavte
proměnnou prostředí <strong>PATH</strong> tak, aby ukazovala i do tohoto
adresáře, nebo <strong>kcli</strong> zkopírujte (popř.&nbsp;vytvořte symbolický
odkaz) do libovolného adresáře zmíněného právě
v&nbsp;<strong>$PATH</strong>.</div></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Připojení <strong>kcli</strong> k&nbsp;brokeru</h2>

<p></p>

<pre>
$ <strong>kcli --help</strong>
&nbsp;
usage: kcli [&lt;flags&gt;]
&nbsp;
Flags:
      --help             Show context-sensitive help (also try --help-long and
                         --help-man).
  -a, --addresses=localhost:9092 ...  
                         comma separated list of kafka addresses
  -l, --log=LOG          for debugging, set the log output to a file
  -t, --topic=TOPIC      go directly to a topic
  -p, --partition=-1     go directly to a partition of a topic
  -o, --offset=-1        go directly to a message
  -d, --decoder=DECODER  path to a plugin to decode kafka messages
</pre>

<p><div class="rs-tip-major">Poznámka: v&nbsp;případě, že logy Apache Kafky
neobsahují žádné téma, je nástroj <strong>kcli</strong> ihned po svém spuštění
ukončen, takže zdánlivě nepracuje korektně. Tento &bdquo;problém&ldquo;
opravíme v&nbsp;následující kapitole.</div></p>



<p><a name="k11"></a></p>
<h2 id="k11">11. Příprava dat &ndash; zpráv poslaných do témat</h2>

<p></p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t topic1</strong>
foo
bar
baz
</pre>

<p></p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t topic2</strong>
first
second
third
</pre>

<p></p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t topic3</strong>
jedna
dva
tri
</pre>

<p>Pro zajímavost se nyní podívejme, jak vypadá struktura souborů a podadresářů vytvořených brokerem. V&nbsp;rámci úvodní kapitoly jsme nastavili cestu k&nbsp;logům na adresář <strong>/tmp/kafka-logs</strong>, který nyní můžeme prozkoumat:</p>

<pre>
$ <strong>tree /tmp/kafka-logs</strong>
&nbsp;
kafka-logs
├── cleaner-offset-checkpoint
├── log-start-offset-checkpoint
├── meta.properties
├── recovery-point-offset-checkpoint
├── replication-offset-checkpoint
├── topic1-0
│   ├── 00000000000000000000.index
│   ├── 00000000000000000000.log
│   ├── 00000000000000000000.timeindex
│   ├── 00000000000000000003.snapshot
│   └── leader-epoch-checkpoint
├── topic2-0
│   ├── 00000000000000000000.index
│   ├── 00000000000000000000.log
│   ├── 00000000000000000000.timeindex
│   ├── 00000000000000000003.snapshot
│   └── leader-epoch-checkpoint
└── topic3-0
    ├── 00000000000000000000.index
    ├── 00000000000000000000.log
    ├── 00000000000000000000.timeindex
    ├── 00000000000000000003.snapshot
    └── leader-epoch-checkpoint
&nbsp;
3 directories, 20 files
</pre>

<p><div class="rs-tip-major">Poznámka: </div></p>

<p></p>

<pre>
$ <strong>tree zookeeper/</strong>
&nbsp;
zookeeper/
└── version-2
    ├── log.1
    ├── log.1e
    ├── snapshot.0
    └── snapshot.1d
&nbsp;
1 directory, 4 files
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Prohlížení témat nástrojem <strong>kcli</strong></h2>

<p></p>

<pre>
$ <strong>kcli -a localhost:9092</strong>
</pre>

*** image ***
<p><i>Obrázek 9: </i></p>

*** image ***
<p><i>Obrázek 10: </i></p>



<p><a name="k13"></a></p>
<h2 id="k13">13. Zápis a prohlížení strukturovaných dat</h2>

<p></p>

<pre>
<i># Update the port accordingly (this one is for Kafka running inside Docker)</i>
KAFKA_PORT=9092
&nbsp;
<i># Produce messages from current directory</i>
<i># All JSON files in current directory will be sent to Kafka via Kafkacat</i>
for file in *.json
do
    echo $file
    kafkacat -b localhost:${KAFKA_PORT} -P -t results $file
    <i># It is possible to change the sleep value (or remove it completely)</i>
    sleep 1
done
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Vytvoření tématu s&nbsp;více oddíly</h2>

<p></p>

<p>Téma zpracovávané Kafkou může na clusteru vypadat například následovně:</p>

<pre>
          +---+---+---+---+---+---+
oddíl #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
          +---+---+---+---+---+---+
oddíl #1  | 0 | 1 | 2 | ...
          +---+---+---+
oddíl #2  | ...
          +---+---+---+---+---+---+---+---+---+
oddíl #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
          +---+---+---+---+---+---+---+---+---+
</pre>

<pre>
$ <strong>./kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 3 --topic partitioned</strong>
&nbsp;
Created topic partitioned.
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. Zápis dat se specifikací oddílů</h2>

<p></p>

<pre>
<i># Update the port accordingly (this one is for Kafka running inside Docker)</i>
KAFKA_PORT=9092
&nbsp;
<i># Produce messages from current directory</i>
<i># All JSON files in current directory will be sent to Kafka via Kafkacat</i>
for file in *.json
do
    echo $file
    kafkacat -b localhost:${KAFKA_PORT} -P -t partitioned -p 0 $file
    kafkacat -b localhost:${KAFKA_PORT} -P -t partitioned -p 1 $file
    kafkacat -b localhost:${KAFKA_PORT} -P -t partitioned -p 2 $file
    <i># It is possible to change the sleep value (or remove it completely)</i>
    sleep 1
done
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. Výběr oddílu v&nbsp;nástroji <strong>kcli</strong></h2>

<p></p>



<p><a name="k17"></a></p>
<h2 id="k17">17. Vyhledávání zpráv, přesun na zvolený offset a další možnosti nástroje <strong>kcli</strong></h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. Repositář s&nbsp;použitými datovými soubory i skripty</h2>

<p>Datové soubory i podpůrné skripty použité v&nbsp;dnešním článku byly uloženy
do Git repositáře, který je dostupný na adrese <a
href="https://github.com/tisnik/presentations/">https://github.com/tisnik/presentations/</a>.
V&nbsp;případě, že nebudete chtít klonovat celý repositář, můžete namísto toho
použít odkazy na jednotlivé soubory, které naleznete v&nbsp;následující
tabulce:</p>

<table>
<tr><th> #</th><th>Příklad/soubor</th><th>Stručný popis</th><th>Cesta</th></tr>
<tr><td> 1</td><td>produce.sh</td><td>produkce (poslání) obsahu datových souborů do tématu s&nbsp;jedním oddílem</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/produce.sh">https://github.com/tisnik/presentations/blob/master/kcli/produce.sh</a></td></tr>
<tr><td> 2</td><td>produce2.sh</td><td>produkce (poslání) obsahu datových souborů do tématu s&nbsp;větším množstvím oddílů</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/produce2.sh">https://github.com/tisnik/presentations/blob/master/kcli/produce2.sh</a></td></tr>
<td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></td>
<tr><td> 3</td><td>05_rules_hits.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/05_rules_hits.json">https://github.com/tisnik/presentations/blob/master/kcli/05_rules_hits.json</a></td></tr>
<tr><td> 4</td><td>05_rules_hits_org_1.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/05_rules_hits_org_1.json">https://github.com/tisnik/presentations/blob/master/kcli/05_rules_hits_org_1.json</a></td></tr>
<tr><td> 5</td><td>10_rules_hits.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/10_rules_hits.json">https://github.com/tisnik/presentations/blob/master/kcli/10_rules_hits.json</a></td></tr>
<tr><td> 6</td><td>10_rules_hits_org_1.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/10_rules_hits_org_1.json">https://github.com/tisnik/presentations/blob/master/kcli/10_rules_hits_org_1.json</a></td></tr>
<tr><td> 7</td><td>15_rules_hits.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/15_rules_hits.json">https://github.com/tisnik/presentations/blob/master/kcli/15_rules_hits.json</a></td></tr>
<tr><td> 8</td><td>15_rules_hits_org_1.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/15_rules_hits_org_1.json">https://github.com/tisnik/presentations/blob/master/kcli/15_rules_hits_org_1.json</a></td></tr>
<tr><td> 9</td><td>big_results.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/big_results.json">https://github.com/tisnik/presentations/blob/master/kcli/big_results.json</a></td></tr>
<tr><td>10</td><td>big_results_no_skips.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/big_results_no_skips.json">https://github.com/tisnik/presentations/blob/master/kcli/big_results_no_skips.json</a></td></tr>
<tr><td>11</td><td>big_results_no_skips_tutorial.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/big_results_no_skips_tutorial.json">https://github.com/tisnik/presentations/blob/master/kcli/big_results_no_skips_tutorial.json</a></td></tr>
<tr><td>12</td><td>big_results_org_1.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/big_results_org_1.json">https://github.com/tisnik/presentations/blob/master/kcli/big_results_org_1.json</a></td></tr>
<tr><td>13</td><td>big_results_tutorial.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/big_results_tutorial.json">https://github.com/tisnik/presentations/blob/master/kcli/big_results_tutorial.json</a></td></tr>
<tr><td>14</td><td>no_hits.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/no_hits.json">https://github.com/tisnik/presentations/blob/master/kcli/no_hits.json</a></td></tr>
<tr><td>15</td><td>no_hits_no_skips.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/no_hits_no_skips.json">https://github.com/tisnik/presentations/blob/master/kcli/no_hits_no_skips.json</a></td></tr>
<tr><td>16</td><td>result01.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/result01.json">https://github.com/tisnik/presentations/blob/master/kcli/result01.json</a></td></tr>
<tr><td>17</td><td>result02.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/result02.json">https://github.com/tisnik/presentations/blob/master/kcli/result02.json</a></td></tr>
<tr><td>18</td><td>result03.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/result03.json">https://github.com/tisnik/presentations/blob/master/kcli/result03.json</a></td></tr>
<tr><td>19</td><td>result04.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/result04.json">https://github.com/tisnik/presentations/blob/master/kcli/result04.json</a></td></tr>
<tr><td>20</td><td>result05.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/result05.json">https://github.com/tisnik/presentations/blob/master/kcli/result05.json</a></td></tr>
<tr><td>21</td><td>tutorial_only.json</td><td>datový soubor ve formátu JSON, který je poslán do vybraného tématu</td><td><a href="https://github.com/tisnik/presentations/blob/master/kcli/tutorial_only.json">https://github.com/tisnik/presentations/blob/master/kcli/tutorial_only.json</a></td></tr>
</table>



<p><a name="k19"></a></p>
<h2 id="k19">19. Odkazy na relevantní články na Rootu</h2>

<ol>

<li>Použití nástroje Apache Kafka v&nbsp;aplikacích založených na mikroslužbách<br />
<a href="https://www.root.cz/clanky/pouziti-nastroje-apache-kafka-v-aplikacich-zalozenych-na-mikrosluzbach/">https://www.root.cz/clanky/pouziti-nastroje-apache-kafka-v-aplikacich-zalozenych-na-mikrosluzbach/</a>
</li>

<li>Apache Kafka: distribuovaná streamovací platforma<br />
<a href="https://www.root.cz/clanky/apache-kafka-distribuovana-streamovaci-platforma/">https://www.root.cz/clanky/apache-kafka-distribuovana-streamovaci-platforma/</a>
</li>

<li>Pokročilý streaming založený na Apache Kafce, jazyku Clojure a knihovně Jackdaw<br />
<a href="https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-apache-kafce-jazyku-clojure-a-knihovne-jackdaw/">https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-apache-kafce-jazyku-clojure-a-knihovne-jackdaw/</a>
</li>

<li>Pokročilý streaming založený na Apache Kafce, jazyku Clojure a knihovně Jackdaw (2. část)<br />
<a href="https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-apache-kafce-jazyku-clojure-a-knihovne-jackdaw-2-cast/">https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-apache-kafce-jazyku-clojure-a-knihovne-jackdaw-2-cast/</a>
</li>

<li>Pokročilý streaming založený na projektu Apache Kafka, jazyku Clojure a knihovně Jackdaw (streamy a kolony)<br />
<a href="https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-projektu-apache-kafka-jazyku-clojure-a-knihovne-jackdaw-streamy-a-kolony/">https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-projektu-apache-kafka-jazyku-clojure-a-knihovne-jackdaw-streamy-a-kolony/</a>
</li>

<li>Vývoj služeb postavených na systému Apache Kafka v&nbsp;jazyku Go<br />
<a href="https://www.root.cz/clanky/vyvoj-sluzeb-postavenych-na-systemu-apache-kafka-v-jazyku-go/">https://www.root.cz/clanky/vyvoj-sluzeb-postavenych-na-systemu-apache-kafka-v-jazyku-go/</a>
</li>

</ol>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Kcli: is a kafka read only command line browser.<br />
<a href="https://github.com/cswank/kcli">https://github.com/cswank/kcli</a>
</li>

<li>Kcli: a kafka command line browser<br />
<a href="https://go.libhunt.com/kcli-alternatives">https://go.libhunt.com/kcli-alternatives</a>
</li>

<li>Awesome Go<br />
<a href="https://github.com/avelino/awesome-go">https://github.com/avelino/awesome-go</a>
</li>

<li>Real-Time Payments with Clojure and Apache Kafka (podcast)<br />
<a href="https://www.evidentsystems.com/news/confluent-podcast-about-apache-kafka/">https://www.evidentsystems.com/news/confluent-podcast-about-apache-kafka/</a>
</li>

<li>Microservices: The Rise Of Kafka<br />
<a href="https://movio.co/blog/microservices-rise-kafka/">https://movio.co/blog/microservices-rise-kafka/</a>
</li>

<li>Building a Microservices Ecosystem with Kafka Streams and KSQL<br />
<a href="https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/">https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/</a>
</li>

<li>An introduction to Apache Kafka and microservices communication<br />
<a href="https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63">https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63</a>
</li>

<li>kappa-architecture.com<br />
<a href="http://milinda.pathirage.org/kappa-architecture.com/">http://milinda.pathirage.org/kappa-architecture.com/</a>
</li>

<li>Questioning the Lambda Architecture<br />
<a href="https://www.oreilly.com/ideas/questioning-the-lambda-architecture">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a>
</li>

<li>Lambda architecture<br />
<a href="https://en.wikipedia.org/wiki/Lambda_architecture">https://en.wikipedia.org/wiki/Lambda_architecture</a>
</li>

<li>Kafka &ndash; ecosystem (Wiki)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem</a>
</li>

<li>The Kafka Ecosystem - Kafka Core, Kafka Streams, Kafka Connect, Kafka REST Proxy, and the Schema Registry<br />
<a href="http://cloudurable.com/blog/kafka-ecosystem/index.html">http://cloudurable.com/blog/kafka-ecosystem/index.html</a>
</li>

<li>A Kafka Operator for Kubernetes<br />
<a href="https://github.com/krallistic/kafka-operator">https://github.com/krallistic/kafka-operator</a>
</li>

<li>Kafka Streams<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams">https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams</a>
</li>

<li>Kafka Streams<br />
<a href="http://kafka.apache.org/documentation/streams/">http://kafka.apache.org/documentation/streams/</a>
</li>

<li>Kafka Streams (FAQ)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams">https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams</a>
</li>

<li>Event stream processing<br />
<a href="https://en.wikipedia.org/wiki/Event_stream_processing">https://en.wikipedia.org/wiki/Event_stream_processing</a>
</li>

<li>Part 1: Apache Kafka for beginners - What is Apache Kafka?<br />
<a href="https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html">https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html</a>
</li>

<li>What are some alternatives to Apache Kafka?<br />
<a href="https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka">https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka</a>
</li>

<li>What is the best alternative to Kafka?<br />
<a href="https://www.slant.co/options/961/alternatives/~kafka-alternatives">https://www.slant.co/options/961/alternatives/~kafka-alternatives</a>
</li>

<li>A super quick comparison between Kafka and Message Queues<br />
<a href="https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0">https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0</a>
</li>

<li>Kafka Queuing: Kafka as a Messaging System<br />
<a href="https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system">https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system</a>
</li>

<li>Apache Kafka Logs: A Comprehensive Guide<br />
<a href="https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/">https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/</a>
</li>

<li>Microservices – Not a free lunch!<br />
<a href="http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html">http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html</a>
</li>

<li>Microservices, Monoliths, and NoOps<br />
<a href="http://blog.arungupta.me/microservices-monoliths-noops/">http://blog.arungupta.me/microservices-monoliths-noops/</a>
</li>

<li>Microservice Design Patterns<br />
<a href="http://blog.arungupta.me/microservice-design-patterns/">http://blog.arungupta.me/microservice-design-patterns/</a>
</li>

<li>REST vs Messaging for Microservices – Which One is Best?<br />
<a href="https://solace.com/blog/experience-awesomeness-event-driven-microservices/">https://solace.com/blog/experience-awesomeness-event-driven-microservices/</a>
</li>

<li>Kappa Architecture Our Experience<br />
<a href="https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf">https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf</a>
</li>

<li>Apache Kafka Streams and Tables, the stream-table duality<br />
<a href="https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854">https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2021</small></p>
</body>
</html>

