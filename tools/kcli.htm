<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title></title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1></h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. </a></p>
<p><a href="#k02">*** 2. Instalace Kafky</a></p>
<p><a href="#k03">*** 3. Spuštění služby ZooKeeper a jedné instance brokera</a></p>
<p><a href="#k04">*** 4. Uložení logů na ramdisk pro vývojový počítač</a></p>
<p><a href="#k05">*** 5. Konfigurace většího množství brokerů</a></p>
<p><a href="#k06">*** 6. Nástroj <strong>kafkacat</strong></a></p>
<p><a href="#k07">*** 7. Instalace nástroje <strong>kafkacat</strong></a></p>
<p><a href="#k08">*** 8. Nástroj <strong>kcli</strong></a></p>
<p><a href="#k09">*** 9. Instalace nástroje <strong>kcli</strong></a></p>
<p><a href="#k10">*** 10. Připojení <strong>kcli</strong> k&nbsp;brokeru</a></p>
<p><a href="#k11">*** 11. Příprava dat &ndash; zpráv poslaných do témat</a></p>
<p><a href="#k12">*** 12. Prohlížení témat nástrojem <strong>kcli</strong></a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. Odkazy na relevantní články na Rootu</a></p>
<p><a href="#k20">*** 20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. </h2>



<p><a name="k02"></a></p>
<h2 id="k02">2. Instalace Kafky</h2>

<p>Popišme si nyní ve stručnosti způsob lokální instalace Apache Kafky.
V&nbsp;případě, že je na počítači nainstalováno JRE (tedy běhové prostředí
Javy), je instalace Kafky pro testovací a vývojové účely triviální. Tarball
s&nbsp;instalací Kafky lze získat z&nbsp;adresy <a
href="https://www.apache.org/dyn/closer.cgi?path=/kafka/2.8.0/kafka_2.12-2.8.0.tgz">https://www.apache.org/dyn/closer.cgi?path=/kafka/2.8.0/kafka_2.12-2.8.0.tgz</a>
(verze platná v&nbsp;době vydání dnešního článku). Stažení a rozbalení tarballu
se provede následovně:</p>

<pre>
$ <strong>wget http://apache.miloslavbrada.cz/kafka/2.8.0/kafka_2.12-2.8.0.tgz</strong>
$ <strong>tar -xzf kafka_2.12-2.8.0.tgz</strong>
$ <strong>cd kafka_2.12-2.8.0</strong>
</pre>

<p>Po rozbalení stáhnutého tarballu získáme adresář, v&nbsp;němž se nachází
všechny potřebné Java archivy (JAR), konfigurační soubory (v&nbsp;podadresáři
<strong>config</strong>) a několik pomocných skriptů (v&nbsp;podadresáři
<strong>bin</strong>). Pro spuštění <i>Zookeepera</i> a brokerů je zapotřebí
mít nainstalovánu JRE (neboli již zmíněný <i>Java Runtime Environment</i>) a
samozřejmě též nějaký shell (BASH, cmd, ...).</p>

<p>Prozatím nebudeme žádné další nastavení ani žádné další nástroje potřebovat,
pochopitelně s&nbsp;výjimkou dále popsaných nástrojů <i>Kafkacat</i> a
<i>Kcli</i>.</p>

<a href="https://www.root.cz/obrazek/401919/"><img src="https://i.iinfo.cz/images/303/kafka-jconsole-1-prev.png" class="image-401919" alt="&#160;" width="324" height="270" /></a>
<p><i>Obrázek XX: Sledování činnosti brokeru přes standardní nástroj JConsole.</i></p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Spuštění služby ZooKeeper a jedné instance brokera</h2>

<p>Po (doufejme že úspěšné a bezproblémové) instalaci Kafky již můžeme spustit
<i>ZooKeeper</i> a jednu instanci brokera (a to přesně v&nbsp;tomto pořadí!
&ndash; tedy nejdříve ZooKeeper a posléze broker). Konfigurace ZooKeepera je
uložena v&nbsp;souboru <strong>config/zookeeper.properties</strong> a zajímat
nás budou především tyto volby &ndash; adresář, kam ZooKeeper ukládá svoje
data, port, který použijí brokeři a omezení počtu připojení jednoho klienta
v&nbsp;daný okamžik:</p>

<pre>
dataDir=/tmp/zookeeper
clientPort=2181
maxClientCnxns=0
</pre>

<p><div class="rs-tip-major">Poznámka: hodnota <strong>maxClientCnxns</strong>
uložená v&nbsp;konfiguračním souboru v&nbsp;tomto případě neznamená, že by se
nemohly připojit žádní klienti, ale je že vypnutý mechanismus, který
zabezpečuje infrastrukturu Kafky před některými typy DOS útoků. Na disku, kde
je adresář <strong>dataDir</strong> by také mělo být dostatek místa, protože
ZooKeeper v&nbsp;některých případech mívá větší nároky. Další informace lze
nalézt na stránce <a
href="https://zookeeper.apache.org/doc/r3.5.6/">https://zookeeper.apache.org/doc/r3.5.6/</a>.</div></p>

<p>Nyní již můžeme Zookeepera spustit z&nbsp;příkazové řádky (ideálně ve
vyhrazeném terminálu):</p>

<pre>
$ <strong>bin/zookeeper-server-start.sh config/zookeeper.properties</strong>
[2020-01-20 17:00:07,823] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-20 17:00:07,825] WARN config/zookeeper.properties is relative. Prepend ./ to indicate that you're sure! (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
[2020-01-20 17:00:07,827] INFO clientPortAddress is 0.0.0.0/0.0.0.0:2181 (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
...
...
[2020-01-20 17:00:07,947] INFO Using checkIntervalMs=60000 maxPerMinute=10000 (org.apache.zookeeper.server.ContainerManager)
[2020-01-20 17:00:26,978] INFO Creating new log file: log.1 (org.apache.zookeeper.server.persistence.FileTxnLog)
</pre>

<p>Konfigurace jednoho brokera je uložená v&nbsp;souboru
<strong>config/server.properties</strong>. Samotný konfigurační soubor obsahuje
několik sekcí:</p>

<ol>
<li>Port, na kterém broker naslouchá, jeho ID, počet použitých vláken pro IO operace a počet vláken pro komunikaci.</li>
<li>Velikost bufferů, maximální povolená velikost požadavků (což omezuje velikost zprávy) atd.</li>
<li>Nastavení počtu <i>partitions</i></li>
<li>Nastavení <i>retence</i> dat</li>
<li>Připojení k&nbsp;Zookeeperovi</li>
</ol>

<pre>
broker.id=0
listeners=PLAINTEXT://:9092
num.network.threads=3
num.io.threads=8
&nbsp;
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
&nbsp;
log.dirs=/tmp/kafka-logs
num.partitions=1
num.recovery.threads.per.data.dir=1
log.retention.hours=168
log.segment.bytes=1073741824
&nbsp;
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=6000
</pre>

<p><div class="rs-tip-major">Poznámka: i velikost adresáře
<strong>log.dirs</strong> roste, a to mnohdy velmi rychle, takže se vyplatí
sledovat příslušné metriky.</div></p>

<p>Spuštění jednoho brokera z&nbsp;příkazové řádky vypadá jednoduše:</p>

<pre>
$ <strong>bin/kafka-server-start.sh config/server.properties</strong>
</pre>

<p>Alternativně je možné Zookeepera i Kafku (jednu instanci brokera) spustit
v&nbsp;Dockeru:</p>

<pre>
$ <strong>docker run -p 2181:2181 -p 9092:9092 --env ADVERTISED_HOST=`docker-machine ip \`docker-machine active\`` --env ADVERTISED_PORT=9092 spotify/kafka</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: předchozí nastavení předpokládá, že
současně na stejném stroji nepoběží žádná další instance Kafky ani Zookeepera.
Pokud budete potřebovat spustit větší množství brokerů, je nutné minimálně
změnit mapování portů (přepínače <strong>-p</strong>).</div></p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Uložení logů na ramdisk pro vývojový počítač</h2>

<p><div class="rs-tip-major">Poznámka: tyto informace byly uvedeny i <a
href="https://www.root.cz/clanky/vyvoj-sluzeb-postavenych-na-systemu-apache-kafka-v-jazyku-go/">v&nbsp;předchozím
článku</a>.</div></p>

<p>Jak broker Apache Kafka, tak i ZooKeeper zapisují poměrně velké množství dat
na disk. Pokud Kafku spouštíte lokálně pouze pro účely vývoje (a tedy bez
reálných dat, které je zapotřebí zachovat), může být užitečné všechny zápisy
provádět na <i>ramdisk</i> &ndash; výsledkem bude jak rychlejší start obou
procesů (cca 2&times; urychleno), tak i menší &bdquo;opotřebování&ldquo; SSD.
Konkrétně na mém vývojovém počítači mám vytvořen ramdisk o velikosti jednoho
gigabajtu, který je připojen do adresáře <strong>/tmp/ramdisk</strong>.
Konfigurace Apache Kafky i ZooKeepera je nutné nepatrně pozměnit, aby se
pracovní data ukládala do tohoto adresáře (resp.&nbsp;přesněji řečeno do
podadresářů). Konkrétní nastavení je ukázáno v&nbsp;dalším odstavci.</p>

<p>Konfigurace ZooKeepera je uložena v&nbsp;souboru
<strong>config/zookeeper.properties</strong>:</p>

<pre>
...
...
...
# the directory where the snapshot is stored.
<strong>dataDir=/tmp/ramdisk/zookeeper</strong>
# the port at which the clients will connect
clientPort=2181
# disable the per-ip limit on the number of connections since this is a non-production config
maxClientCnxns=0
# Disable the adminserver by default to avoid port conflicts.
# Set the port to something non-conflicting if choosing to enable this
admin.enableServer=false
# admin.serverPort=8080
&nbsp;
# Enable snapshot.trust.empty config if the ZK upgrade from 3.4.X to 3.5.6 is failing
# with "java.io.IOException: No snapshot found, but there are log entries" error.
# Check upgrade docs for more details.
# snapshot.trust.empty=true
...
...
...
</pre>

<p>Konfigurace brokera je uložena v&nbsp;souboru <strong></strong>:</p>

<pre>
...
...
...
############################# Log Basics #############################
&nbsp;
# A comma separated list of directories under which to store log files
<strong>log.dirs=/tmp/ramdisk/kafka-logs</strong>
&nbsp;
# The default number of log partitions per topic. More partitions allow greater
# parallelism for consumption, but this will also result in more files across
# the brokers.
num.partitions=1
&nbsp;
# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
# This value is recommended to be increased for installations with data dirs located in RAID array.
num.recovery.threads.per.data.dir=1
&nbsp;
############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
...
...
...
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Konfigurace většího množství brokerů</h2>

<p>Spuštění většího množství brokerů je možné a v&nbsp;praxi i velmi časté.
Postačuje pouze zkopírovat soubor <strong>config/server.properties</strong> do
několika podobných souborů nazvaných například
<strong>config/server0.properties</strong>,
<strong>config/server1.properties</strong> atd. Dále je nutné provést
následující úpravy v&nbsp;každém z&nbsp;těchto konfiguračních souborů:</p>

<ol>

<li><strong>broker.id</strong> musí být unikátní hodnota (každý broker je nutné
jednoznačně identifikovat), takže postačuje ID postupně zvyšovat: 0, 1, 2,
atd.</li>

<li><strong>listeners</strong> musí obsahovat unikátní číslo portu, takže
například 9092, 9192, 9292 atd. (ale můžete použít jakýkoli volný port větší
než 1024 &ndash; porty s&nbsp;menším číslem jsou vyhrazeny pro roota).</li>

<li><strong>log.dirs</strong> by taktéž mělo ukazovat na unikátní adresář
<i>nesdílený</i> s&nbsp;ostatními instancemi brokera. Pokud půjde o sdílený
adresář, mohou sice brokeři zdánlivě pracovat, ovšem nikoli bezproblémově.</li>

</ol>

<p>Po splnění těchto podmínek je možné brokery běžným způsobem spustit &ndash;
každý broker jako samostatný proces:</p>

<pre>
$ <strong>nohup bin/kafka-server-start.sh config/server1.properties &amp;</strong>
$ <strong>nohup bin/kafka-server-start.sh config/server2.properties &amp;</strong>
$ <strong>nohup bin/kafka-server-start.sh config/server3.properties &amp;</strong>
...
...
...
</pre>

<a href="https://www.root.cz/obrazek/401920/"><img src="https://i.iinfo.cz/images/303/kafka-jconsole-2-prev.png" class="image-401920" alt="&#160;" width="324" height="270" /></a>
<p><i>Obrázek 5: Sledování činnosti brokeru přes standardní nástroj JConsole.</i></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Nástroj <strong>kafkacat</strong></h2>

<p>Součástí stále se rozšiřujícího a vylepšujícího se ekosystému vytvořeného
okolo Apache Kafky je i užitečný nástroj nazvaný <strong>kafkacat</strong>
(autoři ho taktéž označují jako &bdquo;netcat for Kafka&ldquo;, v&nbsp;kontextu
REST API by se hodilo i &bdquo;curl for Kafka&ldquo;). Tento nástroj, který
naleznete na adrese <a
href="https://github.com/edenhill/kafkacat">https://github.com/edenhill/kafkacat</a>
slouží pro komunikaci s&nbsp;lokálními i vzdáleně běžícími brokery přímo
z&nbsp;příkazové řádky. Pochopitelně se s&nbsp;velkou pravděpodobností nebude
jednat o řešení používané v&nbsp;produkčním kódu, ovšem možnost vytvořit
producenta zpráv či jejich konzumenta přímo z&nbsp;příkazového řádku je
použitelná jak při vývoji, tak i při řešení problémů, které mohou při běhu
aplikace nastat. Tento nástroj budeme používat později, při ukázkách nasazení
Apache Kafky, takže se v&nbsp;této kapitole krátce zmiňme o příkladech použití
převzatých z&nbsp;oficiální dokumentace. Všechny ukázky předpokládají, že
broker běží na lokálním počítači (<i>localhost</i>) na portu 9092.</p>

<p><div class="rs-tip-major">Poznámka: jedná se o nativní aplikaci, což je
velmi dobré řešení, protože se <strong>kafkacat</strong> spouští poměrně často.
To je v&nbsp;ostrém kontrastu se samotnou Kafkou, která sice startuje (jako
každá aplikace pod JVM) pomaleji, ovšem doba provozu se počítá spíše
v&nbsp;měsících a nikoli v&nbsp;sekundách tak, jak je tomu u nástrojů
spouštěných z&nbsp;interaktivní příkazové řádky.</div></p>

<p>Výpis informací o všech dostupných tématech (<i>topic</i>) a jejich
konfigurace:</p>

<pre>
$ <strong>kafkacat -L -b localhost:9092</strong>
</pre>

<p>Spuštění nového producenta zpráv čtených ze souborů specifikovaných na
příkazové řádce:</p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t filedrop -p 0 file1.bin file2.txt /etc/motd dalsi_soubor.tgz</strong>
</pre>

<p>Producent zpráv zapisovaných na standardní vstup uživatelem (co zpráva, to
jeden řádek):</p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t "upload"</strong>
</pre>

<p>Dtto, ale u každé zprávy lze specifikovat i klíč oddělený od těla zprávy
dvojtečkou:</p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t "upload" -K:</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: v&nbsp;tomto případě musí být každá
zpráva zapsána na jeden řádek ve formátu &bdquo;klíč:hodnota&ldquo;. Zadávání
se ukončuje klasicky stiskem klávesové zkratky
<strong>Ctrl+D</strong>.</div></p>

<p>Konzument zpráv posílaných do tématu &bdquo;upload&ldquo;:</p>

<pre>
$ <strong>kafkacat -C -b localhost:9092 -t "upload"</strong>
</pre>

<p>Přečtení posledních 1000 zpráv z&nbsp;tématu s&nbsp;názvem
&bdquo;téma1&ldquo;. Po této operaci se konzument automaticky ukončí,
tj.&nbsp;nebude čekat na další zprávy:</p>

<pre>
$ <strong>kafkacat -C -b localhost:9092 -t téma1 -p 0 -o -1000 -e</strong>
</pre>

<p>Spuštění konzumentů, kteří jsou přihlášení k&nbsp;tématu
&bdquo;téma1&ldquo;:</p>

<pre>
$ <strong>kafkacat -b localhost:9092 -G skupina_konzumentů téma1</strong>
</pre>

<p>Přihlásit se lze i k&nbsp;odběru většího množství témat:</p>

<pre>
$ <strong>kafkacat -b localhost:9092 -G skupina_konzumentů téma1 téma2</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: možnosti nástroje
<strong>kafkacat</strong> jsou pochopitelně mnohem větší; některé z&nbsp;nich
si ještě popíšeme v&nbsp;dalším textu.</div></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Instalace nástroje <strong>kafkacat</strong></h2>

<p>Nástroj <strong>kafkacat</strong> se skládá z&nbsp;několika komponent, které
jsou většinou naprogramovány v&nbsp;jazyku C popř.&nbsp;v&nbsp;C++. Překlad a
slinkování lze provést takovým způsobem, že výsledkem bude jediný spustitelný
soubor nazvaný též &bdquo;kafkacat&ldquo;, který bude obsahovat i všechny
potřebné (tedy staticky slinkované) knihovny, což zjednodušuje nasazení této
utility. Na druhou stranu však nebude možné použít běžné prostředky operačního
systému při updatu knihoven, například při opravách CVE atd.</p>

<p>Napřed se provede naklonování repositáře se zdrojovými kódy Kafkacatu:</p>

<pre>
$ <strong>git clone git@github.com:edenhill/kafkacat.git</strong>
</pre>

<p>po přesunu do naklonovaného repositáře:</p>

<pre>
$ <strong>cd kafkacat</strong>
</pre>

<p>se překlad provede běžnou trojkombinací příkazů
<strong>configure</strong>+<strong>make</strong>+<strong>make
install</strong>:</p>

<pre>
$ <strong>./configure</strong>
$ <strong>make</strong>
$ <strong>sudo make install</strong>
</pre>

<p>Alternativně je ovšem možné použít připravený skript
<strong>bootstrap.sh</strong>, který zajistí stažení všech potřebných knihoven
(crypto atd.) s&nbsp;jejich překladem:</p>

<pre>
$ <strong>./bootstrap.sh</strong>
</pre>

<p>Výsledkem je potom skutečně &bdquo;tlustý&ldquo; binární soubor o velikosti
přibližně dvaceti megabajtů:</p>

<pre>
$ <strong>ls -l ~/bin/kafkacat</strong>
-rwxrwxr-x. 1 ptisnovs ptisnovs <strong>20987784</strong> 17. led 14.34 /home/ptisnovs/bin/kafkacat
</pre>

<p>Některé linuxové distribuce obsahují přímo ve svých repositářích balíček
<strong>kafkacat</strong>, což samozřejmě celý proces instalace (a případných
updatů) značně zjednodušuje. Například na systémech založených na Debianu
postačuje použít:</p>

<pre>
$ <strong>apt-get install kafkacat</strong>
</pre>

<pre>
$ <strong>kafkacat </strong>
Error: -b &lt;broker,..&gt; missing
&nbsp;
Usage: kafkacat &lt;options&gt; [file1 file2 .. | topic1 topic2 ..]]
kafkacat - Apache Kafka producer and consumer tool
https://github.com/edenhill/kafkacat
Copyright (c) 2014-2019, Magnus Edenhill
Version 1.5.0-4-ge461fb (JSON, Avro, librdkafka 1.1.0 builtin.features=gzip,snappy,ssl,sasl,regex,lz4,sasl_plain,sasl_scram,plugins,zstd,sasl_oauthbearer)
...
...
...
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. Nástroj <strong>kcli</strong></h2>



<p><a name="k09"></a></p>
<h2 id="k09">9. Instalace nástroje <strong>kcli</strong></h2>



<p><a name="k10"></a></p>
<h2 id="k10">10. Připojení <strong>kcli</strong> k&nbsp;brokeru</h2>

<pre>
$ <strong>kcli --help</strong>
&nbsp;
usage: kcli [&lt;flags&gt;]
&nbsp;
Flags:
      --help             Show context-sensitive help (also try --help-long and
                         --help-man).
  -a, --addresses=localhost:9092 ...  
                         comma separated list of kafka addresses
  -l, --log=LOG          for debugging, set the log output to a file
  -t, --topic=TOPIC      go directly to a topic
  -p, --partition=-1     go directly to a partition of a topic
  -o, --offset=-1        go directly to a message
  -d, --decoder=DECODER  path to a plugin to decode kafka messages
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. Příprava dat &ndash; zpráv poslaných do témat</h2>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t topic1</strong>
foo
bar
baz
&nbsp;
$ <strong>kafkacat -P -b localhost:9092 -t topic2</strong>
first
second
third
&nbsp;
$ <strong>kafkacat -P -b localhost:9092 -t topic3</strong>
jedna
dva
tri
</pre>

<p>Pro zajímavost se nyní podívejme, jak vypadá struktura souborů a podadresářů vytvořených brokerem. V&nbsp;rámci úvodní kapitoly jsme nastavili cestu k&nbsp;logům na adresář <strong>/tmp/kafka-logs</strong>, který nyní můžeme prozkoumat:</p>

<pre>
$ <strong>tree /tmp/kafka-logs</strong>
&nbsp;
kafka-logs
├── cleaner-offset-checkpoint
├── log-start-offset-checkpoint
├── meta.properties
├── recovery-point-offset-checkpoint
├── replication-offset-checkpoint
├── topic1-0
│   ├── 00000000000000000000.index
│   ├── 00000000000000000000.log
│   ├── 00000000000000000000.timeindex
│   ├── 00000000000000000003.snapshot
│   └── leader-epoch-checkpoint
├── topic2-0
│   ├── 00000000000000000000.index
│   ├── 00000000000000000000.log
│   ├── 00000000000000000000.timeindex
│   ├── 00000000000000000003.snapshot
│   └── leader-epoch-checkpoint
└── topic3-0
    ├── 00000000000000000000.index
    ├── 00000000000000000000.log
    ├── 00000000000000000000.timeindex
    ├── 00000000000000000003.snapshot
    └── leader-epoch-checkpoint
&nbsp;
3 directories, 20 files
</pre>

<p><div class="rs-tip-major">Poznámka: </div></p>

<pre>
$ <strong>tree zookeeper/</strong>
&nbsp;
zookeeper/
└── version-2
    ├── log.1
    ├── log.1e
    ├── snapshot.0
    └── snapshot.1d

1 directory, 4 files
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Prohlížení témat nástrojem <strong>kcli</strong></h2>

<pre>
$ <strong>kcli -a localhost:9092</strong>
</pre>

*** image ***
<p><i>Obrázek XX: </i></p>

*** image ***
<p><i>Obrázek XX: </i></p>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Odkazy na relevantní články na Rootu</h2>

<ol>

<li>Použití nástroje Apache Kafka v&nbsp;aplikacích založených na mikroslužbách<br />
<a href="https://www.root.cz/clanky/pouziti-nastroje-apache-kafka-v-aplikacich-zalozenych-na-mikrosluzbach/">https://www.root.cz/clanky/pouziti-nastroje-apache-kafka-v-aplikacich-zalozenych-na-mikrosluzbach/</a>
</li>

<li>Apache Kafka: distribuovaná streamovací platforma<br />
<a href="https://www.root.cz/clanky/apache-kafka-distribuovana-streamovaci-platforma/">https://www.root.cz/clanky/apache-kafka-distribuovana-streamovaci-platforma/</a>
</li>

<li>Pokročilý streaming založený na Apache Kafce, jazyku Clojure a knihovně Jackdaw<br />
<a href="https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-apache-kafce-jazyku-clojure-a-knihovne-jackdaw/">https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-apache-kafce-jazyku-clojure-a-knihovne-jackdaw/</a>
</li>

<li>Pokročilý streaming založený na Apache Kafce, jazyku Clojure a knihovně Jackdaw (2. část)<br />
<a href="https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-apache-kafce-jazyku-clojure-a-knihovne-jackdaw-2-cast/">https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-apache-kafce-jazyku-clojure-a-knihovne-jackdaw-2-cast/</a>
</li>

<li>Pokročilý streaming založený na projektu Apache Kafka, jazyku Clojure a knihovně Jackdaw (streamy a kolony)<br />
<a href="https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-projektu-apache-kafka-jazyku-clojure-a-knihovne-jackdaw-streamy-a-kolony/">https://www.root.cz/clanky/pokrocily-streaming-zalozeny-na-projektu-apache-kafka-jazyku-clojure-a-knihovne-jackdaw-streamy-a-kolony/</a>
</li>

<li>Vývoj služeb postavených na systému Apache Kafka v&nbsp;jazyku Go<br />
<a href="https://www.root.cz/clanky/vyvoj-sluzeb-postavenych-na-systemu-apache-kafka-v-jazyku-go/">https://www.root.cz/clanky/vyvoj-sluzeb-postavenych-na-systemu-apache-kafka-v-jazyku-go/</a>
</li>

</ol>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Kcli: is a kafka read only command line browser.<br />
<a href="https://github.com/cswank/kcli">https://github.com/cswank/kcli</a>
</li>

<li>Kcli: a kafka command line browser<br />
<a href="https://go.libhunt.com/kcli-alternatives">https://go.libhunt.com/kcli-alternatives</a>
</li>

<li>Awesome Go<br />
<a href="https://github.com/avelino/awesome-go">https://github.com/avelino/awesome-go</a>
</li>

<li>Real-Time Payments with Clojure and Apache Kafka (podcast)<br />
<a href="https://www.evidentsystems.com/news/confluent-podcast-about-apache-kafka/">https://www.evidentsystems.com/news/confluent-podcast-about-apache-kafka/</a>
</li>

<li>Microservices: The Rise Of Kafka<br />
<a href="https://movio.co/blog/microservices-rise-kafka/">https://movio.co/blog/microservices-rise-kafka/</a>
</li>

<li>Building a Microservices Ecosystem with Kafka Streams and KSQL<br />
<a href="https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/">https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/</a>
</li>

<li>An introduction to Apache Kafka and microservices communication<br />
<a href="https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63">https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63</a>
</li>

<li>kappa-architecture.com<br />
<a href="http://milinda.pathirage.org/kappa-architecture.com/">http://milinda.pathirage.org/kappa-architecture.com/</a>
</li>

<li>Questioning the Lambda Architecture<br />
<a href="https://www.oreilly.com/ideas/questioning-the-lambda-architecture">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a>
</li>

<li>Lambda architecture<br />
<a href="https://en.wikipedia.org/wiki/Lambda_architecture">https://en.wikipedia.org/wiki/Lambda_architecture</a>
</li>

<li>Kafka &ndash; ecosystem (Wiki)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem</a>
</li>

<li>The Kafka Ecosystem - Kafka Core, Kafka Streams, Kafka Connect, Kafka REST Proxy, and the Schema Registry<br />
<a href="http://cloudurable.com/blog/kafka-ecosystem/index.html">http://cloudurable.com/blog/kafka-ecosystem/index.html</a>
</li>

<li>A Kafka Operator for Kubernetes<br />
<a href="https://github.com/krallistic/kafka-operator">https://github.com/krallistic/kafka-operator</a>
</li>

<li>Kafka Streams<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams">https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams</a>
</li>

<li>Kafka Streams<br />
<a href="http://kafka.apache.org/documentation/streams/">http://kafka.apache.org/documentation/streams/</a>
</li>

<li>Kafka Streams (FAQ)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams">https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams</a>
</li>

<li>Event stream processing<br />
<a href="https://en.wikipedia.org/wiki/Event_stream_processing">https://en.wikipedia.org/wiki/Event_stream_processing</a>
</li>

<li>Part 1: Apache Kafka for beginners - What is Apache Kafka?<br />
<a href="https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html">https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html</a>
</li>

<li>What are some alternatives to Apache Kafka?<br />
<a href="https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka">https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka</a>
</li>

<li>What is the best alternative to Kafka?<br />
<a href="https://www.slant.co/options/961/alternatives/~kafka-alternatives">https://www.slant.co/options/961/alternatives/~kafka-alternatives</a>
</li>

<li>A super quick comparison between Kafka and Message Queues<br />
<a href="https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0">https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0</a>
</li>

<li>Kafka Queuing: Kafka as a Messaging System<br />
<a href="https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system">https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system</a>
</li>

<li>Apache Kafka Logs: A Comprehensive Guide<br />
<a href="https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/">https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2021</small></p>
</body>
</html>

