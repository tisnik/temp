<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Témata, oddíly a replikace v systému Apache Kafka</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Témata, oddíly a replikace v systému Apache Kafka</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>Systému Apache Kafka jsme se již na stránkách Roota věnovali v několika článcích. Prozatím jsme si ovšem neukázali, jak se Kafka chová v případě, že se používají témata s replikovanými oddíly uloženými ve více brokerech, ve chvíli, kdy se například některý z brokerů stane nedostupným (pád, problém v síťové infrastruktuře atd.)</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Témata, oddíly a replikace v&nbsp;systému Apache Kafka</a></p>
<p><a href="#k02">2. Základní koncepty, na nichž je Apache Kafka postavena</a></p>
<p><a href="#k03">3. Nejjednodušší konfigurace tématu: jediný broker, jeden oddíl, bez replikace</a></p>
<p><a href="#k04">4. Téma rozdělené na větší počet oddílů</a></p>
<p><a href="#k05">5. Téma s&nbsp;jedním replikovaným oddílem</a></p>
<p><a href="#k06">6. Téma s&nbsp;větším množstvím replikovaných oddílů</a></p>
<p><a href="#k07">7. Praktická část</a></p>
<p><a href="#k08">8. Instalace Apache Kafky</a></p>
<p><a href="#k09">9. Konfigurace a spuštění Zookeepera, test zda Zookeeper přijímá příkazy</a></p>
<p><a href="#k10">10. Konfigurace a spuštění brokera</a></p>
<p><a href="#k11">11. Komunikace přes téma s&nbsp;jediným oddílem a bez replikace</a></p>
<p><a href="#k12">12. Větší množství konzumentů z&nbsp;jedné skupiny vs.z&nbsp;více skupin</a></p>
<p><a href="#k13">13. Komunikace přes téma s&nbsp;větším množstvím oddílů</a></p>
<p><a href="#k14">14. Souběžná konzumace zpráv konzumenty z&nbsp;jedné skupiny</a></p>
<p><a href="#k15">*** 15. Spuštění většího množství brokerů</a></p>
<p><a href="#k16">*** 16. Vytvoření a použití tématu s&nbsp;jedním replikovaným oddílem</a></p>
<p><a href="#k17">*** 17. Chování při nedostupnosti brokeru (brokerů)</a></p>
<p><a href="#k18">*** 18. Vytvoření a použití tématu s&nbsp;několika replikovanými oddíly</a></p>
<p><a href="#k19">19. Repositář s&nbsp;pomocnými skripty a konfiguračními soubory</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Témata, oddíly a replikace v&nbsp;systému Apache Kafka</h2>

<p>Systém Apache Kafka je v&nbsp;současnosti velmi rozšířen a používá se
v&nbsp;mnoha oblastech IT. Někdy se setkáme s&nbsp;tím, že je Apache Kafka
nasazena a využívána jako pouhý &bdquo;vylepšený&ldquo; message broker,
tj.&nbsp;jako centrální část celé architektury sloužící pro komunikaci mezi
jednotlivými (mikro)službami a nástroji. Ovšem možnosti Apache Kafky jsou ve
skutečnosti poněkud větší, a to díky poměrně unikátnímu způsobu práce
s&nbsp;tzv.&nbsp;tématy (<i>topic</i>). Navíc Apache Kafka dokáže zajistit
svoji velkou dostupnost a odolnost vůči pádům jednotlivých komponent či síťové
infrastruktury (<i>resilience</i>). Tomuto tématu, s&nbsp;nímž do značné míry
souvisí tzv.&nbsp;replikace oddílů a systém <i>leader-follower(s)</i>, se
budeme věnovat v&nbsp;dnešním článku.</p>

<img src="https://i.iinfo.cz/images/447/microservices2-3.png" class="image-361670" alt="&#160;" width="450" height="134" />
<p><i>Obrázek 1: Logo nástroje Apache Kafka, kterému se budeme dnes
věnovat.</i></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Základní koncepty, na nichž je Apache Kafka postavena</h2>

<p>V&nbsp;této kapitole si ve stručnosti vysvětlíme základní koncepty, na nichž
je Apache Kafka postavena. Systém Apache Kafka umožňuje ukládání zpráv (zde se
ovšem poměrně často taktéž používá termín záznam &ndash; <i>record</i>) do
různých témat (<i>topic</i>), přičemž každé téma je obecně rozděleno do oddílů
neboli <i>partition</i>. Samozřejmě je možné pro téma vyhradit pouze jediný
oddíl (což je ostatně výchozí nastavení, které se asi nejvíce podobá klasickým
<i>message brokerům</i>) a tvářit se, že máme k&nbsp;dispozici
&bdquo;vylepšenou&ldquo; frontu &ndash; ostatně přesně takto lze s&nbsp;Kafkou
začít a pro mnohé účely může být tato konfigurace dostatečná. Rozdělení tématu
do většího množství oddílů se provádí z&nbsp;několika důvodů. Jedním
z&nbsp;nich je snaha o rozdělení zátěže (<i>load balancing</i>), protože
jednotlivé oddíly mohou být provozovány na různých počítačích v&nbsp;mnohdy i
velmi rozsáhlém clusteru (většinou se jedná o zátěž disků, nikoli CPU).</p>

<a href="https://www.root.cz/obrazek/361674/"><img src="https://i.iinfo.cz/images/447/microservices2-7-prev.png" class="image-361674" alt="kappa" height="270" width="279"></a>
<p><i>Obrázek 2: Kafka nemusí být nasazena jako &bdquo;pouhý&ldquo; message
broker, ale může sloužit i jako primární zdroj dat pro další mikroslužby. To je
základ pro architekturu Kappa.</i></p>

<p>Dále se dělení provádí z&nbsp;toho důvodu, že každý oddíl obsahuje sekvenci
neměnných (<i>immutable</i>) zpráv, přičemž nové zprávy se pouze připojují na
konec oddílu (<i>append-only log</i>). Zprávy z&nbsp;oddílů je možné číst
(konzumovat) nezávisle na ostatních oddílech a zajistit tak potřebný <i>load
balancing</i> (jak uvidíme dále, je tato možnost realizována přes skupiny
konzumentů &ndash; <i>consumer groups</i>). Každá zpráva uložená do oddílu má
přiřazen jednoznačný offset (reprezentovaný v&nbsp;Javě typem
<strong>long</strong>, což je dostatečně vysoká hodnota na to, aby
v&nbsp;reálném nasazení nedošlo k&nbsp;jejímu přetečení).</p>

<p>U většiny reálných nasazení Apache Kafky se taktéž počítá s&nbsp;využitím
většího množství instancí brokerů, z&nbsp;nichž je vytvořen cluster (nazývaný
<i>Kafka Cluster</i>). A právě při takovém uspořádání se setkáme
s&nbsp;důležitým termínem <i>replikace</i> &ndash; každý oddíl je totiž typicky
replikován na několika message brokerech v&nbsp;clusteru (ovšem nemusí se
jednat o všechny brokery, replikace se provádí například na tři brokery ve
větším clusteru, což si ostatně vyzkoušíme v&nbsp;dalších kapitolách).</p>

<p>To však není vše, jelikož je ve skutečnosti konfigurace poněkud složitější
resp.&nbsp;může být složitější &ndash; každý oddíl totiž může být replikován na
více počítačích, přičemž jeden z&nbsp;těchto oddílů je takzvaným
&bdquo;leaderem&ldquo; a ostatní jsou &bdquo;followeři&ldquo;. Zápis nových
zpráv popř.&nbsp;čtení se provádí vždy jen v&nbsp;rámci <i>leaderu</i>, ovšem
změny jsou replikovány na všechny kopie oddílu. Ve chvíli, kdy z&nbsp;nějakého
(libovolného) důvodu dojde k&nbsp;pádu &bdquo;leadera&ldquo;, převezme jeho
roli jeden z&nbsp;dalších uzlů. Pokud tedy existuje N uzlů s&nbsp;replikou
oddílu, bude systém funkční i ve chvíli, kdy zhavaruje N-1 uzlů! (i to si
vyzkoušíme).</p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Nejjednodušší konfigurace tématu: jediný broker, jeden oddíl, bez replikace</h2>

<p>Podívejme se nejdříve na tu nejjednodušší možnou konfiguraci tématu. Jedná
se o konfiguraci, v&nbsp;níž je téma spravováno jediným brokerem a není
prováděna žádná replikace. Zprávy (události) jsou tedy fyzicky uloženy pouze
v&nbsp;jediném souboru, přičemž zápis je všemi producenty prováděn na konec
(což je očekávané chování), zatímco čtení zpráv může být konzumenty provedeno
od libovolného offsetu. Příkladem je situace, kdy je konzument zpráv opožděn za
producentem zpráv, protože čte zprávu na offsetu 4 zatímco producent bude
zapisovat zprávu s&nbsp;offsetem 9:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
+---+---+---+---+---+---+---+---+---+
                  ^
                  |
                read
</pre>

<p>Druhá situace nastane ve chvíli, kdy je producent pomalejší než konzument a
konzument dojde na konec tématu. V&nbsp;tomto případě konzument bude čekat na
příchod (resp.&nbsp;přesněji řečeno na připojení) nové zprávy na konec
tématu:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
+---+---+---+---+---+---+---+---+---+
                                       ^
                                       |
                                     read
</pre>

<p>A samozřejmě je možné k&nbsp;tématu připojit větší množství konzumentů.
Pokud bude každý z&nbsp;konzumentů součástí jiné skupiny konzumentů, bude čtení
zpráv probíhat pro každou skupinu nezávisle na ostatních skupinách. Jinými
slovy &ndash; každá skupina konzumentů si &bdquo;schraňuje&ldquo; svůj offset,
jenž se může lišit od offsetu ostatních skupin:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
+---+---+---+---+---+---+---+---+---+  ^
      ^           ^               ^    |
      |           |               |    |
      |       read-group-1        |    |
      |                           |    |
  read-group-2                read-group-4
                                       |
                                   read-group-3
</pre>

<p><div class="rs-tip-major">Poznámka: právě tato vlastnost odlišuje Apache
Kafku od klasických message brokerů, kteří jsou založeni na použití
front.</div></p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Téma rozdělené na větší počet oddílů</h2>

<p>Poněkud komplikovanější, ale velmi častá je taková konfigurace tématu, kde
dochází k&nbsp;rozdělení zpráv do několika oddílů. V&nbsp;takovém případě
producent či producenti nezapisují zprávy do jednoho oddílu (samozřejmě na
konec), ale zápis je proveden pouze do jednoho z&nbsp;vybraných oddílů. O tom,
do kterého oddílu bude zápis (resp.&nbsp;připojení) zprávy proveden, se
rozhoduje na základě <i>klíče</i> připojeného ke zprávě. Samotná zpráva je
totiž chápána jako dvě sekvence bajtů &ndash; klíč zprávy a tělo zprávy. A
právě na základě klíče se vypočítá hash a algoritmus implementovaný
v&nbsp;samotném brokeru rozhodne, do kterého oddílu bude zpráva uložena:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Po přijetí nové zprávy tedy může být zápis proveden do tohoto místa:</p>

<pre>
                                   write
                                     |
              +---+---+---+---+---+---+  v
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Nebo se může broker rozhodnout pro připojení zprávy do posledního oddílu
atd. atd.:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+  ^
                                                 |
                                               write
</pre>

<p>A jak se provádí čtení? Kafka ve chvíli, kdy je téma rozděleno do větví,
musí přiřadit jednotlivé konzumenty (z&nbsp;jedné skupiny konzumentů)
k&nbsp;nějakému oddílu. Nejjednodušší je situace, kdy má nadá skupina
konzumentů stejný počet konzumentů, jako je počet oddílů, což je ostatně
doporučované řešení. Pak je každý konzument přiřazen jednomu oddílu a konzumuje
tedy pouze podmnožinu zpráv:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ............... konzument #1
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ........................... konzument #3
              +---+---+---+
partition #2  | ....................................... konzument #2
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |.... konzument #4
              +---+---+---+---+---+---+---+---+---+
</pre>

<p><div class="rs-tip-major">Poznámka: konzumenti jsou obecně přiřazeni
k&nbsp;oddílům &bdquo;náhodně&ldquo;.</div></p>

<p>Konzumentů v&nbsp;jedné skupině ovšem může být méně, než je počet oddílů.
V&nbsp;takovém případě musí některý konzument číst zprávy z&nbsp;většího
množství oddílů:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 |          ........... konzument #1
              +---+---+---+---+---+---+          :
partition #1  | 0 | 1 | 2 | ................................ konzument #3
              +---+---+---+
partition #2  | ............................................ konzument #2
              +---+---+---+---+---+---+---+---+---+       :
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |........
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Konzumentů ovšem může být i více. Tehdy nějaký konzument v&nbsp;daný okamžik
nepracuje, tj.&nbsp;nepřijímá zprávy a situace může vypadat takto:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ............... konzument #1
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ........................... konzument #3
              +---+---+---+
partition #2  | ....................................... konzument #2
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |.... konzument #4
              +---+---+---+---+---+---+---+---+---+
                                                        konzument #5

                                                        konzument #6

                                                        konzument #7
</pre>

<p><div class="rs-tip-major">Konzumenti z&nbsp;dalších skupin konzumentů se
budou připojovat nezávisle na ostatních skupinách. Tj.&nbsp;může existovat
skupina konzumentů s&nbsp;menším počtem konzumentů, než je počet oddílů, další
skupina může mít přesný počet konzumentů a třetí skupina naopak větší počet
konzumentů. Vše bude funkční, protože jednotlivé skupiny konzumentů jsou na
sobě nezávislé.</div></p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Téma s&nbsp;jedním replikovaným oddílem</h2>

<p>Další možná konfigurace tématu může vypadat tak, že téma má sice jediný
oddíl, ovšem tento oddíl je replikován mezi několika brokery. Příkladem může
být oddíl replikovaný mezi trojicí brokerů. V&nbsp;takovém případě je jeden
z&nbsp;těchto oddílů nazvaný <i>leader</i> a veškeré operace viděné zvnějšku
Kafky (tedy posílání zpráv a jejich konzumace) probíhá právě s&nbsp;leaderem.
Ostatní repliky jsou nazvané <i>follower(s)</i>, protože pouze sledují leadera
a synchronizují svůj obsah s&nbsp;leaderem:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...    (leader)
+---+---+---+---+---+---+---+---+---+
                  ^               ^
                  |               |
                read              |
                                 sync
                                  |
                                  |
                                  v
+---+---+---+---+---+---+---+---+---+
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |        (follower)
+---+---+---+---+---+---+---+---+---+
                                  ^
                                  |
                                  |
                                 sync
                                  |
                                  |
                                  v
+---+---+---+---+---+---+---+---+---+
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |        (follower)
+---+---+---+---+---+---+---+---+---+
</pre>

<p>K&nbsp;čemu je to však dobré? V&nbsp;případě, že nějaký broker z&nbsp;celého
Kafka clusteru zhavaruje a bude obsahovat oddíl typu <i>follower</i>, bude
komunikace pokračovat dál a teprve po znovupřipojení brokera se <i>follower</i>
postupně sesynchronizuje s&nbsp;<i>leaderem</i>. Zajímavější situace nastane ve
chvíli, kdy zhavaruje samotný <i>leader</i>. V&nbsp;takovém případě Kafka
&bdquo;povýší&ldquo;nějakého <i>followera</i> za nového <i>leadera</i>.
V&nbsp;případě, že téma (resp.&nbsp;oddíl) je replikováno na N brokerů, může
jich zhavarovat N-1 a systém bude stále funkční. I toto chování si pochopitelně
postupně otestujeme.</p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Téma s&nbsp;větším množstvím replikovaných oddílů</h2>

<p>Možnosti popsané <a href="#k04">ve čtvrté</a> a <a href="#k05">v&nbsp;páté
kapitole</a> je pochopitelně možné v&nbsp;případě potřeby zkombinovat a
vytvořit tak konfiguraci tématu, které bude rozděleno na větší množství oddílů
a tyto oddíly budou replikovány mezi větší množství brokerů:</p>

<pre>
          +---+---+---+---+---+---+
oddíl #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
          +---+---+---+---+---+---+
oddíl #1  | 0 | 1 | 2 | ...
          +---+---+---+                               (leader)
oddíl #2  | ...
          +---+---+---+---+---+---+---+---+---+
oddíl #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
          +---+---+---+---+---+---+---+---+---+
                                  ^
                                  |
                                  |
                                 sync
                                  |
                                  |
                                  v
          +---+---+---+---+---+---+
oddíl #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
          +---+---+---+---+---+---+
oddíl #1  | 0 | 1 | 2 | ...
          +---+---+---+
oddíl #2  | ...                                       (follower)
          +---+---+---+---+---+---+---+---+---+
oddíl #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
          +---+---+---+---+---+---+---+---+---+
</pre>

<p>Opět zde můžeme vidět, že oddíl na jednom z&nbsp;brokerů bude zvolen za
<i>leadera</i> a ostatní oddíly budou sledovat změny leadera a aplikovat je na
své straně. A samozřejmě při výpadku leadera je jeden z&nbsp;následovníků
zvolen za leadera a činnost celé infrastruktury Apache Kafky tak může
pokračovat dál.</p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Praktická část</h2>

<p>Druhá část dnešního článku bude zaměřená více prakticky. Nejdříve vytvoříme
tu nejjednodušší instanci Kafka clusteru, která se skládá z&nbsp;jednoho
běžícího Zookeepera a jednoho brokera. Na této instanci si otestujeme způsoby
vytváření témat, chování většího množství konzumentů při připojení
k&nbsp;tématu, použití většího množství oddílů pro téma atd. Ovšem zajímavější
je situace, kdy je spuštěno větší množství brokerů a kdy je navíc nějaký oddíl
replikován mezi tyto brokery. V&nbsp;této chvíli by mělo být možné brokera (či
brokery) zastavit s&nbsp;tím, že zbývající brokeři se postarají o zachování
funkcionality Apache Kafky (resp.&nbsp;přesněji řečeno celého Kafka clusteru).
To, zda je tomu skutečně tak, si taktéž ověříme.</p>



<p><a name="k08"></a></p>
<h2 id="k08">8. Instalace Apache Kafky</h2>

<p>V&nbsp;praktické části budeme brokery Apache Kafky i Zookeeper spouštět
lokálně (popř.&nbsp;z&nbsp;Dockeru), takže je nejdříve nutné Kafku
nainstalovat. Není to vůbec nic složitého. V&nbsp;případě, že je na počítači
nainstalováno JRE (běhové prostředí Javy), je instalace Kafky pro testovací
účely triviální. V&nbsp;článku si ukážeme instalaci verze 3.3.2, ovšem můžete
si stáhnout i nejnovější verzi 3.4.0, která byla vydána prakticky přesně před
měsícem. Tarball s&nbsp;instalací Kafky lze získat z&nbsp;adresy <a
href="https://downloads.apache.org/kafka/3.3.2/kafka_2.13-3.3.2.tgz">https://downloads.apache.org/kafka/3.3.2/kafka_2.13-3.3.2.tgz</a>.
Stažení a rozbalení tarballu:</p>

<pre>
$ <strong>wget https://downloads.apache.org/kafka/3.3.2/kafka_2.13-3.3.2.tgz</strong>
$ <strong>tar xvfz kafka_2.13-3.3.2.tgz</strong>
$ <strong>cd kafka_2.13-3.3.2/</strong>
</pre>

<p>Po rozbalení staženého tarballu získáme adresář, v&nbsp;němž se nachází
všechny potřebné Java archivy (JAR), konfigurační soubory (v&nbsp;podadresáři
<strong>config</strong>) a několik pomocných skriptů (v&nbsp;podadresáři
<strong>bin</strong>). Pro spuštění Zookeepera a brokerů je zapotřebí mít
nainstalovánu JRE (Java Runtime Environment) a samozřejmě též nějaký shell
(BASH, cmd, ...).</p>

<pre>
.
├── bin
│   └── windows
├── config
│   └── kraft
├── libs
├── licenses
└── site-docs
&nbsp;
7 directories
</pre>

<p>Mezi důležité soubory, které budeme používat v&nbsp;rámci dalších kapitol,
patří především skripty pro spouštění jednotlivých služeb, konfiguraci témat,
produkci zpráv či pro jejich konzumaci. Tyto skripty jsou uloženy
v&nbsp;podadresáři <strong>bin</strong> (a pro Windows ještě v&nbsp;dalším
podadresáři <strong>windows</strong>):</p>

<table>
<tr><th>Skript</th><th>Stručný popis</th></tr>
<tr><td>bin/kafka-server-start.sh</td><td>spuštění brokera</td></tr>
<tr><td>bin/zookeeper-server-start.sh</td><td>spuštění Zookeepera</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>bin/kafka-configs.sh</td><td>konfigurace brokerů</td></tr>
<tr><td>bin/kafka-topics.sh</td><td>konfigurace témat, zjištění informace o tématech atd.</td></tr>
<tr><td>bin/kafka-consumer-groups.sh</td><td>konfigurace popř.&nbsp;zjištění informací o skupinách konzumentů</td></tr>
<tr><td>bin/kafka-run-class.sh</td><td>spuštění konkrétní třídy z&nbsp;Apache Kafky (například pro zjištění informací o skupinách konzumentů)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>bin/kafka-console-producer.sh</td><td>jednoduchý producent zpráv</td></tr>
<tr><td>bin/kafka-console-consumer.sh</td><td>jednoduchý konzument zpráv</td></tr>
</table>

<p>Používat budeme i několik konfiguračních souborů. Ty jsou pro změnu uloženy
v&nbsp;podadresáři <strong>config</strong> a jedná se o soubory ve formátu
<i>Java property (file)</i>, tj.&nbsp;vlastně se jedná o sekvence dvojic
klíč:hodnota (s&nbsp;podporou zápisu poznámek):</p>

<table>
<tr><th>Konfigurační soubor</th><th>Stručný popis</th></tr>
<tr><td>config/server.properties</td><td>konfigurace brokeru</td></tr>
<tr><td>config/zookeeper.properties</td><td>konfigurace Zookeepera</td></tr>
</table>



<p><a name="k09"></a></p>
<h2 id="k09">9. Konfigurace a spuštění Zookeepera, test zda Zookeeper přijímá příkazy</h2>

<p>Po (doufejme že úspěšné) instalaci Kafky již můžeme spustit Zookeeper a
jednu instanci brokera (a to přesně v&nbsp;tomto pořadí!). Konfigurace
Zookeepera je uložena <a href="#k08">ve výše</a> zmíněném souboru
<strong>config/zookeeper.properties</strong> a zajímat nás budou především
následující tři konfigurační volby &ndash; adresář, kam ZooKeeper ukládá svoje
data, port, který použijí brokeři a omezení počtu připojení jednoho klienta
v&nbsp;daný okamžik:</p>

<pre>
dataDir=/tmp/zookeeper
clientPort=2181
maxClientCnxns=0
admin.enableServer=false
</pre>

<p><div class="rs-tip-major">Poznámka: hodnota <strong>maxClientCnxns</strong>
v&nbsp;tomto případě neznamená, že by se nemohli připojit žádní klienti, ale je
že vypnutý mechanismus, který zabezpečuje infrastrukturu Kafky před některými
typy DOS útoků. Na disku, kde je adresář <strong>dataDir</strong> by také mělo
být dostatek místa, protože Zookeeper v&nbsp;některých případech mívá větší
nároky. Další informace lze nalézt na stránce <a
href="https://zookeeper.apache.org/doc/r3.8.1/index.html">https://zookeeper.apache.org/doc/r3.8.1/index.html</a>.</div></p>

<p>Nyní již můžeme Zookeepera spustit:</p>

<pre>
$ <strong>cd kafka/kafka_2.12-3.3.2/</strong>
$ <strong>bin/zookeeper-server-start.sh config/zookeeper.properties</strong>
</pre>

<p>Průběh inicializace Zookeepera je vypisován na terminál:</p>

<pre>
[2023-02-04 08:37:49,555] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
...
...
[2023-02-04 08:37:49,591] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,591] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,591] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,591] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO   / /__  | (_) | | (_) | |   &lt;  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
...
...
...
[2023-02-04 08:37:49,691] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2023-02-04 08:37:49,706] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
</pre>

<p>Ověření, zda Zookeeper běží a přijímá požadavky, můžeme provést standardním
nástrojem <strong>telnet</strong>. Nejprve se k&nbsp;Zookeeperovi připojíme, a
to konkrétně na port 2181:</p>

<pre>
$ <strong>telnet localhost 2181</strong>
&nbsp;
Trying 192.168.1.34...
Connected to 192.168.1.34.
Escape character is '^]'.
</pre>

<p>Připojit se pochopitelně můžeme i ke vzdálenému stroji s&nbsp;běžícím Zookeeperem, pokud nám to umožňuje konfigurace sítě a nastavení firewallů:</p>

<pre>
$ <strong>telnet 192.168.1.34 2181</strong>
&nbsp;
Trying 192.168.1.34...
Connected to 192.168.1.34.
Escape character is '^]'.
</pre>

<p>Nyní Zookeeper čeká na zadání <i>four letter word command</i>, tedy příkazu,
který je zapsán formou čtyř znaků. Příkladem může být příkaz
<strong>srvr</strong>. Po jeho zápisu Zookeeper odpoví a odpojí se:</p>

<pre>
<strong>srvr</strong>
&nbsp;
Zookeeper version: 3.6.3--6401e4ad2087061bc6b9f80dec2d69f2e3c8660a, built on 04/08/2021 16:35 GMT
Latency min/avg/max: 0/0.0/0
Received: 1
Sent: 0
Connections: 1
Outstanding: 0
Zxid: 0x0
Mode: standalone
Node count: 5
Connection closed by foreign host.
</pre>

<p>Mezi další podporované čtyřznakové příkazy patří:</p>

<table>
<tr><th>Hodnota 32bitového slova</th><th>Odpovídající příkaz</th></tr>
<tr><td>1936881266</td><td>srvr</td></tr>
<tr><td>1937006964</td><td>stat</td></tr>
<tr><td>2003003491</td><td>wchc</td></tr>
<tr><td>1685417328</td><td>dump</td></tr>
<tr><td>1668445044</td><td>crst</td></tr>
<tr><td>1936880500</td><td>srst</td></tr>
<tr><td>1701738089</td><td>envi</td></tr>
<tr><td>1668247142</td><td>conf</td></tr>
<tr><td>1751217000</td><td>hash</td></tr>
<tr><td>2003003507</td><td>wchs</td></tr>
<tr><td>2003003504</td><td>wchp</td></tr>
<tr><td>1684632179</td><td>dirs</td></tr>
<tr><td>1668247155</td><td>cons</td></tr>
<tr><td>1835955314</td><td>mntr</td></tr>
<tr><td>1769173615</td><td>isro</td></tr>
<tr><td>1920298859</td><td>ruok</td></tr>
<tr><td>1735683435</td><td>gtmk</td></tr>
<tr><td>1937010027</td><td>stmk</td></tr>
</table>

<p><div class="rs-tip-major">Poznámka: kód je odvozen jednoduše tak, že všechny
čtyři znaky (resp.&nbsp;přesněji řečeno jejich ASCII kódy) uložíme do jednoho
32bitového slova, jehož číselnou hodnotu lze poté snadno přečíst.</div></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Konfigurace a spuštění brokera</h2>

<p>Nyní, když již běží jedna instance Zookeepera, si můžeme spustit brokera.
Podívejme se ovšem nejdříve na jeho konfiguraci. Výchozí konfigurace jednoho
brokera je uložená v&nbsp;souboru <strong>config/server.properties</strong>.
Samotný konfigurační soubor obsahuje několik sekcí:</p>

<ol>
<li>Port, na kterém broker naslouchá</li>
<li>Jednoznačné (unikátní) ID brokera</li>
<li>Počet použitých vláken pro IO operace a počet vláken pro komunikaci.</li>
<li>Velikost bufferů, maximální povolená velikost požadavků (což omezuje velikost zprávy) atd.</li>
<li>Nastavení počtu <i>partitions</i></li>
<li>Nastavení <i>retence</i> dat</li>
<li>Připojení k&nbsp;Zookeeperovi</li>
</ol>

<p>Takto vypadá výchozí konfigurace (po odstranění původních komentářů a
přidání komentářů vlastních):</p>

<pre>
#
########################### Jednoznačná identifikace brokera ####################
#
broker.id=0
num.io.threads=8
#
######################## Komunikace s producenty i konzumenty ###################
#
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
#
########################### Adresář se soubory s daty oddílů ####################
#
log.dirs=/tmp/kafka-logs
#
################### Výchozí konfigurace oddílů pro nová témata ##################
#
num.partitions=1
num.recovery.threads.per.data.dir=1
#
######################## Interní témata s offsety a transakcemi #################
#
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
#
############################# Log Retention Policy ##############################
#
log.retention.hours=168
log.retention.check.interval.ms=300000
#
############################# Zookeeper #########################################
#
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=18000
#
############################# Group Coordinator Settings ########################
#
group.initial.rebalance.delay.ms=0
</pre>

<p><div class="rs-tip-major">Poznámka: povšimněte si, že se broker bude snažit
komunikovat se Zookeeperem běžícím na stejném stroji.</div></p>

<p><div class="rs-tip-major">Poznámka<sup>2</sup>: velikost adresáře
<strong>log.dirs</strong> roste, a to mnohdy velmi rychle, takže se vyplatí
sledovat příslušné metriky.</div></p>

<p>Spuštění jednoho brokera vypadá i probíhá jednoduše:</p>

<pre>
$ <strong>cd kafka/kafka_2.12-3.3.2/</strong>
$ <strong>bin/kafka-server-start.sh config/server.properties</strong>
</pre>

<p>Broker by měl vypsat minimálně informaci o tom, že se připojil
k&nbsp;Zookeeperu a že dokázal inicializovat adresář pro uložení dat (zpráv)
oddílů:</p>

<pre>
[2023-02-04 08:41:47,105] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2023-02-04 08:41:47,506] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2023-02-04 08:41:47,587] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2023-02-04 08:41:47,589] INFO starting (kafka.server.KafkaServer)
[2023-02-04 08:41:47,590] <strong>INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)</strong>
[2023-02-04 08:41:47,606] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
...
...
...
[2023-02-04 08:49:52,076] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2023-02-04 08:49:52,167] INFO [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2023-02-04 08:49:52,184] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
</pre>

<p>Alternativně je možné ZooKeepera i Kafku (jednu instanci brokera) spustit
v&nbsp;Dockeru:</p>

<pre>
$ <strong>docker run -p 2181:2181 -p 9092:9092 --env ADVERTISED_HOST=`docker-machine ip \`docker-machine active\`` --env ADVERTISED_PORT=9092 spotify/kafka</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: předchozí nastavení předpokládá, že
současně na stejném stroji nepoběží žádná další instance Kafky ani Zookeepera.
Pokud budete potřebovat spustit větší množství brokerů, je nutné minimálně
změnit mapování portů (přepínače <strong>-p</strong>) a taktéž změnit ID
brokeru &ndash; to vše si pochopitelně ukážeme v&nbsp;dalším textu.</div></p>



<p><a name="k11"></a></p>
<h2 id="k11">11. Komunikace přes téma s&nbsp;jediným oddílem a bez replikace</h2>

<p>Nejprve si ukažme komunikaci mezi producenty zpráv a jejich konzumenty
v&nbsp;případě, že jak producenti, tak i konzumenti používají společné téma
(<i>topic</i>) s&nbsp;jediným oddílem, který navíc není replikovaný. Jedná se
tedy o konfiguraci, která byla popsána <a href="#k03">ve třetí kapitole</a>.
V&nbsp;dalším textu budeme předpokládat, že je již spuštěn jak jeden Zookeeper,
tak i jeden Kafka broker.</p>

<p>Budeme potřebovat další tři terminály (nebo okna spravovaná přes <i>tmux</i>
atd.):</p>

<ol>
<li>V&nbsp;prvním terminálu budeme spouštět příkazy pro konfiguraci Kafky a pro zjišťování jejího stavu</li>
<li>Ve druhém terminálu spustíme producenta zpráv.</li>
<li>Ve třetím terminálu spustíme konzumenta zpráv.</li>
</ol>

<p>Pro větší přehlednost bude mít každý z&nbsp;terminálů nastaven odlišnou
výzvu (<i>prompt</i>):</p>

<pre>
kafka $
producer $
consumer $
</pre>

<p>Vypíšeme si seznam témat; ten by měl být prázdný:</p>

<pre>
kafka $ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9092 --list</strong>
&nbsp;
</pre>

<p>Vytvoříme nové téma nazvané <strong>topic1</strong> a necháme si opět vypsat
seznam témat:</p>

<pre>
kafka $ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic1</strong>
Created topic topic1.
&nbsp;
kafka $ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9092 --list</strong>
topic1
</pre>

<p>Získáme i podrobnější informace o tématu (s&nbsp;jediným oddílem):</p>

<pre>
kafka $ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic1</strong>
&nbsp;
Topic: topic1   TopicId: 3Xfn9Hu1QhmRAdXKmEua-w PartitionCount: 1       ReplicationFactor: 1    Configs: 
        Topic: topic1   Partition: 0    Leader: 0       Replicas: 0     Isr: 0
</pre>

<p>Vypíšeme si (prozatím prázdný) seznam skupin konzumentů:</p>

<pre>
kafka $ <strong>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list</strong>
&nbsp;
</pre>

<p>V&nbsp;dalším terminálu spustíme producenta zpráv a pošleme do tématu
<strong>topic1</strong> tři zprávy s&nbsp;hodnotou (tělem) &bdquo;foo&ldquo;,
&bdquo;bar&ldquo; a &bdquo;baz&ldquo;:</p>

<pre>
producer $ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic1</strong>
&gt;<strong>foo</strong>
&gt;<strong>bar</strong>
&gt;<strong>baz</strong>
<strong>&lt;Ctrl+D&gt;</strong>
</pre>

<p>Spustíme konzumenta zpráv a zajistíme, aby zprávy četl od začátku tématu (jinak by čekal na nejnovější zprávy a již uložené zprávy by ignoroval):</p>

<pre>
consumer $ <strong>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic1 --from-beginning</strong>
foo
bar
baz
</pre>

<p>Opět si zobrazíme seznam skupin konzumentů:</p>

<pre>
kafka $ <strong>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list</strong>
console-consumer-73416
</pre>

<p>A vypíšeme si o nich i podrobnější informace:</p>

<pre>
kafka $ <strong>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups</strong>
&nbsp;
GROUP                  TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                           HOST            CLIENT-ID
console-consumer-73416 topic1          0          -               3               -               console-consumer-938ac3be-f3b6-4e93-aab4-74e34b9a3ac5 /192.168.1.34   console-consumer
</pre>

<p>Lepší však bude vytvořit konzumenta s&nbsp;explicitně specifikovaným jménem
skupiny konzumentů:</p>

<pre>
consumer $ <strong>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic1 --group topic1-group1</strong>
</pre>

<p>Nyní bude výpis informací o skupinách konzumentů vypadat takto:</p>

<pre>
kafka $ <strong>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups</strong>
&nbsp;
GROUP           TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                           HOST            CLIENT-ID
topic1-group1   topic1          0          -               3               -               console-consumer-3dc1ad8a-14fb-4758-b25e-9319436b409b /192.168.1.34   console-consumer
kafka $ bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups
</pre>

<p>Po poslání další zprávy provede konzument její zpracování a upraví si
&bdquo;svůj&ldquo; offset, díky čemuž může Kafka spočítat i <i>lag</i>,
tj.&nbsp;zpoždění konzumentů vůči producentovi (měřené v&nbsp;počtu
nepřečtených zpráv):</p>

<pre>
kafka $ <strong>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups</strong>
&nbsp;
GROUP          TOPIC    PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG   CONSUMER-ID                                           HOST            CLIENT-ID
topic1-group1  topic1   0          4               4               0     console-consumer-3dc1ad8a-14fb-4758-b25e-9319436b409b /192.168.1.34   console-consumer
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Větší množství konzumentů z&nbsp;jedné skupiny vs.z&nbsp;více skupin</h2>

<p>V&nbsp;této kapitole si ukážeme chování Kafky ve chvíli, kdy se
k&nbsp;vybranému tématu připojí větší množství konzumentů, kteří mohou patřit
buď do jedné skupiny nebo do většího množství skupin.</p>

<p>Nejprve nové téma vytvoříme. Není to sice nutné, protože téma dokáže
vytvořit i připojený klient, ale proč nebýt explicitní:</p>

<pre>
kafka $ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic2</strong>
Created topic topic2.
</pre>

<p>Vypíšeme si podrobnější informace o právě vytvořeném tématu. Vidíme, že téma
má jediný oddíl a jediného leadera (což je ten samý oddíl):</p>

<pre>
kafka $<strong> bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic2</strong>
&nbsp;
Topic: topic2   TopicId: 43_uP1TFTuOd-lXgKxbIaA PartitionCount: 1       ReplicationFactor: 1    Configs: 
        Topic: topic2   Partition: 0    Leader: 0       Replicas: 0     Isr: 0
</pre>

<p>V&nbsp;samostatných terminálech spustíme dvojici konzumentů, kteří budou
patřit do stejné skupiny nazvané <strong>topic2-group1</strong>:</p>

<pre>
consumer1 $ <strong>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic2 --group topic2-group1</strong>
consumer2 $ <strong>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic2 --group topic2-group1</strong>
</pre>

<p>A samozřejmě v&nbsp;dalším terminálu spustíme producenta, který bude do
tématu předávat zprávy:</p>

<pre>
producer $ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic2</strong>
&gt;<strong>foo</strong>
&gt;<strong>bar</strong>
&gt;<strong>baz</strong>
<strong>&lt;Ctrl+D&gt;</strong>
</pre>

<p>Povšimněte si, že pouze jeden z&nbsp;producentů (náhodně vybraný) bude
dostávat zprávy, zatímco druhý bude pouze čekat na zprávy, které nedojdou.
Jedná se tedy o následující situaci, kdy v&nbsp;rámci jedné skupiny může být
k&nbsp;jedinému oddílu připojen jediný konzument:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ............... konzument #1
              +---+---+---+---+---+---+
                                                        konzument #2
                                                           ...
                                                           ...
                                                           ...
                                                        konzument #N
</pre>

<p>Co se však bude dít ve chvíli, kdy budeme mít dvojici konzumentů, ovšem
každý bude patřit do jiné skupiny? I to si pochopitelně otestujeme. Vytvoříme
pro tento účel nové téma:</p>

<pre>
kafka $ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic3</strong>
Created topic topic3.
&nbsp;
kafka $ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic3</strong>
Topic: topic3   TopicId: o1Szo6FoQLu67SUK4m9QsA PartitionCount: 1       ReplicationFactor: 1    Configs: 
        Topic: topic3   Partition: 0    Leader: 0       Replicas: 0     Isr: 0
</pre>

<p>V&nbsp;samostatných terminálech spustíme dvojici konzumentů, každý ovšem
bude patřit do jiné skupiny:</p>

<pre>
consumer1 $ <strong>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic3 --group topic3-group1</strong>
consumer2 $ <strong>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic3 --group topic3-group2</strong>
</pre>

<p>Spustíme producenta zpráv:</p>

<pre>
producer $ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic3</strong>
&gt;<strong>foo</strong>
&gt;<strong>bar</strong>
&gt;<strong>baz</strong>
<strong>&lt;Ctrl+D&gt;</strong>
</pre>

<p>Nyní by oba konzumenti měli dostávat stejné zprávy! Tj.&nbsp;bude se jednat
o tuto konfiguraci:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
+---+---+---+---+---+---+---+---+---+
                  ^               ^
                  |               |
            topic3-group1-        |
                                  |
                              topic3-group2
</pre>

<p>O tom, že konzumenti z&nbsp;různých skupin mají uložen svůj offset nezávisle
na dalších skupinách, se lze snadno přesvědčit:</p>

<pre>
kafka $ <strong>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups</strong>
&nbsp;
GROUP          TOPIC   PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID                                           HOST            CLIENT-ID
topic3-group1  topic3  0          3               3               0    console-consumer-bec8112f-8c21-46e0-8a22-997ec663615f /192.168.1.34   console-consumer
&nbsp;
GROUP          TOPIC   PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID                                           HOST            CLIENT-ID
topic3-group2  topic3  0          3               3               0    console-consumer-feb4ff84-460c-4ddb-959c-f949fc18968f /192.168.1.34   console-consumer
</pre>

<p><div class="rs-tip-major">Poznámka: v&nbsp;tomto konkrétním případě mají obě
skupiny konzumentů nulový <i>lag</i>, ovšem v&nbsp;praxi může být
<i>lag</i>odlišný, neboť konzumenti z&nbsp;jedné skupiny mohou být
(z&nbsp;různých důvodů) rychlejší, než je tomu u dalších skupin.</div></p>



<p><a name="k13"></a></p>
<h2 id="k13">13. Komunikace přes téma s&nbsp;větším množstvím oddílů</h2>

<p>Vyzkoušejme si nyní další situaci, konkrétně stav, kdy je jedno téma
rozděleno na dva oddíly na jediném Kafka brokeru. Takové téma je nutné vytvořit
explicitně s&nbsp;použitím parametru <strong>--partitions</strong>:</p>

<pre>
kafka $ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9092 --create --topic topic4 --partitions 2</strong>
Created topic topic4.
</pre>

<p>Nyní bude konfigurace tématu vypsaná samotnou Kafkou vypadat odlišně,
protože se vypíšou informace o obou oddílech:</p>

<pre>
kafka $ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9092 --describe --topic topic4</strong>
Topic: topic4   TopicId: 4qaw38skShK9elEG-gwEIA PartitionCount: 2       ReplicationFactor: 1    Configs: 
        Topic: topic4   Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: topic4   Partition: 1    Leader: 0       Replicas: 0     Isr: 0
</pre>

<p>Spusťme opět dva konzumenty patřící do stejné skupiny:</p>

<pre>
consumer1 $ <strong>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic4 --group topic4-group1</strong>
consumer2 $ <strong>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic4 --group topic4-group1</strong>
</pre>

<p>Kafka broker v&nbsp;tomto případě konzumenty rozdělí po jednotlivých
oddílech:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ............... konzument #1
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ........................... konzument #2
              +---+---+---+
</pre>

<p>O tom se ostatně můžeme velmi snadno přesvědčit:</p>

<pre>
kafka $ <strong>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups </strong>
&nbsp;
GROUP          TOPIC   PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID                                           HOST            CLIENT-ID
topic4-group1  topic4  0          0               0               0    console-consumer-00d59376-f63e-4833-adfa-b0578c275244 /192.168.1.34   console-consumer
topic4-group1  topic4  1          0               0               0    console-consumer-22ddccc4-6ea4-4b97-9c32-e85755788e35 /192.168.1.34   console-consumer
</pre>

<p><div class="rs-tip-major">Poznámka: povšimněte si, že každý
z&nbsp;konzumentů je nyní skutečně připojen ke &bdquo;svému&ldquo; oddílu a
pamatuje si offset v&nbsp;rámci tohoto oddílu.</div></p>

<p>Teoreticky by nyní měly být zprávy rozdělovány &bdquo;spravedlivě&ldquo;
mezi oba oddíly:</p>

<pre>
producer $ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic4</strong>
&gt;<strong>foo</strong>
&gt;<strong>bar</strong>
&gt;<strong>baz</strong>
<strong>&lt;Ctrl+D&gt;</strong>
</pre>

<p>Ve skutečnosti však k&nbsp;rozdělení nedojde, o čemž se lze snadno
přesvědčit &ndash; jeden z&nbsp;konzumentů (nevíme který) bude dostávat všechny
zprávy, druhý konzument nebude zprávy dostávat žádné!</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ............... konzument #1
              +---+---+---+---+---+---+
partition #1  | ....................................... konzument #2
              +
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Souběžná konzumace zpráv konzumenty z&nbsp;jedné skupiny</h2>

<p>Zprávy se (ve výchozím nastavení) rozdělují do jednotlivých oddílů
v&nbsp;tématu na základě svého <i>klíče</i>. Ten lze u posílaných
(resp.&nbsp;produkovaných) zpráv specifikovat podobně jako tělo zprávy. Musíme
však producenta ovládaného z&nbsp;příkazové řádky vhodným způsobem
nakonfigurovat tak, aby věděl, jakým způsobem je klíč (sekvence bajtů) oddělen
od těla zprávy (což je taktéž sekvence bajtů). Jako oddělovač můžeme použít
například dvojtečku. Producent se nakonfiguruje následovně:</p>

<pre>
producer $ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic4 --property parse.key=true --property key.separator=":"</strong>
</pre>

<p>Do tématu nyní pošleme šest zpráv, každou s&nbsp;odlišným klíčem (zadán před
dvojtečkou):</p>

<pre>
&gt;<strong>1:a</strong>
&gt;<strong>2:b</strong>
&gt;<strong>3:c</strong>
&gt;<strong>foo:1</strong>
&gt;<strong>bar:2</strong>
&gt;<strong>baz:3</strong>
<strong>&lt;Ctrl+D&gt;</strong>
</pre>

<p>Pokud jsou současně spuštění dva konzumenti patřící do stejné skupiny,
uvidíme, že zprávy by měly být mezi konzumenty rozděleny a to zhruba
férově:</p>

<pre>
consumer1 $ <strong>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic4 --group topic4-group1</strong>
b
1
3
</pre>

<pre>
consumer2 $ <strong>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic topic4 --group topic4-group1</strong>
a
c
2
</pre>

<p>Dosáhli jsme tedy tohoto stavu:</p>

<pre>
              +---+---+---+
partition #0  | 0 | 1 | 2 | ................ konzument #1
              +---+---+---+
partition #1  | 0 | 1 | 2 | ................ konzument #2
              +---+---+---+
</pre>

<p><div class="rs-tip-major">Poznámka: rozdělení nemusí být zcela férové ve
chvíli, kdy se používá jen malý počet klíčů popř.&nbsp;když heše klíčů nemají
uniformní rozdělení.</div></p>

<p>O stavu jednotlivých oddílů se můžeme snadno přesvědčit zadáním
následujícího příkazu:</p>

<pre>
kafka $ <strong>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --describe --all-groups</strong>
&nbsp;
GROUP          TOPIC   PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID                                           HOST            CLIENT-ID
topic4-group1  topic4  0          3               3               0    console-consumer-00d59376-f63e-4833-adfa-b0578c275244 /192.168.1.34   console-consumer
topic4-group1  topic4  1          6               6               0    console-consumer-22ddccc4-6ea4-4b97-9c32-e85755788e35 /192.168.1.34   console-consumer
</pre>

<p>Z&nbsp;výpisu je patrné, že ve druhém oddílu je větší množství zpráv. To je
způsobeno zprávami, které jsme do stejného tématu poslali v&nbsp;rámci <a
href="#k13">předchozí kapitoly</a>. Tyto zprávy neměly klíče a proto byly
umístěny do jediného oddílu.</p>



<p><a name="k15"></a></p>
<h2 id="k15">15. Spuštění většího množství brokerů</h2>

<p>V&nbsp;dalším textu si ukážeme, jakým způsobem je možné vytvořit oddíly
replikované mezi větší množství brokerů. Ovšem nejprve musíme tyto brokery
spustit. Každý broker musí mít unikátní ID a musí běžet na svém vlastním
(prozatím neobsazeném) portu. Pro spuštění tří brokerů tedy musíme mít tři
konfigurační soubory, které postupně vypadají následovně (důležité řádky jsou
zvýrazněny):</p>

<p>Konfigurační soubor <strong>server1.properties</strong>:</p>

<pre>
<strong>broker.id=0</strong>
<strong>listeners=PLAINTEXT://:9092</strong>
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
<strong>log.dirs=/tmp/kafka-logs</strong>
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
</pre>

<p>Konfigurační soubor <strong>server2.properties</strong>:</p>

<pre>
<strong>broker.id=1</strong>
<strong>listeners=PLAINTEXT://:9093</strong>
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
<strong>log.dirs=/tmp/kafka-logs-2</strong>
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
</pre>

<p>Konfigurační soubor <strong>server3.properties</strong>:</p>

<pre>
<strong>broker.id=2</strong>
<strong>listeners=PLAINTEXT://:9094</strong>
num.network.threads=3
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
<strong>log.dirs=/tmp/kafka-logs-3</strong>
num.partitions=1
num.recovery.threads.per.data.dir=1
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
log.retention.hours=168
log.retention.check.interval.ms=300000
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=18000
group.initial.rebalance.delay.ms=0
</pre>

<p></p>



<p><a name="k16"></a></p>
<h2 id="k16">16. Vytvoření a použití tématu s&nbsp;jedním replikovaným oddílem</h2>

<p></p>



<p><a name="k17"></a></p>
<h2 id="k17">17. Chování při nedostupnosti brokeru (brokerů)</h2>

<p></p>



<p><a name="k18"></a></p>
<h2 id="k18">18. Vytvoření a použití tématu s&nbsp;několika replikovanými oddíly</h2>

<p></p>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;pomocnými skripty a konfiguračními soubory</h2>

<p>Zdrojové kódy dnes použitých producentů a konzumentů byly společně
s&nbsp;konfiguračními soubory Zookeeperu a brokerů uloženy do repositáře, jenž
je dostupný na adrese <a
href="https://github.com/tisnik/slides/">https://github.com/tisnik/slides/</a>.
V&nbsp;případě, že nebudete chtít klonovat celý repositář, můžete namísto toho
použít odkazy na jednotlivé demonstrační příklady i další soubory, které
naleznete v&nbsp;následující tabulce:</p>

<table>
<tr><th>#</th><th>Soubor</th><th>Stručný popis</th><th>Adresa</th></tr>
<tr><td>1</td><td>server1.properties</td><td>konfigurace prvního brokera</td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/server1.properties">https://github.com/tisnik/slides/blob/master/files/kafka/server1.properties</a></td></tr>
<tr><td>2</td><td>server2.properties</td><td>konfigurace druhého brokera</td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/server2.properties">https://github.com/tisnik/slides/blob/master/files/kafka/server2.properties</a></td></tr>
<tr><td>3</td><td>server3.properties</td><td>konfigurace třetího brokera</td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/server3.properties">https://github.com/tisnik/slides/blob/master/files/kafka/server3.properties</a></td></tr>
<tr><td>4</td><td>zookeeper.properties</td><td>konfigurace Zookeepera</td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/zookeeper.properties">https://github.com/tisnik/slides/blob/master/files/kafka/zookeeper.properties</a></td></tr>
<tr><td>5</td><td>server1.sh</td><td>skript pro spuštění prvního brokera</td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/server1.sh">https://github.com/tisnik/slides/blob/master/files/kafka/server1.sh</a></td></tr>
<tr><td>6</td><td>server2.sh</td><td>skript pro spuštění druhého brokera</td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/server2.sh">https://github.com/tisnik/slides/blob/master/files/kafka/server2.sh</a></td></tr>
<tr><td>7</td><td>server3.sh</td><td>skript pro spuštění třetího brokera</td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/server3.sh">https://github.com/tisnik/slides/blob/master/files/kafka/server3.sh</a></td></tr>
<tr><td>8</td><td>zookeeper.sh</td><td>skript pro spuštění Zookeepera</td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/zookeeper.sh">https://github.com/tisnik/slides/blob/master/files/kafka/zookeeper.sh</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Kcli: is a kafka read only command line browser.<br />
<a href="https://github.com/cswank/kcli">https://github.com/cswank/kcli</a>
</li>

<li>Kcli: a kafka command line browser<br />
<a href="https://go.libhunt.com/kcli-alternatives">https://go.libhunt.com/kcli-alternatives</a>
</li>

<li>Kafka Connect and Schemas<br />
<a href="https://rmoff.net/2020/01/22/kafka-connect-and-schemas/">https://rmoff.net/2020/01/22/kafka-connect-and-schemas/</a>
</li>

<li>JSON and schemas<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas">https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas</a>
</li>

<li>What, why, when to use Apache Kafka, with an example<br />
<a href="https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/">https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/</a>
</li>

<li>When NOT to use Apache Kafka?<br />
<a href="https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/">https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/</a>
</li>

<li>Microservices: The Rise Of Kafka<br />
<a href="https://movio.co/blog/microservices-rise-kafka/">https://movio.co/blog/microservices-rise-kafka/</a>
</li>

<li>Building a Microservices Ecosystem with Kafka Streams and KSQL<br />
<a href="https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/">https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/</a>
</li>

<li>An introduction to Apache Kafka and microservices communication<br />
<a href="https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63">https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63</a>
</li>

<li>kappa-architecture.com<br />
<a href="http://milinda.pathirage.org/kappa-architecture.com/">http://milinda.pathirage.org/kappa-architecture.com/</a>
</li>

<li>Questioning the Lambda Architecture<br />
<a href="https://www.oreilly.com/ideas/questioning-the-lambda-architecture">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a>
</li>

<li>Lambda architecture<br />
<a href="https://en.wikipedia.org/wiki/Lambda_architecture">https://en.wikipedia.org/wiki/Lambda_architecture</a>
</li>

<li>Kafka &ndash; ecosystem (Wiki)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem</a>
</li>

<li>The Kafka Ecosystem - Kafka Core, Kafka Streams, Kafka Connect, Kafka REST Proxy, and the Schema Registry<br />
<a href="http://cloudurable.com/blog/kafka-ecosystem/index.html">http://cloudurable.com/blog/kafka-ecosystem/index.html</a>
</li>

<li>A Kafka Operator for Kubernetes<br />
<a href="https://github.com/krallistic/kafka-operator">https://github.com/krallistic/kafka-operator</a>
</li>

<li>Kafka Streams<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams">https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams</a>
</li>

<li>Kafka Streams<br />
<a href="http://kafka.apache.org/documentation/streams/">http://kafka.apache.org/documentation/streams/</a>
</li>

<li>Kafka Streams (FAQ)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams">https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams</a>
</li>

<li>Event stream processing<br />
<a href="https://en.wikipedia.org/wiki/Event_stream_processing">https://en.wikipedia.org/wiki/Event_stream_processing</a>
</li>

<li>Part 1: Apache Kafka for beginners - What is Apache Kafka?<br />
<a href="https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html">https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html</a>
</li>

<li>What are some alternatives to Apache Kafka?<br />
<a href="https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka">https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka</a>
</li>

<li>What is the best alternative to Kafka?<br />
<a href="https://www.slant.co/options/961/alternatives/~kafka-alternatives">https://www.slant.co/options/961/alternatives/~kafka-alternatives</a>
</li>

<li>A super quick comparison between Kafka and Message Queues<br />
<a href="https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0">https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0</a>
</li>

<li>Kafka Queuing: Kafka as a Messaging System<br />
<a href="https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system">https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system</a>
</li>

<li>Apache Kafka Logs: A Comprehensive Guide<br />
<a href="https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/">https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/</a>
</li>

<li>Microservices – Not a free lunch!<br />
<a href="http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html">http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html</a>
</li>

<li>Microservices, Monoliths, and NoOps<br />
<a href="http://blog.arungupta.me/microservices-monoliths-noops/">http://blog.arungupta.me/microservices-monoliths-noops/</a>
</li>

<li>Microservice Design Patterns<br />
<a href="http://blog.arungupta.me/microservice-design-patterns/">http://blog.arungupta.me/microservice-design-patterns/</a>
</li>

<li>REST vs Messaging for Microservices – Which One is Best?<br />
<a href="https://solace.com/blog/experience-awesomeness-event-driven-microservices/">https://solace.com/blog/experience-awesomeness-event-driven-microservices/</a>
</li>

<li>Kappa Architecture Our Experience<br />
<a href="https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf">https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf</a>
</li>

<li>Apache Kafka Streams and Tables, the stream-table duality<br />
<a href="https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854">https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854</a>
</li>

<li>Configure Self-Managed Connectors<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors">https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors</a>
</li>

<li>Schema Evolution and Compatibility<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility">https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility</a>
</li>

<li>Configuring Key and Value Converters<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters">https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters</a>
</li>

<li>Introduction to Kafka Connectors<br />
<a href="https://www.baeldung.com/kafka-connectors-guide">https://www.baeldung.com/kafka-connectors-guide</a>
</li>

<li>Kafka CLI: command to list all consumer groups for a topic?<br />
<a href="https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic">https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic</a>
</li>

<li>Java Property File Processing<br />
<a href="https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php">https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php</a>
</li>

<li>Skipping bad records with the Kafka Connect JDBC sink connector<br />
<a href="https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/">https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/</a>
</li>

<li>Kafka Connect Deep Dive – Error Handling and Dead Letter Queues<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/">https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/</a>
</li>

<li>Errors and Dead Letter Queues<br />
<a href="https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/">https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/</a>
</li>

<li>Confluent Cloud Dead Letter Queue<br />
<a href="https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html">https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html</a>
</li>

<li>Dead Letter Queues (DLQs) in Kafka<br />
<a href="https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309">https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309</a>
</li>

<li>Deserializer<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-json.html#json-schema-serializer-and-deserializer">https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-json.html#json-schema-serializer-and-deserializer</a>
</li>

<li>JSON, Kafka, and the need for schema<br />
<a href="https://mikemybytes.com/2022/07/11/json-kafka-and-the-need-for-schema/">https://mikemybytes.com/2022/07/11/json-kafka-and-the-need-for-schema/</a>
</li>

<li>Using Kafka Connect with Schema Registry<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/connect.html">https://docs.confluent.io/platform/current/schema-registry/connect.html</a>
</li>

<li>Zpracování dat reprezentovaných ve formátu JSON nástrojem jq<br />
<a href="https://www.root.cz/clanky/zpracovani-dat-reprezentovanych-ve-formatu-json-nastrojem-jq/">https://www.root.cz/clanky/zpracovani-dat-reprezentovanych-ve-formatu-json-nastrojem-jq/</a>
</li>

<li>Repositář projektu jq (GitHub)<br />
<a href="https://github.com/stedolan/jq">https://github.com/stedolan/jq</a>
</li>

<li>GitHub stránky projektu jq<br />
<a href="https://stedolan.github.io/jq/">https://stedolan.github.io/jq/</a>
</li>

<li>5 modern alternatives to essential Linux command-line tools<br />
<a href="https://opensource.com/ar­ticle/20/6/modern-linux-command-line-tools">https://opensource.com/ar­ticle/20/6/modern-linux-command-line-tools</a>
</li>

<li>Návod k nástroji jq<br />
<a href="https://stedolan.github.i­o/jq/tutorial/">https://stedolan.github.i­o/jq/tutorial/</a>
</li>

<li>jq Manual (development version)<br />
<a href="https://stedolan.github.io/jq/manual/">https://stedolan.github.io/jq/manual/</a>
</li>

<li>Introducing JSON<br />
<a href="https://www.json.org/json-en.html">https://www.json.org/json-en.html</a>
</li>

<li>Understanding JSON schema<br />
<a href="https://json-schema.org/understanding-json-schema/index.html">https://json-schema.org/understanding-json-schema/index.html</a>
</li>

<li>JDBC Sink Connector for Confluent Platform<br />
<a href="https://docs.confluent.io/kafka-connectors/jdbc/current/sink-connector/overview.html#jdbc-sink-connector-for-cp">https://docs.confluent.io/kafka-connectors/jdbc/current/sink-connector/overview.html#jdbc-sink-connector-for-cp</a>
</li>

<li>JDBC Connector (Source and Sink)<br />
<a href="https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc">https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2023</small></p>
</body>
</html>

