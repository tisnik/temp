<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Témata, oddíly a replikace v systému Apache Kafka</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Témata, oddíly a replikace v systému Apache Kafka</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p></p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. Témata, oddíly a replikace v&nbsp;systému Apache Kafka</a></p>
<p><a href="#k02">2. Základní koncepty, na nichž je Apache Kafka postavena</a></p>
<p><a href="#k03">3. Nejjednodušší konfigurace tématu: jediný broker, jeden oddíl, bez replikace</a></p>
<p><a href="#k04">4. Téma rozdělené na větší počet oddílů</a></p>
<p><a href="#k05">5. Téma s&nbsp;jedním replikovaným oddílem</a></p>
<p><a href="#k06">*** 6. Téma s&nbsp;větším množstvím replikovaných oddílů</a></p>
<p><a href="#k07">*** 7. Praktická část</a></p>
<p><a href="#k08">*** 8. Instalace Apache Kafky</a></p>
<p><a href="#k09">*** 9. Konfigurace a spuštění ZooKeepera</a></p>
<p><a href="#k10">*** 10. Konfigurace a spuštění brokeru</a></p>
<p><a href="#k11">*** 11. Komunikace přes téma s&nbsp;jediným oddílem a bez replikace</a></p>
<p><a href="#k12">*** 12. Větší množství konzumentů z&nbsp;jedné skupiny vs.z&nbsp;více skupin</a></p>
<p><a href="#k13">*** 13. Komunikace přes téma s&nbsp;větším množstvím oddílů</a></p>
<p><a href="#k14">*** 14. Souběžná konzumace zpráv konzumenty z&nbsp;jedné skupiny</a></p>
<p><a href="#k15">*** 15. Spuštění většího množství brokerů</a></p>
<p><a href="#k16">*** 16. Vytvoření a použití tématu s&nbsp;jedním replikovaným oddílem</a></p>
<p><a href="#k17">*** 17. Chování při nedostupnosti brokeru (brokerů)</a></p>
<p><a href="#k18">*** 18. Vytvoření a použití tématu s&nbsp;několika replikovanými oddíly</a></p>
<p><a href="#k19">*** 19. Repositář s&nbsp;demonstračními příklady a konfiguračními soubory</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Témata, oddíly a replikace v&nbsp;systému Apache Kafka</h2>

<img src="https://i.iinfo.cz/images/447/microservices2-3.png" class="image-361670" alt="&#160;" width="450" height="134" />
<p><i>Obrázek 1: Logo nástroje Apache Kafka, kterému se budeme dnes
věnovat.</i></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Základní koncepty, na nichž je Apache Kafka postavena</h2>

<p>V&nbsp;této kapitole si ve stručnosti vysvětlíme základní koncepty, na nichž
je Apache Kafka postavena. Systém Apache Kafka umožňuje ukládání zpráv (zde se
ovšem poměrně často taktéž používá termín záznam &ndash; <i>record</i>) do
různých témat (<i>topic</i>), přičemž každé téma je obecně rozděleno do oddílů
neboli <i>partition</i>. Samozřejmě je možné pro téma vyhradit pouze jediný
oddíl (což je ostatně výchozí nastavení, které se asi nejvíce podobá klasickým
<i>message brokerům</i>) a tvářit se, že máme k&nbsp;dispozici
&bdquo;vylepšenou&ldquo; frontu &ndash; ostatně přesně takto lze s&nbsp;Kafkou
začít a pro mnohé účely může být tato konfigurace dostatečná. Rozdělení tématu
do většího množství oddílů se provádí z&nbsp;několika důvodů. Jedním
z&nbsp;nich je snaha o rozdělení zátěže (<i>load balancing</i>), protože
jednotlivé oddíly mohou být provozovány na různých počítačích v&nbsp;mnohdy i
velmi rozsáhlém clusteru (většinou se jedná o zátěž disků, nikoli CPU).</p>

<p>Dále se dělení provádí z&nbsp;toho důvodu, že každý oddíl obsahuje sekvenci
neměnných (<i>immutable</i>) zpráv, přičemž nové zprávy se pouze připojují na
konec oddílu (<i>append-only log</i>). Zprávy z&nbsp;oddílů je možné číst
(konzumovat) nezávisle na ostatních oddílech a zajistit tak potřebný <i>load
balancing</i> (jak uvidíme dále, je tato možnost realizována přes skupiny
konzumentů &ndash; <i>consumer groups</i>). Každá zpráva uložená do oddílu má
přiřazen jednoznačný offset (reprezentovaný v&nbsp;Javě typem
<strong>long</strong>, což je dostatečně vysoká hodnota na to, aby
v&nbsp;reálném nasazení nedošlo k&nbsp;jejímu přetečení).</p>

<p>U většiny reálných nasazení Apache Kafky se taktéž počítá s&nbsp;využitím
většího množství instancí brokerů, z&nbsp;nichž je vytvořen cluster (nazývaný
<i>Kafka Cluster</i>). A právě při takovém uspořádání se setkáme
s&nbsp;důležitým termínem <i>replikace</i> &ndash; každý oddíl je totiž typicky
replikován na několika message brokerech v&nbsp;clusteru (ovšem nemusí se
jednat o všechny brokery, replikace se provádí například na tři brokery ve
větším clusteru, což si ostatně vyzkoušíme v&nbsp;dalších kapitolách).</p>

<p>To však není vše, jelikož je ve skutečnosti konfigurace poněkud složitější
resp.&nbsp;může být složitější &ndash; každý oddíl totiž může být replikován na
více počítačích, přičemž jeden z&nbsp;těchto oddílů je takzvaným
&bdquo;leaderem&ldquo; a ostatní jsou &bdquo;followeři&ldquo;. Zápis nových
zpráv popř.&nbsp;čtení se provádí vždy jen v&nbsp;rámci <i>leaderu</i>, ovšem
změny jsou replikovány na všechny kopie oddílu. Ve chvíli, kdy z&nbsp;nějakého
(libovolného) důvodu dojde k&nbsp;pádu &bdquo;leadera&ldquo;, převezme jeho
roli jeden z&nbsp;dalších uzlů. Pokud tedy existuje N uzlů s&nbsp;replikou
oddílu, bude systém funkční i ve chvíli, kdy zhavaruje N-1 uzlů! (i to si
vyzkoušíme).</p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Nejjednodušší konfigurace tématu: jediný broker, jeden oddíl, bez replikace</h2>

<p>Podívejme se nejdříve na tu nejjednodušší možnou konfiguraci tématu. Jedná
se o konfiguraci, v&nbsp;níž je téma spravováno jediným brokerem a není
prováděna žádná replikace. Zprávy (události) jsou tedy fyzicky uloženy pouze
v&nbsp;jediném souboru, přičemž zápis je všemi producenty prováděn na konec
(což je očekávané chování), zatímco čtení zpráv může být konzumenty provedeno
od libovolného offsetu. Příkladem je situace, kdy je konzument zpráv opožděn za
producentem zpráv, protože čte zprávu na offsetu 4 zatímco producent bude
zapisovat zprávu s&nbsp;offsetem 9:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
+---+---+---+---+---+---+---+---+---+
                  ^
                  |
                read
</pre>

<p>Druhá situace nastane ve chvíli, kdy je producent pomalejší než konzument a
konzument dojde na konec tématu. V&nbsp;tomto případě konzument bude čekat na
příchod (resp.&nbsp;přesněji řečeno na připojení) nové zprávy na konec
tématu:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
+---+---+---+---+---+---+---+---+---+
                                       ^
                                       |
                                     read
</pre>

<p>A samozřejmě je možné k&nbsp;tématu připojit větší množství konzumentů.
Pokud bude každý z&nbsp;konzumentů součástí jiné skupiny konzumentů, bude čtení
zpráv probíhat pro každou skupinu nezávisle na ostatních skupinách. Jinými
slovy &ndash; každá skupina konzumentů si &bdquo;schraňuje&ldquo; svůj offset,
jenž se může lišit od offsetu ostatních skupin:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
+---+---+---+---+---+---+---+---+---+  ^
      ^           ^               ^    |
      |           |               |    |
      |       read-group-1        |    |
      |                           |    |
  read-group-2                read-group-4
                                       |
                                   read-group-3
</pre>

<p><div class="rs-tip-major">Poznámka: právě tato vlastnost odlišuje Apache
Kafku od klasických message brokerů, kteří jsou založeni na použití
front.</div></p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Téma rozdělené na větší počet oddílů</h2>

<p>Poněkud komplikovanější, ale velmi častá je taková konfigurace tématu, kde
dochází k&nbsp;rozdělení zpráv do několika oddílů. V&nbsp;takovém případě
producent či producenti nezapisují zprávy do jednoho oddílu (samozřejmě na
konec), ale zápis je proveden pouze do jednoho z&nbsp;vybraných oddílů. O tom,
do kterého oddílu bude zápis (resp.&nbsp;připojení) zprávy proveden, se
rozhoduje na základě <i>klíče</i> připojeného ke zprávě. Samotná zpráva je
totiž chápána jako dvě sekvence bajtů &ndash; klíč zprávy a tělo zprávy. A
právě na základě klíče se vypočítá hash a algoritmus implementovaný
v&nbsp;samotném brokeru rozhodne, do kterého oddílu bude zpráva uložena:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Po přijetí nové zprávy tedy může být zápis proveden do tohoto místa:</p>

<pre>
                                   write
                                     |
              +---+---+---+---+---+---+  v
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Nebo se může broker rozhodnout pro připojení zprávy do posledního oddílu
atd. atd.:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+  ^
                                                 |
                                               write
</pre>

<p>A jak se provádí čtení? Kafka ve chvíli, kdy je téma rozděleno do větví,
musí přiřadit jednotlivé konzumenty (z&nbsp;jedné skupiny konzumentů)
k&nbsp;nějakému oddílu. Nejjednodušší je situace, kdy má nadá skupina
konzumentů stejný počet konzumentů, jako je počet oddílů, což je ostatně
doporučované řešení. Pak je každý konzument přiřazen jednomu oddílu a konzumuje
tedy pouze podmnožinu zpráv:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ............... konzument #1
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ........................... konzument #3
              +---+---+---+
partition #2  | ....................................... konzument #2
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |.... konzument #4
              +---+---+---+---+---+---+---+---+---+
</pre>

<p><div class="rs-tip-major">Poznámka: konzumenti jsou obecně přiřazeni
k&nbsp;oddílům &bdquo;náhodně&ldquo;.</div></p>

<p>Konzumentů v&nbsp;jedné skupině ovšem může být méně, než je počet oddílů.
V&nbsp;takovém případě musí některý konzument číst zprávy z&nbsp;většího
množství oddílů:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 |          ........... konzument #1
              +---+---+---+---+---+---+          :
partition #1  | 0 | 1 | 2 | ................................ konzument #3
              +---+---+---+
partition #2  | ............................................ konzument #2
              +---+---+---+---+---+---+---+---+---+       :
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |........
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Konzumentů ovšem může být i více. Tehdy nějaký konzument v&nbsp;daný okamžik
nepracuje, tj.&nbsp;nepřijímá zprávy a situace může vypadat takto:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ............... konzument #1
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ........................... konzument #3
              +---+---+---+
partition #2  | ....................................... konzument #2
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |.... konzument #4
              +---+---+---+---+---+---+---+---+---+
                                                        konzument #5

                                                        konzument #6

                                                        konzument #7
</pre>

<p><div class="rs-tip-major">Konzumenti z&nbsp;dalších skupin konzumentů se
budou připojovat nezávisle na ostatních skupinách. Tj.&nbsp;může existovat
skupina konzumentů s&nbsp;menším počtem konzumentů, než je počet oddílů, další
skupina může mít přesný počet konzumentů a třetí skupina naopak větší počet
konzumentů. Vše bude funkční, protože jednotlivé skupiny konzumentů jsou na
sobě nezávislé.</div></p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Téma s&nbsp;jedním replikovaným oddílem</h2>

<p>Další možná konfigurace tématu může vypadat tak, že téma má sice jediný
oddíl, ovšem tento oddíl je replikován mezi několika brokery. Příkladem může
být oddíl replikovaný mezi trojicí brokerů. V&nbsp;takovém případě je jeden
z&nbsp;těchto oddílů nazvaný <i>leader</i> a veškeré operace viděné zvnějšku
Kafky (tedy posílání zpráv a jejich konzumace) probíhá právě s&nbsp;leaderem.
Ostatní repliky jsou nazvané <i>follower(s)</i>, protože pouze sledují leadera
a synchronizují svůj obsah s&nbsp;leaderem:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...    (leader)
+---+---+---+---+---+---+---+---+---+
                  ^               ^
                  |               |
                read              |
                                 sync
                                  |
                                  |
                                  v
+---+---+---+---+---+---+---+---+---+
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |        (follower)
+---+---+---+---+---+---+---+---+---+
                                  ^
                                  |
                                  |
                                 sync
                                  |
                                  |
                                  v
+---+---+---+---+---+---+---+---+---+
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |        (follower)
+---+---+---+---+---+---+---+---+---+
</pre>

<p>K&nbsp;čemu je to však dobré? V&nbsp;případě, že nějaký broker z&nbsp;celého
Kafka clusteru zhavaruje a bude obsahovat oddíl typu <i>follower</i>, bude
komunikace pokračovat dál a teprve po znovupřipojení brokera se <i>follower</i>
postupně sesynchronizuje s&nbsp;<i>leaderem</i>. Zajímavější situace nastane ve
chvíli, kdy zhavaruje samotný <i>leader</i>. V&nbsp;takovém případě Kafka
&bdquo;povýší&ldquo;nějakého <i>followera</i> za nového <i>leadera</i>.
V&nbsp;případě, že téma (resp.&nbsp;oddíl) je replikováno na N brokerů, může
jich zhavarovat N-1 a systém bude stále funkční. I toto chování si pochopitelně
postupně otestujeme.</p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Téma s&nbsp;větším množstvím replikovaných oddílů</h2>

<p>Možnosti popsané <a href="#k04">ve čtvrté</a> a <a href="#k05">v&nbsp;páté
kapitole</a> je pochopitelně možné zkombinovat a vytvořit tak konfiguraci
tématu, které bude rozděleno na větší množství oddílů a tyto oddíly budou
replikovány mezi větší množství brokerů:</p>

<pre>
          +---+---+---+---+---+---+
oddíl #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
          +---+---+---+---+---+---+
oddíl #1  | 0 | 1 | 2 | ...
          +---+---+---+
oddíl #2  | ...
          +---+---+---+---+---+---+---+---+---+
oddíl #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
          +---+---+---+---+---+---+---+---+---+
                                  ^
                                  |
                                  |
                                 sync
                                  |
                                  |
                                  v
          +---+---+---+---+---+---+
oddíl #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
          +---+---+---+---+---+---+
oddíl #1  | 0 | 1 | 2 | ...
          +---+---+---+
oddíl #2  | ...
          +---+---+---+---+---+---+---+---+---+
oddíl #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
          +---+---+---+---+---+---+---+---+---+
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. Praktická část</h2>

<p></p>



<p><a name="k08"></a></p>
<h2 id="k08">8. Instalace Apache Kafky</h2>

<p></p>

<pre>
dataDir=/tmp/zookeeper
clientPort=2181
maxClientCnxns=0
admin.enableServer=false
</pre>

<pre>
broker.id=0
num.io.threads=8
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
log.dirs=/tmp/kafka-logs
num.partitions=1
num.recovery.threads.per.data.dir=1
#
######################## Interní témata s offsety a transakcemi #################
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
#
############################# Log Retention Policy ##############################
log.retention.hours=168
log.retention.check.interval.ms=300000
#
############################# Zookeeper #########################################
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=18000
#
############################# Group Coordinator Settings ########################
group.initial.rebalance.delay.ms=0
</pre>



<p>Po (doufejme že úspěšné) instalaci Kafky již můžeme spustit ZooKeeper a
jednu instanci brokera (a to přesně v&nbsp;tomto pořadí!). Konfigurace
ZooKeepera je uložena v&nbsp;souboru
<strong>config/zookeeper.properties</strong> a zajímat nás budou především
následující tři konfigurační volby &ndash; adresář, kam ZooKeeper ukládá svoje
data, port, který použijí brokeři a omezení počtu připojení jednoho klienta
v&nbsp;daný okamžik:</p>

<pre>
dataDir=/tmp/zookeeper
clientPort=2181
maxClientCnxns=0
</pre>

<p><div class="rs-tip-major">Poznámka: hodnota <strong>maxClientCnxns</strong>
v&nbsp;tomto případě neznamená, že by se nemohli připojit žádní klienti, ale je
že vypnutý mechanismus, který zabezpečuje infrastrukturu Kafky před některými
typy DOS útoků. Na disku, kde je adresář <strong>dataDir</strong> by také mělo
být dostatek místa, protože ZooKeeper v&nbsp;některých případech mívá větší
nároky. Další informace lze nalézt na stránce <a
href="https://zookeeper.apache.org/doc/r3.8.1/index.html">https://zookeeper.apache.org/doc/r3.8.1/index.html</a>.</div></p>

<p>Nyní již můžeme ZooKeepera spustit:</p>

<pre>
$ <strong>cd kafka/kafka_2.12-3.3.2/</strong>
$ <strong>bin/zookeeper-server-start.sh config/zookeeper.properties</strong>
</pre>

<pre>
[2023-02-04 08:37:49,555] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
...
...
[2023-02-04 08:37:49,591] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,591] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,591] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,591] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO   / /__  | (_) | | (_) | |   &lt;  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
...
...
...
[2023-02-04 08:37:49,691] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2023-02-04 08:37:49,706] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
</pre>

<p>Konfigurace jednoho brokera je uložená v&nbsp;souboru
<strong>config/server.properties</strong>. Samotný konfigurační soubor obsahuje
několik sekcí:</p>

<ol>
<li>Port, na kterém broker naslouchá, jeho ID, počet použitých vláken pro IO operace a počet vláken pro komunikaci.</li>
<li>Velikost bufferů, maximální povolená velikost požadavků (což omezuje velikost zprávy) atd.</li>
<li>Nastavení počtu <i>partitions</i></li>
<li>Nastavení <i>retence</i> dat</li>
<li>Připojení k&nbsp;Zookeeperovi</li>
</ol>

<pre>
broker.id=0
listeners=PLAINTEXT://:9092
num.network.threads=3
num.io.threads=8
&nbsp;
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
&nbsp;
log.dirs=/tmp/kafka-logs
num.partitions=1
num.recovery.threads.per.data.dir=1
log.retention.hours=168
log.segment.bytes=1073741824
&nbsp;
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=6000
</pre>

<p><div class="rs-tip-major">Poznámka: i velikost adresáře
<strong>log.dirs</strong> roste, a to mnohdy velmi rychle, takže se vyplatí
sledovat příslušné metriky.</div></p>

<p>Spuštění jednoho brokera vypadá i probíhá jednoduše:</p>

<pre>
$ <strong>cd kafka/kafka_2.12-3.3.2/</strong>
$ <strong>bin/kafka-server-start.sh config/server.properties</strong>
</pre>

<pre>
$ <strong>cd kafka/kafka_2.12-3.3.2/</strong>
$ <strong>bin/kafka-server-start.sh config/server.properties</strong>
</pre>

<pre>
[2023-02-04 08:41:47,105] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2023-02-04 08:41:47,506] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2023-02-04 08:41:47,587] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2023-02-04 08:41:47,589] INFO starting (kafka.server.KafkaServer)
[2023-02-04 08:41:47,590] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2023-02-04 08:41:47,606] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
...
...
...
[2023-02-04 08:49:52,076] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2023-02-04 08:49:52,167] INFO [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2023-02-04 08:49:52,184] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Konfigurace a spuštění ZooKeepera</h2>

<p></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Konfigurace a spuštění brokeru</h2>

<p></p>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>

<p></p>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>

<p></p>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>

<p></p>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>

<p></p>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>

<p></p>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>

<p></p>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>

<p></p>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>

<p></p>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady a konfiguračními soubory</h2>

<p>Zdrojové kódy dnes použitých producentů a konzumentů byly společně
s&nbsp;konfiguračními soubory ZooKeeperu a brokerů uloženy do repositáře, jenž
je dostupný na adrese <a
href="https://github.com/tisnik/slides/">https://github.com/tisnik/slides/</a>.
V&nbsp;případě, že nebudete chtít klonovat celý repositář, můžete namísto toho
použít odkazy na jednotlivé demonstrační příklady i další soubory, které
naleznete v&nbsp;následující tabulce:</p>

<table>
<tr><th> #</th><th>Soubor</th><th>Stručný popis</th><th>Adresa</th></tr>
<tr><td> 1</td><td></td><td></td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/">https://github.com/tisnik/slides/blob/master/files/kafka/</a></td></tr>
<tr><td> 2</td><td></td><td></td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/">https://github.com/tisnik/slides/blob/master/files/kafka/</a></td></tr>
<tr><td> 3</td><td></td><td></td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/">https://github.com/tisnik/slides/blob/master/files/kafka/</a></td></tr>
<tr><td> 4</td><td></td><td></td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/">https://github.com/tisnik/slides/blob/master/files/kafka/</a></td></tr>
<tr><td> 5</td><td></td><td></td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/">https://github.com/tisnik/slides/blob/master/files/kafka/</a></td></tr>
<tr><td> 6</td><td></td><td></td><td><a href="https://github.com/tisnik/slides/blob/master/files/kafka/">https://github.com/tisnik/slides/blob/master/files/kafka/</a></td></tr>
</table>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Kcli: is a kafka read only command line browser.<br />
<a href="https://github.com/cswank/kcli">https://github.com/cswank/kcli</a>
</li>

<li>Kcli: a kafka command line browser<br />
<a href="https://go.libhunt.com/kcli-alternatives">https://go.libhunt.com/kcli-alternatives</a>
</li>

<li>Kafka Connect and Schemas<br />
<a href="https://rmoff.net/2020/01/22/kafka-connect-and-schemas/">https://rmoff.net/2020/01/22/kafka-connect-and-schemas/</a>
</li>

<li>JSON and schemas<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas">https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas</a>
</li>

<li>What, why, when to use Apache Kafka, with an example<br />
<a href="https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/">https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/</a>
</li>

<li>When NOT to use Apache Kafka?<br />
<a href="https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/">https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/</a>
</li>

<li>Microservices: The Rise Of Kafka<br />
<a href="https://movio.co/blog/microservices-rise-kafka/">https://movio.co/blog/microservices-rise-kafka/</a>
</li>

<li>Building a Microservices Ecosystem with Kafka Streams and KSQL<br />
<a href="https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/">https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/</a>
</li>

<li>An introduction to Apache Kafka and microservices communication<br />
<a href="https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63">https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63</a>
</li>

<li>kappa-architecture.com<br />
<a href="http://milinda.pathirage.org/kappa-architecture.com/">http://milinda.pathirage.org/kappa-architecture.com/</a>
</li>

<li>Questioning the Lambda Architecture<br />
<a href="https://www.oreilly.com/ideas/questioning-the-lambda-architecture">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a>
</li>

<li>Lambda architecture<br />
<a href="https://en.wikipedia.org/wiki/Lambda_architecture">https://en.wikipedia.org/wiki/Lambda_architecture</a>
</li>

<li>Kafka &ndash; ecosystem (Wiki)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem</a>
</li>

<li>The Kafka Ecosystem - Kafka Core, Kafka Streams, Kafka Connect, Kafka REST Proxy, and the Schema Registry<br />
<a href="http://cloudurable.com/blog/kafka-ecosystem/index.html">http://cloudurable.com/blog/kafka-ecosystem/index.html</a>
</li>

<li>A Kafka Operator for Kubernetes<br />
<a href="https://github.com/krallistic/kafka-operator">https://github.com/krallistic/kafka-operator</a>
</li>

<li>Kafka Streams<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams">https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams</a>
</li>

<li>Kafka Streams<br />
<a href="http://kafka.apache.org/documentation/streams/">http://kafka.apache.org/documentation/streams/</a>
</li>

<li>Kafka Streams (FAQ)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams">https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams</a>
</li>

<li>Event stream processing<br />
<a href="https://en.wikipedia.org/wiki/Event_stream_processing">https://en.wikipedia.org/wiki/Event_stream_processing</a>
</li>

<li>Part 1: Apache Kafka for beginners - What is Apache Kafka?<br />
<a href="https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html">https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html</a>
</li>

<li>What are some alternatives to Apache Kafka?<br />
<a href="https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka">https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka</a>
</li>

<li>What is the best alternative to Kafka?<br />
<a href="https://www.slant.co/options/961/alternatives/~kafka-alternatives">https://www.slant.co/options/961/alternatives/~kafka-alternatives</a>
</li>

<li>A super quick comparison between Kafka and Message Queues<br />
<a href="https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0">https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0</a>
</li>

<li>Kafka Queuing: Kafka as a Messaging System<br />
<a href="https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system">https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system</a>
</li>

<li>Apache Kafka Logs: A Comprehensive Guide<br />
<a href="https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/">https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/</a>
</li>

<li>Microservices – Not a free lunch!<br />
<a href="http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html">http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html</a>
</li>

<li>Microservices, Monoliths, and NoOps<br />
<a href="http://blog.arungupta.me/microservices-monoliths-noops/">http://blog.arungupta.me/microservices-monoliths-noops/</a>
</li>

<li>Microservice Design Patterns<br />
<a href="http://blog.arungupta.me/microservice-design-patterns/">http://blog.arungupta.me/microservice-design-patterns/</a>
</li>

<li>REST vs Messaging for Microservices – Which One is Best?<br />
<a href="https://solace.com/blog/experience-awesomeness-event-driven-microservices/">https://solace.com/blog/experience-awesomeness-event-driven-microservices/</a>
</li>

<li>Kappa Architecture Our Experience<br />
<a href="https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf">https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf</a>
</li>

<li>Apache Kafka Streams and Tables, the stream-table duality<br />
<a href="https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854">https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854</a>
</li>

<li>Configure Self-Managed Connectors<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors">https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors</a>
</li>

<li>Schema Evolution and Compatibility<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility">https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility</a>
</li>

<li>Configuring Key and Value Converters<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters">https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters</a>
</li>

<li>Introduction to Kafka Connectors<br />
<a href="https://www.baeldung.com/kafka-connectors-guide">https://www.baeldung.com/kafka-connectors-guide</a>
</li>

<li>Kafka CLI: command to list all consumer groups for a topic?<br />
<a href="https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic">https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic</a>
</li>

<li>Java Property File Processing<br />
<a href="https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php">https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php</a>
</li>

<li>Skipping bad records with the Kafka Connect JDBC sink connector<br />
<a href="https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/">https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/</a>
</li>

<li>Kafka Connect Deep Dive – Error Handling and Dead Letter Queues<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/">https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/</a>
</li>

<li>Errors and Dead Letter Queues<br />
<a href="https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/">https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/</a>
</li>

<li>Confluent Cloud Dead Letter Queue<br />
<a href="https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html">https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html</a>
</li>

<li>Dead Letter Queues (DLQs) in Kafka<br />
<a href="https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309">https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309</a>
</li>

<li>Deserializer<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-json.html#json-schema-serializer-and-deserializer">https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-json.html#json-schema-serializer-and-deserializer</a>
</li>

<li>JSON, Kafka, and the need for schema<br />
<a href="https://mikemybytes.com/2022/07/11/json-kafka-and-the-need-for-schema/">https://mikemybytes.com/2022/07/11/json-kafka-and-the-need-for-schema/</a>
</li>

<li>Using Kafka Connect with Schema Registry<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/connect.html">https://docs.confluent.io/platform/current/schema-registry/connect.html</a>
</li>

<li>Zpracování dat reprezentovaných ve formátu JSON nástrojem jq<br />
<a href="https://www.root.cz/clanky/zpracovani-dat-reprezentovanych-ve-formatu-json-nastrojem-jq/">https://www.root.cz/clanky/zpracovani-dat-reprezentovanych-ve-formatu-json-nastrojem-jq/</a>
</li>

<li>Repositář projektu jq (GitHub)<br />
<a href="https://github.com/stedolan/jq">https://github.com/stedolan/jq</a>
</li>

<li>GitHub stránky projektu jq<br />
<a href="https://stedolan.github.io/jq/">https://stedolan.github.io/jq/</a>
</li>

<li>5 modern alternatives to essential Linux command-line tools<br />
<a href="https://opensource.com/ar­ticle/20/6/modern-linux-command-line-tools">https://opensource.com/ar­ticle/20/6/modern-linux-command-line-tools</a>
</li>

<li>Návod k nástroji jq<br />
<a href="https://stedolan.github.i­o/jq/tutorial/">https://stedolan.github.i­o/jq/tutorial/</a>
</li>

<li>jq Manual (development version)<br />
<a href="https://stedolan.github.io/jq/manual/">https://stedolan.github.io/jq/manual/</a>
</li>

<li>Introducing JSON<br />
<a href="https://www.json.org/json-en.html">https://www.json.org/json-en.html</a>
</li>

<li>Understanding JSON schema<br />
<a href="https://json-schema.org/understanding-json-schema/index.html">https://json-schema.org/understanding-json-schema/index.html</a>
</li>

<li>JDBC Sink Connector for Confluent Platform<br />
<a href="https://docs.confluent.io/kafka-connectors/jdbc/current/sink-connector/overview.html#jdbc-sink-connector-for-cp">https://docs.confluent.io/kafka-connectors/jdbc/current/sink-connector/overview.html#jdbc-sink-connector-for-cp</a>
</li>

<li>JDBC Connector (Source and Sink)<br />
<a href="https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc">https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2023</small></p>
</body>
</html>

