<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Kafka Connect: tvorba producentů a konzumentů bez nutnosti udržovat zdrojový kód</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Kafka Connect: tvorba producentů a konzumentů bez nutnosti udržovat zdrojový kód</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>V dnešním článku se ve stručnosti seznámíme s frameworkem nazvaným Kafka Connect. S využitím této technologie je možné vytvářet producenty, konzumenty a transformátory zpráv pro Apache Kafku, a to bez nutnosti tvorby a následné údržby zdrojového kódu.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Kafka Connect: tvorba producentů a konzumentů bez nutnosti udržovat zdrojový kód</a></p>
<p><a href="#k02">2. Tvorba producentů a konzumentů klasickým způsobem</a></p>
<p><a href="#k03">3. Využití frameworku Kafka Connect</a></p>
<p><a href="#k04">4. Konfigurace jednoduchého konektoru typu <i>sink</i></a></p>
<p><a href="#k05">5. Stručný popis jednotlivých konfiguračních parametrů</a></p>
<p><a href="#k06">6. Instalace Apache Kafky</a></p>
<p><a href="#k07">7. Spuštění Apache Kafky před inicializací konektoru</a></p>
<p><a href="#k08">8. Spuštění konektoru</a></p>
<p><a href="#k09">9. Poslání několika zpráv do tématu <strong>connect-test-1</strong> s&nbsp;jejich konzumací konektorem</a></p>
<p><a href="#k10">10. Skupina konzumentů (<i>consumers group</i>) vytvořená konektorem</a></p>
<p><a href="#k11">11. Konektor akceptující zprávy ve formátu JSON</a></p>
<p><a href="#k12">12. Zpracování zpráv posílaných ve formátu JSON</a></p>
<p><a href="#k13">13. Výchozí reakce na zprávu se špatným formátem</a></p>
<p><a href="#k14">14. Přeskakování zpráv s&nbsp;nekorektním formátem</a></p>
<p><a href="#k15">15. Otestování upraveného konektoru</a></p>
<p><a href="#k16">16. Poslání všech nekorektně naformátovaných zpráv do &bdquo;dead letter queue&ldquo;</a></p>
<p><a href="#k17">17. Otestování upraveného konektoru a výpis obsahu &bdquo;dead letter queue&ldquo;</a></p>
<p><a href="#k18">18. Obsah druhé části článku</a></p>
<p><a href="#k19">19. Příloha: nástroj Kafkacat (Kcat)</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Kafka Connect: tvorba producentů a konzumentů bez nutnosti udržovat zdrojový kód</h2>

<p>V&nbsp;dnešním článku se ve stručnosti seznámíme s&nbsp;frameworkem nazvaným
<i>Kafka Connect</i>. S&nbsp;využitím této relativně nové technologie (navržené
přímo od tvůrců Apache Kafky) je možné vytvářet producenty, konzumenty a taktéž
různé transformátory a konvertory zpráv pro <i>Apache Kafku</i>, a to bez
nutnosti tvorby, nasazení, monitoringu a následné údržby zdrojového kódu. Navíc
je možné definovat chování konzumentů, kteří například mohou zprávy validovat
oproti zadanému schématu, mohou přeposílat zprávy se špatným formátem do DLQ
(<i>dead letter queue</i>), ukládat zprávy do relačních (ale i jiných) databází
apod.</p>

<img src="https://i.iinfo.cz/images/447/microservices2-3.png" class="image-361670" alt="&#160;" width="450" height="134" />
<p><i>Obrázek 1: Logo nástroje Apache Kafka, kterému se budeme dnes
věnovat.</i></p>

<p><div class="rs-tip-major">Poznámka: i když jsou hned <a
href="#k02">v&nbsp;následující</a> kapitole ukázány zdrojové kódy jednoduchých
konzumentů a producentů naprogramované v&nbsp;Pythonu a Go, dokážeme
s&nbsp;využitím Kafka Connect provádět podobné operace jen
&bdquo;nasazením&ldquo; jednoduchého konfiguračního souboru
<strong>muj_konektor.properties</strong>. Dokonce ani nebude nutné instalovat
další nástroje, protože Kafka Connect je již součástí samotného systému Apache
Kafka (&bdquo;pouze&ldquo; je někdy nutné doinstalovat konkrétní konektory, což
je snadné).</div></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Tvorba producentů a konzumentů klasickým způsobem</h2>

<p>S&nbsp;využitím vhodných podpůrných knihoven může být tvorba producentů a
konzumentů pro Apache Kafku zdánlivě poměrně jednoduchou záležitostí. Příkladem
může být producent naprogramovaný v&nbsp;Pythonu, který po svém spuštění pošle
do lokálně běžící Kafky 1000 zpráv:</p>

<pre>
#!/usr/bin/env python3
&nbsp;
from kafka import KafkaProducer
from time import sleep
from json import dumps
&nbsp;
server = "localhost:9092"
topic = "upload"
&nbsp;
print("Connecting to Kafka")
producer = KafkaProducer(
    bootstrap_servers=[server], value_serializer=lambda x: dumps(x).encode("utf-8")
)
print("Connected to Kafka")
&nbsp;
for i in range(1000):
    data = {"counter": i}
    producer.send(topic, value=data)
    sleep(5)
</pre>

<p>I zdrojový kód konzumenta může být na první pohled snadný a bezchybný (ať
již toto slovo v&nbsp;kontextu IT znamená cokoli):</p>

<pre>
#!/usr/bin/env python3
&nbsp;
import sys
from kafka import KafkaConsumer
&nbsp;
server = "localhost:9092"
topic = "upload"
group_id = "group1"
&nbsp;
print("Connecting to Kafka")
consumer = KafkaConsumer(
    topic, group_id=group_id, bootstrap_servers=[server], auto_offset_reset="earliest"
)
print("Connected to Kafka")
&nbsp;
try:
    for message in consumer:
        print(
            "%s:%d:%d: key=%s value=%s"
            % (
                message.topic,
                message.partition,
                message.offset,
                message.key,
                message.value,
            )
        )
except KeyboardInterrupt:
    sys.exit()
</pre>

<a href="https://www.root.cz/obrazek/401919/"><img src="https://i.iinfo.cz/images/303/kafka-jconsole-1-prev.png" class="image-401919" alt="&#160;" width="324" height="270" /></a>
<p><i>Obrázek 2: Sledování činnosti brokeru přes standardní nástroj JConsole.</i></p>

<p>Podobným způsobem můžeme naprogramovat producenta i v&nbsp;dalších jazycích,
například v&nbsp;Go. Zde konkrétně používáme knihovnu <i>Sarama</i>, i když pro
Go existují i další podpůrné knihovny:</p>

<pre>
package main
&nbsp;
import (
        "log"
&nbsp;
        "github.com/Shopify/sarama"
)
&nbsp;
const (
        <i>// KafkaConnectionString obsahuje jméno počítače a port, na kterém běží Kafka broker</i>
        KafkaConnectionString = "localhost:9092"
&nbsp;
        <i>// KafkaTopic obsahuje jméno tématu</i>
        KafkaTopic = "test-topic"
)
&nbsp;
func main() {
        <i>// konstrukce konzumenta</i>
        producer, err := sarama.NewSyncProducer([]string{KafkaConnectionString}, nil)
&nbsp;
        <i>// kontrola chyby při připojování ke Kafce</i>
        if err != nil {
                log.Fatal(err)
        }
&nbsp;
        log.Printf("Connected to %s", KafkaConnectionString)
&nbsp;
        <i>// zajištění uzavření připojení ke Kafce</i>
        defer func() {
                if err := producer.Close(); err != nil {
                        log.Fatal(err)
                }
        }()
&nbsp;
        <i>// poslání (produkce) zprávy</i>
        msg := &amp;sarama.ProducerMessage{Topic: KafkaTopic, Value: sarama.StringEncoder("testing 123")}
        partition, offset, err := producer.SendMessage(msg)
        if err != nil {
                log.Printf("FAILED to send message: %s\n", err)
        } else {
                log.Printf("&gt; message sent to partition %d at offset %d\n", partition, offset)
        }
&nbsp;
        log.Print("Done")
}
</pre>

<p>A nakonec se podívejme na konzumenta, opět naprogramovaného v&nbsp;jazyce
Go:</p>

<pre>
package main
&nbsp;
import (
        "log"
&nbsp;
        "github.com/Shopify/sarama"
)
&nbsp;
const (
        <i>// KafkaConnectionString obsahuje jméno počítače a port, na kterém běží Kafka broker</i>
        KafkaConnectionString = "localhost:9092"
&nbsp;
        <i>// KafkaTopic obsahuje jméno tématu</i>
        KafkaTopic = "test-topic"
)
&nbsp;
func main() {
        <i>// konstrukce konzumenta</i>
        consumer, err := sarama.NewConsumer([]string{KafkaConnectionString}, nil)
&nbsp;
        <i>// kontrola chyby při připojování ke Kafce</i>
        if err != nil {
                log.Fatal(err)
        }
&nbsp;
        log.Printf("Connected to %s", KafkaConnectionString)
&nbsp;
        <i>// zajištění uzavření připojení ke Kafce</i>
        defer func() {
                if err := consumer.Close(); err != nil {
                        log.Fatal(err)
                }
        }()
&nbsp;
        <i>// přihlášení ke zvolenému tématu</i>
        partitionConsumer, err := consumer.ConsumePartition(KafkaTopic, 0, sarama.OffsetNewest)
        if err != nil {
                log.Fatal(err)
        }
&nbsp;
        <i>// zajištění ukončení přihlášení ke zvolenému tématu</i>
        defer func() {
                if err := partitionConsumer.Close(); err != nil {
                        log.Fatal(err)
                }
        }()
&nbsp;
        <i>// postupné čtení zpráv, které byly do zvoleného tématu publikovány</i>
        consumed := 0
        for {
                msg := &lt;-partitionConsumer.Messages()
                // vypíšeme pouze offset zprávy, její klíč a tělo (value, payload)
                log.Printf("Consumed message offset %d: %s:%s", msg.Offset, msg.Key, msg.Value)
                consumed++
        }
&nbsp;
        <i>// výpis počtu zpracovaných zpráv (ovšem sem se stejně nedostaneme :-)</i>
        log.Printf("Consumed: %d", consumed)
        log.Print("Done")
}
</pre>

<p>Mohlo by se zdát, že pokud je naprogramování producenta nebo konzumenta pro
Kafku otázkou několika (desítek) řádků, nemá asi význam se frameworkem Kafka
Connect zabývat. Ve skutečnosti je však existence samotného kódu jen nezbytnou
podmínkou pro nasazení producenta/konzumenta do produkce. Kód je nutné
otestovat, v&nbsp;tomto případě nejenom jednotkovými testy, ale i testy
integračními (a záhy zjistíte, že kód obsahuje spoustu nedostatků). Dále je
nutné mít k&nbsp;dispozici skripty pro nasazení nové verze služby (CD), musí se
nastavit logování, monitoring, pravidla pro nasazení nové verze atd. A
samozřejmě je nutné sledovat, zda použité knihovny nemají hlášená nová CVE
popř.&nbsp;zajistit, že kód bude přeložitelný a/nebo spustitelný i po vydání
nové verze jazyka.  S&nbsp;využitím frameworku Kafka Connect mnoho
z&nbsp;těchto požadavků odpadá, což uvidíme především ve druhém článku.</p>

<a href="https://www.root.cz/obrazek/362664/"><img src="https://i.iinfo.cz/images/138/microservices4-1-prev.png" class="image-362664" alt="&#160;" width="370" height="237" /></a>
<p><i>Obrázek 3: Příklad použití ekosystému Kafky (Kafka Streams, konektory pro databáze atd.).</i></p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Využití frameworku Kafka Connect</h2>

<p>Některé možnosti využití frameworku Kafka Connect jsou ukázány na
následujících diagramech i s&nbsp;příslušným popiskem:</p>

<img src="https://i.iinfo.cz/images/485/kafka-connect-1-1.png" class="image-763557" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" width="668" height="120" />
<p><i>Obrázek 4: Zprávy jsou přes jeden konektor načítány z&nbsp;databáze
(například z&nbsp;PostgreSQL) a posílány do zvoleného tématu v&nbsp;Apache
Kafce. Odtud si je načítá (konzumuje) další konektor, který zprávy ukládá do
Hadoopu.</i></p>

<img src="https://i.iinfo.cz/images/485/kafka-connect-1-2.png" class="image-763558" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" width="668" height="142" />
<p><i>Obrázek 5: Zprávy jsou získávány z&nbsp;fronty <a
href="https://www.root.cz/clanky/protokol-mqtt-komunikacni-standard-pro-iot/">MQTT</a>
(tedy z&nbsp;jiného message brokeru) a opět ukládány do zvoleného tématu. Odtud
jsou konzumovány druhým konektorem, který zprávy posílá do třetího message
brokeru, zde konkrétně do Amazon SQS (Amazon Simple Queue Service).</i></p>

<img src="https://i.iinfo.cz/images/485/kafka-connect-1-3.png" class="image-763559" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" width="698" height="367" />
<p><i>Obrázek 6: Alternativa k&nbsp;diagramu z&nbsp;obrázku číslo 4. Ke
zvolenému tématu Apache Kafky je připojeno několik konektorů. Ty zprávy
souběžně konzumují a ukládají do Amazon S3 (Amazon Simple Storage Service), do
textového logu a souběžně například do dokumentové databáze.</i></p>

<img src="https://i.iinfo.cz/images/485/kafka-connect-1-4.png" class="image-763560" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" width="698" height="358" />
<p><i>Obrázek 7: Zprávy produkované přes Kafka Connect do zvoleného tématu se
nijak neliší od zpráv produkovaných jakýmkoli jiným producentem. Proto tyto
zprávy můžeme zpracovávat i dalšími nástroji, vlastními konzumenty, přes kSQL
atd. atd.</i></p>

<p><div class="rs-tip-major">Poznámka: opět si pro jistotu připomeňme, že
všechny předchozí architektury lze realizovat jen
&bdquo;nasazením&ldquo;několika souborů <strong>.properties</strong>
popř.&nbsp;zkopírováním JARu s&nbsp;příslušným konektorem.</div></p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Konfigurace jednoduchého konektoru typu <i>sink</i></h2>

<p>Podívejme se, jak může vypadat konfigurace velmi jednoduchého konektoru typu
<i>sink</i>, který bude konzumovat zprávy z&nbsp;vybraného tématu
(<i>topic</i>) a bude je ukládat do textového souboru, jehož jméno je opět
uvedeno v&nbsp;konfiguračním souboru. Celá konfigurace je popsána
v&nbsp;jediném (a to velmi krátkém) souboru ve formátu s&nbsp;koncovkou
&bdquo;.properties&ldquo;. Tento formát, v&nbsp;němž jsou uloženy dvojice
klíč(string)=hodnota(string), je velmi často používán v&nbsp;ekosystému Javy
&ndash; nejenom vlastního jazyka, ale především JVM &ndash; takže jeho podpora
v&nbsp;Apache Kafce nemusí být velkým překvapením (na rozdíl od jiných
ekosystémů, v&nbsp;nichž se spíše setkáme s&nbsp;konfiguračními soubory ve
formátu JSON, TOML, YAML atd.).</p>

<p>Vraťme se však ke konfiguraci našeho konektoru. Bude se (alespoň prozatím)
jednat o specifikaci devíti parametrů:</p>

<pre>
name=local-file-sink
connector.class=FileStreamSink
tasks.max=1
file=test.sink.txt
topics=connect-test-1
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.storage.StringConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false
</pre>

<p><div class="rs-tip-major">Poznámka: povšimněte si, že jména parametrů (tedy
klíč) tvoří určitou hierarchii. Můžeme zde vidět především skupiny
(<strong>connector</strong>, <strong>key</strong>, <strong>value</strong>) a
podskupiny (<strong>key.converter</strong>, <strong>value.converter</strong>).
Dále je důležité, že hodnoty jsou uloženy jako řetězce, i když se například
jedná o celá čísla (v&nbsp;našem případě konkrétně o hodnotu 1) nebo
pravdivostní hodnoty (false). V&nbsp;<i>property</i> souborech se tedy
řetězcové hodnoty nevkládají do apostrofů ani uvozovek atd. &ndash; o případný
parsing z&nbsp;řetězce na celé číslo, pravdivostní hodnotu, časové razítko
apod. se musí postarat až aplikace, která tento soubor načítá.</div></p>

<p>V&nbsp;případě, že některou z&nbsp;voleb v&nbsp;našem <strong>.properties</strong> souboru neuvedeme, bude tato volba načtena ze souboru <strong>config/connect-standalone.properties</strong>:</p>

<pre>
bootstrap.servers=localhost:9092
&nbsp;
key.converter.schemas.enable=true
value.converter.schemas.enable=true
&nbsp;
offset.storage.file.filename=/tmp/connect.offsets
&nbsp;
offset.flush.interval.ms=10000
&nbsp;
#plugin.path=
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Stručný popis jednotlivých konfiguračních parametrů</h2>

<p>Význam parametrů uložených v&nbsp;konfiguračním souboru je následující:</p>

<ol>

<li><strong>name</strong>: jméno konektoru, které by mělo být unikátní.</li>

<li><strong>connector.class</strong>: třída implementující konektor. Jméno
třídy <strong>FileStreamSink</strong> naznačuje, že se jedná o třídu, jenž je
standardní součástí celého frameworku. V&nbsp;opačném případě by zde bylo
uvedeno celé jméno i se jménem balíčku, popř.&nbsp;se zde může vyskytnout jméno
JAR souboru s&nbsp;balíčky (s&nbsp;takovými třídami se setkáme příště).</li>

<li><strong>tasks.max</strong>: maximální počet souběžně spuštěných úloh pro
zpracování zpráv. Tato hodnota není zcela směrodatná, neboť framework může
počet úloh snížit.</li>

<li><strong>file</strong>: jméno souboru, do kterého se budou ukládat zprávy
přečtené z&nbsp;vybraného tématu.</li>

<li><strong>topics</strong>: téma či témata, která budou konektorem
konzumována.</li>

<li><strong>key.converter</strong>: třída, která je použita pro načtení a další
zpracování klíče (<i>key</i>), který je součástí zprávy. V&nbsp;našem případě
klíč přečteme a převedeme na řetězec (obecně se totiž jedná o sekvenci
bajtů).</li>

<li><strong>value.converter</strong>: podobný význam, jako má předchozí volba,
nyní ovšem pro hodnotu zprávy, tedy pro její tělo.</li>

<li><strong>key.converter.schemas.enable</strong>: formát klíče může být
validován s&nbsp;využitím schématu (a samotné schéma je buď součástí zprávy
nebo je přečtené z&nbsp;nakonfigurovaného úložiště). Prozatím schémata používat
nebudeme, takže je vhodné explicitně použití schémat zakázat.</li>

<li><strong>value.converter.schemas.enable</strong>: podobný význam, jako má
předchozí volba, nyní ovšem pro hodnotu zprávy, tedy pro její tělo.</li>

</ol>

<p><div class="rs-tip-major">Poznámka: samotná implementace konektoru může být
velmi jednoduchá &ndash; viz <a
href="https://github.com/apache/kafka/blob/2.6/connect/file/src/main/java/org/apache/kafka/connect/file/FileStreamSinkTask.java">FileStreamSinkTask.java</a>.</div></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Instalace Apache Kafky</h2>

<p>V&nbsp;případě, že je na počítači nainstalováno JRE, je instalace Kafky pro
testovací účely triviální. Tarball s&nbsp;instalací Kafky lze získat
z&nbsp;adresy <a
href="https://downloads.apache.org/kafka/3.3.2/kafka_2.13-3.3.2.tgz">https://downloads.apache.org/kafka/3.3.2/kafka_2.13-3.3.2.tgz</a>.
Stažení a rozbalení tarballu:</p>

<pre>
$ <strong>wget https://downloads.apache.org/kafka/3.3.2/kafka_2.13-3.3.2.tgz</strong>
$ <strong>tar xvfz kafka_2.13-3.3.2.tgz</strong>
$ <strong>cd kafka_2.13-3.3.2/</strong>
</pre>

<p>Po rozbalení získáme adresář, v&nbsp;němž se nachází všechny potřebné Java
archivy (JAR), konfigurační soubory (v&nbsp;podadresáři
<strong>config</strong>) a několik pomocných skriptů (v&nbsp;podadresáři
<strong>bin</strong>). Pro spuštění Zookeepera a brokerů je zapotřebí mít
nainstalovánu JRE (Java Runtime Environment) a samozřejmě též nějaký shell
(BASH, cmd, ...).</p>

<pre>
.
├── bin
│   └── windows
├── config
│   └── kraft
├── libs
├── licenses
└── site-docs

7 directories
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. Spuštění Apache Kafky před inicializací konektoru</h2>

<p>Po (doufejme že úspěšné) instalaci Kafky již můžeme spustit ZooKeeper a
jednu instanci brokera (a to přesně v&nbsp;tomto pořadí!). Konfigurace
ZooKeepera je uložena v&nbsp;souboru
<strong>config/zookeeper.properties</strong> a zajímat nás budou především
následující tři konfigurační volby &ndash; adresář, kam ZooKeeper ukládá svoje
data, port, který použijí brokeři a omezení počtu připojení jednoho klienta
v&nbsp;daný okamžik:</p>

<pre>
dataDir=/tmp/zookeeper
clientPort=2181
maxClientCnxns=0
</pre>

<p><div class="rs-tip-major">Poznámka: hodnota <strong>maxClientCnxns</strong>
v&nbsp;tomto případě neznamená, že by se nemohli připojit žádní klienti, ale je
že vypnutý mechanismus, který zabezpečuje infrastrukturu Kafky před některými
typy DOS útoků. Na disku, kde je adresář <strong>dataDir</strong> by také mělo
být dostatek místa, protože ZooKeeper v&nbsp;některých případech mívá větší
nároky. Další informace lze nalézt na stránce <a
href="https://zookeeper.apache.org/doc/r3.8.1/index.html">https://zookeeper.apache.org/doc/r3.8.1/index.html</a>.</div></p>

<p>Nyní již můžeme ZooKeepera spustit:</p>

<pre>
$ <strong>cd kafka/kafka_2.12-3.3.2/</strong>
$ <strong>bin/zookeeper-server-start.sh config/zookeeper.properties</strong>
</pre>

<pre>
[2023-02-04 08:37:49,555] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
...
...
[2023-02-04 08:37:49,591] INFO  (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,591] INFO   ______                  _                                           (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,591] INFO  |___  /                 | |                                          (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,591] INFO     / /    ___     ___   | | __   ___    ___   _ __     ___   _ __    (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO    / /    / _ \   / _ \  | |/ /  / _ \  / _ \ | '_ \   / _ \ | '__| (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO   / /__  | (_) | | (_) | |   &lt;  |  __/ |  __/ | |_) | |  __/ | |     (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO  /_____|  \___/   \___/  |_|\_\  \___|  \___| | .__/   \___| |_| (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO                                               | |                      (org.apache.zookeeper.server.ZooKeeperServer)
[2023-02-04 08:37:49,592] INFO                                               |_|                      (org.apache.zookeeper.server.ZooKeeperServer)
...
...
...
[2023-02-04 08:37:49,691] INFO zookeeper.request_throttler.shutdownTimeout = 10000 (org.apache.zookeeper.server.RequestThrottler)
[2023-02-04 08:37:49,706] INFO Using checkIntervalMs=60000 maxPerMinute=10000 maxNeverUsedIntervalMs=0 (org.apache.zookeeper.server.ContainerManager)
</pre>

<p>Konfigurace jednoho brokera je uložená v&nbsp;souboru
<strong>config/server.properties</strong>. Samotný konfigurační soubor obsahuje
několik sekcí:</p>

<ol>
<li>Port, na kterém broker naslouchá, jeho ID, počet použitých vláken pro IO operace a počet vláken pro komunikaci.</li>
<li>Velikost bufferů, maximální povolená velikost požadavků (což omezuje velikost zprávy) atd.</li>
<li>Nastavení počtu <i>partitions</i></li>
<li>Nastavení <i>retence</i> dat</li>
<li>Připojení k&nbsp;Zookeeperovi</li>
</ol>

<pre>
broker.id=0
listeners=PLAINTEXT://:9092
num.network.threads=3
num.io.threads=8
&nbsp;
socket.send.buffer.bytes=102400
socket.receive.buffer.bytes=102400
socket.request.max.bytes=104857600
&nbsp;
log.dirs=/tmp/kafka-logs
num.partitions=1
num.recovery.threads.per.data.dir=1
log.retention.hours=168
log.segment.bytes=1073741824
&nbsp;
zookeeper.connect=localhost:2181
zookeeper.connection.timeout.ms=6000
</pre>

<p><div class="rs-tip-major">Poznámka: i velikost adresáře
<strong>log.dirs</strong> roste, a to mnohdy velmi rychle, takže se vyplatí
sledovat příslušné metriky.</div></p>

<p>Spuštění jednoho brokera vypadá i probíhá jednoduše:</p>

<pre>
$ <strong>cd kafka/kafka_2.12-3.3.2/</strong>
$ <strong>bin/kafka-server-start.sh config/server.properties</strong>
</pre>

<pre>
[2023-02-04 08:41:47,105] INFO Registered kafka:type=kafka.Log4jController MBean (kafka.utils.Log4jControllerRegistration$)
[2023-02-04 08:41:47,506] INFO Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation (org.apache.zookeeper.common.X509Util)
[2023-02-04 08:41:47,587] INFO Registered signal handlers for TERM, INT, HUP (org.apache.kafka.common.utils.LoggingSignalHandler)
[2023-02-04 08:41:47,589] INFO starting (kafka.server.KafkaServer)
[2023-02-04 08:41:47,590] INFO Connecting to zookeeper on localhost:2181 (kafka.server.KafkaServer)
[2023-02-04 08:41:47,606] INFO [ZooKeeperClient Kafka server] Initializing a new session to localhost:2181. (kafka.zookeeper.ZooKeeperClient)
...
...
...
[2023-02-04 08:49:52,076] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2023-02-04 08:49:52,167] INFO [BrokerToControllerChannelManager broker=0 name=alterPartition]: Recorded new controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
[2023-02-04 08:49:52,184] INFO [BrokerToControllerChannelManager broker=0 name=forwarding]: Recorded new controller, from now on will use node localhost:9092 (id: 0 rack: null) (kafka.server.BrokerToControllerRequestThread)
</pre>

<p>Alternativně je možné ZooKeepera i Kafku (jednu instanci brokera) spustit
v&nbsp;Dockeru:</p>

<pre>
$ <strong>docker run -p 2181:2181 -p 9092:9092 --env ADVERTISED_HOST=`docker-machine ip \`docker-machine active\`` --env ADVERTISED_PORT=9092 spotify/kafka</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: předchozí nastavení předpokládá, že
současně na stejném stroji nepoběží žádná další instance Kafky ani Zookeepera.
Pokud budete potřebovat spustit větší množství brokerů, je nutné minimálně
změnit mapování portů (přepínače <strong>-p</strong>).</div></p>



<p><a name="k08"></a></p>
<h2 id="k08">8. Spuštění konektoru</h2>

<p>Ve chvíli, kdy je spuštěn jak ZooKeeper, tak i minimálně jeden broker, již
můžeme spustit náš jednoduchý konektor. Prozatím spustíme jediný konektor bez
možnosti jeho distribuce přes více systémů. Z&nbsp;tohoto důvodu se pro
spuštění použije skript <strong>bin/connect-standalone.sh</strong>, kterému se
předá výchozí konfigurační soubor
<strong>config/connect-standalone.properties</strong> i námi upravený
konfigurační soubor <strong>config/connect-fie-sink.properties</strong>:</p>

<pre>
$ <strong>cd kafka/kafka_2.12-3.3.2/</strong>
$ <strong>bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-sink.properties</strong>
</pre>

<p>Nejprve by se měly vypsat obecné informace o konfiguraci:</p>

<pre>
[2023-02-04 08:46:13,573] INFO Kafka Connect standalone worker initializing ... (org.apache.kafka.connect.cli.ConnectStandalone:68)
[2023-02-04 08:46:13,580] INFO WorkerInfo values: 
        jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:
...
...
...
</pre>

<p>A následně i informace o tom, že došlo k&nbsp;připojení konektoru, a to
včetně jména tématu, identifikace partition atd.:</p>

<pre>
[2023-02-04 08:47:06,680] INFO [local-file-sink|task-0] [Consumer clientId=connector-consumer-local-file-sink-0, groupId=connect-local-file-sink] Notifying assignor about the new Assignment(partitions=[connect-test-1-0]) (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:300)
[2023-02-04 08:47:06,682] INFO [local-file-sink|task-0] [Consumer clientId=connector-consumer-local-file-sink-0, groupId=connect-local-file-sink] Adding newly assigned partitions: connect-test-1-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:312)
[2023-02-04 08:47:06,689] INFO [local-file-sink|task-0] [Consumer clientId=connector-consumer-local-file-sink-0, groupId=connect-local-file-sink] Found no committed offset for partition connect-test-1-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1538)
[2023-02-04 08:47:06,698] INFO [local-file-sink|task-0] [Consumer clientId=connector-consumer-local-file-sink-0, groupId=connect-local-file-sink] Resetting offset for partition connect-test-1-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
</pre>

<p>Pro kontrolu, zda vzniklo nové téma <strong>connect-test-1</strong> si
všechna témata můžeme nechat vypsat:</p>

<pre>
$ <strong>cd kafka/kafka_2.12-3.3.2/</strong>
<strong>bin/kafka-topics.sh --bootstrap-server=localhost:9092 --list</strong>
&nbsp;
__consumer_offsets
connect-test-1
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Poslání několika zpráv do tématu <strong>connect-test-1</strong> s&nbsp;jejich konzumací konektorem</h2>

<p>Nyní do nově vytvořeného tématu <strong>connect-test-1</strong> pošleme
několik zpráv. V&nbsp;případě, že zůstaneme u standardních nástrojů
poskytovaných samotným systémem Apache Kafka, se pro posílání zpráv
z&nbsp;příkazové řádky může využít skript
<strong>kafka-console-producer.sh</strong>, a to konkrétně následujícím
způsobem:</p>

<pre>
$ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic connect-test-1</strong>
</pre>

<p>Skript nyní očekává, že na standardní vstup zapíšeme těla zpráv oddělená
<strong>Enterem</strong>. Ukončení posílání zpráv je snadné &ndash; použijeme
standardní klávesovou zkratku <strong>Ctrl+D</strong>:</p>

<pre>
&gt;foo
&gt;bar
&gt;baz
&lt;Ctrl-D&gt;
</pre>

<p>Můžeme dokonce posílat i zprávy obsahující kromě těla (<i>value,
content</i>) i klíč (<i>key</i>). V&nbsp;tomto případě je vhodné explicitně
specifikovat, jakým způsobem je klíč oddělen od těla zprávy. Použijeme
například dvojtečku (:) ve funkci oddělovače:</p>

<pre>
$ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic conect-test-1 -property parse.key=true --property key.separator=:</strong>
&gt;first:1
&gt;second:2
&gt;third:3
</pre>

<p>Pro kontrolu, jaké zprávy byly do tématu poslány, lze použít jak standardní
nástroje Apache Kafky (konzument), tak i vlastní skripty nebo nástroj typu
<i>Kafkacat</i> (nyní přejmenován na <i>kcat</i>, aby neobsahoval jméno
&bdquo;Kafka&ldquo;, což mi osobně přijde jako poměrně absurdní požadavek
&ndash; takový skoro až kafkovský). Kafkacat spustíme v&nbsp;režimu konzumenta
(<strong>-C</strong>) a necháme si vypsat jak těla zpráv, tak i klíče:</p>

<pre>
$ <strong>kafkacat -C -b localhost:9092 -t connect-test-1 -K:</strong>
:foo
:bar
:baz
first:1
second:2
third:3
</pre>

<p>Ovšem samozřejmě nás bude zajímat to nejdůležitější &ndash; jak a zda vůbec
vlastně konektor pracuje. V&nbsp;adresáři, z&nbsp;něhož byl konektor spuštěn,
by se měl nacházet soubor <strong>test.sing.txt</strong>, jehož obsah si
pochopitelně můžeme nechat vypsat:</p>

<pre>
$ <strong>cat test.sink.txt</strong>
&nbsp;
foo
bar
baz
1
2
3
1
2
</pre>

<p><div class="rs-tip-major">Poznámka: povšimněte si důležité skutečnosti
&ndash; zapsány jsou pouze těla zpráv, nikoli klíče. To je výchozí chování
konektoru založeného na třídě <strong>FileStreamSink</strong>. Příště si
ukážeme, jak je možné zprávu před uložením transformovat tak, aby se pracovalo
i s&nbsp;klíči (pokud je to pochopitelně vyžadováno).</div></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Skupina konzumentů (<i>consumers group</i>) vytvořená konektorem</h2>

<p>Konektor se po svém spuštění přidá do skupiny konzumentů, jejíž jméno je
odvozeno od jeho jména uvedeného v&nbsp;souboru <strong>.properties</strong> a
typu (lokální či distribuovaný konektor). I o této vlastnosti se můžeme
přesvědčit a to velmi snadno: vypsáním všech skupin konzumentů, které Apache
Kafka regitruje:</p>

<pre>
$ <strong>./bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --all-groups count_errors --describe</strong>
</pre>

<p>Výpis by měl vypadat následovně (kromě jména konzumenta, které je
generováno):</p>

<pre>
GROUP                   TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                               HOST            CLIENT-ID
connect-local-file-sink connect-test-1  0          8               8               0               connector-consumer-local-file-sink-0-e6443ddc-4623-4995-a95d-9e659c0c657d /127.0.0.1      connector-consumer-local-file-sink-0
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. Konektor akceptující zprávy ve formátu JSON</h2>

<p>V&nbsp;praxi se poměrně často setkáme s&nbsp;požadavkem na zpracování zpráv
uložených ve formátu JSON. Tento formát může mít nejenom samotné tělo zprávy,
ale i její klíč (tj.&nbsp;klíč nemusí být pouhým celým číslem nebo řetězcem,
ale může mít složitější strukturu). Modifikace konektoru typu <i>sink</i>
takovým způsobem, aby kontroloval, zda klíče i hodnoty zpráv odpovídají formátu
JSON, je relativně snadná. Připomeňme si, jak vlastně vypadala konfigurace
původního konektoru:</p>

<pre>
name=local-file-sink
connector.class=FileStreamSink
tasks.max=1
file=test.sink.txt
topics=connect-test-1
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.storage.StringConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false
</pre>

<p>Od této konfigurace odvodíme konfiguraci novou. Změníme především jméno
konektoru i jméno souboru, do kterého bude konektor zprávy ukládat. A taktéž
změníme jméno tématu:</p>

<pre>
name=<strong>local-file-sink-json</strong>
file=<strong>test.sink.jsons</strong>
topics=<strong>connect-test-json</strong>
</pre>

<p>Ovšem modifikovat musíme především jméno třídy použité při interpretaci
(&bdquo;konverzi&ldquo;) klíče a těla zprávy. Namísto třídy
<strong>org.apache.kafka.connect.storage.StringConverter</strong> se bude
jednat o třídu <strong>org.apache.kafka.connect.json.JsonConverter</strong>.
Pro zprávy prozatím nemáme definované schéma, takže stále necháme kontrolu vůči
schématům zakázánu:</p>

<pre>
key.converter=<strong>org.apache.kafka.connect.json.JsonConverter</strong>
value.converter=<strong>org.apache.kafka.connect.json.JsonConverter</strong>
</pre>

<p>Nový konfigurační soubor by měl vypadat následovně (změněné položky jsou
zvýrazněny):</p>

<pre>
name=<strong>local-file-sink-json</strong>
connector.class=FileStreamSink
tasks.max=1
file=<strong>test.sink.jsons</strong>
topics=<strong>connect-test-json</strong>
key.converter=<strong>org.apache.kafka.connect.json.JsonConverter</strong>
value.converter=<strong>org.apache.kafka.connect.json.JsonConverter</strong>
key.converter.schemas.enable=false
value.converter.schemas.enable=false
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Zpracování zpráv posílaných ve formátu JSON</h2>

<p>V&nbsp;novém terminálu spustíme druhý konektor, a to příkazem:</p>

<pre>
$ <strong>cd kafka/kafka_2.12-3.3.2/</strong>
$ <strong>bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-sink-2.properties</strong>
</pre>

<p>Konektor při své inicializaci vypíše několik obrazovek logů, ovšem důležité
jsou jen poslední záznamy, ve kterých se píše, zda při spuštění nastala chyba
či nikoli:</p>

<pre>
...
...
...
[2023-02-06 17:38:49,169] INFO [local-file-sink-json|task-0] [Consumer clientId=connector-consumer-local-file-sink-json-0, groupId=connect-local-file-sink-json] Found no committed offset for partition connect-test-json-0 (org.apache.kafka.clients.consumer.internals.ConsumerCoordinator:1538)
[2023-02-06 17:38:49,186] INFO [local-file-sink-json|task-0] [Consumer clientId=connector-consumer-local-file-sink-json-0, groupId=connect-local-file-sink-json] Resetting offset for partition connect-test-json-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:9092 (id: 0 rack: null)], epoch=0}}. (org.apache.kafka.clients.consumer.internals.SubscriptionState:399)
</pre>

<p>Nyní pošleme do tématu <strong>connect-test-json</strong> několik zpráv,
které jsou všechny reprezentovány v&nbsp;JSONu (jak klíče, tak i hodnoty). U
poslední zprávy je klíč vynechán, což je ovšem korektní:</p>

<pre>
$ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic connect-test-json -property parse.key=true --property key.separator=;</strong>
&nbsp;
&gt;{"foo":1};{"bar":2}
&gt;{"baz":false}
&gt;42
</pre>

<p>Konektor by měl všechny tyto zprávy zpracovat a vypsat do souboru
<strong>test.sink.jsons</strong>. Opět zde nalezneme jen těla zpráv, nikoli
jejich klíče:</p>

<pre>
$ <strong>cat test.sink.jsons</strong>
&nbsp;
{foo=1}
{baz=false}
42
</pre>



<p><a name="k13"></a></p>
<h2 id="k13">13. Výchozí reakce na zprávu se špatným formátem</h2>

<p>Nyní se pokusme poslat do tématu <strong>connect-test-json</strong> zprávu,
která <i>není</i> uložena ve formátu JSON:</p>

<pre>
$ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic connect-test-json -property parse.key=true --property key.separator=;</strong>
&nbsp;
&gt;xyzzy
</pre>

<p>V&nbsp;logu connectoru by se měla zobrazit tato chyba (resp.&nbsp;přesněji
řečeno výjimka):</p>

<pre>
[2023-02-06 17:45:34,590] ERROR [local-file-sink-json|task-0] WorkerSinkTask{id=local-file-sink-json-0} Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted (org.apache.kafka.connect.runtime.WorkerTask:196)
org.apache.kafka.connect.errors.ConnectException: Tolerance exceeded in error handler
</pre>

<p>Výše uvedená výjimka je způsobena touto výjimkou:</p>

<pre>
Caused by: org.apache.kafka.common.errors.SerializationException: com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'xyzzy': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
 at [Source: (byte[])"xyzzy"; line: 1, column: 6]
        at org.apache.kafka.connect.json.JsonDeserializer.deserialize(JsonDeserializer.java:66)
        at org.apache.kafka.connect.json.JsonConverter.toConnectData(JsonConverter.java:322)
        ... 17 more
Caused by: com.fasterxml.jackson.core.JsonParseException: Unrecognized token 'xyzzy': was expecting (JSON String, Number, Array, Object or token 'null', 'true' or 'false')
 at [Source: (byte[])"xyzzy"; line: 1, column: 6]
</pre>

<p>Následně je konektor ukončen:</p>

<pre>
[2023-02-06 17:45:34,600] INFO [local-file-sink-json|task-0] Metrics reporters closed (org.apache.kafka.common.metrics.Metrics:703)
[2023-02-06 17:45:34,605] INFO [local-file-sink-json|task-0] App info kafka.consumer for connector-consumer-local-file-sink-json-0 unregistered (org.apache.kafka.common.utils.AppInfoParser:83)
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Přeskakování zpráv s&nbsp;nekorektním formátem</h2>

<p>Chování konektoru, s&nbsp;nímž jsme se setkali <a
href="#k13">v&nbsp;předchozí kapitole</a> pochopitelně nemusí vyhovovat pro
každou situaci. Framework <i>Kafka Connect</i> ovšem nabízí i další možnosti
zpracování zpráv, které nemají korektní formát. Jedna z&nbsp;nabízených
možností spočívá v&nbsp;přeskakování těchto zpráv. Úprava konfiguračního
souboru konektoru je v&nbsp;tomto případě triviální, protože do něj postačuje
přidat jediný řádek:</p>

<pre>
<strong>errors.tolerance=all</strong>
</pre>

<p>Navíc ještě změníme řádek se jménem souboru, do kterého se budou ukládat
zprávy s&nbsp;<i>korektním</i> formátem:</p>

<pre>
file=<strong>test.sink3.jsons</strong>
</pre>

<p>Výsledná podoba upraveného konfiguračního souboru je následující:</p>

<pre>
name=local-file-sink-json
connector.class=FileStreamSink
tasks.max=1
file=<strong>test.sink3.jsons</strong>
topics=connect-test-json
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false
<strong>errors.tolerance=all</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: na tomto místě je vhodné si uvědomit, že
tato jednořádková změna by byla v&nbsp;případě, kdyby byl konzument
naprogramován například v&nbsp;Javě, Go či Pythonu, už složitější a
s&nbsp;velkou pravděpodobností by vyžadovala i úpravu testů atd.</div></p>



<p><a name="k15"></a></p>
<h2 id="k15">15. Otestování upraveného konektoru</h2>

<p>Nově nakonfigurovaný konektor je samozřejmě vhodné si otestovat a vyzkoušet
si tak, jak a zda vůbec reaguje na zprávy s&nbsp;nekorektním formátem. Konektor
tedy spustíme, a to konkrétně následujícím příkazem:</p>

<pre>
$ <strong>bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-sink-3.properties</strong>
</pre>

<p>Dále v&nbsp;novém terminálu spustíme producenta zpráv ovládaného
z&nbsp;příkazové řádky. Povšimněte si toho, že stále používáme téma
nazvané <strong>connect-test-json</strong>:</p>

<pre>
$ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic connect-test-json -property parse.key=true --property key.separator=;</strong>
</pre>

<p>Do tématu pošleme pět zpráv s&nbsp;tímto formátem (znak &gt; na začátku
řádku je výzva vypisovaná řádkovým klientem):</p>

<pre>
&gt;{"1st":1}
&gt;{"2nd":2}
&gt;{"improper":message}
&gt;"proper one"
&gt;xyzzy
</pre>

<p>Producenta nyní můžeme ukončit klávesovou zkratkou <strong>CTRL+D</strong> a
zjistit, jaké zprávy (resp.&nbsp;přesněji řečeno jejich těla) byly zapsány do
souboru <strong>test.sink3.jsons</strong>:</p>

<pre>
$ <strong>cat test.sink3.jsons</strong>
</pre>

<p>Z&nbsp;výpisu obsahu tohoto souboru by mělo být patrné, že zapsány byly
pouze ty zprávy, jejichž těla jsou uložena ve formátu JSON. Ostatní zprávy by
měly být přeskočeny:</p>

<pre>
{1st=1}
{2nd=2}
proper one
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. Poslání všech nekorektně naformátovaných zpráv do &bdquo;dead letter queue&ldquo;</h2>

<p>Prozatím jsme si ukázali dvě varianty &bdquo;zpracování&ldquo; zpráv
s&nbsp;nekorektním formátem (v&nbsp;našem konkrétním případě zpráv, jejichž
klíč nebo tělo není uloženo v&nbsp;JSONu). První varianta spočívala v&nbsp;tom,
že se konektor (konzument) zastavil, což znamená, že nekorektní zprávu bude
nutné z&nbsp;tématu načíst jinými prostředky. Druhá varianta naopak zprávy
s&nbsp;nekorektním formátem zcela přeskakovala. Ovšem v&nbsp;mnoha situacích je
vhodnější zvolit si nějakou formu střední cesty &ndash; konektor (konzument) se
při příjmu nekorektní zprávy nezastaví a současně nebude taková zpráva zcela
ignorována. V&nbsp;oblasti <i>message brokerů</i> samozřejmě řešení existuje, a
to již velmi dlouho. Jedná se o využití <i>DLQ</i> neboli <i>dead letter
queue</i>. Ve světě message brokerů se jedná o frontu či o fronty, kam se
ukládají jinak nezpracované zprávy, ve světě Apache Kafky se samozřejmě namísto
fronty použije téma.</p>

<p>Takovou DLQ (resp.&nbsp;spíše &bdquo;dead letter topic&ldquo;) si můžeme
nadefinovat přímo v&nbsp;konfiguraci konektoru:</p>

<pre>
<strong>errors.deadletterqueue.topic.name=dlq_bad_jsons</strong>
</pre>

<p>Ještě je vhodné při lokálním běhu brokeru omezit počet replikací tohoto
tématu na jedničku (při distribuovaném běhu však nikoli):</p>

<pre>
<strong>errors.deadletterqueue.topic.replication.factor=1</strong>
</pre>

<p>Úplná konfigurace upraveného konektoru by mohla vypadat následovně:</p>

<pre>
name=local-file-sink-json
connector.class=FileStreamSink
tasks.max=1
file=<strong>test.sink4.jsons</strong>
topics=connect-test-json
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false
errors.tolerance=all
<strong>errors.deadletterqueue.topic.name=dlq_bad_jsons</strong>
<strong>errors.deadletterqueue.topic.replication.factor=1</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: opět si povšimněte, jak dokážeme úpravou
několika řádků zcela změnit logiku realizovanou konektorem. Přeposílání zpráv
do DLQ realizované programově by bylo mnohem delší.</div></p>



<p><a name="k17"></a></p>
<h2 id="k17">17. Otestování upraveného konektoru a výpis obsahu &bdquo;dead letter queue&ldquo;</h2>

<p>Nově nakonfigurovaný konektor si pochopitelně opět otestujeme. Nejdříve
konektor spustíme, a to prakticky stejným způsobem, jako konektory
předchozí:</p>

<pre>
$ <strong>bin/connect-standalone.sh config/connect-standalone.properties config/connect-file-sink-4.properties</strong>
</pre>

<p>Nyní do tématu <strong>connect-test-json</strong> pošleme několik zpráv přes
producenta ovládaného z&nbsp;příkazové řádky:</p>

<pre>
$ <strong>bin/kafka-console-producer.sh --broker-list localhost:9092 --topic connect-test-json -property parse.key=true --property key.separator=;</strong>
</pre>

<p>Zprávy poslané do tématu a zapsané na příkazovou řádku:</p>

<pre>
&gt;{"1st":1}
&gt;{"2nd":2}
&gt;{"improper":message}
&gt;{"id":this-is-not-valid-too}
&gt;"proper one"
&gt;xyzzy
</pre>

<p>Po ukončení producenta klávesovou zkratkou <strong>CTRL+D</strong> si opět
prohlédneme soubor, do něhož by se měly ukládat pouze korektní zprávy:</p>

<pre>
$ <strong>cat test.sink4.jsons</strong>
</pre>

<p>Soubor by měl vypadat takto:</p>

<pre>
{1st=1}
{2nd=2}
proper one
</pre>

<p>Ovšem navíc si můžeme prohlédnout i obsah tématu nazvaného
<strong>dlq_bad_jsons</strong>, do něhož by měly být uloženy všechny nekorektní
zprávy. Konzumaci zpráv začneme od zprávy první:</p>

<pre>
$ <strong>bin/kafka-console-consumer.sh  --bootstrap-server localhost:9092 --topic dlq_bad_jsons --partition 0 --offset earliest</strong>
</pre>

<p>Vypsat by se měly tyto tři řádky:</p>

<pre>
{"id":this-is-not-valid-too}
{"improper":message}
xyzzy
</pre>

<p>V&nbsp;tomto případě je ovšem výhodnější použít nástroj <i>Kafkacat</i> a
netrápit se s&nbsp;uváděním offsetů a oddílů:</p>

<pre>
$ <strong>kafkacat -b localhost:9092 -t dlq_bad_jsons -C</strong>
</pre>

<p>Zprávy se vypíšou i s&nbsp;hlavičkou:</p>

<pre>
{"id":this-is-not-valid-too}
{"improper":message}
xyzzy
% Reached end of topic dlq_bad_jsons [0] at offset 6
</pre>

<p>Výpis podrobnějších informací (prakticky všech zjistitelných informací o
zprávě) nám zajistí příkaz:</p>

<pre>
kafkacat -b localhost:9092 -t dlq_bad_jsons -C \
  -f '\nKey (%K bytes): %k
  Value (%S bytes): %s
  Timestamp: %T
  Partition: %p
  Offset: %o
  Headers: %h\n'
</pre>

<p>Příklad výstupu:</p>

<pre>
Key (0 bytes): 
  Value (28 bytes): {"id":this-is-not-valid-too}
  Timestamp: 1675703045452
  Partition: 0
  Offset: 3
  Headers: 
&nbsp;
Key (0 bytes): 
  Value (20 bytes): {"improper":message}
  Timestamp: 1675765176990
  Partition: 0
  Offset: 4
  Headers: 
&nbsp;
Key (0 bytes): 
  Value (5 bytes): xyzzy
  Timestamp: 1675765183798
  Partition: 0
  Offset: 5
  Headers: 
</pre>

<p><div class="rs-tip-major">Poznámka: tyto informace lze s&nbsp;využitím
standardních nástrojů Kafky získat jen obtížně, a proto je skutečně lepší
použít Kafkacat.</div></p>



<p><a name="k18"></a></p>
<h2 id="k18">18. Obsah druhé části článku</h2>

<p>Ve druhé části článku o frameworku <i>Kafka Connect</i> se nejdříve
seznámíme s&nbsp;jednoduchým zdrojem zpráv realizovaným (například) obsahem
zvoleného textového souboru:</p>

<pre>
name=local-file-source
connector.class=FileStreamSource
tasks.max=1
file=test.txt
topic=connect-test
</pre>

<p>V&nbsp;mnoha oblastech je důležitá i kontrola formátu zprávy oproti zadanému
schématu (tedy validace). Ukážeme si tedy způsob kontroly zpráv, což lze
realizovat například takto nakonfigurovaným konektorem (ve skutečnosti bude
konfigurace nepatrně složitější):</p>

<pre>
name=local-file-sink-json
connector.class=FileStreamSink
tasks.max=1
file=test.sink4.jsons
topics=connect-test-json
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
<strong>key.converter.schemas.enable=true</strong>
<strong>value.converter.schemas.enable=true</strong>
errors.tolerance=all
errors.deadletterqueue.topic.name=dlq_bad_jsons
errors.deadletterqueue.topic.replication.factor=1
</pre>

<p>A konečně si ukážeme, jak lze použít konektor pro parsing obsahu zpráv
s&nbsp;jejich uložením do relační databáze. Použijeme konfigurační soubor,
který bude zhruba vypadat následovně:</p>

<pre>
name=db-sink
connector.class=io.confluent.connect.jdbc.JdbcSinkConnector
tasks.max=1
topics=connect-test-3
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=true
value.converter.schemas.enable=true
connection.url=jdbc:postgresql://localhost:5432/kafka_sink?user=postgres&amp;password=postgres
auto.create=true
delete.enabled=false
</pre>



<p><a name="k19"></a></p>
<h2 id="k19">19. Příloha: nástroj Kafkacat (Kcat)</h2>

<p>V&nbsp;předchozím textu jsme několikrát použili nástroj, který se jmenoval
<i>Kafkacat</i>; v&nbsp;současnosti však došlo k&nbsp;jeho přejmenování na
<i>Kcat</i> (jak jsem již psal výše, důvody pro přejmenování jsou poněkud
absurdní). Tento nástroj, který jeho autoři taktéž označují jako &bdquo;netcat
for Apache Kafka&ldquo;, a jenž slouží pro komunikaci s&nbsp;brokery přímo
z&nbsp;příkazové řádky, naleznete na adrese <a
href="https://github.com/edenhill/kafkacat">https://github.com/edenhill/kafkacat</a>.</p>

<p>Pochopitelně se s&nbsp;velkou pravděpodobností nebude jednat o řešení
používané v&nbsp;produkčním kódu, ovšem možnost vytvořit producenta zpráv či
jejich konzumenta přímo z&nbsp;CLI je vítaná jak při vývoji, tak i při řešení
problémů, které mohou při běhu aplikace nastat (my Kafkacat mimochodem
používáme i v&nbsp;integračních testech). Tento nástroj budeme volat i
v&nbsp;navazujícím článku, a to konkrétně při ukázkách nasazení Apache Kafky a
Kafka Connectu, takže se v&nbsp;této kapitole krátce zmiňme o příkladech
použití převzatých z&nbsp;oficiální dokumentace. Všechny ukázky předpokládají,
že broker je již spuštěn na lokálním počítači, a to konkrétně na portu
9092.</p>

<p><div class="rs-tip-major">Poznámka: jedná se o nativní aplikaci, což je
velmi dobré řešení, protože se <strong>kafkacat</strong> spouští poměrně často.
To je v&nbsp;ostrém kontrastu se samotnou Kafkou, která sice startuje (jako
každá aplikace pod JVM) pomaleji, ovšem doba provozu se počítá spíše
v&nbsp;měsících a nikoli v&nbsp;sekundách.</div></p>

<p>Výpis informací o všech tématech a jejich konfigurace:</p>

<pre>
$ <strong>kafkacat -L -b localhost:9092</strong>
</pre>

<p>Spuštění nového producenta zpráv čtených ze souborů specifikovaných na
příkazové řádce:</p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t filedrop -p 0 file1.bin file2.txt /etc/motd dalsi_soubor.tgz</strong>
</pre>

<p>Přečtení posledních 1000 zpráv z&nbsp;tématu &bdquo;téma1&ldquo;. Po této
operaci se konzument automaticky ukončí, tj.&nbsp;nebude čekat na další
zprávy:</p>

<pre>
$ <strong>kafkacat -C -b localhost:9092 -t tema1 -p 0 -o -1000 -e</strong>
</pre>

<p>Spuštění konzumentů, kteří jsou přihlášení k&nbsp;tématu
&bdquo;téma1&ldquo;:</p>

<pre>
$ <strong>kafkacat -b localhost:9092 -G skupina_konzumentů téma1</strong>
</pre>

<p>Přihlásit se lze i k&nbsp;odběru většího množství témat:</p>

<pre>
$ <strong>kafkacat -b localhost:9092 -G skupina_konzumentů téma1 téma2</strong>
</pre>

<p>Nástroj <strong>kafkacat</strong> je možné použít společně s&nbsp;producenty
a konzumenty, s&nbsp;nimiž se setkáme v&nbsp;navazujících kapitolách. Ve všech
demonstračních příkladech budeme používat téma (<i>topic</i>) nazvaný
&bdquo;upload&ldquo;.</p>

<p>Konzument zpráv posílaných do tématu &bdquo;upload&ldquo;:</p>

<pre>
$ <strong>kafkacat -C -b localhost:9092 -t "upload"</strong>
</pre>

<p>Producent zpráv zapisovaných na standardní vstup uživatelem (co zpráva, to
jeden řádek):</p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t "upload"</strong>
</pre>

<p>Dtto, ale u každé zprávy lze specifikovat i klíč oddělený od těla zprávy
dvojtečkou:</p>

<pre>
$ <strong>kafkacat -P -b localhost:9092 -t "upload" -K:</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: v&nbsp;tomto případě musí být každá
zpráva zapsána na jeden řádek ve formátu &bdquo;klíč:hodnota&ldquo;. Zadávání
se ukončuje klasicky stiskem klávesové zkratky
<strong>Ctrl+D</strong>.</div></p>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Kafka Connect and Schemas<br />
<a href="https://rmoff.net/2020/01/22/kafka-connect-and-schemas/">https://rmoff.net/2020/01/22/kafka-connect-and-schemas/</a>
</li>

<li>JSON and schemas<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas">https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas</a>
</li>

<li>What, why, when to use Apache Kafka, with an example<br />
<a href="https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/">https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/</a>
</li>

<li>When NOT to use Apache Kafka?<br />
<a href="https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/">https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/</a>
</li>

<li>Microservices: The Rise Of Kafka<br />
<a href="https://movio.co/blog/microservices-rise-kafka/">https://movio.co/blog/microservices-rise-kafka/</a>
</li>

<li>Building a Microservices Ecosystem with Kafka Streams and KSQL<br />
<a href="https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/">https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/</a>
</li>

<li>An introduction to Apache Kafka and microservices communication<br />
<a href="https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63">https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63</a>
</li>

<li>kappa-architecture.com<br />
<a href="http://milinda.pathirage.org/kappa-architecture.com/">http://milinda.pathirage.org/kappa-architecture.com/</a>
</li>

<li>Questioning the Lambda Architecture<br />
<a href="https://www.oreilly.com/ideas/questioning-the-lambda-architecture">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a>
</li>

<li>Lambda architecture<br />
<a href="https://en.wikipedia.org/wiki/Lambda_architecture">https://en.wikipedia.org/wiki/Lambda_architecture</a>
</li>

<li>Kafka &ndash; ecosystem (Wiki)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem</a>
</li>

<li>The Kafka Ecosystem - Kafka Core, Kafka Streams, Kafka Connect, Kafka REST Proxy, and the Schema Registry<br />
<a href="http://cloudurable.com/blog/kafka-ecosystem/index.html">http://cloudurable.com/blog/kafka-ecosystem/index.html</a>
</li>

<li>A Kafka Operator for Kubernetes<br />
<a href="https://github.com/krallistic/kafka-operator">https://github.com/krallistic/kafka-operator</a>
</li>

<li>Kafka Streams<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams">https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams</a>
</li>

<li>Kafka Streams<br />
<a href="http://kafka.apache.org/documentation/streams/">http://kafka.apache.org/documentation/streams/</a>
</li>

<li>Kafka Streams (FAQ)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams">https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams</a>
</li>

<li>Event stream processing<br />
<a href="https://en.wikipedia.org/wiki/Event_stream_processing">https://en.wikipedia.org/wiki/Event_stream_processing</a>
</li>

<li>Part 1: Apache Kafka for beginners - What is Apache Kafka?<br />
<a href="https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html">https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html</a>
</li>

<li>What are some alternatives to Apache Kafka?<br />
<a href="https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka">https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka</a>
</li>

<li>What is the best alternative to Kafka?<br />
<a href="https://www.slant.co/options/961/alternatives/~kafka-alternatives">https://www.slant.co/options/961/alternatives/~kafka-alternatives</a>
</li>

<li>A super quick comparison between Kafka and Message Queues<br />
<a href="https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0">https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0</a>
</li>

<li>Kafka Queuing: Kafka as a Messaging System<br />
<a href="https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system">https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system</a>
</li>

<li>Configure Self-Managed Connectors<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors">https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors</a>
</li>

<li>Schema Evolution and Compatibility<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility">https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility</a>
</li>

<li>Configuring Key and Value Converters<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters">https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters</a>
</li>

<li>Introduction to Kafka Connectors<br />
<a href="https://www.baeldung.com/kafka-connectors-guide">https://www.baeldung.com/kafka-connectors-guide</a>
</li>

<li>Kafka CLI: command to list all consumer groups for a topic?<br />
<a href="https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic">https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic</a>
</li>

<li>Java Property File Processing<br />
<a href="https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php">https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php</a>
</li>

<li>Skipping bad records with the Kafka Connect JDBC sink connector<br />
<a href="https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/">https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/</a>
</li>

<li>Kafka Connect Deep Dive – Error Handling and Dead Letter Queues<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/">https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/</a>
</li>

<li>Errors and Dead Letter Queues<br />
<a href="https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/">https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/</a>
</li>

<li>Confluent Cloud Dead Letter Queue<br />
<a href="https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html">https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html</a>
</li>

<li>Dead Letter Queues (DLQs) in Kafka<br />
<a href="https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309">https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2023</small></p>
</body>
</html>

