<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Nástroj MirrorMaker pro Apache Kafku</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Nástroj MirrorMaker pro Apache Kafku</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>Systému Apache Kafka jsme se již na stránkách Roota věnovali v několika článcích. Zabývali jsme se i problematikou replikace oddílů a chování Kafka v případě nedostupnosti některého z brokerů. Ovšem Kafka obsahuje ještě podporu pro replikaci zpráv mezi datovými centry. Tuto problematiku si popíšeme dnes.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Nástroj MirrorMaker pro Apache Kafku</a></p>
<p><a href="#k02">2. Replikace oddílů v&nbsp;rámci jednoho Kafka clusteru</a></p>
<p><a href="#k03">3. Několik samostatně běžících Kafka clusterů</a></p>
<p><a href="#k04">4. Nástroj MirrorMaker</a></p>
<p><a href="#k05">5. MirrorMaker 1 vs MirrorMaker 2</a></p>
<p><a href="#k06">6. Praktická část</a></p>
<p><a href="#k07">7. Konfigurace dvou lokálních Kafka clusterů</a></p>
<p><a href="#k08">8. Obsah konfiguračních souborů</a></p>
<p><a href="#k09">9. Konfigurace MirrorMakeru 2</a></p>
<p><a href="#k10">10. Spuštění Kafka clusterů</a></p>
<p><a href="#k11">11. Spuštění MirrorMakeru</a></p>
<p><a href="#k12">12. Producent a konzument pro téma na prvním clusteru</a></p>
<p><a href="#k13">13. Konzument naslouchající na druhém clusteru</a></p>
<p><a href="#k14">14. Témata vytvořená a spravovaná MirrorMakerem</a></p>
<p><a href="#k15">15. Obousměrné zrcadlení</a></p>
<p><a href="#k16">16. Omezení témat, která se mají replikovat</a></p>
<p><a href="#k17">17. Když regulární výrazy nestačí</a></p>
<p><a href="#k18">18. Jednosměrná replikace</a></p>
<p><a href="#k19">19. Zrcadlení bez přejmenování témat</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Nástroj MirrorMaker pro Apache Kafku</h2>

<p>Systém Apache Kafka je v&nbsp;současnosti velmi rozšířen a používá se
v&nbsp;mnoha oblastech IT. Někdy se setkáme s&nbsp;tím, že je Apache Kafka
nasazen a využíván jako pouhý &bdquo;vylepšený&ldquo; message broker,
tj.&nbsp;jako centrální část celé architektury sloužící pro komunikaci mezi
jednotlivými (mikro)službami a nástroji. V&nbsp;takovém případě se typicky
používají komunikační strategie <i>pub-sub</i> nebo <i>push-pull</i>,
s&nbsp;nimiž jsme se již na stránkách Roota seznámili <a
href="https://www.root.cz/serialy/message-brokery/">v&nbsp;seriálu o message
brokerech</a> (například <a
href="https://www.root.cz/clanky/apache-activemq-dalsi-system-implementujici-message-brokera/">v&nbsp;článku
o Apache ActiveMQ</a>).</p>

<p>Ovšem možnosti Apache Kafky jsou ve skutečnosti poněkud větší, a to díky
poměrně unikátnímu způsobu práce s&nbsp;takzvanými tématy (<i>topic</i>) a
oddíly (<i>partition</i>) i díky tomu, že si <i>offsety</i> čtených zpráv řídí
konzumenti resp.&nbsp;jejich skupiny (<i>consumer groups</i>). Navíc Apache
Kafka dokáže zajistit svoji velkou dostupnost a odolnost vůči pádům
jednotlivých komponent či síťové infrastruktury (<i>resilience</i>). Tomuto
tématu jsme se již věnovali, ovšem zbývá nám popsat ještě jednu technologii,
kterou lze použít pro replikaci zpráv z&nbsp;vybraných oddílů mezi oddělenými
(a mnohdy i vzdálenými) datovými centry. Tato technologie se jmenuje
<i>MirrorMaker</i>, což je název, který poměrně přesně popisuje, k&nbsp;jakým
operacím při nasazení MirrorMakeru dochází.</p>

<img src="https://i.iinfo.cz/images/447/microservices2-3.png" class="image-361670" alt="&#160;" width="450" height="134" />
<p><i>Obrázek 1: Známé logo nástroje Apache Kafka, kterému se budeme věnovat
v&nbsp;dnešním článku.</i></p>

<p><div class="rs-tip-major">Poznámka: v&nbsp;současnosti ve skutečnosti
existují dva nástroje nazvané <i>MirrorMaker</i>, přičemž druhá verze se
oficiálně jmenuje <i>MirrorMaker2</i>. Každá z&nbsp;těchto verzí interně
pracuje odlišně a odlišná (a obecně nepřenositelná) je i jejich konfigurace.
V&nbsp;dnešním článku se nejdříve zmíníme o původní verzi, která je sice
označena jako <i>deprecated</i>, ovšem bez problémů ji lze provozovat i na
nejnovější verzi Apache Kafky. A poté si ukážeme možnosti MirrorMakeru2, které
jsou mnohem zajímavější a v&nbsp;praxi i užitečnější (a opět se pochopitelně
jedná o technologii využitelnou i v&nbsp;současné verzi Apache
Kafky).</div></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Replikace oddílů v&nbsp;rámci jednoho Kafka clusteru</h2>

<p>Připomeňme si, že téma (<i>topic</i>), do kterého se posílají zprávy, může
být v&nbsp;systému Apache Kafky rozděleno do několika oddílů. V&nbsp;takovém
případě producent či producenti nezapisují zprávy do jednoho oddílu (samozřejmě
na konec), ale zápis je proveden pouze do jediného z&nbsp;vybraných oddílů. O
tom, do kterého oddílu bude zápis (resp.&nbsp;připojení) zprávy proveden, se
rozhoduje na základě <i>klíče</i> připojeného ke zprávě. Samotná zpráva je
totiž chápána jako dvě sekvence bajtů &ndash; první sekvence tvoří klíč zprávy
a druhá sekvence tělo zprávy. A právě na základě předaného klíče se vypočítá
hash a algoritmus implementovaný v&nbsp;samotném brokeru rozhodne, do kterého
oddílu bude zpráva uložena:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Po přijetí nové zprávy tedy může být zápis proveden například do prvního
oddílu na offset číslo 6:</p>

<pre>
                                       write
                                         |
              +---+---+---+---+---+---+  v
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Nebo se může broker rozhodnout pro připojení zprávy do posledního oddílu
atd. atd.:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+  ^
                                                     |
                                                   write
</pre>

<p><div class="rs-tip-major">Poznámka: tato konfigurace se používá
v&nbsp;případě, kdy budeme chtít využít více paralelně běžících konzumentů,
které jsou součástí jedné skupiny konzumentů (<i>consumer groups</i>). Jedná se
tedy o konfiguraci určenou pro zajištění větší průchodnosti dat.</div></p>

<p>Další možná a podporovaná konfigurace tématu může vypadat tak, že pro dané
téma je vytvořen pouze jediný oddíl, ovšem tento oddíl je replikován mezi
několika brokery. Příkladem může být oddíl replikovaný mezi trojicí brokerů
běžících v&nbsp;rámci stejného Kafka clusteru. V&nbsp;takovém případě je jeden
z&nbsp;těchto oddílů nazvaný <i>leader</i> a veškeré operace viděné zvnějšku
Kafky (tedy posílání zpráv a jejich konzumace) probíhá právě s&nbsp;leaderem.
Ostatní repliky jsou nazvané <i>follower(s)</i>, protože pouze sledují leadera
a synchronizují svůj obsah s&nbsp;leaderem. Ovšem zápis nové zprávy primárně
proběhne v&nbsp;oddílu leadera:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...    (leader)
+---+---+---+---+---+---+---+---+---+
                  ^               ^
                  |               |
                read              |
                                 sync
                                  |
                                  |
                                  v
+---+---+---+---+---+---+---+---+---+
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |        (follower)
+---+---+---+---+---+---+---+---+---+
                                  ^
                                  |
                                  |
                                 sync
                                  |
                                  |
                                  v
+---+---+---+---+---+---+---+---+---+
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |        (follower)
+---+---+---+---+---+---+---+---+---+
</pre>

<p>K&nbsp;čemu je to však dobré? V&nbsp;případě, že nějaký broker z&nbsp;celého
Kafka clusteru zhavaruje a tento broker bude (pro dané téma) obsahovat oddíl
typu <i>follower</i>, bude komunikace pokračovat dál a teprve po znovupřipojení
brokera se <i>follower</i> postupně sesynchronizuje s&nbsp;<i>leaderem</i>.
Zajímavější situace nastane ve chvíli, kdy zhavaruje samotný <i>leader</i>.
V&nbsp;takovém případě Kafka &bdquo;povýší&ldquo;nějakého <i>followera</i> za
nového <i>leadera</i>. V&nbsp;případě, že téma (resp.&nbsp;oddíl) je
replikováno na N brokerů, může jich zhavarovat N-1 a systém bude stále funkční.
Jinými slovy to znamená, že takto nakonfigurované téma dokáže
&bdquo;přežít&ldquo; pád některého z&nbsp;brokerů aniž by došlo
k&nbsp;závažnějšímu narušení komunikace (pouze se producenti a konzumenti
přepojí na jiného brokera, což zabere nějaký čas). Na druhou stranu se však
nezvyšuje propustnost v&nbsp;případě připojení většího množství konzumentů ze
stejné skupiny konzumentů.</p>

<p>Obě výše zmíněné možnosti je pochopitelně možné v&nbsp;případě potřeby
zkombinovat a vytvořit tak konfiguraci tématu, které bude rozděleno na větší
množství oddílů a tyto oddíly budou replikovány mezi větší množství
brokerů:</p>

<pre>
          +---+---+---+---+---+---+
oddíl #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
          +---+---+---+---+---+---+
oddíl #1  | 0 | 1 | 2 | ...
          +---+---+---+                               (leader)
oddíl #2  | ...
          +---+---+---+---+---+---+---+---+---+
oddíl #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
          +---+---+---+---+---+---+---+---+---+
                                  ^
                                  |
                                  |
                                 sync
                                  |
                                  |
                                  v
          +---+---+---+---+---+---+
oddíl #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
          +---+---+---+---+---+---+
oddíl #1  | 0 | 1 | 2 | ...
          +---+---+---+
oddíl #2  | ...                                       (follower)
          +---+---+---+---+---+---+---+---+---+
oddíl #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
          +---+---+---+---+---+---+---+---+---+
</pre>

<p>Tím dosáhneme toho, že Kafka cluster &bdquo;přežije&ldquo; pád N-1 brokerů a
navíc se zajistí paralelní čtení zpráv větším množstvím konzumentů patřících do
stejné skupiny konzumentů.</p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Několik samostatně běžících Kafka clusterů</h2>

<p>Podpora pro replikaci oddílů je v&nbsp;současnosti nedílnou součástí Apache
Kafky a nebylo by bez ní možné zajistit fungování celého Kafka clusteru i
v&nbsp;tom případě (který dříve či později nastane), kdy některý prvek clusteru
zhavaruje (nebo se &bdquo;jen&ldquo; stane nedostupným). Jedná se o známou a
velmi často používanou technologii, která však má své limity. Na tyto limity
poměrně brzy narazíme ve chvíli, kdy je provozováno několik Kafka clusterů,
přičemž každý z&nbsp;nich je typicky umístěn v&nbsp;samostatném datovém centru.
Zatímco propojení počítačů v&nbsp;rámci jednoho datového centra bývá velmi
rychlé (to je ostatně jeden z&nbsp;důvodů, i když nikoli jediný, proč vůbec
tato centra vznikají), přenos dat mezi datovými centry bývá pomalejší a mívá
zpoždění. Ovšem pokud by jednotlivé uzly Kafka clusteru byly umístěny
v&nbsp;různých centrech, celá technologie replikace by zpomalovala zpracování
zpráv a byla by zde i větší náchylnost na rozpad clusteru kvůli tomu, že
spojení mezi datovými centry může být (i na relativně krátkou chvíli)
přerušeno.</p>

<p>V&nbsp;takové situaci se může přistoupit k&nbsp;tomu, že se v&nbsp;každém
datovém centru spustí samostatný Kafka cluster, jenž bude prakticky nezávislý
na clusterech v&nbsp;jiných datových centrech. Některá témata (<i>topic</i>)
mohou být skutečně lokální (například některé téma může být určeno pouze pro
Evropu, další téma pro jiný Kafka cluster pro severní Ameriku atd.), ale
pochopitelně většinou nastane i situace vyžadující, aby bylo některé téma
replikováno i mezi jednotlivými Kafka clustery. A právě v&nbsp;těchto případech
lze sáhnout po nástroji nazvaném <i>MirrorMaker</i>, jímž se budeme zabývat
v&nbsp;navazujících kapitolách.</p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Nástroj MirrorMaker</h2>

<p>Nástroj MirrorMaker slouží, jak již bylo ostatně naznačeno v&nbsp;předchozím
textu, k&nbsp;propojení několika Kafka clusterů, přičemž se očekává, že každý
takový cluster poběží v&nbsp;odděleném datovém centru, takže komunikace mezi
clustery může být obecně pomalejší (s&nbsp;případnými výpadky), než komunikace
mezi uzly nacházejícími se v&nbsp;jediném clusteru. Samotný MirrorMaker je
z&nbsp;pohledu systému Apache Kafky konzumentem zpráv z&nbsp;vybraných témat a
producentem zpráv do jiných témat, přičemž témata se mohou nacházet
v&nbsp;různých clusterech. Nejedná se tedy (alespoň ne v&nbsp;případě
MirrorMakeru 1) o žádnou &bdquo;raketovou vědu&ldquo;, ale vlastně jen o
triviální konzumaci zpráv docházejících do tématu (témat) v&nbsp;jednom
clusteru a o jejich přeposílání do dalšího clusteru (MirrorMaker 2 je již
komplikovanější). Samozřejmě je možné v&nbsp;případě potřeby realizovat i
propojení mezi několika clustery, nikoli pouze mezi dvojicí clusterů.</p>

<p>Graficky můžeme nejjednodušší způsob použití MirrorMakeru znázornit
takto:</p>

<img src="https://i.iinfo.cz/images/318/mirror-maker-1.webp" class="image-1115979" width="466" height="127" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 2: MirrorMaker pro replikaci dat z&nbsp;prvního Kafka clusteru do
clusteru druhého.</i></p>

<p>Interně používá MirrorMaker (1) standardní komunikační prostředky Apache
Kafky. Konkrétně to znamená, že data (zprávy) načítá jako běžný konzument a
naopak data zapisuje jako běžný producent. Z&nbsp;pohledu Kafka clusterů i
jednotlivých brokerů se tedy jedná o zcela běžného klienta, který nepotřebuje
využívat speciální komunikační prostředky (a navíc je relativně snadné si
napsat vlastní verzi MirrorMakeru, pokud to někoho láká):</p>

<img src="https://i.iinfo.cz/images/318/mirror-maker-2.webp" class="image-1115980" width="579" height="146" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 3: MirrorMaker se interně skládá z&nbsp;konzumenta a producenta zpráv.</i></p>

<p>Ovšem tento nástroj lze využít i pro další účely, například pro přenos zpráv
z&nbsp;vybraných témat z&nbsp;interního (privátního) Kafka clusteru do clusteru
dostupného i dalším firmám (<i>data isolation</i>). A taktéž lze stejnou
technologii použít pro agregaci dat získaných z&nbsp;libovolného množství Kafka
clusterů s&nbsp;uložením do libovolného (dalšího) clusteru. To ale není vše,
protože lze realizovat i komunikaci typu <i>fan-in</i> a <i>fan-out</i> (tedy
spojení zpráv z&nbsp;více clusterů do jediného výsledného tématu či naopak
přečtení zpráv z&nbsp;jednoho tématu s&nbsp;jejich rozesláním do většího
množství clusterů).</p>



<p><a name="k05"></a></p>
<h2 id="k05">5. MirrorMaker 1 vs MirrorMaker 2</h2>

<p>Jak jsme si již řekli v&nbsp;poznámce uvedené <a href="#k01">v&nbsp;úvodní
kapitole</a>, nacházíme se nyní v&nbsp;situaci, kdy existují dvě vzájemně
odlišné verze MirrorMakeru. Původní verze je stále dostupná (a spouští se
skriptem <strong>bin/kafka-mirror-maker.sh</strong>
resp.&nbsp;<strong>bin/windows/kafka-mirror-maker.bat</strong>) a od verze
Kafky 2.4.0 (viz též <a
href="https://archive.apache.org/dist/kafka/2.4.0/RELEASE_NOTES.html">https://archive.apache.org/dist/kafka/2.4.0/RELEASE_NOTES.html</a>)
je dostupná i druhá verze MirrorMakeru. Ta se spouští skriptem
<strong>bin/connect-mirror.maker.sh</strong> (pro Windows varianta tohoto
skriptu neexistuje :-). Názvy těchto skriptů mohou být zpočátku matoucí, což se
pravděpodobně vyřeší ve chvíli, kdy bude původní MirrorMaker 1 z&nbsp;Apache
Kafky odstraněn.</p>

<p>Druhá verze MirrorMakeru je založena na technologii Kafka Connect,
s&nbsp;níž jsme se seznámili ve dvojici článků <a
href="https://www.root.cz/clanky/kafka-connect-tvorba-producentu-a-konzumentu-bez-zdrojoveho-kodu/">Kafka
Connect: tvorba producentů a konzumentů bez zdrojového kódu</a> a <a
href="https://www.root.cz/clanky/kafka-connect-definice-a-kontrola-schematu-zprav/">Kafka
Connect: definice a kontrola schématu zpráv</a>. Konkrétně MirrorMaker 2
realizuje hned několik <i>konektorů</i>, z&nbsp;nichž každý je určen pro
realizaci odlišných funkcí:</p>

<ol>

<li><strong>MirrorSourceConnector</strong>: replikace zpráv z&nbsp;lokálního do
vzdáleného clusteru, synchronizace offsetů</li>

<li><strong>MirrorCheckpointConnector</strong>: synchronizace offsetů, failower
v&nbsp;případě výpadů Kafka clusterů, realizace checkpointů</li>

<li><strong>MirrorHeartbeatConnector</strong>: tzv. heartbeats (zjištění, zda
protistrana komunikuje), monitoring replikací, zjištění topologie pro replikace
atd.</li>

</ol>

<p><div class="rs-tip-major">Poznámka: už jen z&nbsp;tohoto výčtu je patrné, že
MirrorMaker 2 je interně složitější, než původní relativně triviální kombinace
konzumentů s&nbsp;producenty.</div></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Praktická část</h2>

<p>Druhá část dnešního článku bude zaměřená více prakticky. Nejdříve vytvoříme
dvě instance Kafka clusterů, přičemž každá instance se bude skládat
z&nbsp;jednoho běžícího Zookeepera a z&nbsp;jednoho brokera. Na této instanci
si otestujeme způsoby vytváření témat, chování většího množství konzumentů při
připojení k&nbsp;tématu, použití většího množství oddílů pro téma atd. Dále oba
Kafka clustery propojíme s&nbsp;využitím MirrorMakeru (2) a opět budeme
sledovat chování producentů a konzumentů připojených k&nbsp;oběma
clusterům.</p>

<p>V&nbsp;praktické části budeme brokera Apache Kafky i Zookeepera spouštět
lokálně (popř.&nbsp;z&nbsp;Dockeru či Podmana), takže je nejdříve nutné Apache
Kafku nainstalovat. Není to vůbec nic složitého. V&nbsp;případě, že je na
počítači nainstalováno JRE (běhové prostředí Javy), je instalace Apache Kafky
pro testovací účely triviální. V&nbsp;článku si ukážeme instalaci verze
2.13-3.6.1, ovšem můžete si stáhnout i prakticky libovolnou novější či některé
starší verze (3.5.x nebo 3.6.x, ovšem dále popsaný postup by měl být platný i
pro ještě starší verze, v&nbsp;podstatě můžeme dojít až k&nbsp;verzi 2.4.0).
Tarball s&nbsp;instalací Apache Kafky lze získat z&nbsp;adresy <a
href="https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz">https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz</a>.</p>

<p>Stažení a rozbalení tarballu zajistí tyto příkazy:</p>

<pre>
$ <strong>wget https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz</strong>
$ <strong>tar xvfz kafka_2.13-3.6.1.tgz</strong>
$ <strong>cd kafka_2.13-3.6.1/</strong>
</pre>

<p>Po rozbalení staženého tarballu získáme adresář, v&nbsp;němž se nachází
všechny potřebné Java archivy (JAR), konfigurační soubory (v&nbsp;podadresáři
<strong>config</strong>) a několik pomocných skriptů (v&nbsp;podadresáři
<strong>bin</strong> a <strong>bin/windows</strong>). Pro spuštění Zookeepera a
brokerů je zapotřebí, jak jsme si již řekli v&nbsp;předchozím odstavci, mít
nainstalovánu JRE (Java Runtime Environment) a samozřejmě též nějaký shell
(BASH, cmd, ...).</p> 
 
<pre>
.
├── bin
│   └── windows
├── config
│   └── kraft
├── libs
├── licenses
└── site-docs
&nbsp;
7 directories
</pre>

<p>Mezi důležité soubory, které budeme používat v&nbsp;rámci dalších kapitol,
patří především skripty pro spouštění jednotlivých služeb, konfiguraci témat,
produkci zpráv či pro jejich konzumaci. Tyto skripty jsou uloženy
v&nbsp;podadresáři <strong>bin</strong> (a pro Windows ještě v&nbsp;dalším
podadresáři <strong>windows</strong>). A pochopitelně nesmíme zapomenout na
skript spouštějící samotný MirrorMaker 1 či 2:</p>

<table>
<tr><th>Skript</th><th>Stručný popis</th></tr>
<tr><td>bin/kafka-server-start.sh</td><td>spuštění brokera</td></tr>
<tr><td>bin/zookeeper-server-start.sh</td><td>spuštění Zookeepera</td></tr>
<tr><td>bin/kafka-mirror-maker.sh</td><td>spuštění MirrorMakeru 1</td></tr>
<tr><td>bin/connect-mirror-maker.sh</td><td>spuštění MirrorMakeru 2</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>bin/kafka-configs.sh</td><td>konfigurace brokerů</td></tr>
<tr><td>bin/kafka-topics.sh</td><td>konfigurace témat, zjištění informace o tématech atd.</td></tr>
<tr><td>bin/kafka-consumer-groups.sh</td><td>konfigurace popř.&nbsp;zjištění informací o skupinách konzumentů</td></tr>
<tr><td>bin/kafka-run-class.sh</td><td>spuštění konkrétní třídy z&nbsp;Apache Kafky (například pro zjištění informací o skupinách konzumentů)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>bin/kafka-console-producer.sh</td><td>jednoduchý producent zpráv</td></tr>
<tr><td>bin/kafka-console-consumer.sh</td><td>jednoduchý konzument zpráv</td></tr>
</table>

<p><div class="rs-tip-major">Poznámka: většina výše uvedených skriptů byla
upravena i pro spuštění ve Windows. Tyto varianty naleznete v&nbsp;podadresáři
<strong>bin/windows</strong> (kupodivu chybí skript pro MirrorMaker 2, ovšem
úprava shell skriptu do podoby BAT souboru není v&nbsp;tomto konkrétním případě
nijak obtížná).</div></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Konfigurace dvou lokálních Kafka clusterů</h2>

<p>Pro účely dnešního článku nám postačí si spustit dvojici lokálně běžících
Kafka clusterů, ovšem samozřejmě vám nic nebrání ve spuštění dvou vzdálených
clusterů. Každý cluster se bude skládat ze dvou prvků &ndash; jednoho
Zookeepera a jednoho brokera. První cluster bude mít Zookeepera spuštěného na
portu 2181 a brokera na portu 9091 (jedničky na konci se budou dobře pamatovat)
a druhý cluster bude mít Zookeepera spuštěného na portu 2182 a brokera na portu
9092 (opět &ndash; dvojky na konci se budou dobře pamatovat):</p>

<img src="https://i.iinfo.cz/images/318/mirror-maker-3.webp" class="image-1115981" width="341" height="269" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 4: Dva lokálně běžící Kafka clustery.</i></p>

<p>Budeme tedy potřebovat celkem pět konfiguračních souborů:</p>

<table>
<tr><th>Soubor</th><th>Stručný popis</th></tr>
<tr><td>server1.properties</td><td>konfigurace brokera z&nbsp;prvního Kafka clusteru</td></tr>
<tr><td>server2.properties</td><td>konfigurace brokera ze druhého Kafka clusteru</td></tr>
<tr><td>zookeeper1.properties</td><td>konfigurace Zookeepera z&nbsp;prvního Kafka clusteru</td></tr>
<tr><td>zookeeper2.properties</td><td>konfigurace Zookeepera ze druhého Kafka clusteru</td></tr>
<tr><td>mirror-maker.properties</td><td>konfigurace MirrorMakeru 2</td></tr>
</table>

<p>Pro jednoduchost budou tyto konfigurační soubory uloženy v&nbsp;tom
adresáři, kam byla nainstalována Apache Kafka.</p>



<p><a name="k08"></a></p>
<h2 id="k08">8. Obsah konfiguračních souborů</h2>

<p>Broker z&nbsp;prvního Kafka clusteru bude mít následující konfiguraci.
Povšimněte si nastaveného ID, portu, ale i unikátního adresáře pro ukládání
témat (resp.&nbsp;přesněji řečeno oddílů). Důležité hodnoty jsou
zvýrazněny:</p>

<pre>
<i># The id of the broker. This must be set to a unique integer for each broker.</i>
<strong>broker.id=0</strong>
&nbsp;
<i># The address the socket server listens on. If not configured, the host name will be equal to the value of</i>
<strong>listeners=PLAINTEXT://:9091</strong>
&nbsp;
<i># The number of threads that the server uses for receiving requests from the network and sending responses to the network</i>
num.network.threads=2
&nbsp;
<i># The number of threads that the server uses for processing requests, which may include disk I/O</i>
num.io.threads=4
&nbsp;
<i># The send buffer (SO_SNDBUF) used by the socket server</i>
socket.send.buffer.bytes=102400
&nbsp;
<i># The receive buffer (SO_RCVBUF) used by the socket server</i>
socket.receive.buffer.bytes=102400
&nbsp;
<i># The maximum size of a request that the socket server will accept (protection against OOM)</i>
socket.request.max.bytes=104857600
&nbsp;
<i># A comma separated list of directories under which to store log files</i>
<strong>log.dirs=/tmp/ramdisk/kafka-logs-1</strong>
&nbsp;
<i># The default number of log partitions per topic.</i>
num.partitions=1
&nbsp;
<i># The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.</i>
num.recovery.threads.per.data.dir=1
&nbsp;
<i># Internal Topic Settings</i>
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
&nbsp;
<i># The minimum age of a log file to be eligible for deletion due to age</i>
log.retention.hours=168
&nbsp;
<i># The interval at which log segments are checked to see if they can be deleted according</i>
<i># to the retention policies</i>
log.retention.check.interval.ms=300000
&nbsp;
<i># Zookeeper connection string (see zookeeper docs for details).</i>
<strong>zookeeper.connect=localhost:2181</strong>
&nbsp;
<i># Timeout in ms for connecting to zookeeper</i>
zookeeper.connection.timeout.ms=18000
&nbsp;
<i># Group Coordinator Settings</i>
group.initial.rebalance.delay.ms=0
</pre>

<p>Broker pro druhý cluster může mít stejné ID (to je unikátní jen v&nbsp;rámci
jednoho clusteru), ale musí se lišit jeho port, adresář pro ukládání oddílů i
port Zookeepera (pokud tedy cluster budeme provozovat na stejném počítači):</p>

<pre>
<i># The id of the broker. This must be set to a unique integer for each broker.</i>
<strong>broker.id=0</strong>
&nbsp;
<i># The address the socket server listens on. If not configured, the host name will be equal to the value of</i>
<strong>listeners=PLAINTEXT://:9092</strong>
&nbsp;
<i># The number of threads that the server uses for receiving requests from the network and sending responses to the network</i>
num.network.threads=2
&nbsp;
<i># The number of threads that the server uses for processing requests, which may include disk I/O</i>
num.io.threads=4
&nbsp;
<i># The send buffer (SO_SNDBUF) used by the socket server</i>
socket.send.buffer.bytes=102400
&nbsp;
<i># The receive buffer (SO_RCVBUF) used by the socket server</i>
socket.receive.buffer.bytes=102400
&nbsp;
<i># The maximum size of a request that the socket server will accept (protection against OOM)</i>
socket.request.max.bytes=104857600
&nbsp;
<i># A comma separated list of directories under which to store log files</i>
<strong>log.dirs=/tmp/ramdisk/kafka-logs-2</strong>
&nbsp;
<i># The default number of log partitions per topic.</i>
num.partitions=1
&nbsp;
<i># The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.</i>
num.recovery.threads.per.data.dir=1
&nbsp;
<i># Internal Topic Settings</i>
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1
&nbsp;
<i># The minimum age of a log file to be eligible for deletion due to age</i>
log.retention.hours=168
&nbsp;
<i># The interval at which log segments are checked to see if they can be deleted according</i>
<i># to the retention policies</i>
log.retention.check.interval.ms=300000
&nbsp;
<i># Zookeeper connection string (see zookeeper docs for details).</i>
<strong>zookeeper.connect=localhost:2182</strong>
&nbsp;
<i># Timeout in ms for connecting to zookeeper</i>
zookeeper.connection.timeout.ms=18000
&nbsp;
<i># Group Coordinator Settings</i>
group.initial.rebalance.delay.ms=0
</pre>

<p>Následuje konfigurace Zookeepera pro první Kafka cluster. Opět musíme použít
unikátní adresář i unikátní číslo portu:</p>

<pre>
<i># the directory where the snapshot is stored.</i>
<strong>dataDir=/tmp/ramdisk/zookeeper-1</strong>
<i># the port at which the clients will connect</i>
<strong>clientPort=2181</strong>
<i># disable the per-ip limit on the number of connections since this is a non-production config</i>
maxClientCnxns=0
<i># Disable the adminserver by default to avoid port conflicts.</i>
<i># Set the port to something non-conflicting if choosing to enable this</i>
admin.enableServer=false
</pre>

<p>A konečně konfigurace Zookeepera pro druhý Kafka cluster:</p>

<pre>
<i># the directory where the snapshot is stored.</i>
<strong>dataDir=/tmp/ramdisk/zookeeper-2</strong>
<i># the port at which the clients will connect</i>
<strong>clientPort=2182</strong>
<i># disable the per-ip limit on the number of connections since this is a non-production config</i>
maxClientCnxns=0
<i># Disable the adminserver by default to avoid port conflicts.</i>
<i># Set the port to something non-conflicting if choosing to enable this</i>
admin.enableServer=false
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Konfigurace MirrorMakeru 2</h2>

<p>Nejvíc nás ovšem bude zajímat konfigurace samotného MirrorMakeru 2. Ta
nejdříve obsahuje symbolická jména Kafka clusterů, ke kterým se bude
MirrorMaker 2 připojovat:

<img src="https://i.iinfo.cz/images/318/mirror-maker-4.webp" class="image-1115982" width="341" height="269" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 5: Pojmenování clusterů (platné pouze pro konkrétní instanci
MirrorMakera).</i></p>

<p>Můžeme ponechat například jména z&nbsp;původního souboru, tedy clustery A a
B:</p>

<pre>
<strong>clusters = A, B</strong>
</pre>

<p>Dále je nutné specifikovat seznam brokerů pro každý Kafka cluster. To je
v&nbsp;našem případě jednoduché, protože oba clustery (a tedy i jejich brokery)
běží na jediném počítači a lišit se budou jen čísla portů:</p>

<pre>
<strong>A.bootstrap.servers = localhost:9091</strong>
<strong>B.bootstrap.servers = localhost:9092</strong>
</pre>

<p><div class="rs-tip-major">Poznámka: samozřejmě je možné uvést i seznam
většího množství brokerů.</div></p>

<p>A konečně &ndash; konfigurace témat, která budou zrcadlena z&nbsp;clusteru A
do clusteru B či naopak. Zde se používají regulární výrazy. Pro začátek
povolíme zrcadlení všech témat, a to oběma směry:</p>

<pre>
<strong>A-&gt;B.enabled = true</strong>
<strong>A-&gt;B.topics = .*</strong>
&nbsp;
<strong>B-&gt;A.enabled = true</strong>
<strong>B-&gt;A.topics = .*</strong>
</pre>

<p>Reálný konfigurační soubor obsahuje i další vlastnosti, například replikační
faktor. Ten prozatím ponecháme na hodnotě 1, protože každý cluster má jen
jediného brokera. V&nbsp;praxi by měla být tato hodnota pochopitelně větší:</p>

<pre>
<i># specify any number of cluster aliases</i>
<strong>clusters = A, B</strong>
&nbsp;
<i># connection information for each cluster</i>
<i># This is a comma separated host:port pairs for each cluster</i>
<i># for e.g. "A_host1:9092, A_host2:9092, A_host3:9092"</i>
<strong>A.bootstrap.servers = localhost:9091</strong>
<strong>B.bootstrap.servers = localhost:9092</strong>
&nbsp;
<i># enable and configure individual replication flows</i>
<strong>A-&gt;B.enabled = true</strong>
&nbsp;
<i># regex which defines which topics gets replicated. For eg "foo-.*"</i>
<strong>A-&gt;B.topics = .*</strong>
&nbsp;
<strong>B-&gt;A.enabled = true</strong>
<strong>B-&gt;A.topics = .*</strong>
&nbsp;
<i># Setting replication factor of newly created remote topics</i>
replication.factor=1
&nbsp;
############################# Internal Topic Settings  #############################
<i># The replication factor for mm2 internal topics "heartbeats", "B.checkpoints.internal" and</i>
<i># "mm2-offset-syncs.B.internal"</i>
<i># For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.</i>
checkpoints.topic.replication.factor=1
heartbeats.topic.replication.factor=1
offset-syncs.topic.replication.factor=1
&nbsp;
<i># The replication factor for connect internal topics "mm2-configs.B.internal", "mm2-offsets.B.internal" and</i>
<i># "mm2-status.B.internal"</i>
<i># For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.</i>
offset.storage.replication.factor=1
status.storage.replication.factor=1
config.storage.replication.factor=1
&nbsp;
<i># customize as needed</i>
<i># replication.policy.separator = _</i>
<i># sync.topic.acls.enabled = false</i>
<i># emit.heartbeats.interval.seconds = 5</i>
</pre>



<p><a name="k10"></a></p>
<h2 id="k10">10. Spuštění Kafka clusterů</h2>

<p>Nyní si oba Kafka clustery spustíme. Připomeňme si, že nejdříve je vždy
nutné spustit Zookeepera a teprve poté brokera či brokery. Pro sledování
činnosti všech procesů si můžete každého Zookeepera i brokera spustit
v&nbsp;samostatném terminálu, využít nástroj <strong>screen</strong> atd.</p>

<p>Spuštění Zookeepera pro první cluster:</p>

<pre>
$ <strong>cd ${kafka_dir}</strong>
$ <strong>bin/zookeeper-server-start.sh zookeeper1.properties</strong>
</pre>

<p>Spuštění brokera pro první cluster:</p>

<pre>
$ <strong>cd ${kafka_dir}</strong>
$ <strong>bin/kafka-server-start.sh server1.properties</strong>
</pre>

<p>Spuštění Zookeepera pro druhý cluster:</p>

<pre>
$ <strong>cd ${kafka_dir}</strong>
$ <strong>bin/zookeeper-server-start.sh zookeeper2.properties</strong>
</pre>

<p>Spuštění brokera pro druhý cluster:</p>

<pre>
$ <strong>cd ${kafka_dir}</strong>
$ <strong>bin/kafka-server-start.sh server2.properties</strong>
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. Spuštění MirrorMakeru</h2>

<p>V&nbsp;posledním terminálu spustíme samotného MirrorMakera. Vzhledem
k&nbsp;tomu, že používáme MirrorMaker 2, je pro spuštění použit skript
<strong>bin/connect-mirror-maker.sh</strong>:</p>

<pre>
$ <strong>bin/connect-mirror-maker.sh mirror-maker.properties</strong>
</pre>

<p>Pokud se nepodaří připojení k&nbsp;jednomu Kafka clusteru či k&nbsp;oběma
Kafka clusterům, budou se vypisovat tyto zprávy:</p>

<pre>
[2024-02-10 16:35:30,310] WARN [AdminClient clientId=B-&gt;A] Connection to node -1 (localhost/127.0.0.1:9091) could not be established. Broker may not be available. (org.apache.kafka.clients.NetworkClient:814)
[2024-02-10 16:35:31,322] INFO [AdminClient clientId=B-&gt;A] Node -1 disconnected. (org.apache.kafka.clients.NetworkClient:977)
</pre>

<p>Naopak při úspěšném připojení by se na terminálu měla objevit tato hlášení:</p>

<pre>
[2024-02-10 16:38:15,657] INFO [MirrorSourceConnector|worker] Started MirrorSourceConnector with 2 topic-partitions. (org.apache.kafka.connect.mirror.MirrorSourceConnector:174)
[2024-02-10 16:38:15,657] INFO [MirrorSourceConnector|worker] Starting MirrorSourceConnector took 56 ms. (org.apache.kafka.connect.mirror.MirrorSourceConnector:175)
[2024-02-10 16:38:15,661] INFO [MirrorSourceConnector|worker] No ACL authorizer is configured on the source Kafka cluster, so no topic ACL syncing will take place. Consider disabling topic ACL syncing by setting sync.topic.acls.enabled to 'false'. (org.apache.kafka.connect.mirror.MirrorSourceConnector:533)
[2024-02-10 16:38:15,661] INFO [MirrorSourceConnector|worker] syncing topic ACLs took 4 ms (org.apache.kafka.connect.mirror.Scheduler:95)
[2024-02-10 16:38:15,667] INFO [MirrorSourceConnector|worker] syncing topic configs took 14 ms (org.apache.kafka.connect.mirror.Scheduler:95)
[2024-02-10 16:38:15,671] INFO [MirrorSourceConnector|worker] syncing topic configs took 10 ms (org.apache.kafka.connect.mirror.Scheduler:95)
</pre>

<p>Poté se již budou periodicky (zhruba po jedné minutě) opakovat zprávy o
synchronizaci a o testování stavu obou clusterů:</p>

<pre>
[2024-02-10 16:40:15,211] INFO [MirrorHeartbeatConnector|task-0|offsets] WorkerSourceTask{id=MirrorHeartbeatConnector-0} Committing offsets for 60 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
[2024-02-10 16:40:15,212] INFO [MirrorSourceConnector|task-0|offsets] WorkerSourceTask{id=MirrorSourceConnector-0} Committing offsets for 60 acknowledged messages (org.apache.kafka.connect.runtime.WorkerSourceTask:233)
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Producent a konzument pro téma na prvním clusteru</h2>

<p>V&nbsp;této chvíli by tedy mělo běžet všech pět služeb: dvojice Zookeeperů,
dvojice Kafka brokerů a samozřejmě i MirrorMaker 2. Zbývá nám otestování
funkcionality obou propojených Kafka clusterů. Spustíme tedy producenta zpráv.
Konkrétně se bude jednat o producenta, který bude posílat zprávy do tématu
nazvaného <strong>test1</strong> na prvním Kafka clusteru. Producenta lze
pochopitelně vytvořit v&nbsp;prakticky jakémkoli programovacím jazyku, pro
který existuje příslušná knihovna s&nbsp;rozhraním k&nbsp;Apache Kafce. Ovšem
my dnes využijeme standardního producenta dodávaného přímo s&nbsp;Apache
Kafkou, který se spouští následovně (povšimněte si, že se připojujeme
k&nbsp;brokeru z&nbsp;prvního clusteru):</p>

<pre>
$ <strong>bin/kafka-console-producer.sh --bootstrap-server localhost:9091 --topic test1</strong>
</pre>

<p>Nyní lze do konzole, na které byl producent spuštěn, zapisovat zprávy, které
budou posílány do tématu <strong>test1</strong>.</p>

<p>V&nbsp;dalším terminálu si otevřeme konzumenta zpráv z&nbsp;tohoto tématu.
Opět se bude jednat o standardní implementaci konzumenta dodávaného společně
s&nbsp;Apache Kafkou:</p>

<pre>
$ <strong>bin/kafka-console-consumer.sh  --bootstrap-server localhost:9091 --topic test1</strong>
</pre>

<p>Všechny zprávy posílané producentem budou vypsány na terminálu konzumenta
&ndash; což je obvyklá vlastnost Kafky, do které (zdánlivě) Mirror Maker nijak
nezasahuje.</p>



<p><a name="k13"></a></p>
<h2 id="k13">13. Konzument naslouchající na druhém clusteru</h2>

<p>Nyní si konečně vyzkoušejme, jak do celého systému přeposílání zpráv
zasahuje Mirror Maker. Spustíme dalšího konzumenta, ovšem nyní se bude jednat o
konzumenta připojeného ke druhému Kafka clusteru. Konkrétně se tedy budeme
muset připojit k&nbsp;brokeru běžícímu na portu 9092. A dochází ještě
k&nbsp;jedné změně &ndash; původní téma, které se jmenovalo
<strong>test1</strong>, bude na druhém clusteru pojmenováno
<strong>A.test1</strong>; bude tedy obsahovat i symbolické jméno clusteru,
odkud je zrcadleno (toto jméno tedy volí Mirror Maker na základě své
konfigurace).</p>

<img src="https://i.iinfo.cz/images/318/mirror-maker-5.webp" class="image-1115983" width="452" height="381" alt="&#160;" title="Autor: tisnik, podle licence: &lt;a href=&quot;http://en.wikipedia.org/wiki/Rights_Managed&quot;&gt;Rights Managed&lt;/a&gt;" />
<p><i>Obrázek 6: Připojení producenta a dvojice konzumentů ke zrcadlenému tématu.</i></p>

<p>Konzumenta tedy spustíme následovně:</p>

<pre>
$ <strong>bin/kafka-console-consumer.sh  --bootstrap-server localhost:9092 --topic A.test1</strong>
</pre>

<p>Zprávy posílané do tématu <strong>test1</strong> do prvního clusteru budou
zrcadleny do tématu <strong>A.test1</strong> ve druhém clusteru, což si sami
můžete velmi snadno ověřit zápisem zpráv do terminálu producenta:</p>

<p><strong>Producent:</strong></p>

<pre>
&gt;prvni
&gt;druha
&gt;treti
</pre>

<p><strong>Konzument:</strong></p>

<pre>
prvni
druha
treti
</pre>



<p><a name="k14"></a></p>
<h2 id="k14">14. Témata vytvořená a spravovaná MirrorMakerem</h2>

<p>Podívejme se nyní, jaká témata vlastně v&nbsp;jednotlivých Kafka clusterech
vznikla. Nejdříve si vypíšeme témata v&nbsp;prvním clusteru:</p>

<pre>
$ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9091 --list</strong>
&nbsp;
B.checkpoints.internal
B.heartbeats
__consumer_offsets
heartbeats
mm2-configs.B.internal
mm2-offset-syncs.B.internal
mm2-offsets.B.internal
mm2-status.B.internal
test1
</pre>

<p>Nalezneme zde tedy zejména naše téma <strong>test1</strong>, ovšem i témata
začínající prefixem <strong>B.</strong> (tedy symbolickým jménem druhého
clusteru) a dále interní témata Mirror Makeru začínající na
<strong>mm2-</strong>.</p>

<p>Naproti tomu ve druhém clusteru budou odlišná témata:</p>

<pre>
$ <strong>bin/kafka-topics.sh --bootstrap-server localhost:9092 --list</strong>
&nbsp;
A.checkpoints.internal
A.heartbeats
A.test1
__consumer_offsets
heartbeats
mm2-configs.A.internal
mm2-offset-syncs.A.internal
mm2-offsets.A.internal
mm2-status.A.internal
</pre>

<p>Namísto tématu <strong>test1</strong> je zde téma <strong>A.test1</strong> a
&bdquo;zrcadleně&ldquo; zde nalezneme témata, v&nbsp;nichž je uložen stav
prvního clusteru z&nbsp;pohledu Mirror Makeru.</p>

<p>Některá výše vypsaná témata jsou rozdělena na oddíly, další pak mají pouze
jediný oddíl (což jsme ostatně nastavili v&nbsp;konfiguračním souboru):</p>

<pre>
Topic: heartbeats       TopicId: 7IyMK73ETfaQXJl7JfdIDg PartitionCount: 1       ReplicationFactor: 1    Configs: cleanup.policy=compact
        Topic: heartbeats       Partition: 0    Leader: 0       Replicas: 0     Isr: 0
Topic: B.heartbeats     TopicId: YgRWcTVMQqO6XHO62yO2Yg PartitionCount: 1       ReplicationFactor: 1    Configs: cleanup.policy=compact
        Topic: B.heartbeats     Partition: 0    Leader: 0       Replicas: 0     Isr: 0
Topic: mm2-configs.B.internal   TopicId: py8p8QjOTuKRtvalWRsnOg PartitionCount: 1       ReplicationFactor: 1    Configs: cleanup.policy=compact
        Topic: mm2-configs.B.internal   Partition: 0    Leader: 0       Replicas: 0     Isr: 0
Topic: mm2-status.B.internal    TopicId: 8cw1WB9sRz-p16On6F6ePA PartitionCount: 5       ReplicationFactor: 1    Configs: cleanup.policy=compact
        Topic: mm2-status.B.internal    Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-status.B.internal    Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-status.B.internal    Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-status.B.internal    Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-status.B.internal    Partition: 4    Leader: 0       Replicas: 0     Isr: 0
Topic: B.checkpoints.internal   TopicId: od5v7gliTI2oM6cfPmUkhQ PartitionCount: 1       ReplicationFactor: 1    Configs: cleanup.policy=compact
        Topic: B.checkpoints.internal   Partition: 0    Leader: 0       Replicas: 0     Isr: 0
Topic: mm2-offsets.B.internal   TopicId: zgHMHUQdRQaY7kiTknju6g PartitionCount: 25      ReplicationFactor: 1    Configs: cleanup.policy=compact
        Topic: mm2-offsets.B.internal   Partition: 0    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 1    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 2    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 3    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 4    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 5    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 6    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 7    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 8    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 9    Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 10   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 11   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 12   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 13   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 14   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 15   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 16   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 17   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 18   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 19   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 20   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 21   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 22   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 23   Leader: 0       Replicas: 0     Isr: 0
        Topic: mm2-offsets.B.internal   Partition: 24   Leader: 0       Replicas: 0     Isr: 0
Topic: mm2-offset-syncs.B.internal      TopicId: hXRJKh8VTNWhmwYXCsEL5g PartitionCount: 1       ReplicationFactor: 1    Configs: cleanup.policy=compact
        Topic: mm2-offset-syncs.B.internal      Partition: 0    Leader: 0       Replicas: 0     Isr: 0
</pre>



<p><a name="k15"></a></p>
<h2 id="k15">15. Obousměrné zrcadlení</h2>

<p>Nic nám nebrání v&nbsp;tom, aby se téma <strong>test1</strong> vytvořilo i
ve druhém Kafka clusteru. Pokud je povolena automatická tvorba témat, je to
snadné, protože pro tento účel stačí použít producenta:</p>

<pre>
$ <strong>bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic test1</strong>
</pre>

<p>Zprávy jsou zrcadleny na první Kafka cluster, ovšem do tématu
s&nbsp;prefixem, tedy do tématu <strong>B.test1</strong>:</p>

<pre>
$ <strong>bin/kafka-console-consumer.sh  --bootstrap-server localhost:9091 --topic B.test1</strong>
</pre>

<p>Nyní budou seznamy témat &bdquo;symetrické&ldquo; v&nbsp;obou
clusterech:</p>

<pre>
B.checkpoints.internal
B.heartbeats
B.test1
__consumer_offsets
heartbeats
mm2-configs.B.internal
mm2-offset-syncs.B.internal
mm2-offsets.B.internal
mm2-status.B.internal
test1
</pre>

<p>popř.&nbsp;pro druhý cluster:</p>

<pre>
A.checkpoints.internal
A.heartbeats
A.test1
__consumer_offsets
heartbeats
mm2-configs.A.internal
mm2-offset-syncs.A.internal
mm2-offsets.A.internal
mm2-status.A.internal
test1
</pre>

<p><div class="rs-tip-major">Poznámka: obě témata <strong>test1</strong> i
jejich kopie <strong>B.test1</strong> a <strong>A.test1</strong> jsou zcela
odlišná &ndash; obsahují jiné zprávy, jiné offsety pro skupiny konzumentů
atd.!</div></p>



<p><a name="k16"></a></p>
<h2 id="k16">16. Omezení témat, která se mají replikovat</h2>

<p>Témata, která se mají replikovat, jsou specifikována regulárním výrazem. To
tedy znamená, že témata je vhodné pojmenovávat tak, aby jména tvořila
resp.&nbsp;popisovala určitou strukturu. Například se může používat jmenná
konvence odvozená od problémové domény, například
<strong>public.sales.ecommerce.shoppingcarts</strong> nebo
<strong>private.risk.portfolio.pricingengine.assetpricing</strong>.
V&nbsp;takovém případě je relativně snadné specifikovat regulární výrazy pro ta
témata, která se mají zrcadlit:</p>

<pre>
# enable and configure individual replication flows
A-&gt;B.enabled = true
&nbsp;
# regex which defines which topics gets replicated. For eg "foo-.*"
A-&gt;B.topics = public\..*
</pre>



<p><a name="k17"></a></p>
<h2 id="k17">17. Když regulární výrazy nestačí</h2>

<p>Regulární výrazy pochopitelně nedokáží vystihnout všechny způsoby zrcadlení.
Mohlo by se tedy zdát, že je v&nbsp;tomto ohledu MirrorMaker poměrně omezený.
Ovšem díky tomu, že jsou clusterům přiřazena nějaká symbolická jména, je možné
stejný cluster v&nbsp;konfiguraci použít vícekrát a pokaždé s&nbsp;jiným
nastavením:</p>

<pre>
clusters = A, B, C, D
&nbsp;
A.bootstrap.servers = localhost:9091
B.bootstrap.servers = localhost:9091
C.bootstrap.servers = localhost:9091
D.bootstrap.servers = localhost:9092
</pre>

<p>Nyní se bude MirrorMaker chovat ke clusterům A, B i C, jakoby se jednalo o
samostatné entity, i když se ve skutečnosti jedná o stejný cluster.</p>



<p><a name="k18"></a></p>
<h2 id="k18">18. Jednosměrná replikace</h2>

<p>Zajištění jednosměrné replikace (resp.&nbsp;zrcadlení) je triviální &ndash;
každou cestu z&nbsp;cluster A do B či naopak lze zakázat:</p>

<pre>
clusters = A, B
&nbsp;
A.bootstrap.servers = localhost:9091
B.bootstrap.servers = localhost:9092
&nbsp;
A-&gt;B.enabled = true
&nbsp;
A-&gt;B.topics = .*
&nbsp;
<strong>B-&gt;A.enabled = false</strong>
B-&gt;A.topics = .*
</pre>



<p><a name="k19"></a></p>
<h2 id="k19">19. Zrcadlení bez přejmenování témat</h2>

<p>V&nbsp;případě, že preferujete skutečné zrcadlení témat bez jejich
přejmenování, je nutné do konfiguračního souboru Mirror Makeru přidat tento
řádek:</p>

<pre>
replication.policy.class=org.apache.kafka.connect.mirror.IdentityReplicationPolicy
</pre>

<p><div class="rs-tip-major">Poznámka: v&nbsp;tomto případě již narazíme na
určité problémy při kopii offsetů, což je ovšem téma na samostatný
článek.</div></p>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Kafka mirroring (MirrorMaker)<br />
<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330">https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330</a>
</li>

<li>Mastering Kafka migration with MirrorMaker 2<br />
<a href="https://developers.redhat.com/articles/2024/01/04/mastering-kafka-migration-mirrormaker-2">https://developers.redhat.com/articles/2024/01/04/mastering-kafka-migration-mirrormaker-2</a>
</li>

<li>Apache Kafka MirrorMaker 2 (MM2) Part 1: Theory<br />
<a href="https://www.instaclustr.com/blog/kafka-mirrormaker-2-theory/#h-2-replication-in-kafka">https://www.instaclustr.com/blog/kafka-mirrormaker-2-theory/#h-2-replication-in-kafka</a>
</li>

<li>Apache Kafka MirrorMaker 2 (MM2) Part 2: Practice<br />
<a href="https://www.instaclustr.com/blog/apache-kafka-mirrormaker-2-practice/">https://www.instaclustr.com/blog/apache-kafka-mirrormaker-2-practice/</a>
</li>

<li>Demystifying Kafka MirrorMaker 2: Use cases and architecture <br />
<a href="https://developers.redhat.com/articles/2023/11/13/demystifying-kafka-mirrormaker-2-use-cases-and-architecture#">https://developers.redhat.com/articles/2023/11/13/demystifying-kafka-mirrormaker-2-use-cases-and-architecture#</a>
</li>

<li>How to use Kafka MirrorMaker 2.0 in data migration, replication and the use-cases<br />
<a href="https://learn.microsoft.com/en-us/azure/hdinsight/kafka/kafka-mirrormaker-2-0-guide">https://learn.microsoft.com/en-us/azure/hdinsight/kafka/kafka-mirrormaker-2-0-guide</a>
</li>

<li>Release Notes - Kafka - Version 2.4.0<br />
<a href="https://archive.apache.org/dist/kafka/2.4.0/RELEASE_NOTES.html">https://archive.apache.org/dist/kafka/2.4.0/RELEASE_NOTES.html</a>
</li>

<li>Kafka Mirror Maker Best Practices<br />
<a href="https://community.cloudera.com/t5/Community-Articles/Kafka-Mirror-Maker-Best-Practices/ta-p/249269">https://community.cloudera.com/t5/Community-Articles/Kafka-Mirror-Maker-Best-Practices/ta-p/249269</a>
</li>

<li>Apache Kafka MirrorMaker 2 (MM2) Part 1: Theory<br />
<a href="https://www.instaclustr.com/blog/kafka-mirrormaker-2-theory/">https://www.instaclustr.com/blog/kafka-mirrormaker-2-theory/</a>
</li>

<li>Kcli: is a kafka read only command line browser.<br />
<a href="https://github.com/cswank/kcli">https://github.com/cswank/kcli</a>
</li>

<li>Kcli: a kafka command line browser<br />
<a href="https://go.libhunt.com/kcli-alternatives">https://go.libhunt.com/kcli-alternatives</a>
</li>

<li>Kafka Connect and Schemas<br />
<a href="https://rmoff.net/2020/01/22/kafka-connect-and-schemas/">https://rmoff.net/2020/01/22/kafka-connect-and-schemas/</a>
</li>

<li>JSON and schemas<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas">https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas</a>
</li>

<li>What, why, when to use Apache Kafka, with an example<br />
<a href="https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/">https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/</a>
</li>

<li>When NOT to use Apache Kafka?<br />
<a href="https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/">https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/</a>
</li>

<li>Microservices: The Rise Of Kafka<br />
<a href="https://movio.co/blog/microservices-rise-kafka/">https://movio.co/blog/microservices-rise-kafka/</a>
</li>

<li>Building a Microservices Ecosystem with Kafka Streams and KSQL<br />
<a href="https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/">https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/</a>
</li>

<li>An introduction to Apache Kafka and microservices communication<br />
<a href="https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63">https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63</a>
</li>

<li>kappa-architecture.com<br />
<a href="http://milinda.pathirage.org/kappa-architecture.com/">http://milinda.pathirage.org/kappa-architecture.com/</a>
</li>

<li>Questioning the Lambda Architecture<br />
<a href="https://www.oreilly.com/ideas/questioning-the-lambda-architecture">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a>
</li>

<li>Lambda architecture<br />
<a href="https://en.wikipedia.org/wiki/Lambda_architecture">https://en.wikipedia.org/wiki/Lambda_architecture</a>
</li>

<li>Kafka &ndash; ecosystem (Wiki)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem</a>
</li>

<li>The Kafka Ecosystem - Kafka Core, Kafka Streams, Kafka Connect, Kafka REST Proxy, and the Schema Registry<br />
<a href="http://cloudurable.com/blog/kafka-ecosystem/index.html">http://cloudurable.com/blog/kafka-ecosystem/index.html</a>
</li>

<li>A Kafka Operator for Kubernetes<br />
<a href="https://github.com/krallistic/kafka-operator">https://github.com/krallistic/kafka-operator</a>
</li>

<li>Kafka Streams<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams">https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams</a>
</li>

<li>Kafka Streams<br />
<a href="http://kafka.apache.org/documentation/streams/">http://kafka.apache.org/documentation/streams/</a>
</li>

<li>Kafka Streams (FAQ)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams">https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams</a>
</li>

<li>Event stream processing<br />
<a href="https://en.wikipedia.org/wiki/Event_stream_processing">https://en.wikipedia.org/wiki/Event_stream_processing</a>
</li>

<li>Part 1: Apache Kafka for beginners - What is Apache Kafka?<br />
<a href="https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html">https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html</a>
</li>

<li>What are some alternatives to Apache Kafka?<br />
<a href="https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka">https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka</a>
</li>

<li>What is the best alternative to Kafka?<br />
<a href="https://www.slant.co/options/961/alternatives/~kafka-alternatives">https://www.slant.co/options/961/alternatives/~kafka-alternatives</a>
</li>

<li>A super quick comparison between Kafka and Message Queues<br />
<a href="https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0">https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0</a>
</li>

<li>Kafka Queuing: Kafka as a Messaging System<br />
<a href="https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system">https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system</a>
</li>

<li>Apache Kafka Logs: A Comprehensive Guide<br />
<a href="https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/">https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/</a>
</li>

<li>Microservices – Not a free lunch!<br />
<a href="http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html">http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html</a>
</li>

<li>Microservices, Monoliths, and NoOps<br />
<a href="http://blog.arungupta.me/microservices-monoliths-noops/">http://blog.arungupta.me/microservices-monoliths-noops/</a>
</li>

<li>Microservice Design Patterns<br />
<a href="http://blog.arungupta.me/microservice-design-patterns/">http://blog.arungupta.me/microservice-design-patterns/</a>
</li>

<li>REST vs Messaging for Microservices – Which One is Best?<br />
<a href="https://solace.com/blog/experience-awesomeness-event-driven-microservices/">https://solace.com/blog/experience-awesomeness-event-driven-microservices/</a>
</li>

<li>Kappa Architecture Our Experience<br />
<a href="https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf">https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf</a>
</li>

<li>Apache Kafka Streams and Tables, the stream-table duality<br />
<a href="https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854">https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854</a>
</li>

<li>Configure Self-Managed Connectors<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors">https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors</a>
</li>

<li>Schema Evolution and Compatibility<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility">https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility</a>
</li>

<li>Configuring Key and Value Converters<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters">https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters</a>
</li>

<li>Introduction to Kafka Connectors<br />
<a href="https://www.baeldung.com/kafka-connectors-guide">https://www.baeldung.com/kafka-connectors-guide</a>
</li>

<li>Kafka CLI: command to list all consumer groups for a topic?<br />
<a href="https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic">https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic</a>
</li>

<li>Java Property File Processing<br />
<a href="https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php">https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php</a>
</li>

<li>Skipping bad records with the Kafka Connect JDBC sink connector<br />
<a href="https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/">https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/</a>
</li>

<li>Kafka Connect Deep Dive – Error Handling and Dead Letter Queues<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/">https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/</a>
</li>

<li>Errors and Dead Letter Queues<br />
<a href="https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/">https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/</a>
</li>

<li>Confluent Cloud Dead Letter Queue<br />
<a href="https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html">https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html</a>
</li>

<li>Dead Letter Queues (DLQs) in Kafka<br />
<a href="https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309">https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309</a>
</li>

<li>Deserializer<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-json.html#json-schema-serializer-and-deserializer">https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-json.html#json-schema-serializer-and-deserializer</a>
</li>

<li>JSON, Kafka, and the need for schema<br />
<a href="https://mikemybytes.com/2022/07/11/json-kafka-and-the-need-for-schema/">https://mikemybytes.com/2022/07/11/json-kafka-and-the-need-for-schema/</a>
</li>

<li>Using Kafka Connect with Schema Registry<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/connect.html">https://docs.confluent.io/platform/current/schema-registry/connect.html</a>
</li>

<li>Zpracování dat reprezentovaných ve formátu JSON nástrojem jq<br />
<a href="https://www.root.cz/clanky/zpracovani-dat-reprezentovanych-ve-formatu-json-nastrojem-jq/">https://www.root.cz/clanky/zpracovani-dat-reprezentovanych-ve-formatu-json-nastrojem-jq/</a>
</li>

<li>Repositář projektu jq (GitHub)<br />
<a href="https://github.com/stedolan/jq">https://github.com/stedolan/jq</a>
</li>

<li>GitHub stránky projektu jq<br />
<a href="https://stedolan.github.io/jq/">https://stedolan.github.io/jq/</a>
</li>

<li>5 modern alternatives to essential Linux command-line tools<br />
<a href="https://opensource.com/ar­ticle/20/6/modern-linux-command-line-tools">https://opensource.com/ar­ticle/20/6/modern-linux-command-line-tools</a>
</li>

<li>Návod k nástroji jq<br />
<a href="https://stedolan.github.i­o/jq/tutorial/">https://stedolan.github.i­o/jq/tutorial/</a>
</li>

<li>jq Manual (development version)<br />
<a href="https://stedolan.github.io/jq/manual/">https://stedolan.github.io/jq/manual/</a>
</li>

<li>Introducing JSON<br />
<a href="https://www.json.org/json-en.html">https://www.json.org/json-en.html</a>
</li>

<li>Understanding JSON schema<br />
<a href="https://json-schema.org/understanding-json-schema/index.html">https://json-schema.org/understanding-json-schema/index.html</a>
</li>

<li>JDBC Sink Connector for Confluent Platform<br />
<a href="https://docs.confluent.io/kafka-connectors/jdbc/current/sink-connector/overview.html#jdbc-sink-connector-for-cp">https://docs.confluent.io/kafka-connectors/jdbc/current/sink-connector/overview.html#jdbc-sink-connector-for-cp</a>
</li>

<li>JDBC Connector (Source and Sink)<br />
<a href="https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc">https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc</a>
</li>

<li>Introduction to Schema Registry in Kafka<br />
<a href="https://medium.com/slalom-technology/introduction-to-schema-registry-in-kafka-915ccf06b902">https://medium.com/slalom-technology/introduction-to-schema-registry-in-kafka-915ccf06b902</a>
</li>

<li>Understanding JSON Schema Compatibility<br />
<a href="https://yokota.blog/2021/03/29/understanding-json-schema-compatibility/">https://yokota.blog/2021/03/29/understanding-json-schema-compatibility/</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2023</small></p>
</body>
</html>

