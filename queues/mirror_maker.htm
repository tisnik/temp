<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Nástroj MirrorMaker pro Apache Kafku</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Nástroj MirrorMaker pro Apache Kafku</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>Systému Apache Kafka jsme se již na stránkách Roota věnovali v několika článcích. Zabývali jsme se i problematikou replikace oddílů a chování Kafka v případě nedostupnosti některého z brokerů. Ovšem Kafka obsahuje ještě podporu pro replikaci zpráv mezi datovými centry. Tuto problematiku si popíšeme dnes.</p>



<h2>Obsah</h2>

<p><a href="#k01">*** 1. Nástroj MirrorMaker pro Apache Kafku</a></p>
<p><a href="#k02">*** 2. Replikace oddílů v&nbsp;rámci jednoho Kafka clusteru</a></p>
<p><a href="#k03">*** 3. Několik samostatně běžících Kafka clusterů</a></p>
<p><a href="#k04">*** 4. Nástroj MirrorMaker</a></p>
<p><a href="#k05">*** 5. Konfigurace MirrorMakeru</a></p>
<p><a href="#k06">*** 6. Praktická část</a></p>
<p><a href="#k07">*** 7. </a></p>
<p><a href="#k08">*** 8. </a></p>
<p><a href="#k09">*** 9. </a></p>
<p><a href="#k10">*** 10. </a></p>
<p><a href="#k11">*** 11. </a></p>
<p><a href="#k12">*** 12. </a></p>
<p><a href="#k13">*** 13. </a></p>
<p><a href="#k14">*** 14. </a></p>
<p><a href="#k15">*** 15. </a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. </a></p>
<p><a href="#k20">*** 20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Nástroj MirrorMaker pro Apache Kafku</h2>

<p>Systém Apache Kafka je v&nbsp;současnosti velmi rozšířen a používá se
v&nbsp;mnoha oblastech IT. Někdy se setkáme s&nbsp;tím, že je Apache Kafka
nasazena a využívána jako pouhý &bdquo;vylepšený&ldquo; message broker,
tj.&nbsp;jako centrální část celé architektury sloužící pro komunikaci mezi
jednotlivými (mikro)službami a nástroji. Ovšem možnosti Apache Kafky jsou ve
skutečnosti poněkud větší, a to díky poměrně unikátnímu způsobu práce
s&nbsp;tzv.&nbsp;tématy (<i>topic</i>). Navíc Apache Kafka dokáže zajistit
svoji velkou dostupnost a odolnost vůči pádům jednotlivých komponent či síťové
infrastruktury (<i>resilience</i>). Tomuto tématu jsme se již věnovali, ovšem
zbývá nám popsat ještě jednu technologii, kterou lze použít pro replikaci zpráv
z&nbsp;vybraných oddílů mezi oddělenými (a mnohdy i vzdálenými) datovými
centry. Tato technologie se jmenuje <i>MirrorMaker</i>, což je název, který
poměrně přesně popisuje, k&nbsp;jakým operacím dochází.</p>

<img src="https://i.iinfo.cz/images/447/microservices2-3.png" class="image-361670" alt="&#160;" width="450" height="134" />
<p><i>Obrázek 1: Známé logo nástroje Apache Kafka, kterému se budeme dnes
věnovat.</i></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Replikace oddílů v&nbsp;rámci jednoho Kafka clusteru</h2>

<p>Připomeňme si, že téma (<i>topic</i>), do kterého se posílají zprávy, může
být rozděleno do několika oddílů. V&nbsp;takovém případě producent či
producenti nezapisují zprávy do jednoho oddílu (samozřejmě na konec), ale zápis
je proveden pouze do jednoho z&nbsp;vybraných oddílů. O tom, do kterého oddílu
bude zápis (resp.&nbsp;připojení) zprávy proveden, se rozhoduje na základě
<i>klíče</i> připojeného ke zprávě. Samotná zpráva je totiž chápána jako dvě
sekvence bajtů &ndash; klíč zprávy a tělo zprávy. A právě na základě klíče se
vypočítá hash a algoritmus implementovaný v&nbsp;samotném brokeru rozhodne, do
kterého oddílu bude zpráva uložena:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Po přijetí nové zprávy tedy může být zápis proveden do tohoto místa:</p>

<pre>
                                   write
                                     |
              +---+---+---+---+---+---+  v
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Nebo se může broker rozhodnout pro připojení zprávy do posledního oddílu
atd. atd.:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+  ^
                                                 |
                                               write
</pre>

<p>Další možná konfigurace tématu může vypadat tak, že téma má sice jediný
oddíl, ovšem tento oddíl je replikován mezi několika brokery. Příkladem může
být oddíl replikovaný mezi trojicí brokerů. V&nbsp;takovém případě je jeden
z&nbsp;těchto oddílů nazvaný <i>leader</i> a veškeré operace viděné zvnějšku
Kafky (tedy posílání zpráv a jejich konzumace) probíhá právě s&nbsp;leaderem.
Ostatní repliky jsou nazvané <i>follower(s)</i>, protože pouze sledují leadera
a synchronizují svůj obsah s&nbsp;leaderem:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...    (leader)
+---+---+---+---+---+---+---+---+---+
                  ^               ^
                  |               |
                read              |
                                 sync
                                  |
                                  |
                                  v
+---+---+---+---+---+---+---+---+---+
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |        (follower)
+---+---+---+---+---+---+---+---+---+
                                  ^
                                  |
                                  |
                                 sync
                                  |
                                  |
                                  v
+---+---+---+---+---+---+---+---+---+
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |        (follower)
+---+---+---+---+---+---+---+---+---+
</pre>

<p>K&nbsp;čemu je to však dobré? V&nbsp;případě, že nějaký broker z&nbsp;celého
Kafka clusteru zhavaruje a bude obsahovat oddíl typu <i>follower</i>, bude
komunikace pokračovat dál a teprve po znovupřipojení brokera se <i>follower</i>
postupně sesynchronizuje s&nbsp;<i>leaderem</i>. Zajímavější situace nastane ve
chvíli, kdy zhavaruje samotný <i>leader</i>. V&nbsp;takovém případě Kafka
&bdquo;povýší&ldquo;nějakého <i>followera</i> za nového <i>leadera</i>.
V&nbsp;případě, že téma (resp.&nbsp;oddíl) je replikováno na N brokerů, může
jich zhavarovat N-1 a systém bude stále funkční. I toto chování si pochopitelně
postupně otestujeme.</p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Několik samostatně běžících Kafka clusterů</h2>

<p>Podpora pro replikaci oddílů je v&nbsp;současnosti nedílnou součástí Apache Kafky a nebylo by bez ní možné zajistit fungování celého Kafka clusteru i v&nbsp;tom případě, kdy některý prvek clusteru zhavaruje (nebo se &bdquo;jen&ldquo; stane nedostupným). Jedná se o známou a velmi často používanou technologii, která však má své limity. Na tyto limity narazíme ve chvíli, kdy běží několik Kafka clusterů, přičemž každý z&nbsp;nich je typicky umístěn v&nbsp;samostatném datovém centru. Zatímco propojení počítačů v&nbsp;rámci jednoho datového centra bývá velmi rychlé (to je ostatně jeden z&nbsp;důvodů, i když nikoli jediný, proč tato centra vznikají), přenos dat mezi datovými centry bývá pomalejší a mívá zpoždění. Ovšem pokud by jednotlivé uzly Kafka clusteru byly umístěny v&nbsp;různých centrech, celá technologie replikace by zpomalovala zpracování zpráv a byla by zde i větší náchylnost na rozpad uzlu kvůli tomu, že spojení mezi datovými centry může být (i na chvíli) přerušeno.</p>

<p>V&nbsp;takové situaci se může přistoupit k&nbsp;tomu, že se v&nbsp;každém datovém centru spustí samostatný Kafka cluster, jenž bude prakticky nezávislý na clusterech v&nbsp;jiných datových centrech. Některá témata (<i>topic</i>) mohou být skutečně lokální (například pouze pro Evropu, další téma pro jiný Kafka cluster pro severní Ameriku atd.), ale pochopitelně nastane situace vyžadující, aby bylo některé téma replikováno i mezi jednotlivými Kafka clustery. A právě v&nbsp;těchto případech lze sáhnout po nástroji nazvaném <i>MirrorMaker</i>, jímž se budeme zabývat v&nbsp;navazujících kapitolách.</p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Nástroj MirrorMaker</h2>

<p>Nástroj MirrorMaker slouží k&nbsp;propojení Kafka clusterů, přičemž se očekává, že každý takový cluster poběží v&nbsp;odděleném datovém centru, takže komunikace mezi clustery bude obecně pomalejší, než komunikace mezi uzly jediného clusteru. Samotný MirrorMaker je z&nbsp;pohledu Apache Kafky konzumentem zpráv z&nbsp;vybraného tématu producentem zpráv do jiného tématu a navíc i v&nbsp;odlišném clusteru. Nejedná se tedy o žádnou &bdquo;raketovou vědu&ldquo;, ale o konzumaci zpráv docházejících do tématu (témat) v&nbsp;jednom clusteru a o jejich přeposílání do dalšího clusteru. Samozřejmě je možné realizovat i propojení mezi několika clustery, nikoli pouze mezi dvojicí clusterů.</p>

<p>Graficky můžeme nejjednodušší způsob použití MirrorMakeru znázornit takto:</p>

*** image ***
<p><i>Obrázek 2: MirrorMaker pro replikaci dat z&nbsp;prvního Kafka clusteru do clusteru druhého.</i></p>

<p>Interně používá MirrorMaker standardní komunikační prostředky Apache Kafky. Konkrétně to znamená, že data (zprávy) načítá jako běžný konzument a naopak data zapisuje jako běžný producent. Z&nbsp;pohledu Kafka clusterů i jednotlivých brokerů se tedy jedná o zcela běžného klienta, který nepotřebuje využívat speciální komunikační prostředky (a navíc je relativně snadné si napsat vlastní verzi MirrorMakeru, pokud to někoho láká):</p>

*** image ***
<p><i>Obrázek 3: MirrorMaker se interně skládá z&nbsp;konzumenta a producenta zpráv.</i></p>



<p><a name="k05"></a></p>
<h2 id="k05">5. Konfigurace MirrorMakeru</h2>

<p></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Praktická část</h2>

<p>Druhá část dnešního článku bude zaměřená více prakticky. Nejdříve vytvoříme dvě instance Kafka clusterů, přičemž každá instance se bude skládat z&nbsp;jednoho běžícího Zookeepera a jednoho brokera. Na této instanci si otestujeme způsoby vytváření témat, chování většího množství konzumentů při připojení k&nbsp;tématu, použití většího množství oddílů pro téma atd. Dále oba Kafka clustery propojíme s&nbsp;využitím MirrorMakeru a opět budeme sledovat chování producentů a konzumentů připojených k&nbsp;oběma clusterům.</p>

<p>V&nbsp;praktické části budeme brokera Apache Kafky i Zookeepera spouštět lokálně (popř.&nbsp;z&nbsp;Dockeru), takže je nejdříve nutné Kafku nainstalovat. Není to vůbec nic složitého. V&nbsp;případě, že je na počítači nainstalováno JRE (běhové prostředí Javy), je instalace Kafky pro testovací účely triviální. V&nbsp;článku si ukážeme instalaci verze 3.6.1, ovšem můžete si stáhnout i prakticky libovolnou novější či některé starší verze (3.5.x nebo 3.6.x, ovšem dále popsaný postup by měl být platný i pro ještě starší verze). Tarball s&nbsp;instalací Kafky lze získat z&nbsp;adresy <a href="https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz">https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz</a>. Stažení a rozbalení tarballu:</p>

<pre>
$ <strong>wget https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz</strong>
$ <strong>tar xvfz kafka_2.13-3.6.1.tgz</strong>
$ <strong>cd kafka_2.13-3.6.1/</strong>
</pre>

<p>Po rozbalení staženého tarballu získáme adresář, v&nbsp;němž se nachází všechny potřebné Java archivy (JAR), konfigurační soubory (v&nbsp;podadresáři <strong>config</strong>) a několik pomocných skriptů (v&nbsp;podadresáři <strong>bin</strong>). Pro spuštění Zookeepera a brokerů je zapotřebí mít nainstalovánu JRE (Java Runtime Environment) a samozřejmě též nějaký shell (BASH, cmd, ...).</p> 
 
<pre>
.
├── bin
│   └── windows
├── config
│   └── kraft
├── libs
├── licenses
└── site-docs
&nbsp;
7 directories
</pre>

<p>Mezi důležité soubory, které budeme používat v&nbsp;rámci dalších kapitol, patří především skripty pro spouštění jednotlivých služeb, konfiguraci témat, produkci zpráv či pro jejich konzumaci. Tyto skripty jsou uloženy v&nbsp;podadresáři <strong>bin</strong> (a pro Windows ještě v&nbsp;dalším podadresáři <strong>windows</strong>):</p>


<table>
<tr><th>Skript</th><th>Stručný popis</th></tr>
<tr><td>bin/kafka-server-start.sh</td><td>spuštění brokera</td></tr>
<tr><td>bin/zookeeper-server-start.sh</td><td>spuštění Zookeepera</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>bin/kafka-configs.sh</td><td>konfigurace brokerů</td></tr>
<tr><td>bin/kafka-topics.sh</td><td>konfigurace témat, zjištění informace o tématech atd.</td></tr>
<tr><td>bin/kafka-consumer-groups.sh</td><td>konfigurace popř.&nbsp;zjištění informací o skupinách konzumentů</td></tr>
<tr><td>bin/kafka-run-class.sh</td><td>spuštění konkrétní třídy z&nbsp;Apache Kafky (například pro zjištění informací o skupinách konzumentů)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>bin/kafka-console-producer.sh</td><td>jednoduchý producent zpráv</td></tr>
<tr><td>bin/kafka-console-consumer.sh</td><td>jednoduchý konzument zpráv</td></tr>
</table>



<p><a name="k07"></a></p>
<h2 id="k07">7. </h2>



<p><a name="k08"></a></p>
<h2 id="k08">8. </h2>



<p><a name="k09"></a></p>
<h2 id="k09">9. </h2>



<p><a name="k10"></a></p>
<h2 id="k10">10. </h2>



<p><a name="k11"></a></p>
<h2 id="k11">11. </h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. </h2>



<p><a name="k13"></a></p>
<h2 id="k13">13. </h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. </h2>



<p><a name="k15"></a></p>
<h2 id="k15">15. </h2>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Kafka mirroring (MirrorMaker)<br />
<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330">https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330</a>
</li>

<li>Mastering Kafka migration with MirrorMaker 2<br />
<a href="https://developers.redhat.com/articles/2024/01/04/mastering-kafka-migration-mirrormaker-2">https://developers.redhat.com/articles/2024/01/04/mastering-kafka-migration-mirrormaker-2</a>
</li>

<li>How to use Kafka MirrorMaker 2.0 in data migration, replication and the use-cases<br />
<a href="https://learn.microsoft.com/en-us/azure/hdinsight/kafka/kafka-mirrormaker-2-0-guide">https://learn.microsoft.com/en-us/azure/hdinsight/kafka/kafka-mirrormaker-2-0-guide</a>
</li>

<li>Kafka Mirror Maker Best Practices<br />
<a href="https://community.cloudera.com/t5/Community-Articles/Kafka-Mirror-Maker-Best-Practices/ta-p/249269">https://community.cloudera.com/t5/Community-Articles/Kafka-Mirror-Maker-Best-Practices/ta-p/249269</a>
</li>

<li>Apache Kafka MirrorMaker 2 (MM2) Part 1: Theory<br />
<a href="https://www.instaclustr.com/blog/kafka-mirrormaker-2-theory/">https://www.instaclustr.com/blog/kafka-mirrormaker-2-theory/</a>
</li>

<li>Kcli: is a kafka read only command line browser.<br />
<a href="https://github.com/cswank/kcli">https://github.com/cswank/kcli</a>
</li>

<li>Kcli: a kafka command line browser<br />
<a href="https://go.libhunt.com/kcli-alternatives">https://go.libhunt.com/kcli-alternatives</a>
</li>

<li>Kafka Connect and Schemas<br />
<a href="https://rmoff.net/2020/01/22/kafka-connect-and-schemas/">https://rmoff.net/2020/01/22/kafka-connect-and-schemas/</a>
</li>

<li>JSON and schemas<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas">https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas</a>
</li>

<li>What, why, when to use Apache Kafka, with an example<br />
<a href="https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/">https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/</a>
</li>

<li>When NOT to use Apache Kafka?<br />
<a href="https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/">https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/</a>
</li>

<li>Microservices: The Rise Of Kafka<br />
<a href="https://movio.co/blog/microservices-rise-kafka/">https://movio.co/blog/microservices-rise-kafka/</a>
</li>

<li>Building a Microservices Ecosystem with Kafka Streams and KSQL<br />
<a href="https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/">https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/</a>
</li>

<li>An introduction to Apache Kafka and microservices communication<br />
<a href="https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63">https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63</a>
</li>

<li>kappa-architecture.com<br />
<a href="http://milinda.pathirage.org/kappa-architecture.com/">http://milinda.pathirage.org/kappa-architecture.com/</a>
</li>

<li>Questioning the Lambda Architecture<br />
<a href="https://www.oreilly.com/ideas/questioning-the-lambda-architecture">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a>
</li>

<li>Lambda architecture<br />
<a href="https://en.wikipedia.org/wiki/Lambda_architecture">https://en.wikipedia.org/wiki/Lambda_architecture</a>
</li>

<li>Kafka &ndash; ecosystem (Wiki)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem</a>
</li>

<li>The Kafka Ecosystem - Kafka Core, Kafka Streams, Kafka Connect, Kafka REST Proxy, and the Schema Registry<br />
<a href="http://cloudurable.com/blog/kafka-ecosystem/index.html">http://cloudurable.com/blog/kafka-ecosystem/index.html</a>
</li>

<li>A Kafka Operator for Kubernetes<br />
<a href="https://github.com/krallistic/kafka-operator">https://github.com/krallistic/kafka-operator</a>
</li>

<li>Kafka Streams<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams">https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams</a>
</li>

<li>Kafka Streams<br />
<a href="http://kafka.apache.org/documentation/streams/">http://kafka.apache.org/documentation/streams/</a>
</li>

<li>Kafka Streams (FAQ)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams">https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams</a>
</li>

<li>Event stream processing<br />
<a href="https://en.wikipedia.org/wiki/Event_stream_processing">https://en.wikipedia.org/wiki/Event_stream_processing</a>
</li>

<li>Part 1: Apache Kafka for beginners - What is Apache Kafka?<br />
<a href="https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html">https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html</a>
</li>

<li>What are some alternatives to Apache Kafka?<br />
<a href="https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka">https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka</a>
</li>

<li>What is the best alternative to Kafka?<br />
<a href="https://www.slant.co/options/961/alternatives/~kafka-alternatives">https://www.slant.co/options/961/alternatives/~kafka-alternatives</a>
</li>

<li>A super quick comparison between Kafka and Message Queues<br />
<a href="https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0">https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0</a>
</li>

<li>Kafka Queuing: Kafka as a Messaging System<br />
<a href="https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system">https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system</a>
</li>

<li>Apache Kafka Logs: A Comprehensive Guide<br />
<a href="https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/">https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/</a>
</li>

<li>Microservices – Not a free lunch!<br />
<a href="http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html">http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html</a>
</li>

<li>Microservices, Monoliths, and NoOps<br />
<a href="http://blog.arungupta.me/microservices-monoliths-noops/">http://blog.arungupta.me/microservices-monoliths-noops/</a>
</li>

<li>Microservice Design Patterns<br />
<a href="http://blog.arungupta.me/microservice-design-patterns/">http://blog.arungupta.me/microservice-design-patterns/</a>
</li>

<li>REST vs Messaging for Microservices – Which One is Best?<br />
<a href="https://solace.com/blog/experience-awesomeness-event-driven-microservices/">https://solace.com/blog/experience-awesomeness-event-driven-microservices/</a>
</li>

<li>Kappa Architecture Our Experience<br />
<a href="https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf">https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf</a>
</li>

<li>Apache Kafka Streams and Tables, the stream-table duality<br />
<a href="https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854">https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854</a>
</li>

<li>Configure Self-Managed Connectors<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors">https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors</a>
</li>

<li>Schema Evolution and Compatibility<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility">https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility</a>
</li>

<li>Configuring Key and Value Converters<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters">https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters</a>
</li>

<li>Introduction to Kafka Connectors<br />
<a href="https://www.baeldung.com/kafka-connectors-guide">https://www.baeldung.com/kafka-connectors-guide</a>
</li>

<li>Kafka CLI: command to list all consumer groups for a topic?<br />
<a href="https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic">https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic</a>
</li>

<li>Java Property File Processing<br />
<a href="https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php">https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php</a>
</li>

<li>Skipping bad records with the Kafka Connect JDBC sink connector<br />
<a href="https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/">https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/</a>
</li>

<li>Kafka Connect Deep Dive – Error Handling and Dead Letter Queues<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/">https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/</a>
</li>

<li>Errors and Dead Letter Queues<br />
<a href="https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/">https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/</a>
</li>

<li>Confluent Cloud Dead Letter Queue<br />
<a href="https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html">https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html</a>
</li>

<li>Dead Letter Queues (DLQs) in Kafka<br />
<a href="https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309">https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309</a>
</li>

<li>Deserializer<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-json.html#json-schema-serializer-and-deserializer">https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-json.html#json-schema-serializer-and-deserializer</a>
</li>

<li>JSON, Kafka, and the need for schema<br />
<a href="https://mikemybytes.com/2022/07/11/json-kafka-and-the-need-for-schema/">https://mikemybytes.com/2022/07/11/json-kafka-and-the-need-for-schema/</a>
</li>

<li>Using Kafka Connect with Schema Registry<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/connect.html">https://docs.confluent.io/platform/current/schema-registry/connect.html</a>
</li>

<li>Zpracování dat reprezentovaných ve formátu JSON nástrojem jq<br />
<a href="https://www.root.cz/clanky/zpracovani-dat-reprezentovanych-ve-formatu-json-nastrojem-jq/">https://www.root.cz/clanky/zpracovani-dat-reprezentovanych-ve-formatu-json-nastrojem-jq/</a>
</li>

<li>Repositář projektu jq (GitHub)<br />
<a href="https://github.com/stedolan/jq">https://github.com/stedolan/jq</a>
</li>

<li>GitHub stránky projektu jq<br />
<a href="https://stedolan.github.io/jq/">https://stedolan.github.io/jq/</a>
</li>

<li>5 modern alternatives to essential Linux command-line tools<br />
<a href="https://opensource.com/ar­ticle/20/6/modern-linux-command-line-tools">https://opensource.com/ar­ticle/20/6/modern-linux-command-line-tools</a>
</li>

<li>Návod k nástroji jq<br />
<a href="https://stedolan.github.i­o/jq/tutorial/">https://stedolan.github.i­o/jq/tutorial/</a>
</li>

<li>jq Manual (development version)<br />
<a href="https://stedolan.github.io/jq/manual/">https://stedolan.github.io/jq/manual/</a>
</li>

<li>Introducing JSON<br />
<a href="https://www.json.org/json-en.html">https://www.json.org/json-en.html</a>
</li>

<li>Understanding JSON schema<br />
<a href="https://json-schema.org/understanding-json-schema/index.html">https://json-schema.org/understanding-json-schema/index.html</a>
</li>

<li>JDBC Sink Connector for Confluent Platform<br />
<a href="https://docs.confluent.io/kafka-connectors/jdbc/current/sink-connector/overview.html#jdbc-sink-connector-for-cp">https://docs.confluent.io/kafka-connectors/jdbc/current/sink-connector/overview.html#jdbc-sink-connector-for-cp</a>
</li>

<li>JDBC Connector (Source and Sink)<br />
<a href="https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc">https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc</a>
</li>

<li>Introduction to Schema Registry in Kafka<br />
<a href="https://medium.com/slalom-technology/introduction-to-schema-registry-in-kafka-915ccf06b902">https://medium.com/slalom-technology/introduction-to-schema-registry-in-kafka-915ccf06b902</a>
</li>

<li>Understanding JSON Schema Compatibility<br />
<a href="https://yokota.blog/2021/03/29/understanding-json-schema-compatibility/">https://yokota.blog/2021/03/29/understanding-json-schema-compatibility/</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2023</small></p>
</body>
</html>

