<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Nástroj MirrorMaker pro Apache Kafku</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Nástroj MirrorMaker pro Apache Kafku</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>Systému Apache Kafka jsme se již na stránkách Roota věnovali v několika článcích. Zabývali jsme se i problematikou replikace oddílů a chování Kafka v případě nedostupnosti některého z brokerů. Ovšem Kafka obsahuje ještě podporu pro replikaci zpráv mezi datovými centry. Tuto problematiku si popíšeme dnes.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Nástroj MirrorMaker pro Apache Kafku</a></p>
<p><a href="#k02">2. Replikace oddílů v&nbsp;rámci jednoho Kafka clusteru</a></p>
<p><a href="#k03">3. Několik samostatně běžících Kafka clusterů</a></p>
<p><a href="#k04">4. Nástroj MirrorMaker</a></p>
<p><a href="#k05">5. MirrorMaker 1 vs MirrorMaker 2</a></p>
<p><a href="#k06">6. Praktická část</a></p>
<p><a href="#k07">*** 7. Konfigurace dvou lokálních Kafka clusterů</a></p>
<p><a href="#k08">*** 8. Konfigurace MirrorMakeru 2</a></p>
<p><a href="#k09">*** 9. Spuštění Kafka clusterů, spuštění MirrorMakeru</a></p>
<p><a href="#k10">*** 10. Producent a konzument pro téma na prvním clusteru</a></p>
<p><a href="#k11">*** 11. Konzument naslouchající na druhém clusteru</a></p>
<p><a href="#k12">*** 12. Témata vytvořená a spravovaná MirrorMakerem</a></p>
<p><a href="#k13">*** 13. Další možnosti nastavení MirrorMakeru</a></p>
<p><a href="#k14">*** 14. Omezení témat, která se mají replikovat</a></p>
<p><a href="#k15">*** 15. Jednosměrná replikace</a></p>
<p><a href="#k16">*** 16. </a></p>
<p><a href="#k17">*** 17. </a></p>
<p><a href="#k18">*** 18. </a></p>
<p><a href="#k19">*** 19. </a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Nástroj MirrorMaker pro Apache Kafku</h2>

<p>Systém Apache Kafka je v&nbsp;současnosti velmi rozšířen a používá se
v&nbsp;mnoha oblastech IT. Někdy se setkáme s&nbsp;tím, že je Apache Kafka
nasazen a využíván jako pouhý &bdquo;vylepšený&ldquo; message broker,
tj.&nbsp;jako centrální část celé architektury sloužící pro komunikaci mezi
jednotlivými (mikro)službami a nástroji. V&nbsp;takovém případě se typicky
používají komunikační strategie <i>pub-sub</i> nebo <i>push-pull</i>,
s&nbsp;nimiž jsme se již na stránkách Roota seznámili <a
href="https://www.root.cz/serialy/message-brokery/">v&nbsp;seriálu o message
brokerech</a> (například <a
href="https://www.root.cz/clanky/apache-activemq-dalsi-system-implementujici-message-brokera/">v&nbsp;článku
o Apache ActiveMQ</a>).</p>

<p>Ovšem možnosti Apache Kafky jsou ve skutečnosti poněkud větší, a to díky
poměrně unikátnímu způsobu práce s&nbsp;takzvanými tématy (<i>topic</i>) a
oddíly (<i>partition</i>) i díky tomu, že si <i>offsety</i> čtených zpráv řídí
konzumenti resp.&nbsp;jejich skupiny (<i>consumer groups</i>). Navíc Apache
Kafka dokáže zajistit svoji velkou dostupnost a odolnost vůči pádům
jednotlivých komponent či síťové infrastruktury (<i>resilience</i>). Tomuto
tématu jsme se již věnovali, ovšem zbývá nám popsat ještě jednu technologii,
kterou lze použít pro replikaci zpráv z&nbsp;vybraných oddílů mezi oddělenými
(a mnohdy i vzdálenými) datovými centry. Tato technologie se jmenuje
<i>MirrorMaker</i>, což je název, který poměrně přesně popisuje, k&nbsp;jakým
operacím při nasazení MirrorMakeru dochází.</p>

<img src="https://i.iinfo.cz/images/447/microservices2-3.png" class="image-361670" alt="&#160;" width="450" height="134" />
<p><i>Obrázek 1: Známé logo nástroje Apache Kafka, kterému se budeme věnovat
v&nbsp;dnešním článku.</i></p>

<p><div class="rs-tip-major">Poznámka: v&nbsp;současnosti ve skutečnosti
existují dva nástroje nazvané <i>MirrorMaker</i>, přičemž druhá verze se
oficiálně jmenuje <i>MirrorMaker2</i>. Každá z&nbsp;těchto verzí interně
pracuje odlišně a odlišná (a obecně nepřenositelná) je i jejich konfigurace.
V&nbsp;dnešním článku se nejdříve zmíníme o původní verzi, která je sice
označena jako <i>deprecated</i>, ovšem bez problémů ji lze provozovat i na
nejnovější verzi Apache Kafky. A poté si ukážeme možnosti MirrorMakeru2, které
jsou mnohem zajímavější a v&nbsp;praxi i užitečnější (a opět se pochopitelně
jedná o technologii využitelnou i v&nbsp;současné verzi Apache
Kafky).</div></p>



<p><a name="k02"></a></p>
<h2 id="k02">2. Replikace oddílů v&nbsp;rámci jednoho Kafka clusteru</h2>

<p>Připomeňme si, že téma (<i>topic</i>), do kterého se posílají zprávy, může
být v&nbsp;systému Apache Kafky rozděleno do několika oddílů. V&nbsp;takovém
případě producent či producenti nezapisují zprávy do jednoho oddílu (samozřejmě
na konec), ale zápis je proveden pouze do jediného z&nbsp;vybraných oddílů. O
tom, do kterého oddílu bude zápis (resp.&nbsp;připojení) zprávy proveden, se
rozhoduje na základě <i>klíče</i> připojeného ke zprávě. Samotná zpráva je
totiž chápána jako dvě sekvence bajtů &ndash; první sekvence tvoří klíč zprávy
a druhá sekvence tělo zprávy. A právě na základě předaného klíče se vypočítá
hash a algoritmus implementovaný v&nbsp;samotném brokeru rozhodne, do kterého
oddílu bude zpráva uložena:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Po přijetí nové zprávy tedy může být zápis proveden například do prvního
oddílu na offset číslo 6:</p>

<pre>
                                       write
                                         |
              +---+---+---+---+---+---+  v
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+
</pre>

<p>Nebo se může broker rozhodnout pro připojení zprávy do posledního oddílu
atd. atd.:</p>

<pre>
              +---+---+---+---+---+---+
partition #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
              +---+---+---+---+---+---+
partition #1  | 0 | 1 | 2 | ...
              +---+---+---+
partition #2  | ...
              +---+---+---+---+---+---+---+---+---+
partition #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
              +---+---+---+---+---+---+---+---+---+  ^
                                                     |
                                                   write
</pre>

<p><div class="rs-tip-major">Poznámka: tato konfigurace se používá
v&nbsp;případě, kdy budeme chtít využít více paralelně běžících konzumentů,
které jsou součástí jedné skupiny konzumentů (<i>consumer groups</i>). Jedná se
tedy o konfiguraci určenou pro zajištění větší průchodnosti dat.</div></p>

<p>Další možná a podporovaná konfigurace tématu může vypadat tak, že pro dané
téma je vytvořen pouze jediný oddíl, ovšem tento oddíl je replikován mezi
několika brokery. Příkladem může být oddíl replikovaný mezi trojicí brokerů
běžících v&nbsp;rámci stejného Kafka clusteru. V&nbsp;takovém případě je jeden
z&nbsp;těchto oddílů nazvaný <i>leader</i> a veškeré operace viděné zvnějšku
Kafky (tedy posílání zpráv a jejich konzumace) probíhá právě s&nbsp;leaderem.
Ostatní repliky jsou nazvané <i>follower(s)</i>, protože pouze sledují leadera
a synchronizují svůj obsah s&nbsp;leaderem. Ovšem zápis nové zprávy primárně
proběhne v&nbsp;oddílu leadera:</p>

<pre>
                                     write
                                       |
+---+---+---+---+---+---+---+---+---+  v
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...    (leader)
+---+---+---+---+---+---+---+---+---+
                  ^               ^
                  |               |
                read              |
                                 sync
                                  |
                                  |
                                  v
+---+---+---+---+---+---+---+---+---+
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |        (follower)
+---+---+---+---+---+---+---+---+---+
                                  ^
                                  |
                                  |
                                 sync
                                  |
                                  |
                                  v
+---+---+---+---+---+---+---+---+---+
| 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |        (follower)
+---+---+---+---+---+---+---+---+---+
</pre>

<p>K&nbsp;čemu je to však dobré? V&nbsp;případě, že nějaký broker z&nbsp;celého
Kafka clusteru zhavaruje a tento broker bude (pro dané téma) obsahovat oddíl
typu <i>follower</i>, bude komunikace pokračovat dál a teprve po znovupřipojení
brokera se <i>follower</i> postupně sesynchronizuje s&nbsp;<i>leaderem</i>.
Zajímavější situace nastane ve chvíli, kdy zhavaruje samotný <i>leader</i>.
V&nbsp;takovém případě Kafka &bdquo;povýší&ldquo;nějakého <i>followera</i> za
nového <i>leadera</i>. V&nbsp;případě, že téma (resp.&nbsp;oddíl) je
replikováno na N brokerů, může jich zhavarovat N-1 a systém bude stále funkční.
Jinými slovy to znamená, že takto nakonfigurované téma dokáže
&bdquo;přežít&ldquo; pád některého z&nbsp;brokerů aniž by došlo
k&nbsp;závažnějšímu narušení komunikace (pouze se producenti a konzumenti
přepojí na jiného brokera, což zabere nějaký čas). Na druhou stranu se však
nezvyšuje propustnost v&nbsp;případě připojení většího množství konzumentů ze
stejné skupiny konzumentů.</p>

<p>Obě výše zmíněné možnosti je pochopitelně možné v&nbsp;případě potřeby
zkombinovat a vytvořit tak konfiguraci tématu, které bude rozděleno na větší
množství oddílů a tyto oddíly budou replikovány mezi větší množství
brokerů:</p>

<pre>
          +---+---+---+---+---+---+
oddíl #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
          +---+---+---+---+---+---+
oddíl #1  | 0 | 1 | 2 | ...
          +---+---+---+                               (leader)
oddíl #2  | ...
          +---+---+---+---+---+---+---+---+---+
oddíl #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
          +---+---+---+---+---+---+---+---+---+
                                  ^
                                  |
                                  |
                                 sync
                                  |
                                  |
                                  v
          +---+---+---+---+---+---+
oddíl #0  | 0 | 1 | 2 | 3 | 4 | 5 | ...
          +---+---+---+---+---+---+
oddíl #1  | 0 | 1 | 2 | ...
          +---+---+---+
oddíl #2  | ...                                       (follower)
          +---+---+---+---+---+---+---+---+---+
oddíl #3  | 0 | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | ...
          +---+---+---+---+---+---+---+---+---+
</pre>

<p>Tím dosáhneme toho, že Kafka cluster &bdquo;přežije&ldquo; pád N-1 brokerů a
navíc se zajistí paralelní čtení zpráv větším množstvím konzumentů patřících do
stejné skupiny konzumentů.</p>



<p><a name="k03"></a></p>
<h2 id="k03">3. Několik samostatně běžících Kafka clusterů</h2>

<p>Podpora pro replikaci oddílů je v&nbsp;současnosti nedílnou součástí Apache
Kafky a nebylo by bez ní možné zajistit fungování celého Kafka clusteru i
v&nbsp;tom případě (který dříve či později nastane), kdy některý prvek clusteru
zhavaruje (nebo se &bdquo;jen&ldquo; stane nedostupným). Jedná se o známou a
velmi často používanou technologii, která však má své limity. Na tyto limity
poměrně brzy narazíme ve chvíli, kdy je provozováno několik Kafka clusterů,
přičemž každý z&nbsp;nich je typicky umístěn v&nbsp;samostatném datovém centru.
Zatímco propojení počítačů v&nbsp;rámci jednoho datového centra bývá velmi
rychlé (to je ostatně jeden z&nbsp;důvodů, i když nikoli jediný, proč vůbec
tato centra vznikají), přenos dat mezi datovými centry bývá pomalejší a mívá
zpoždění. Ovšem pokud by jednotlivé uzly Kafka clusteru byly umístěny
v&nbsp;různých centrech, celá technologie replikace by zpomalovala zpracování
zpráv a byla by zde i větší náchylnost na rozpad clusteru kvůli tomu, že
spojení mezi datovými centry může být (i na relativně krátkou chvíli)
přerušeno.</p>

<p>V&nbsp;takové situaci se může přistoupit k&nbsp;tomu, že se v&nbsp;každém
datovém centru spustí samostatný Kafka cluster, jenž bude prakticky nezávislý
na clusterech v&nbsp;jiných datových centrech. Některá témata (<i>topic</i>)
mohou být skutečně lokální (například některé téma může být určeno pouze pro
Evropu, další téma pro jiný Kafka cluster pro severní Ameriku atd.), ale
pochopitelně většinou nastane i situace vyžadující, aby bylo některé téma
replikováno i mezi jednotlivými Kafka clustery. A právě v&nbsp;těchto případech
lze sáhnout po nástroji nazvaném <i>MirrorMaker</i>, jímž se budeme zabývat
v&nbsp;navazujících kapitolách.</p>



<p><a name="k04"></a></p>
<h2 id="k04">4. Nástroj MirrorMaker</h2>

<p>Nástroj MirrorMaker slouží, jak již bylo ostatně naznačeno v&nbsp;předchozím
textu, k&nbsp;propojení několika Kafka clusterů, přičemž se očekává, že každý
takový cluster poběží v&nbsp;odděleném datovém centru, takže komunikace mezi
clustery může být obecně pomalejší (s&nbsp;případnými výpadky), než komunikace
mezi uzly nacházejícími se v&nbsp;jediném clusteru. Samotný MirrorMaker je
z&nbsp;pohledu systému Apache Kafky konzumentem zpráv z&nbsp;vybraných témat a
producentem zpráv do jiných témat, přičemž témata se mohou nacházet
v&nbsp;různých clusterech. Nejedná se tedy (alespoň ne v&nbsp;případě
MirrorMakeru 1) o žádnou &bdquo;raketovou vědu&ldquo;, ale vlastně jen o
triviální konzumaci zpráv docházejících do tématu (témat) v&nbsp;jednom
clusteru a o jejich přeposílání do dalšího clusteru (MirrorMaker 2 je již
komplikovanější). Samozřejmě je možné v&nbsp;případě potřeby realizovat i
propojení mezi několika clustery, nikoli pouze mezi dvojicí clusterů.</p>

<p>Graficky můžeme nejjednodušší způsob použití MirrorMakeru znázornit
takto:</p>

*** image ***
<p><i>Obrázek 2: MirrorMaker pro replikaci dat z&nbsp;prvního Kafka clusteru do
clusteru druhého.</i></p>

<p>Interně používá MirrorMaker (1) standardní komunikační prostředky Apache
Kafky. Konkrétně to znamená, že data (zprávy) načítá jako běžný konzument a
naopak data zapisuje jako běžný producent. Z&nbsp;pohledu Kafka clusterů i
jednotlivých brokerů se tedy jedná o zcela běžného klienta, který nepotřebuje
využívat speciální komunikační prostředky (a navíc je relativně snadné si
napsat vlastní verzi MirrorMakeru, pokud to někoho láká):</p>

*** image ***
<p><i>Obrázek 3: MirrorMaker se interně skládá z&nbsp;konzumenta a producenta zpráv.</i></p>

<p>Ovšem tento nástroj lze využít i pro další účely, například pro přenos zpráv
z&nbsp;vybraných témat z&nbsp;interního (privátního) Kafka clusteru do clusteru
dostupného i dalším firmám (<i>data isolation</i>). A taktéž lze stejnou
technologii použít pro agregaci dat získaných z&nbsp;libovolného množství Kafka
clusterů s&nbsp;uložením do libovolného (dalšího) clusteru. To ale není vše,
protože lze realizovat i komunikaci typu <i>fan-in</i> a <i>fan-out</i> (tedy
spojení zpráv z&nbsp;více clusterů do jediného výsledného tématu či naopak
přečtení zpráv z&nbsp;jednoho tématu s&nbsp;jejich rozesláním do většího
množství clusterů).</p>



<p><a name="k05"></a></p>
<h2 id="k05">5. MirrorMaker 1 vs MirrorMaker 2</h2>

<p>Jak jsme si již řekli v&nbsp;poznámce uvedené <a href="#k01">v&nbsp;úvodní
kapitole</a>, nacházíme se nyní v&nbsp;situaci, kdy existují dvě vzájemně
odlišné verze MirrorMakeru. Původní verze je stále dostupná (a spouští se
skriptem <strong>bin/kafka-mirror-maker.sh</strong>
resp.&nbsp;<strong>bin/windows/kafka-mirror-maker.bat</strong>) a od verze
Kafky 2.4.0 (viz též <a
href="https://archive.apache.org/dist/kafka/2.4.0/RELEASE_NOTES.html">https://archive.apache.org/dist/kafka/2.4.0/RELEASE_NOTES.html</a>)
je dostupná i druhá verze MirrorMakeru. Ta se spouští skriptem
<strong>bin/connect-mirror.maker.sh</strong> (pro Windows varianta tohoto
skriptu neexistuje :-). Názvy těchto skriptů mohou být zpočátku matoucí, což se
pravděpodobně vyřeší ve chvíli, kdy bude původní MirrorMaker 1 z&nbsp;Apache
Kafky odstraněn.</p>

<p>Druhá verze MirrorMakeru je založena na technologii Kafka Connect,
s&nbsp;níž jsme se seznámili ve dvojici článků <a
href="https://www.root.cz/clanky/kafka-connect-tvorba-producentu-a-konzumentu-bez-zdrojoveho-kodu/">Kafka
Connect: tvorba producentů a konzumentů bez zdrojového kódu</a> a <a
href="https://www.root.cz/clanky/kafka-connect-definice-a-kontrola-schematu-zprav/">Kafka
Connect: definice a kontrola schématu zpráv</a>. Konkrétně MirrorMaker 2
realizuje hned několik <i>konektorů</i>, z&nbsp;nichž každý je určen pro
realizaci odlišných funkcí:</p>

<ol>

<li><strong>MirrorSourceConnector</strong>: replikace zpráv z&nbsp;lokálního do
vzdáleného clusteru, synchronizace offsetů</li>

<li><strong>MirrorCheckpointConnector</strong>: synchronizace offsetů, failower
v&nbsp;případě výpadů Kafka clusterů, realizace checkpointů</li>

<li><strong>MirrorHeartbeatConnector</strong>: tzv. heartbeats (zjištění, zda
protistrana komunikuje), monitoring replikací, zjištění topologie pro replikace
atd.</li>

</ol>

<p><div class="rs-tip-major">Poznámka: už jen z&nbsp;tohoto výčtu je patrné, že
MirrorMaker 2 je interně složitější, než původní relativně triviální kombinace
konzumentů s&nbsp;producenty.</div></p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Praktická část</h2>

<p>Druhá část dnešního článku bude zaměřená více prakticky. Nejdříve vytvoříme
dvě instance Kafka clusterů, přičemž každá instance se bude skládat
z&nbsp;jednoho běžícího Zookeepera a z&nbsp;jednoho brokera. Na této instanci
si otestujeme způsoby vytváření témat, chování většího množství konzumentů při
připojení k&nbsp;tématu, použití většího množství oddílů pro téma atd. Dále oba
Kafka clustery propojíme s&nbsp;využitím MirrorMakeru (2) a opět budeme
sledovat chování producentů a konzumentů připojených k&nbsp;oběma
clusterům.</p>

<p>V&nbsp;praktické části budeme brokera Apache Kafky i Zookeepera spouštět
lokálně (popř.&nbsp;z&nbsp;Dockeru či Podmana), takže je nejdříve nutné Apache
Kafku nainstalovat. Není to vůbec nic složitého. V&nbsp;případě, že je na
počítači nainstalováno JRE (běhové prostředí Javy), je instalace Apache Kafky
pro testovací účely triviální. V&nbsp;článku si ukážeme instalaci verze
2.13-3.6.1, ovšem můžete si stáhnout i prakticky libovolnou novější či některé
starší verze (3.5.x nebo 3.6.x, ovšem dále popsaný postup by měl být platný i
pro ještě starší verze, v&nbsp;podstatě můžeme dojít až k&nbsp;verzi 2.4.0).
Tarball s&nbsp;instalací Apache Kafky lze získat z&nbsp;adresy <a
href="https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz">https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz</a>.</p>

<p>Stažení a rozbalení tarballu zajistí tyto příkazy:</p>

<pre>
$ <strong>wget https://downloads.apache.org/kafka/3.6.1/kafka_2.13-3.6.1.tgz</strong>
$ <strong>tar xvfz kafka_2.13-3.6.1.tgz</strong>
$ <strong>cd kafka_2.13-3.6.1/</strong>
</pre>

<p>Po rozbalení staženého tarballu získáme adresář, v&nbsp;němž se nachází
všechny potřebné Java archivy (JAR), konfigurační soubory (v&nbsp;podadresáři
<strong>config</strong>) a několik pomocných skriptů (v&nbsp;podadresáři
<strong>bin</strong> a <strong>bin/windows</strong>). Pro spuštění Zookeepera a
brokerů je zapotřebí, jak jsme si již řekli v&nbsp;předchozím odstavci, mít
nainstalovánu JRE (Java Runtime Environment) a samozřejmě též nějaký shell
(BASH, cmd, ...).</p> 
 
<pre>
.
├── bin
│   └── windows
├── config
│   └── kraft
├── libs
├── licenses
└── site-docs
&nbsp;
7 directories
</pre>

<p>Mezi důležité soubory, které budeme používat v&nbsp;rámci dalších kapitol,
patří především skripty pro spouštění jednotlivých služeb, konfiguraci témat,
produkci zpráv či pro jejich konzumaci. Tyto skripty jsou uloženy
v&nbsp;podadresáři <strong>bin</strong> (a pro Windows ještě v&nbsp;dalším
podadresáři <strong>windows</strong>). A pochopitelně nesmíme zapomenout na
skript spouštějící samotný MirrorMaker 1 či 2:</p>

<table>
<tr><th>Skript</th><th>Stručný popis</th></tr>
<tr><td>bin/kafka-server-start.sh</td><td>spuštění brokera</td></tr>
<tr><td>bin/zookeeper-server-start.sh</td><td>spuštění Zookeepera</td></tr>
<tr><td>bin/kafka-mirror-maker.sh</td><td>spuštění MirrorMakeru 1</td></tr>
<tr><td>bin/connect-mirror-maker.sh</td><td>spuštění MirrorMakeru 2</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>bin/kafka-configs.sh</td><td>konfigurace brokerů</td></tr>
<tr><td>bin/kafka-topics.sh</td><td>konfigurace témat, zjištění informace o tématech atd.</td></tr>
<tr><td>bin/kafka-consumer-groups.sh</td><td>konfigurace popř.&nbsp;zjištění informací o skupinách konzumentů</td></tr>
<tr><td>bin/kafka-run-class.sh</td><td>spuštění konkrétní třídy z&nbsp;Apache Kafky (například pro zjištění informací o skupinách konzumentů)</td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>bin/kafka-console-producer.sh</td><td>jednoduchý producent zpráv</td></tr>
<tr><td>bin/kafka-console-consumer.sh</td><td>jednoduchý konzument zpráv</td></tr>
</table>

<p><div class="rs-tip-major">Poznámka: většina výše uvedených skriptů byla
upravena i pro spuštění ve Windows. Tyto varianty naleznete v&nbsp;podadresáři
<strong>bin/windows</strong> (kupodivu chybí skript pro MirrorMaker 2, ovšem
úprava shell skriptu do podoby BAT souboru není v&nbsp;tomto konkrétním případě
nijak obtížná).</div></p>



<p><a name="k07"></a></p>
<h2 id="k07">7. Konfigurace dvou lokálních Kafka clusterů</h2>

<pre>
# The id of the broker. This must be set to a unique integer for each broker.
broker.id=0

# The address the socket server listens on. If not configured, the host name will be equal to the value of
listeners=PLAINTEXT://:9091

# The number of threads that the server uses for receiving requests from the network and sending responses to the network
num.network.threads=2

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=4

# The send buffer (SO_SNDBUF) used by the socket server
socket.send.buffer.bytes=102400

# The receive buffer (SO_RCVBUF) used by the socket server
socket.receive.buffer.bytes=102400

# The maximum size of a request that the socket server will accept (protection against OOM)
socket.request.max.bytes=104857600

# A comma separated list of directories under which to store log files
log.dirs=/tmp/ramdisk/kafka-logs-1

# The default number of log partitions per topic.
num.partitions=1

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
num.recovery.threads.per.data.dir=1

# Internal Topic Settings
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

# The minimum age of a log file to be eligible for deletion due to age
log.retention.hours=168

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000

# Zookeeper connection string (see zookeeper docs for details).
zookeeper.connect=localhost:2181

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=18000

# Group Coordinator Settings
group.initial.rebalance.delay.ms=0
</pre>

<pre>
# The id of the broker. This must be set to a unique integer for each broker.
broker.id=0

# The address the socket server listens on. If not configured, the host name will be equal to the value of
listeners=PLAINTEXT://:9092

# The number of threads that the server uses for receiving requests from the network and sending responses to the network
num.network.threads=2

# The number of threads that the server uses for processing requests, which may include disk I/O
num.io.threads=4

# The send buffer (SO_SNDBUF) used by the socket server
socket.send.buffer.bytes=102400

# The receive buffer (SO_RCVBUF) used by the socket server
socket.receive.buffer.bytes=102400

# The maximum size of a request that the socket server will accept (protection against OOM)
socket.request.max.bytes=104857600

# A comma separated list of directories under which to store log files
log.dirs=/tmp/ramdisk/kafka-logs-2

# The default number of log partitions per topic.
num.partitions=1

# The number of threads per data directory to be used for log recovery at startup and flushing at shutdown.
num.recovery.threads.per.data.dir=1

# Internal Topic Settings
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

# The minimum age of a log file to be eligible for deletion due to age
log.retention.hours=168

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000

# Zookeeper connection string (see zookeeper docs for details).
zookeeper.connect=localhost:2182

# Timeout in ms for connecting to zookeeper
zookeeper.connection.timeout.ms=18000

# Group Coordinator Settings
group.initial.rebalance.delay.ms=0
</pre>

<pre>
# the directory where the snapshot is stored.
dataDir=/tmp/ramdisk/zookeeper-1
# the port at which the clients will connect
clientPort=2181
# disable the per-ip limit on the number of connections since this is a non-production config
maxClientCnxns=0
# Disable the adminserver by default to avoid port conflicts.
# Set the port to something non-conflicting if choosing to enable this
admin.enableServer=false
</pre>

<pre>
# the directory where the snapshot is stored.
dataDir=/tmp/ramdisk/zookeeper-2
# the port at which the clients will connect
clientPort=2182
# disable the per-ip limit on the number of connections since this is a non-production config
maxClientCnxns=0
# Disable the adminserver by default to avoid port conflicts.
# Set the port to something non-conflicting if choosing to enable this
admin.enableServer=false
</pre>



<p><a name="k08"></a></p>
<h2 id="k08">8. Konfigurace MirrorMakeru 2</h2>

<pre>
# specify any number of cluster aliases
clusters = A, B

# connection information for each cluster
# This is a comma separated host:port pairs for each cluster
# for e.g. "A_host1:9092, A_host2:9092, A_host3:9092"
A.bootstrap.servers = localhost:9091
B.bootstrap.servers = localhost:9092

# enable and configure individual replication flows
A->B.enabled = true

# regex which defines which topics gets replicated. For eg "foo-.*"
A->B.topics = .*

B->A.enabled = true
B->A.topics = .*

# Setting replication factor of newly created remote topics
replication.factor=1

############################# Internal Topic Settings  #############################
# The replication factor for mm2 internal topics "heartbeats", "B.checkpoints.internal" and
# "mm2-offset-syncs.B.internal"
# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.
checkpoints.topic.replication.factor=1
heartbeats.topic.replication.factor=1
offset-syncs.topic.replication.factor=1

# The replication factor for connect internal topics "mm2-configs.B.internal", "mm2-offsets.B.internal" and
# "mm2-status.B.internal"
# For anything other than development testing, a value greater than 1 is recommended to ensure availability such as 3.
offset.storage.replication.factor=1
status.storage.replication.factor=1
config.storage.replication.factor=1

# customize as needed
# replication.policy.separator = _
# sync.topic.acls.enabled = false
# emit.heartbeats.interval.seconds = 5
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Spuštění Kafka clusterů, spuštění MirrorMakeru</h2>



<p><a name="k10"></a></p>
<h2 id="k10">10. Producent a konzument pro téma na prvním clusteru</h2>



<p><a name="k11"></a></p>
<h2 id="k11">11. Konzument naslouchající na druhém clusteru</h2>



<p><a name="k12"></a></p>
<h2 id="k12">12. Témata vytvořená a spravovaná MirrorMakerem</h2>

<pre>
$ bin/kafka-topics.sh --bootstrap-server localhost:9091 --list

B.checkpoints.internal
B.heartbeats
B.test1
__consumer_offsets
heartbeats
mm2-configs.B.internal
mm2-offset-syncs.B.internal
mm2-offsets.B.internal
mm2-status.B.internal
test1
</pre>

<pre>
$ bin/kafka-topics.sh --bootstrap-server localhost:9092 --list

A.checkpoints.internal
A.heartbeats
A.test1
__consumer_offsets
heartbeats
mm2-configs.A.internal
mm2-offset-syncs.A.internal
mm2-offsets.A.internal
mm2-status.A.internal
test1
</pre>

<pre>
Topic: heartbeats	TopicId: 7IyMK73ETfaQXJl7JfdIDg	PartitionCount: 1	ReplicationFactor: 1	Configs: cleanup.policy=compact
	Topic: heartbeats	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
Topic: B.heartbeats	TopicId: YgRWcTVMQqO6XHO62yO2Yg	PartitionCount: 1	ReplicationFactor: 1	Configs: cleanup.policy=compact
	Topic: B.heartbeats	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
Topic: mm2-configs.B.internal	TopicId: py8p8QjOTuKRtvalWRsnOg	PartitionCount: 1	ReplicationFactor: 1	Configs: cleanup.policy=compact
	Topic: mm2-configs.B.internal	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
Topic: mm2-status.B.internal	TopicId: 8cw1WB9sRz-p16On6F6ePA	PartitionCount: 5	ReplicationFactor: 1	Configs: cleanup.policy=compact
	Topic: mm2-status.B.internal	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-status.B.internal	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-status.B.internal	Partition: 2	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-status.B.internal	Partition: 3	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-status.B.internal	Partition: 4	Leader: 0	Replicas: 0	Isr: 0
Topic: B.checkpoints.internal	TopicId: od5v7gliTI2oM6cfPmUkhQ	PartitionCount: 1	ReplicationFactor: 1	Configs: cleanup.policy=compact
	Topic: B.checkpoints.internal	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
Topic: mm2-offsets.B.internal	TopicId: zgHMHUQdRQaY7kiTknju6g	PartitionCount: 25	ReplicationFactor: 1	Configs: cleanup.policy=compact
	Topic: mm2-offsets.B.internal	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 1	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 2	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 3	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 4	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 5	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 6	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 7	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 8	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 9	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 10	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 11	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 12	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 13	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 14	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 15	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 16	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 17	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 18	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 19	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 20	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 21	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 22	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 23	Leader: 0	Replicas: 0	Isr: 0
	Topic: mm2-offsets.B.internal	Partition: 24	Leader: 0	Replicas: 0	Isr: 0
Topic: mm2-offset-syncs.B.internal	TopicId: hXRJKh8VTNWhmwYXCsEL5g	PartitionCount: 1	ReplicationFactor: 1	Configs: cleanup.policy=compact
	Topic: mm2-offset-syncs.B.internal	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
Topic: test1	TopicId: M0bcocRNQ-CLv6Cq-gooWw	PartitionCount: 1	ReplicationFactor: 1	Configs: 
	Topic: test1	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
Topic: B.test1	TopicId: TIXsuLO5QC6SZESthg0MGw	PartitionCount: 1	ReplicationFactor: 1	Configs: 
	Topic: B.test1	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
</pre>


<p><a name="k13"></a></p>
<h2 id="k13">13. Další možnosti nastavení MirrorMakeru</h2>



<p><a name="k14"></a></p>
<h2 id="k14">14. Omezení témat, která se mají replikovat</h2>



<p><a name="k15"></a></p>
<h2 id="k15">15. Jednosměrná replikace</h2>

<pre>
# specify any number of cluster aliases
clusters = A, B

# connection information for each cluster
# This is a comma separated host:port pairs for each cluster
# for e.g. "A_host1:9092, A_host2:9092, A_host3:9092"
A.bootstrap.servers = localhost:9091
B.bootstrap.servers = localhost:9092

# enable and configure individual replication flows
A->B.enabled = true

# regex which defines which topics gets replicated. For eg "foo-.*"
A->B.topics = .*

B->A.enabled = false
B->A.topics = .*
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. </h2>



<p><a name="k17"></a></p>
<h2 id="k17">17. </h2>



<p><a name="k18"></a></p>
<h2 id="k18">18. </h2>



<p><a name="k19"></a></p>
<h2 id="k19">19. Repositář s&nbsp;demonstračními příklady</h2>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>Kafka mirroring (MirrorMaker)<br />
<a href="https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330">https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=27846330</a>
</li>

<li>Mastering Kafka migration with MirrorMaker 2<br />
<a href="https://developers.redhat.com/articles/2024/01/04/mastering-kafka-migration-mirrormaker-2">https://developers.redhat.com/articles/2024/01/04/mastering-kafka-migration-mirrormaker-2</a>
</li>

<li>Apache Kafka MirrorMaker 2 (MM2) Part 1: Theory<br />
<a href="https://www.instaclustr.com/blog/kafka-mirrormaker-2-theory/#h-2-replication-in-kafka">https://www.instaclustr.com/blog/kafka-mirrormaker-2-theory/#h-2-replication-in-kafka</a>
</li>

<li>Apache Kafka MirrorMaker 2 (MM2) Part 2: Practice<br />
<a href="https://www.instaclustr.com/blog/apache-kafka-mirrormaker-2-practice/">https://www.instaclustr.com/blog/apache-kafka-mirrormaker-2-practice/</a>
</li>

<li>Demystifying Kafka MirrorMaker 2: Use cases and architecture <br />
<a href="https://developers.redhat.com/articles/2023/11/13/demystifying-kafka-mirrormaker-2-use-cases-and-architecture#">https://developers.redhat.com/articles/2023/11/13/demystifying-kafka-mirrormaker-2-use-cases-and-architecture#</a>
</li>

<li>How to use Kafka MirrorMaker 2.0 in data migration, replication and the use-cases<br />
<a href="https://learn.microsoft.com/en-us/azure/hdinsight/kafka/kafka-mirrormaker-2-0-guide">https://learn.microsoft.com/en-us/azure/hdinsight/kafka/kafka-mirrormaker-2-0-guide</a>
</li>

<li>Release Notes - Kafka - Version 2.4.0<br />
<a href="https://archive.apache.org/dist/kafka/2.4.0/RELEASE_NOTES.html">https://archive.apache.org/dist/kafka/2.4.0/RELEASE_NOTES.html</a>
</li>

<li>Kafka Mirror Maker Best Practices<br />
<a href="https://community.cloudera.com/t5/Community-Articles/Kafka-Mirror-Maker-Best-Practices/ta-p/249269">https://community.cloudera.com/t5/Community-Articles/Kafka-Mirror-Maker-Best-Practices/ta-p/249269</a>
</li>

<li>Apache Kafka MirrorMaker 2 (MM2) Part 1: Theory<br />
<a href="https://www.instaclustr.com/blog/kafka-mirrormaker-2-theory/">https://www.instaclustr.com/blog/kafka-mirrormaker-2-theory/</a>
</li>

<li>Kcli: is a kafka read only command line browser.<br />
<a href="https://github.com/cswank/kcli">https://github.com/cswank/kcli</a>
</li>

<li>Kcli: a kafka command line browser<br />
<a href="https://go.libhunt.com/kcli-alternatives">https://go.libhunt.com/kcli-alternatives</a>
</li>

<li>Kafka Connect and Schemas<br />
<a href="https://rmoff.net/2020/01/22/kafka-connect-and-schemas/">https://rmoff.net/2020/01/22/kafka-connect-and-schemas/</a>
</li>

<li>JSON and schemas<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas">https://www.confluent.io/blog/kafka-connect-deep-dive-converters-serialization-explained/#json-schemas</a>
</li>

<li>What, why, when to use Apache Kafka, with an example<br />
<a href="https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/">https://www.startdataengineering.com/post/what-why-and-how-apache-kafka/</a>
</li>

<li>When NOT to use Apache Kafka?<br />
<a href="https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/">https://www.kai-waehner.de/blog/2022/01/04/when-not-to-use-apache-kafka/</a>
</li>

<li>Microservices: The Rise Of Kafka<br />
<a href="https://movio.co/blog/microservices-rise-kafka/">https://movio.co/blog/microservices-rise-kafka/</a>
</li>

<li>Building a Microservices Ecosystem with Kafka Streams and KSQL<br />
<a href="https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/">https://www.confluent.io/blog/building-a-microservices-ecosystem-with-kafka-streams-and-ksql/</a>
</li>

<li>An introduction to Apache Kafka and microservices communication<br />
<a href="https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63">https://medium.com/@ulymarins/an-introduction-to-apache-kafka-and-microservices-communication-bf0a0966d63</a>
</li>

<li>kappa-architecture.com<br />
<a href="http://milinda.pathirage.org/kappa-architecture.com/">http://milinda.pathirage.org/kappa-architecture.com/</a>
</li>

<li>Questioning the Lambda Architecture<br />
<a href="https://www.oreilly.com/ideas/questioning-the-lambda-architecture">https://www.oreilly.com/ideas/questioning-the-lambda-architecture</a>
</li>

<li>Lambda architecture<br />
<a href="https://en.wikipedia.org/wiki/Lambda_architecture">https://en.wikipedia.org/wiki/Lambda_architecture</a>
</li>

<li>Kafka &ndash; ecosystem (Wiki)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem">https://cwiki.apache.org/confluence/display/KAFKA/Ecosystem</a>
</li>

<li>The Kafka Ecosystem - Kafka Core, Kafka Streams, Kafka Connect, Kafka REST Proxy, and the Schema Registry<br />
<a href="http://cloudurable.com/blog/kafka-ecosystem/index.html">http://cloudurable.com/blog/kafka-ecosystem/index.html</a>
</li>

<li>A Kafka Operator for Kubernetes<br />
<a href="https://github.com/krallistic/kafka-operator">https://github.com/krallistic/kafka-operator</a>
</li>

<li>Kafka Streams<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams">https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams</a>
</li>

<li>Kafka Streams<br />
<a href="http://kafka.apache.org/documentation/streams/">http://kafka.apache.org/documentation/streams/</a>
</li>

<li>Kafka Streams (FAQ)<br />
<a href="https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams">https://cwiki.apache.org/confluence/display/KAFKA/FAQ#FAQ-Streams</a>
</li>

<li>Event stream processing<br />
<a href="https://en.wikipedia.org/wiki/Event_stream_processing">https://en.wikipedia.org/wiki/Event_stream_processing</a>
</li>

<li>Part 1: Apache Kafka for beginners - What is Apache Kafka?<br />
<a href="https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html">https://www.cloudkarafka.com/blog/2016-11-30-part1-kafka-for-beginners-what-is-apache-kafka.html</a>
</li>

<li>What are some alternatives to Apache Kafka?<br />
<a href="https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka">https://www.quora.com/What-are-some-alternatives-to-Apache-Kafka</a>
</li>

<li>What is the best alternative to Kafka?<br />
<a href="https://www.slant.co/options/961/alternatives/~kafka-alternatives">https://www.slant.co/options/961/alternatives/~kafka-alternatives</a>
</li>

<li>A super quick comparison between Kafka and Message Queues<br />
<a href="https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0">https://hackernoon.com/a-super-quick-comparison-between-kafka-and-message-queues-e69742d855a8?gi=e965191e72d0</a>
</li>

<li>Kafka Queuing: Kafka as a Messaging System<br />
<a href="https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system">https://dzone.com/articles/kafka-queuing-kafka-as-a-messaging-system</a>
</li>

<li>Apache Kafka Logs: A Comprehensive Guide<br />
<a href="https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/">https://hevodata.com/learn/apache-kafka-logs-a-comprehensive-guide/</a>
</li>

<li>Microservices – Not a free lunch!<br />
<a href="http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html">http://highscalability.com/blog/2014/4/8/microservices-not-a-free-lunch.html</a>
</li>

<li>Microservices, Monoliths, and NoOps<br />
<a href="http://blog.arungupta.me/microservices-monoliths-noops/">http://blog.arungupta.me/microservices-monoliths-noops/</a>
</li>

<li>Microservice Design Patterns<br />
<a href="http://blog.arungupta.me/microservice-design-patterns/">http://blog.arungupta.me/microservice-design-patterns/</a>
</li>

<li>REST vs Messaging for Microservices – Which One is Best?<br />
<a href="https://solace.com/blog/experience-awesomeness-event-driven-microservices/">https://solace.com/blog/experience-awesomeness-event-driven-microservices/</a>
</li>

<li>Kappa Architecture Our Experience<br />
<a href="https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf">https://events.static.linux­found.org/sites/events/fi­les/slides/ASPgems%20-%20Kappa%20Architecture.pdf</a>
</li>

<li>Apache Kafka Streams and Tables, the stream-table duality<br />
<a href="https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854">https://towardsdatascience.com/apache-kafka-streams-and-tables-the-stream-table-duality-ee904251a7e?gi=f22a29cd1854</a>
</li>

<li>Configure Self-Managed Connectors<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors">https://docs.confluent.io/kafka-connectors/self-managed/configuring.html#configure-self-managed-connectors</a>
</li>

<li>Schema Evolution and Compatibility<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility">https://docs.confluent.io/platform/current/schema-registry/avro.html#schema-evolution-and-compatibility</a>
</li>

<li>Configuring Key and Value Converters<br />
<a href="https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters">https://docs.confluent.io/kafka-connectors/self-managed/userguide.html#configuring-key-and-value-converters</a>
</li>

<li>Introduction to Kafka Connectors<br />
<a href="https://www.baeldung.com/kafka-connectors-guide">https://www.baeldung.com/kafka-connectors-guide</a>
</li>

<li>Kafka CLI: command to list all consumer groups for a topic?<br />
<a href="https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic">https://stackoverflow.com/questions/63883999/kafka-cli-command-to-list-all-consumer-groups-for-a-topic</a>
</li>

<li>Java Property File Processing<br />
<a href="https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php">https://www.w3resource.com/java-tutorial/java-propertyfile-processing.php</a>
</li>

<li>Skipping bad records with the Kafka Connect JDBC sink connector<br />
<a href="https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/">https://rmoff.net/2019/10/15/skipping-bad-records-with-the-kafka-connect-jdbc-sink-connector/</a>
</li>

<li>Kafka Connect Deep Dive – Error Handling and Dead Letter Queues<br />
<a href="https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/">https://www.confluent.io/blog/kafka-connect-deep-dive-error-handling-dead-letter-queues/</a>
</li>

<li>Errors and Dead Letter Queues<br />
<a href="https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/">https://developer.confluent.io/learn-kafka/kafka-connect/error-handling-and-dead-letter-queues/</a>
</li>

<li>Confluent Cloud Dead Letter Queue<br />
<a href="https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html">https://docs.confluent.io/cloud/current/connectors/dead-letter-queue.html</a>
</li>

<li>Dead Letter Queues (DLQs) in Kafka<br />
<a href="https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309">https://medium.com/@sannidhi.s.t/dead-letter-queues-dlqs-in-kafka-afb4b6835309</a>
</li>

<li>Deserializer<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-json.html#json-schema-serializer-and-deserializer">https://docs.confluent.io/platform/current/schema-registry/serdes-develop/serdes-json.html#json-schema-serializer-and-deserializer</a>
</li>

<li>JSON, Kafka, and the need for schema<br />
<a href="https://mikemybytes.com/2022/07/11/json-kafka-and-the-need-for-schema/">https://mikemybytes.com/2022/07/11/json-kafka-and-the-need-for-schema/</a>
</li>

<li>Using Kafka Connect with Schema Registry<br />
<a href="https://docs.confluent.io/platform/current/schema-registry/connect.html">https://docs.confluent.io/platform/current/schema-registry/connect.html</a>
</li>

<li>Zpracování dat reprezentovaných ve formátu JSON nástrojem jq<br />
<a href="https://www.root.cz/clanky/zpracovani-dat-reprezentovanych-ve-formatu-json-nastrojem-jq/">https://www.root.cz/clanky/zpracovani-dat-reprezentovanych-ve-formatu-json-nastrojem-jq/</a>
</li>

<li>Repositář projektu jq (GitHub)<br />
<a href="https://github.com/stedolan/jq">https://github.com/stedolan/jq</a>
</li>

<li>GitHub stránky projektu jq<br />
<a href="https://stedolan.github.io/jq/">https://stedolan.github.io/jq/</a>
</li>

<li>5 modern alternatives to essential Linux command-line tools<br />
<a href="https://opensource.com/ar­ticle/20/6/modern-linux-command-line-tools">https://opensource.com/ar­ticle/20/6/modern-linux-command-line-tools</a>
</li>

<li>Návod k nástroji jq<br />
<a href="https://stedolan.github.i­o/jq/tutorial/">https://stedolan.github.i­o/jq/tutorial/</a>
</li>

<li>jq Manual (development version)<br />
<a href="https://stedolan.github.io/jq/manual/">https://stedolan.github.io/jq/manual/</a>
</li>

<li>Introducing JSON<br />
<a href="https://www.json.org/json-en.html">https://www.json.org/json-en.html</a>
</li>

<li>Understanding JSON schema<br />
<a href="https://json-schema.org/understanding-json-schema/index.html">https://json-schema.org/understanding-json-schema/index.html</a>
</li>

<li>JDBC Sink Connector for Confluent Platform<br />
<a href="https://docs.confluent.io/kafka-connectors/jdbc/current/sink-connector/overview.html#jdbc-sink-connector-for-cp">https://docs.confluent.io/kafka-connectors/jdbc/current/sink-connector/overview.html#jdbc-sink-connector-for-cp</a>
</li>

<li>JDBC Connector (Source and Sink)<br />
<a href="https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc">https://www.confluent.io/hub/confluentinc/kafka-connect-jdbc</a>
</li>

<li>Introduction to Schema Registry in Kafka<br />
<a href="https://medium.com/slalom-technology/introduction-to-schema-registry-in-kafka-915ccf06b902">https://medium.com/slalom-technology/introduction-to-schema-registry-in-kafka-915ccf06b902</a>
</li>

<li>Understanding JSON Schema Compatibility<br />
<a href="https://yokota.blog/2021/03/29/understanding-json-schema-compatibility/">https://yokota.blog/2021/03/29/understanding-json-schema-compatibility/</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2023</small></p>
</body>
</html>

