<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
        "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html>
<head>
<title>Nástroj pytest a jednotkové testy: životní cyklus testů, užitečné tipy a triky</title>
<meta name="Author" content="Pavel Tisnovsky" />
<meta name="Generator" content="vim" />
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<style type="text/css">
         body {color:#000000; background:#ffffff;}
         h1  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#c00000; text-align:center; padding-left:1em}
         h2  {font-family: arial, helvetica, sans-serif; color:#ffffff; background-color:#0000c0; padding-left:1em; text-align:left}
         h3  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#c0c0c0; padding-left:1em; text-align:left}
         h4  {font-family: arial, helvetica, sans-serif; color:#000000; background-color:#e0e0e0; padding-left:1em; text-align:left}
         a   {font-family: arial, helvetica, sans-serif;}
         li  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ol  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         ul  {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify; width:450px;}
         p   {font-family: arial, helvetica, sans-serif; color:#000000; text-align:justify;}
         pre {background:#e0e0e0}
</style>
</head>

<body>

<h1>Nástroj pytest a jednotkové testy: životní cyklus testů, užitečné tipy a triky</h1>

<h3>Pavel Tišnovský</h3>

<p></p>

<h1>Úvodník</h1>

<p>V páté části seriálu o testování s využitím programovacího jazyka Python se naposledy budeme zabývat použitím frameworku pytest při tvorbě a spouštění jednotkových testů. Ukážeme si mj. životní cyklus testů, některé užitečné přídavné moduly pro pytest a další užitečné tipy a triky.</p>



<h2>Obsah</h2>

<p><a href="#k01">1. Test fixtures (zopakování z&nbsp;minula)</a></p>
<p><a href="#k02">2. Výpis existujících fixtures</a></p>
<p><a href="#k03">3. Jednotkové testy implementované formou třídy</a></p>
<p><a href="#k04">4. Výstup produkovaný upravenými jednotkovými testy</a></p>
<p><a href="#k05">5. Přídavný modul <strong>pytest-print</strong></a></p>
<p><a href="#k06">6. Ukázka výstupů z&nbsp;modulu <strong>pytest-print</strong></a></p>
<p><a href="#k07">7. Životní cyklus testů</a></p>
<p><a href="#k08">8. Funkce <strong>setup_module</strong> a <strong>teardown_module</strong></a></p>
<p><a href="#k09">9. Třídní metody <strong>setup_class</strong> a <strong>teardown_class</strong></a></p>
<p><a href="#k10">10. Metody <strong>setup_method</strong> a <strong>teardown_method</strong></a></p>
<p><a href="#k11">11. Funkce <strong>setup_function</strong> a <strong>teardown_function</strong></a></p>
<p><a href="#k12">12. Export výsledků testů do XML</a></p>
<p><a href="#k13">13. Export výsledků testů do formátu CSV</a></p>
<p><a href="#k14">14. Detailní výpis zásobníkových rámců při vzniku chyby</a></p>
<p><a href="#k15">15. Spuštění nástroje Pycodestyle přímo z&nbsp;testů</a></p>
<p><a href="#k16">16. Automatický záznam chyb v&nbsp;repositáři na GitHubu</a></p>
<p><a href="#k17">17. Obsah následující části seriálu</a></p>
<p><a href="#k18">18. Repositář s&nbsp;demonstračními příklady</a></p>
<p><a href="#k19">19. Předchozí články s&nbsp;tématem testování (nejenom) v&nbsp;Pythonu</a></p>
<p><a href="#k20">20. Odkazy na Internetu</a></p>



<p><a name="k01"></a></p>
<h2 id="k01">1. Test fixtures</h2>

<p><a
href="https://www.root.cz/clanky/nastroj-pytest-a-jednotkove-testy-fixtures-vyjimky-parametrizace-testu/">V&nbsp;předchozím
článku</a> o tvorbě jednotkových testů s&nbsp;využitím frameworku
<strong>pytest</strong> jsme se mj.&nbsp;zmínili i o existenci takzvaných
<i>test fixtures</i> (popř.&nbsp;zkráceně jen <i>fixtures</i>), které umožňují
(mj.&nbsp;) připravit kontext pro spouštění jednotkových testů, generovat
testovací data apod. Fixture je reprezentována funkcí s&nbsp;anotací
<strong>@pytest.fixture</strong>:</p>

<pre>
@pytest.fixture
def <strong>input_values</strong>():
    <i>"""Vygenerování vstupních hodnot pro jednotkový test."""</i>
    return (1, 2, 3, 4, 5)
</pre>

<p>Jakýkoli jednotkový test, který akceptuje parametr se stejným názvem, jako
má <i>fixture</i> (v&nbsp;tomto konkrétním případě
<strong>input_values</strong>) získá při svém zavolání návratovou hodnotu
z&nbsp;funkce <strong>input_values</strong>, kterou je možné v&nbsp;testech
použít:</p>

<pre>
def <strong>test_average_five_values</strong>(input_values, expected_result):
    <i>"""Otestování výpočtu průměru."""</i>
    result = average(input_values)
    assert result == expected_result, "Očekávaná hodnota {}, vráceno {}".format(expected_result, result)
</pre>

<p>Minule jsme si uvedli i kompletní příklad s&nbsp;několika jednotkovými
testy:</p>

<pre>
<i>"""Implementace jednotkových testů."""</i>
&nbsp;
import pytest
&nbsp;
from average import average
&nbsp;
&nbsp;
def <strong>pytest_configure</strong>(config):
    <i>"""Konfigurace jednotkových testů."""</i>
    config.addinivalue_line(
        "markers", "smoketest: mark test that are performed very smoketest"
    )
&nbsp;
&nbsp;
testdata = [
        ((1, 1), 1),
        ((1, 2), 1.5),
        ((0, 1), 0.5),
        ((1, 2, 3), 2.0),
        ((0, 10), 0.5),
]
&nbsp;
&nbsp;
@pytest.mark.smoketest
@pytest.mark.parametrize("values,expected", testdata)
def <strong>test_average_basic_1</strong>(values, expected):
    <i>"""Otestování výpočtu průměru."""</i>
    result = average(values)
    assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
&nbsp;
&nbsp;
@pytest.mark.smoketest
@pytest.mark.parametrize("values,expected", testdata, ids=["1,1", "1,2", "0,1", "1,2,3", "0,10"])
def <strong>test_average_basic_2</strong>(values, expected):
    <i>"""Otestování výpočtu průměru."""</i>
    result = average(values)
    assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
&nbsp;
&nbsp;
@pytest.mark.smoketest
@pytest.mark.parametrize(
    "values,expected",
    [
        pytest.param(
            (1, 1), 1
        ),
        pytest.param(
            (1, 2), 1.5
        ),
        pytest.param(
            (0, 1), 0.5
        ),
        pytest.param(
            (1, 2, 3), 2.0
        ),
        pytest.param(
            (0, 10), 0.5
        ),
        pytest.param(
            (), 0
        ),
    ],
)
def <strong>test_average_basic_3</strong>(values, expected):
    <i>"""Otestování výpočtu průměru."""</i>
    result = average(values)
    assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
&nbsp;
&nbsp;
@pytest.mark.thorough
def <strong>test_average_empty_list_1</strong>():
    <i>"""Otestování výpočtu průměru pro prázdný vstup."""</i>
    with pytest.raises(ZeroDivisionError) as excinfo:
        result = average([])
&nbsp;
&nbsp;
@pytest.mark.thorough
def <strong>test_average_empty_list_2</strong>():
    <i>"""Otestování výpočtu průměru pro prázdný vstup."""</i>
    with pytest.raises(Exception) as excinfo:
        result = average([])
    # poměrně křehký způsob testování!
    assert excinfo.type == ZeroDivisionError
    assert str(excinfo.value) == "float division by zero"
&nbsp;
&nbsp;
@pytest.fixture
def <strong>input_values</strong>():
    <i>"""Vygenerování vstupních hodnot pro jednotkový test."""</i>
    return (1, 2, 3, 4, 5)
&nbsp;
&nbsp;
@pytest.fixture
def <strong>expected_result</strong>():
    <i>"""Vygenerování očekávaného výsledku testu."""</i>
    return 3
&nbsp;
&nbsp;
def <strong>test_average_five_values</strong>(input_values, expected_result):
    <i>"""Otestování výpočtu průměru."""</i>
    result = average(input_values)
    assert result == expected_result, "Očekávaná hodnota {}, vráceno {}".format(expected_result, result)
</pre>

<p>Můžeme ovšem využít i existující <i>fixtures</i>, například
<strong>cache</strong>, která si dokáže zapamatovat hodnoty mezi spuštěními
testů (ve skutečnosti se v&nbsp;příkladu používá ještě fixture
<strong>printer</strong> popsaná níže):</p>

<pre>
"""Implementace jednotkových testů."""
&nbsp;
import pytest
&nbsp;
&nbsp;
def test_cache(printer, cache):
    """Test fixture cache."""
    counter = cache.get("foobar/counter", 0)
    printer(counter)
    counter += 1
    cache.set("foobar/counter", counter)
</pre>

<p>Příklad dvojího spuštění testů, pokaždé s&nbsp;jinou hodnotou uloženou do
čítače a zapamatovanou v&nbsp;cache:</p>

<pre>
===================================================================== test session starts =====================================================================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/cache
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, csv-2.0.2, cov-2.5.1
collected 1 item                                                                                                                                              
&nbsp;
test_cache.py::test_cache 
        <strong>1</strong>
PASSED
&nbsp;
====================================================================== 1 passed in 0.02s ======================================================================
&nbsp;
&nbsp;
&nbsp;
===================================================================== test session starts =====================================================================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/cache
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, csv-2.0.2, cov-2.5.1
collected 1 item                                                                                                                                              
&nbsp;
test_cache.py::test_cache 
        <strong>2</strong>
PASSED
</pre>



<p><a name="k02"></a></p>
<h2 id="k02">2. Výpis existujících fixtures</h2>

<p>Mnoho <i>fixtures</i> je poskytováno jak vlastním frameworkem
<strong>pytest</strong>, tak i přídavnými moduly (pluginy). Základní informace
o nich je možné získat příkazem:</p>

<pre>
$ <strong>pytest --fixtures</strong>
</pre>

<p>Nejdříve se vypíšou standardní fixtures a následně fixtures nainstalované
v&nbsp;rámci přídavných modulů:</p>

<pre>
cache
    Return a cache object that can persist state between testing sessions.
&nbsp;
    cache.get(key, default)
    cache.set(key, value)
&nbsp;
    Keys must be a ``/`` separated value, where the first part is usually the
    name of your plugin or application to avoid clashes with other cache users.
    &nbsp;
    Values can be any object handled by the json stdlib module.
&nbsp;
capsys
    Enable text capturing of writes to ``sys.stdout`` and ``sys.stderr``.
    &nbsp;
    The captured output is made available via ``capsys.readouterr()`` method
    calls, which return a ``(out, err)`` namedtuple.
    ``out`` and ``err`` will be ``text`` objects.
&nbsp;
...
...
...
---------------- fixtures defined from pytest_benchmark.plugin -----------------
benchmark
    /home/ptisnovs/.local/lib/python3.6/site-packages/pytest_benchmark/plugin.py:391: no docstring available
&nbsp;
benchmark_weave
    /home/ptisnovs/.local/lib/python3.6/site-packages/pytest_benchmark/plugin.py:415: no docstring available
&nbsp;
&nbsp;
------------------- fixtures defined from pytest_cov.plugin --------------------
cov
    A pytest fixture to provide access to the underlying coverage object.
&nbsp;
&nbsp;
---------------------- fixtures defined from pytest_print ----------------------
printer
    pytest plugin to print test progress steps in verbose mode
&nbsp;
&nbsp;
============================ no tests ran in 0.02s =============================
</pre>



<p><a name="k03"></a></p>
<h2 id="k03">3. Jednotkové testy implementované formou třídy</h2>

<p>Jednotkové testy nemusí být tvořeny pouze jednotlivými funkcemi; můžeme
namísto nich vytvořit třídy, typicky každou třídu pro jednu testovanou jednotku
nebo testovanou oblast. Musí se pouze dodržet jmenné konvence, tj.&nbsp;třída
s&nbsp;implementací jednotkových testů by měla začínat slovem
<strong>Test</strong> a metody s&nbsp;testy předponou <strong>test_</strong>.
Taktéž by třída s&nbsp;implementací jednotkových testů neměla obsahovat
konstruktor (aby <strong>pytest</strong> omylem nepracovat se třídou, která
čistě náhodou začíná slovem <strong>Test</strong>, ovšem nemá
s&nbsp;jednotkovými testy nic společného).</p>

<p>Přepis jednotkových testů do nové podoby ve skutečnosti není vůbec složitý,
protože lze stále používat <i>test fixtures</i> atd. Metodám
s&nbsp;implementací testů se pochopitelně předává parametr
<strong>self</strong> (pokud se nejedná o třídní metody):</p>

<pre>
<i>"""Implementace jednotkových testů."""</i>
&nbsp;
import pytest
&nbsp;
from average import average
&nbsp;
&nbsp;
testdata = [
        ((1, 1), 1),
        ((1, 2), 1.5),
        ((0, 1), 0.5),
        ((1, 2, 3), 2.0),
        ((0, 10), 0.5),
]
&nbsp;
&nbsp;
@pytest.fixture
def <strong>input_values</strong>():
    <i>"""Vygenerování vstupních hodnot pro jednotkový test."""</i>
    return (1, 2, 3, 4, 5)
&nbsp;
&nbsp;
@pytest.fixture
def <strong>expected_result</strong>():
    <i>"""Vygenerování očekávaného výsledku testu."""</i>
    return 3
&nbsp;
&nbsp;
class <strong>TestAverageFunction</strong>:
    <i>"""Jednotkové testy pro otestování funkce average z modulu average."""</i>
&nbsp;
    @pytest.mark.parametrize("values,expected", testdata)
    def <strong>test_average_basic_1</strong>(self, values, expected):
        <i>"""Otestování výpočtu průměru."""</i>
        result = average(values)
        assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
&nbsp;
    @pytest.mark.parametrize("values,expected", testdata, ids=["1,1", "1,2", "0,1", "1,2,3", "0,10"])
    def <strong>test_average_basic_2</strong>(self, values, expected):
        <i>"""Otestování výpočtu průměru."""</i>
        result = average(values)
        assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
&nbsp;
    @pytest.mark.parametrize(
        "values,expected",
        [
            pytest.param(
                (1, 1), 1
            ),
            pytest.param(
                (1, 2), 1.5
            ),
            pytest.param(
                (0, 1), 0.5
            ),
            pytest.param(
                (1, 2, 3), 2.0
            ),
            pytest.param(
                (0, 10), 0.5
            ),
            pytest.param(
                (), 0
            ),
        ],
    )
    def <strong>test_average_basic_3</strong>(self, values, expected):
        <i>"""Otestování výpočtu průměru."""</i>
        result = average(values)
        assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
&nbsp;
    def <strong>test_average_empty_list_1</strong>(self):
        <i>"""Otestování výpočtu průměru pro prázdný vstup."""</i>
        with pytest.raises(ZeroDivisionError) as excinfo:
            result = average([])
&nbsp;
    def <strong>test_average_empty_list_2</strong>(self):
        <i>"""Otestování výpočtu průměru pro prázdný vstup."""</i>
        with pytest.raises(Exception) as excinfo:
            result = average([])
        <i># poměrně křehký způsob testování!</i>
        assert excinfo.type == ZeroDivisionError
        assert str(excinfo.value) == "float division by zero"
&nbsp;
    def <strong>test_average_five_values</strong>(self, input_values, expected_result):
        <i>"""Otestování výpočtu průměru."""</i>
        result = average(input_values)
        assert result == expected_result, "Očekávaná hodnota {}, vráceno {}".format(expected_result, result)
</pre>



<p><a name="k04"></a></p>
<h2 id="k04">4. Výstup produkovaný upravenými jednotkovými testy</h2>

<p>Po spuštění jednotkových testů s&nbsp;přepínačem <strong>-v</strong> získáme
výstup, který je poněkud odlišný od výstupů, které jsme prozatím viděli. Je to
logické, protože plné jméno jednotlivých testů nyní musí obsahovat i jméno
třídy a metody:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/tests_in_class, inifile: pytest.ini
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 19 items
&nbsp;
test_average.py::TestAverageFunction::test_average_basic_1[values0-1] PASSED   [  5%]
test_average.py::TestAverageFunction::test_average_basic_1[values1-1.5] PASSED [ 10%]
test_average.py::TestAverageFunction::test_average_basic_1[values2-0.5] PASSED [ 15%]
test_average.py::TestAverageFunction::test_average_basic_1[values3-2.0] PASSED [ 21%]
test_average.py::TestAverageFunction::test_average_basic_1[values4-0.5] FAILED [ 26%]
test_average.py::TestAverageFunction::test_average_basic_2[1,1] PASSED         [ 31%]
test_average.py::TestAverageFunction::test_average_basic_2[1,2] PASSED         [ 36%]
test_average.py::TestAverageFunction::test_average_basic_2[0,1] PASSED         [ 42%]
test_average.py::TestAverageFunction::test_average_basic_2[1,2,3] PASSED       [ 47%]
test_average.py::TestAverageFunction::test_average_basic_2[0,10] FAILED        [ 52%]
test_average.py::TestAverageFunction::test_average_basic_3[values0-1] PASSED   [ 57%]
test_average.py::TestAverageFunction::test_average_basic_3[values1-1.5] PASSED [ 63%]
test_average.py::TestAverageFunction::test_average_basic_3[values2-0.5] PASSED [ 68%]
test_average.py::TestAverageFunction::test_average_basic_3[values3-2.0] PASSED [ 73%]
test_average.py::TestAverageFunction::test_average_basic_3[values4-0.5] FAILED [ 78%]
test_average.py::TestAverageFunction::test_average_basic_3[values5-0] FAILED   [ 84%]
test_average.py::TestAverageFunction::test_average_empty_list_1 PASSED         [ 89%]
test_average.py::TestAverageFunction::test_average_empty_list_2 PASSED         [ 94%]
test_average.py::TestAverageFunction::test_average_five_values PASSED          [100%]
&nbsp;
=================================== FAILURES ===================================
____________ TestAverageFunction.test_average_basic_1[values4-0.5] _____________
&nbsp;
self = &lt;test_average.TestAverageFunction object at 0x7f980b260588&gt;
values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.parametrize("values,expected", testdata)
    def test_average_basic_1(self, values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
test_average.py:36: AssertionError
________________ TestAverageFunction.test_average_basic_2[0,10] ________________
&nbsp;
self = &lt;test_average.TestAverageFunction object at 0x7f980b57ce10&gt;
values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.parametrize("values,expected", testdata, ids=["1,1", "1,2", "0,1", "1,2,3", "0,10"])
    def test_average_basic_2(self, values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
test_average.py:42: AssertionError
____________ TestAverageFunction.test_average_basic_3[values4-0.5] _____________
&nbsp;
self = &lt;test_average.TestAverageFunction object at 0x7f980aa14080&gt;
values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.parametrize(
        "values,expected",
        [
            pytest.param(
                (1, 1), 1
            ),
            pytest.param(
                (1, 2), 1.5
            ),
            pytest.param(
                (0, 1), 0.5
            ),
            pytest.param(
                (1, 2, 3), 2.0
            ),
            pytest.param(
                (0, 10), 0.5
            ),
            pytest.param(
                (), 0
            ),
        ],
    )
    def test_average_basic_3(self, values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
test_average.py:70: AssertionError
_____________ TestAverageFunction.test_average_basic_3[values5-0] ______________
&nbsp;
self = &lt;test_average.TestAverageFunction object at 0x7f980aa4b240&gt;, values = ()
expected = 0
&nbsp;
    @pytest.mark.parametrize(
        "values,expected",
        [
            pytest.param(
                (1, 1), 1
            ),
            pytest.param(
                (1, 2), 1.5
            ),
            pytest.param(
                (0, 1), 0.5
            ),
            pytest.param(
                (1, 2, 3), 2.0
            ),
            pytest.param(
                (0, 10), 0.5
            ),
            pytest.param(
                (), 0
            ),
        ],
    )
    def test_average_basic_3(self, values, expected):
        """Otestování výpočtu průměru."""
&gt;       result = average(values)
&nbsp;
test_average.py:69: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
average.py:6: in average
    return f1(x)
average.py:11: in f1
    return f2(x)
average.py:16: in f2
    return f3(x)
average.py:21: in f3
    return f4(x)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
&nbsp;
x = ()
&nbsp;
    def f4(x):
        """Část špagetového kódu testovaného modulu."""
&gt;       return sum(x)/float(len(x))
E       ZeroDivisionError: float division by zero
&nbsp;
average.py:26: ZeroDivisionError
=========================== short test summary info ============================
FAILED test_average.py::TestAverageFunction::test_average_basic_1[values4-0.5]
FAILED test_average.py::TestAverageFunction::test_average_basic_2[0,10] - Ass...
FAILED test_average.py::TestAverageFunction::test_average_basic_3[values4-0.5]
FAILED test_average.py::TestAverageFunction::test_average_basic_3[values5-0]
========================= 4 failed, 15 passed in 0.09s =========================
</pre>



<p><a name="k05"></a></p>
<h2 id="k05">5. Přídavný modul <strong>pytest-print</strong></h2>

<p>V&nbsp;dalších kapitolách budeme potřebovat zajistit tisk nějakých textových
zpráv přímo v&nbsp;průběhu testování. Testovací framework
<strong>pytest</strong> ovšem (pokud není nějakým vhodným způsobem
rekonfigurován) standardní i chybový výstup zachycuje a provede tisk zpráv jen
u těch testů, které zhavarují. Jedno z&nbsp;možných řešení tohoto problému
představuje použití přídavného modulu (<i>plugin</i>) nazvaného příznačně
<strong>pytest-print</strong>. Ten nainstalujeme snadno &ndash; stejným
způsobem jako jakýkoli jiný balíček Pythonu:</p>

<pre>
$ <strong>pip3 install --user pytest-print</strong>
</pre>

<pre>
Collecting pytest-print
  Downloading https://files.pythonhosted.org/packages/1c/35/e9c31c1473758c4388778644cc9b0048eb1fdeb827ba4a28789e35ed4dc5/pytest_print-0.1.3-py2.py3-none-any.whl
Requirement already satisfied: pytest&lt;6,&gt;=3.0.0 in ./.local/lib/python3.6/site-packages (from pytest-print)
Requirement already satisfied: six&lt;2,&gt;=1.10.0 in ./.local/lib/python3.6/site-packages (from pytest-print)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/lib/python3.6/site-packages (from pytest&lt;6,&gt;=3.0.0-&gt;pytest-print)
Requirement already satisfied: packaging in ./.local/lib/python3.6/site-packages (from pytest&lt;6,&gt;=3.0.0-&gt;pytest-print)
Requirement already satisfied: wcwidth in ./.local/lib/python3.6/site-packages (from pytest&lt;6,&gt;=3.0.0-&gt;pytest-print)
Requirement already satisfied: importlib-metadata&gt;=0.12; python_version &lt; "3.8" in ./.local/lib/python3.6/site-packages (from pytest&lt;6,&gt;=3.0.0-&gt;pytest-print)
Requirement already satisfied: py&gt;=1.5.0 in /usr/lib/python3.6/site-packages (from pytest&lt;6,&gt;=3.0.0-&gt;pytest-print)
Requirement already satisfied: pluggy&lt;1.0,&gt;=0.12 in ./.local/lib/python3.6/site-packages (from pytest&lt;6,&gt;=3.0.0-&gt;pytest-print)
Requirement already satisfied: more-itertools&gt;=4.0.0 in ./.local/lib/python3.6/site-packages (from pytest&lt;6,&gt;=3.0.0-&gt;pytest-print)
Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/lib/python3.6/site-packages (from packaging-&gt;pytest&lt;6,&gt;=3.0.0-&gt;pytest-print)
Requirement already satisfied: zipp&gt;=0.5 in ./.local/lib/python3.6/site-packages (from importlib-metadata&gt;=0.12; python_version &lt; "3.8"-&gt;pytest&lt;6,&gt;=3.0.0-&gt;pytest-print)
Installing collected packages: pytest-print
Successfully installed pytest-print-0.1.3
</pre>

<p>Tento modul vytváří nový <i>text fixture</i> nazvaný
<strong>printer</strong>. Způsob jeho použití si ukážeme <a
href="#k06">v&nbsp;navazující kapitole</a>.</p>



<p><a name="k06"></a></p>
<h2 id="k06">6. Ukázka výstupů z&nbsp;modulu <strong>pytest-print</strong></h2>

<p><a href="#k04">V&nbsp;předchozí kapitole</a> jsme si řekli, že modul
<strong>pytest-printer</strong> vytváří nový <i>text fixture</i> nazvaný
<strong>printer</strong>. Jedná se o funkci, které se předá řetězec, jenž je
posléze vytištěn na standardní výstup. Ukažme si nyní způsob použití:</p>

<pre>
@pytest.mark.parametrize("values,expected", testdata)
def <strong>test_average_basic_1</strong>(printer, values, expected):
    <i>"""Otestování výpočtu průměru."""</i>
    printer("About to compute average from {} with expected output {}".format(values, expected))
    ...
    ...
    ...
</pre>

<p><div class="rs-tip-major">Poznámka: na pořadí předání <i>text fixtures</i>
nezáleží, parametry je možné libovolně prohazovat.</div></p>

<p>Úplný zdrojový text s&nbsp;jednotkovými testy bude vypadat následovně.
Vidíme, že se jedná o zjednodušenou variantu testů, s&nbsp;nimiž jsme se
setkali minule i v&nbsp;úvodních kapitolách:</p>

<pre>
<i>"""Implementace jednotkových testů."""</i>
&nbsp;
import pytest
&nbsp;
from average import average
&nbsp;
&nbsp;
def <strong>pytest_configure</strong>(config):
    <i>"""Konfigurace jednotkových testů."""</i>
    config.addinivalue_line(
        "markers", "smoketest: mark test that are performed very smoketest"
    )
&nbsp;
&nbsp;
testdata = [
        ((1, 1), 1),
        ((1, 2), 1.5),
        ((0, 1), 0.5),
        ((1, 2, 3), 2.0),
        ((0, 10), 5.0),
]
&nbsp;
&nbsp;
@pytest.mark.parametrize("values,expected", testdata)
def <strong>test_average_basic_1</strong>(printer, values, expected):
    <i>"""Otestování výpočtu průměru."""</i>
    printer("About to compute average from {} with expected output {}".format(values, expected))
    result = average(values)
    printer("Computed average is {}".format(result))
    assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
</pre>

<p>V&nbsp;případě, že jednotkové testy spustíme běžným způsobem, nebude žádný
výstup zachycen:</p>

<pre>
$ <strong>pytest</strong>
</pre>

<p>S&nbsp;výstupem:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/printer
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collected 5 items
&nbsp;
test_average.py .....
&nbsp;
============================== 5 passed in 0.02s ===============================
</pre>

<p>Nepomůže nám ani přepínač <strong>-v</strong> (<i>verbose</i>):</p>

<pre>
$ <strong>pytest -v</strong>
</pre>

<p>S&nbsp;výstupem:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/printer
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 5 items
&nbsp;
test_average.py::test_average_basic_1[values0-1] PASSED                   [ 20%]
test_average.py::test_average_basic_1[values1-1.5] PASSED                 [ 40%]
test_average.py::test_average_basic_1[values2-0.5] PASSED                 [ 60%]
test_average.py::test_average_basic_1[values3-2.0] PASSED                 [ 80%]
test_average.py::test_average_basic_1[values4-5.0] PASSED                 [100%]
&nbsp;
============================== 5 passed in 0.02s ===============================
</pre>

<p>Nutné je přidat přepínač <strong>-s</strong> nebo jeho delší podobu
<strong>--capture=no</strong>, který zajistí, že se výstup zobrazí:</p>

<pre>
$ <strong>pytest -s -v</strong>
</pre>

<p>Nyní je již patrné, jak se zobrazí zprávy, které v&nbsp;testech
vytváříme:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/printer
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 5 items
&nbsp;
test_average.py::test_average_basic_1[values0-1] 
        About to compute average from (1, 1) with expected output 1
        Computed average is 1.0
PASSED
test_average.py::test_average_basic_1[values1-1.5] 
        About to compute average from (1, 2) with expected output 1.5
        Computed average is 1.5
PASSED
test_average.py::test_average_basic_1[values2-0.5] 
        About to compute average from (0, 1) with expected output 0.5
        Computed average is 0.5
PASSED
test_average.py::test_average_basic_1[values3-2.0] 
        About to compute average from (1, 2, 3) with expected output 2.0
        Computed average is 2.0
PASSED
test_average.py::test_average_basic_1[values4-5.0] 
        About to compute average from (0, 10) with expected output 5.0
        Computed average is 5.0
PASSED
&nbsp;
============================== 5 passed in 0.02s ===============================
</pre>

<p>Při použití přepínače <strong>--print-relative-time</strong> se navíc před
zprávami zobrazí relativní čas počítaný od spuštění testu:</p>

<pre>
$ <strong>pytest -s -v --print-relative-time</strong>
</pre>

<p>S&nbsp;výstupem:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/printer
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 5 items
&nbsp;
test_average.py::test_average_basic_1[values0-1] 
        0.000461        About to compute average from (1, 1) with expected output 1
        0.000506        Computed average is 1.0
PASSED
test_average.py::test_average_basic_1[values1-1.5] 
        0.000346        About to compute average from (1, 2) with expected output 1.5
        0.00038 Computed average is 1.5
PASSED
test_average.py::test_average_basic_1[values2-0.5] 
        0.000346        About to compute average from (0, 1) with expected output 0.5
        0.00038 Computed average is 0.5
PASSED
test_average.py::test_average_basic_1[values3-2.0] 
        0.000344        About to compute average from (1, 2, 3) with expected output 2.0
        0.000378        Computed average is 2.0
PASSED
test_average.py::test_average_basic_1[values4-5.0] 
        0.000353        About to compute average from (0, 10) with expected output 5.0
        0.000386        Computed average is 5.0
PASSED
&nbsp;
============================== 5 passed in 0.02s ===============================
</pre>



<p><a name="k07"></a></p>
<h2 id="k07">7. Životní cyklus testů</h2>

<p>Prozatím jsme jednotlivé jednotkové testy spouštěli zcela nezávisle na sobě,
bez kontextu a bez nutnosti přípravy a posléze finalizace nějakých objektů.
Ovšem v&nbsp;praxi bývá situace složitější, protože jednotkové testy jsou
spouštěny v&nbsp;rámci nějakého kontextu (řekněme zjednodušeně připraveného
prostředí), které je zapotřebí připravit popř.&nbsp;nakonec zrušit. A právě pro
tyto účely podporuje nástroj <strong>pytest</strong> životní cyklus testů
&ndash; s&nbsp;využitím speciálně pojmenovaných funkcí a metod je možné
zajistit kontext, a to jak v&nbsp;rámci celého modulu, tak i v&nbsp;rámci třídy
s&nbsp;implementací testů či dokonce jen pro jedinou metodu nebo funkci.
Možnosti nabízené <strong>pytestem</strong> v&nbsp;této oblasti jsou popsány
v&nbsp;navazujících kapitolách.</p>

<p><div class="rs-tip-major">Poznámka: v&nbsp;příkladech budeme používat text
fixture nazvaný <strong>printer</strong>, s&nbsp;nímž jsme se seznámili
v&nbsp;rámci předchozích dvou kapitol.</div></p>



<p><a name="k08"></a></p>
<h2 id="k08">8. Funkce <strong>setup_module</strong> a <strong>teardown_module</strong></h2>

<p>Funkce nazvaná <strong>setup_module</strong> je spuštěná &ndash; pokud ovšem
existuje &ndash; na začátku inicializace modulu s&nbsp;jednotkovým testem.
Podobně funkce pojmenovaná <strong>teardown_module</strong> je spuštěna po
dokončení všech jednotkových testů v&nbsp;tomto modulu. Oběma zmíněným funkcím
je předán objekt s&nbsp;informacemi o modulu, který je tak možné
modifikovat.</p>

<p><div class="rs-tip-major">Poznámka: tyto dvě funkce akceptují vždy pouze
jediný parametr &ndash; <strong>module</strong>. Není zde možné využít žádné
<i>test fixtures</i>, což je nepochybně škoda (například by se nám hodil
fixture <strong>printer</strong>).</div></p>

<p>Příklad velmi jednoduchého jednotkového testu, který obě funkce
obsahuje:</p>

<pre>
<i>"""Implementace jednotkových testů."""</i>
&nbsp;
import pytest
&nbsp;
&nbsp;
def <strong>setup_module</strong>(module):
    <i>"""Zavoláno při inicializaci modulu s testem."""</i>
    print("\nSETUP\n")
&nbsp;
&nbsp;
def <strong>teardown_module</strong>(module):
    <i>"""Zavoláno při finalizaci modulu s testem."""</i>
    print("\nTEARDOWN\n")
&nbsp;
&nbsp;
def <strong>test_1</strong>(printer):
    <i>"""Kostra jednotkového testu."""</i>
    printer("Test #1")
&nbsp;
&nbsp;
def <strong>test_2</strong>(printer):
    <i>"""Kostra jednotkového testu."""</i>
    printer("Test #2")
&nbsp;
&nbsp;
testdata = [
        (0, 1),
        (1, 2),
        (2, 3),
        (3, 4),
]
&nbsp;
&nbsp;
@pytest.mark.parametrize("value,expected", testdata)
def <strong>test_succ</strong>(printer, value, expected):
    <i>"""Otestování výpočtu následují hodnoty v číselné řadě."""</i>
    printer("Test succ")
    result = value+1
    assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
</pre>

<p>Výpis výsledků běhu jednotkových testů:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/lifecycle_module
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collected 6 items
&nbsp;
test_module.py 
SETUP
&nbsp;
......
TEARDOWN
&nbsp;
&nbsp;
&nbsp;
============================== 6 passed in 0.02s ===============================
</pre>

<p>Samozřejmě můžeme povolit režim <i>verbose</i>, který využije i funkci typu
<strong>printer</strong>:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/lifecycle_module
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 6 items
&nbsp;
test_module.py::test_1 
SETUP
&nbsp;
&nbsp;
        Test #1
PASSED
test_module.py::test_2 
        Test #2
PASSED
test_module.py::test_succ[0-1] 
        Test succ
PASSED
test_module.py::test_succ[1-2] 
        Test succ
PASSED
test_module.py::test_succ[2-3] 
        Test succ
PASSED
test_module.py::test_succ[3-4] 
        Test succ
PASSED
TEARDOWN
&nbsp;
&nbsp;
&nbsp;
============================== 6 passed in 0.02s ===============================
</pre>



<p><a name="k09"></a></p>
<h2 id="k09">9. Třídní metody <strong>setup_class</strong> a <strong>teardown_class</strong></h2>

<p>Je možné předepsat i třídní metody se jmény <strong>setup_class</strong> a
<strong>teardown_class</strong>, které jsou testovacím frameworkem
<strong>pytest</strong> zavolány ve chvíli, kdy je inicializována nebo naopak
finalizována třída s&nbsp;implementací jednotkových testů. Těmto metodám je
poslán objekt představující celou třídu (tedy v&nbsp;idiomaticky napsaném kódu
nikoli <strong>self</strong> ale <strong>cls</strong>) a opět platí, že
neakceptují žádné <i>test fixtures</i>. Ukažme si příklad:</p>

<pre>
<i>"""Implementace jednotkových testů."""</i>
&nbsp;
import pytest
&nbsp;
&nbsp;
def <strong>setup_module</strong>(module):
    <i>"""Zavoláno při inicializaci modulu s testem."""</i>
    print("SETUP MODULE")
&nbsp;
&nbsp;
def <strong>teardown_module</strong>(module):
    <i>"""Zavoláno při finalizaci modulu s testem."""</i>
    print("TEARDOWN MODULE")
&nbsp;
&nbsp;
class <strong>TestClass</strong>:
    <i>"""Jednotkové testy ve třídě."""</i>
&nbsp;
    @classmethod
    def <strong>setup_class</strong>(cls):
        <i>"""Zavoláno při inicializaci třídy s testy."""</i>
        print("SETUP CLASS")
&nbsp;
    @classmethod
    def <strong>teardown_class</strong>(cls):
        <i>"""Zavoláno při finalizaci třídy s testy."""</i>
        print("\nTEARDOWN CLASS")
&nbsp;
    def <strong>test_1</strong>(self):
        <i>"""Kostra jednotkového testu."""</i>
        print("Test #1")
&nbsp;
    def <strong>test_2</strong>(self):
        <i>"""Kostra jednotkového testu."""</i>
        print("Test #2")
</pre>

<p>Zprávy ve výsledcích jsou poněkud přeházené, protože testovací framework
<strong>pytest</strong> vypisuje informace o spouštěném testu již při analýze
skriptů s&nbsp;jednotkovými testy:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/lifecycle_class
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 2 items
&nbsp;
test_class.py::TestClass::test_1 <strong>SETUP MODULE</strong>
<strong>SETUP CLASS</strong>
Test #1
<strong>PASSED</strong>
test_class.py::TestClass::test_2 Test #2
<strong>PASSED</strong>
<strong>TEARDOWN CLASS</strong>
<strong>TEARDOWN MODULE</strong>
&nbsp;
&nbsp;
============================== 2 passed in 0.01s ===============================
</pre>

<p><div class="rs-tip-major">Poznámka: z&nbsp;předchozího výpisu je zřejmé,
proč je tisk jakýchkoli zpráv v&nbsp;průběhu testování poměrně problematické a
spíše matoucí.</div></p>



<p><a name="k10"></a></p>
<h2 id="k10">10. Metody <strong>setup_method</strong> a <strong>teardown_method</strong></h2>

<p>Třetí skupina struktur umožňujících ovlivnění kontextu, v&nbsp;němž se
jednotkové testy spouští, je vázána k&nbsp;metodám s&nbsp;implementací
jednotkových testů. Před každou takovou metodou je možné spustit jinou metodu
nazvanou <strong>setup_method</strong> a po ukončení pak metodu
<strong>teardown_method</strong>. Ukažme si nyní nepatrně upravený předchozí
demonstrační příklad, v&nbsp;němž jsou tyto metody definovány (jedná se o běžné
metody objektu):</p>

<pre>
<i>"""Implementace jednotkových testů."""</i>
&nbsp;
import pytest
&nbsp;
&nbsp;
def <strong>setup_module</strong>(module):
    <i>"""Zavoláno při inicializaci modulu s testem."""</i>
    print("SETUP MODULE")
&nbsp;
&nbsp;
def <strong>teardown_module</strong>(module):
    <i>"""Zavoláno při finalizaci modulu s testem."""</i>
    print("TEARDOWN MODULE")
&nbsp;
&nbsp;
class <strong>TestClass</strong>:
    <i>"""Jednotkové testy ve třídě."""</i>
&nbsp;
    @classmethod
    def <strong>setup_class</strong>(cls):
        <i>"""Zavoláno při inicializaci třídy s testy."""</i>
        print("SETUP CLASS")
&nbsp;
    @classmethod
    def <strong>teardown_class</strong>(cls):
        <i>"""Zavoláno při finalizaci třídy s testy."""</i>
        print("\nTEARDOWN CLASS")
&nbsp;
    def <strong>setup_method</strong>(cls):
        <i>"""Zavoláno před každou metodou s jednotkovými testy."""</i>
        print("SETUP METHOD")
&nbsp;
    def <strong>teardown_method</strong>(cls):
        <i>"""Zavoláno po každé metodě s jednotkovými testy."""</i>
        print("\nTEARDOWN METHOD")
&nbsp;
    def <strong>test_1</strong>(self):
        <i>"""Kostra jednotkového testu."""</i>
        print("Test #1")
&nbsp;
    def <strong>test_2</strong>(self):
        <i>"""Kostra jednotkového testu."""</i>
        print("Test #2")
&nbsp;
    def <strong>test_3</strong>(self):
        <i>"""Kostra jednotkového testu."""</i>
        print("Test #3")
</pre>

<p>S&nbsp;výsledky:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/lifecycle_method
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 3 items
&nbsp;
test_method.py::TestClass::test_1 SETUP MODULE
SETUP CLASS
SETUP METHOD
Test #1
PASSED
TEARDOWN METHOD
&nbsp;
test_method.py::TestClass::test_2 SETUP METHOD
Test #2
PASSED
TEARDOWN METHOD
&nbsp;
test_method.py::TestClass::test_3 SETUP METHOD
Test #3
PASSED
TEARDOWN METHOD
&nbsp;
TEARDOWN CLASS
TEARDOWN MODULE
&nbsp;
&nbsp;
============================== 3 passed in 0.01s ===============================
</pre>



<p><a name="k11"></a></p>
<h2 id="k11">11. Funkce <strong>setup_function</strong> a <strong>teardown_function</strong></h2>

<p>Funkce nazvaná <strong>setup_function</strong>, která akceptuje jediný
parametr s&nbsp;informacemi o testovací funkci, je zavolána před každou funkcí
s&nbsp;implementací jednotkového testu. Podobně nazvaná funkce
<strong>teardown_function</strong> je &ndash; jak již ostatně správně očekáváte
&ndash; zavolána po každém jednotkovém testu. Opět platí, že tyto speciálně
pojmenované funkce nemohou akceptovat žádný další <i>fixture</i>. Podívejme se
na jednoduchý (umělý) příklad s&nbsp;jednotkovými testy:</p>

<pre>
<i>"""Implementace jednotkových testů."""</i>
&nbsp;
import pytest
&nbsp;
&nbsp;
def <strong>setup_module</strong>(module):
    <i>"""Zavoláno při inicializaci modulu s testem."""</i>
    print("\nSETUP MODULE\n")
&nbsp;
&nbsp;
def <strong>teardown_module</strong>(module):
    <i>"""Zavoláno při finalizaci modulu s testem."""</i>
    print("\nTEARDOWN MODULE")
&nbsp;
&nbsp;
def <strong>setup_function</strong>(function):
    <i>"""Zavoláno při inicializaci funkce s testem."""</i>
    print("\nSETUP FUNCTION")
&nbsp;
&nbsp;
def <strong>teardown_function</strong>(function):
    <i>"""Zavoláno při finalizaci funkce s testem."""</i>
    print("\nTEARDOWN FUNCTION")
&nbsp;
&nbsp;
def <strong>test_1</strong>(printer):
    <i>"""Kostra jednotkového testu."""</i>
    printer("Test #1")
&nbsp;
&nbsp;
def <strong>test_2</strong>(printer):
    <i>"""Kostra jednotkového testu."""</i>
    printer("Test #2")
&nbsp;
&nbsp;
testdata = [
        (0, 1),
        (1, 2),
        (2, 3),
        (3, 4),
]
&nbsp;
&nbsp;
@pytest.mark.parametrize("value,expected", testdata)
def <strong>test_succ</strong>(printer, value, expected):
    <i>"""Otestování výpočtu následují hodnoty v číselné řadě."""</i>
    printer("Test succ")
    result = value+1
    assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
</pre>

<p>Po spuštění testů s&nbsp;přepínači <strong>-v</strong> a <strong>-s</strong>
dostaneme následující výsledky, které ukazují, kdy přesně (a kolikrát) se
volají funkce <strong>setup_module</strong>, <strong>setup_function</strong>,
<strong>teardown_function</strong> a <strong>teardown_module</strong>:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/lifecycle_function
plugins: print-0.1.3, voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 6 items
&nbsp;
test_module.py::test_1 
SETUP MODULE
&nbsp;
&nbsp;
SETUP FUNCTION
&nbsp;
        Test #1
PASSED
TEARDOWN FUNCTION
&nbsp;
test_module.py::test_2 
SETUP FUNCTION
&nbsp;
        Test #2
PASSED
TEARDOWN FUNCTION
&nbsp;
test_module.py::test_succ[0-1] 
SETUP FUNCTION
&nbsp;
        Test succ
PASSED
TEARDOWN FUNCTION
&nbsp;
test_module.py::test_succ[1-2] 
SETUP FUNCTION
&nbsp;
        Test succ
PASSED
TEARDOWN FUNCTION
&nbsp;
test_module.py::test_succ[2-3] 
SETUP FUNCTION
&nbsp;
        Test succ
PASSED
TEARDOWN FUNCTION
&nbsp;
test_module.py::test_succ[3-4] 
SETUP FUNCTION
&nbsp;
        Test succ
PASSED
TEARDOWN FUNCTION
&nbsp;
TEARDOWN MODULE
&nbsp;
&nbsp;
============================== 6 passed in 0.02s ===============================
</pre>



<p><a name="k12"></a></p>
<h2 id="k12">12. Export výsledků testů do XML</h2>

<p>V&nbsp;případě, že se jednotkové testy spouští například v&nbsp;prostředí
CI, je nutné jejich výsledky nějakým způsobem automaticky zpracovat. Pro tento
účel se ovšem příliš nehodí použití textového formátu, s&nbsp;nímž jsme se
seznámili minule i v&nbsp;předchozích kapitolách. Namísto toho se typicky
používá formát XML používaný například nástrojem <i>JUnit</i> pro Javu. I tento
formát je frameworkem <strong>pytest</strong> podporován, postačuje pouze zadat
formát i se jménem souboru, který se má vygenerovat:</p>

<pre>
$ <strong>pytest -v --junitxml="junit.xml"</strong>
</pre>

<p>V&nbsp;některých případech je striktně vyžadováno jméno souboru
&bdquo;results.xml&ldquo;:</p>

<pre>
$ <strong>pytest -v --junitxml="results.xml"</strong>
</pre>

<p>Neformátovaný výstup vypadá následovně: <a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/result.xml">https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/result.xml</a>.</p>

<p>Po naformátování externím nástrojem:</p>

<pre>
&lt;?xml version="1.0" encoding="UTF-8"?&gt;
&lt;testsuites&gt;
   &lt;testsuite errors="0" failures="4" hostname="localhost.localdomain" name="pytest" skipped="0" tests="19" time="0.136" timestamp="2020-05-19T20:52:52.067423"&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="23" name="test_average_basic_1[values0-1]" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="23" name="test_average_basic_1[values1-1.5]" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="23" name="test_average_basic_1[values2-0.5]" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="23" name="test_average_basic_1[values3-2.0]" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="23" name="test_average_basic_1[values4-0.5]" time="0.003"&gt;
         &lt;failure message="AssertionError: Očekávaná hodnota 0.5, vráceno 5.0 assert 5.0 == 0.5   +5.0   -0.5"&gt;values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize("values,expected", testdata)
    def test_average_basic_1(values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
test_average.py:29: AssertionError&lt;/failure&gt;
      &lt;/testcase&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="31" name="test_average_basic_2[1,1]" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="31" name="test_average_basic_2[1,2]" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="31" name="test_average_basic_2[0,1]" time="0.002" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="31" name="test_average_basic_2[1,2,3]" time="0.002" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="31" name="test_average_basic_2[0,10]" time="0.002"&gt;
         &lt;failure message="AssertionError: Očekávaná hodnota 0.5, vráceno 5.0 assert 5.0 == 0.5   +5.0   -0.5"&gt;values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize("values,expected", testdata, ids=["1,1", "1,2", "0,1", "1,2,3", "0,10"])
    def test_average_basic_2(values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
test_average.py:37: AssertionError&lt;/failure&gt;
      &lt;/testcase&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="39" name="test_average_basic_3[values0-1]" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="39" name="test_average_basic_3[values1-1.5]" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="39" name="test_average_basic_3[values2-0.5]" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="39" name="test_average_basic_3[values3-2.0]" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="39" name="test_average_basic_3[values4-0.5]" time="0.001"&gt;
         &lt;failure message="AssertionError: Očekávaná hodnota 0.5, vráceno 5.0 assert 5.0 == 0.5   +5.0   -0.5"&gt;values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize(
        "values,expected",
        [
            pytest.param(
                (1, 1), 1
            ),
            pytest.param(
                (1, 2), 1.5
            ),
            pytest.param(
                (0, 1), 0.5
            ),
            pytest.param(
                (1, 2, 3), 2.0
            ),
            pytest.param(
                (0, 10), 0.5
            ),
            pytest.param(
                (), 0
            ),
        ],
    )
    def test_average_basic_3(values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
test_average.py:67: AssertionError&lt;/failure&gt;
      &lt;/testcase&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="39" name="test_average_basic_3[values5-0]" time="0.001"&gt;
         &lt;failure message="ZeroDivisionError: float division by zero"&gt;values = (), expected = 0
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize(
        "values,expected",
        [
            pytest.param(
                (1, 1), 1
            ),
            pytest.param(
                (1, 2), 1.5
            ),
            pytest.param(
                (0, 1), 0.5
            ),
            pytest.param(
                (1, 2, 3), 2.0
            ),
            pytest.param(
                (0, 10), 0.5
            ),
            pytest.param(
                (), 0
            ),
        ],
    )
    def test_average_basic_3(values, expected):
        """Otestování výpočtu průměru."""
&gt;       result = average(values)
&nbsp;
test_average.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
average.py:6: in average
    return f1(x)
average.py:11: in f1
    return f2(x)
average.py:16: in f2
    return f3(x)
average.py:21: in f3
    return f4(x)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
&nbsp;
x = ()
&nbsp;
    def f4(x):
        """Část špagetového kódu testovaného modulu."""
&gt;       return sum(x)/float(len(x))
E       ZeroDivisionError: float division by zero
&nbsp;
average.py:26: ZeroDivisionError&lt;/failure&gt;
      &lt;/testcase&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="69" name="test_average_empty_list_1" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="76" name="test_average_empty_list_2" time="0.001" /&gt;
      &lt;testcase classname="test_average" file="test_average.py" line="98" name="test_average_five_values" time="0.001" /&gt;
   &lt;/testsuite&gt;
&lt;/testsuites&gt;
</pre>



<p><a name="k13"></a></p>
<h2 id="k13">13. Export výsledků testů do formátu CSV</h2>

<p>Výsledky testů je možné exportovat i do formátu CSV, ovšem pro tento účel je
nejdřív nutné nainstalovat balíček nazvaný <strong>pytest-csv</strong>:</p>

<pre>
$ <strong>pip3 install --user pytest-csv</strong>
&nbsp;
Collecting pytest-csv
  Downloading https://files.pythonhosted.org/packages/17/1f/74cc8ae9d0927ffe8bf28637868a5103b6a0d686ab046108aadc752f46a8/pytest_csv-2.0.2-py2.py3-none-any.whl
Requirement already satisfied: pytest&gt;=4.4 in ./.local/lib/python3.6/site-packages (from pytest-csv)
Requirement already satisfied: six&gt;=1.0.0 in ./.local/lib/python3.6/site-packages (from pytest-csv)
Requirement already satisfied: wcwidth in ./.local/lib/python3.6/site-packages (from pytest&gt;=4.4-&gt;pytest-csv)
Requirement already satisfied: pluggy&lt;1.0,&gt;=0.12 in ./.local/lib/python3.6/site-packages (from pytest&gt;=4.4-&gt;pytest-csv)
Requirement already satisfied: py&gt;=1.5.0 in /usr/lib/python3.6/site-packages (from pytest&gt;=4.4-&gt;pytest-csv)
Requirement already satisfied: packaging in ./.local/lib/python3.6/site-packages (from pytest&gt;=4.4-&gt;pytest-csv)
Requirement already satisfied: more-itertools&gt;=4.0.0 in ./.local/lib/python3.6/site-packages (from pytest&gt;=4.4-&gt;pytest-csv)
Requirement already satisfied: importlib-metadata&gt;=0.12; python_version &lt; "3.8" in ./.local/lib/python3.6/site-packages (from pytest&gt;=4.4-&gt;pytest-csv)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/lib/python3.6/site-packages (from pytest&gt;=4.4-&gt;pytest-csv)
Requirement already satisfied: pyparsing&gt;=2.0.2 in /usr/lib/python3.6/site-packages (from packaging-&gt;pytest&gt;=4.4-&gt;pytest-csv)
Requirement already satisfied: zipp&gt;=0.5 in ./.local/lib/python3.6/site-packages (from importlib-metadata&gt;=0.12; python_version &lt; "3.8"-&gt;pytest&gt;=4.4-&gt;pytest-csv)
Installing collected packages: pytest-csv
Successfully installed pytest-csv-2.0.2
</pre>

<p>Samotný výstup do CSV pak zařídí příkaz:</p>

<pre>
$ <strong>pytest --csv tests.csv</strong>
</pre>

<p>Takto získané výsledky je možné dále zpracovat, typicky v&nbsp;tabulkových
procesorech:</p>

*** image ***
<p><i>Obrázek 1: Výsledek jednotkových testů zobrazený v&nbsp;tabulkovém
procesoru.</i></p>



<p><a name="k14"></a></p>
<h2 id="k14">14. Detailní výpis zásobníkových rámců při vzniku chyby</h2>

<p>Ve druhé části dnešního článku si uvedeme různé více či méně praktické triky
nabízené nástrojem <strong>pytest</strong>, které se mohou hodit v&nbsp;praxi.
Prvním trikem je řízení způsobu zobrazení výpisu zásobníkových rámců ve chvíli,
kdy v&nbsp;testovaném kódu vznikne nějaká chyba. Výpis zásobníkových rámců je
možné zcela zakázat, a to následujícím způsobem:</p>

<pre>
$ <strong>pytest -v --tb=no</strong>
</pre>

<p>Výstup bude v&nbsp;tomto případě vypadat takto:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/average14, inifile: pytest.ini
plugins: voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 19 items
&nbsp;
test_average.py::test_average_basic_1[values0-1] PASSED                  [  5%]
test_average.py::test_average_basic_1[values1-1.5] PASSED                [ 10%]
test_average.py::test_average_basic_1[values2-0.5] PASSED                [ 15%]
test_average.py::test_average_basic_1[values3-2.0] PASSED                [ 21%]
test_average.py::test_average_basic_1[values4-0.5] FAILED                [ 26%]
test_average.py::test_average_basic_2[1,1] PASSED                        [ 31%]
test_average.py::test_average_basic_2[1,2] PASSED                        [ 36%]
test_average.py::test_average_basic_2[0,1] PASSED                        [ 42%]
test_average.py::test_average_basic_2[1,2,3] PASSED                      [ 47%]
test_average.py::test_average_basic_2[0,10] FAILED                       [ 52%]
test_average.py::test_average_basic_3[values0-1] PASSED                  [ 57%]
test_average.py::test_average_basic_3[values1-1.5] PASSED                [ 63%]
test_average.py::test_average_basic_3[values2-0.5] PASSED                [ 68%]
test_average.py::test_average_basic_3[values3-2.0] PASSED                [ 73%]
test_average.py::test_average_basic_3[values4-0.5] FAILED                [ 78%]
test_average.py::test_average_basic_3[values5-0] FAILED                  [ 84%]
test_average.py::test_average_empty_list_1 PASSED                        [ 89%]
test_average.py::test_average_empty_list_2 PASSED                        [ 94%]
test_average.py::test_average_five_values PASSED                         [100%]
&nbsp;
=========================== short test summary info ============================
FAILED test_average.py::test_average_basic_1[values4-0.5] - AssertionError: O...
FAILED test_average.py::test_average_basic_2[0,10] - AssertionError: Očekávan...
FAILED test_average.py::test_average_basic_3[values4-0.5] - AssertionError: O...
FAILED test_average.py::test_average_basic_3[values5-0] - ZeroDivisionError: ...
========================= 4 failed, 15 passed in 0.09s =========================
</pre>

<p><div class="rs-tip-major">Poznámka: můžeme vidět, že se zobrazily pouze
základní informace o tom, které testy prošly bez chyby a které naopak
s&nbsp;chybou. Žádné další informace nejsou k&nbsp;dispozici.</div></p>

<p>Přepínačem <strong>--showlocals</strong> zajistíme zobrazení podrobnějších
informací o chybě, zejména hodnoty lokálních proměnných atd.:</p>

<pre>
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
expected   = 0.5
result     = 5.0
values     = (0, 10)
</pre>

<p>Opět si to ukažme v&nbsp;praxi:</p>

<pre>
$ <strong>pytest -v --showlocals</strong>
</pre>

<p>S&nbsp;výstupem:</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/average14, inifile: pytest.ini
plugins: voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 19 items
&nbsp;
test_average.py::test_average_basic_1[values0-1] PASSED                  [  5%]
test_average.py::test_average_basic_1[values1-1.5] PASSED                [ 10%]
test_average.py::test_average_basic_1[values2-0.5] PASSED                [ 15%]
test_average.py::test_average_basic_1[values3-2.0] PASSED                [ 21%]
test_average.py::test_average_basic_1[values4-0.5] FAILED                [ 26%]
test_average.py::test_average_basic_2[1,1] PASSED                        [ 31%]
test_average.py::test_average_basic_2[1,2] PASSED                        [ 36%]
test_average.py::test_average_basic_2[0,1] PASSED                        [ 42%]
test_average.py::test_average_basic_2[1,2,3] PASSED                      [ 47%]
test_average.py::test_average_basic_2[0,10] FAILED                       [ 52%]
test_average.py::test_average_basic_3[values0-1] PASSED                  [ 57%]
test_average.py::test_average_basic_3[values1-1.5] PASSED                [ 63%]
test_average.py::test_average_basic_3[values2-0.5] PASSED                [ 68%]
test_average.py::test_average_basic_3[values3-2.0] PASSED                [ 73%]
test_average.py::test_average_basic_3[values4-0.5] FAILED                [ 78%]
test_average.py::test_average_basic_3[values5-0] FAILED                  [ 84%]
test_average.py::test_average_empty_list_1 PASSED                        [ 89%]
test_average.py::test_average_empty_list_2 PASSED                        [ 94%]
test_average.py::test_average_five_values PASSED                         [100%]
&nbsp;
=================================== FAILURES ===================================
______________________ test_average_basic_1[values4-0.5] _______________________
&nbsp;
values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize("values,expected", testdata)
    def test_average_basic_1(values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
expected   = 0.5
result     = 5.0
values     = (0, 10)
&nbsp;
test_average.py:29: AssertionError
__________________________ test_average_basic_2[0,10] __________________________
&nbsp;
values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize("values,expected", testdata, ids=["1,1", "1,2", "0,1", "1,2,3", "0,10"])
    def test_average_basic_2(values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
expected   = 0.5
result     = 5.0
values     = (0, 10)
&nbsp;
test_average.py:37: AssertionError
______________________ test_average_basic_3[values4-0.5] _______________________

values = (0, 10), expected = 0.5

    @pytest.mark.smoketest
    @pytest.mark.parametrize(
        "values,expected",
        [
            pytest.param(
                (1, 1), 1
            ),
            pytest.param(
                (1, 2), 1.5
            ),
            pytest.param(
                (0, 1), 0.5
            ),
            pytest.param(
                (1, 2, 3), 2.0
            ),
            pytest.param(
                (0, 10), 0.5
            ),
            pytest.param(
                (), 0
            ),
        ],
    )
    def test_average_basic_3(values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
expected   = 0.5
result     = 5.0
values     = (0, 10)
&nbsp;
test_average.py:67: AssertionError
_______________________ test_average_basic_3[values5-0] ________________________
&nbsp;
values = (), expected = 0
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize(
        "values,expected",
        [
            pytest.param(
                (1, 1), 1
            ),
            pytest.param(
                (1, 2), 1.5
            ),
            pytest.param(
                (0, 1), 0.5
            ),
            pytest.param(
                (1, 2, 3), 2.0
            ),
            pytest.param(
                (0, 10), 0.5
            ),
            pytest.param(
                (), 0
            ),
        ],
    )
    def test_average_basic_3(values, expected):
        """Otestování výpočtu průměru."""
&gt;       result = average(values)
&nbsp;
expected   = 0
values     = ()
&nbsp;
test_average.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
average.py:6: in average
    return f1(x)
        x          = ()
average.py:11: in f1
    return f2(x)
        x          = ()
average.py:16: in f2
    return f3(x)
        x          = ()
average.py:21: in f3
    return f4(x)
        x          = ()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
&nbsp;
x = ()
&nbsp;
    def f4(x):
        """Část špagetového kódu testovaného modulu."""
&gt;       return sum(x)/float(len(x))
E       ZeroDivisionError: float division by zero
&nbsp;
x          = ()
&nbsp;
average.py:26: ZeroDivisionError
=========================== short test summary info ============================
FAILED test_average.py::test_average_basic_1[values4-0.5] - AssertionError: O...
FAILED test_average.py::test_average_basic_2[0,10] - AssertionError: Očekávan...
FAILED test_average.py::test_average_basic_3[values4-0.5] - AssertionError: O...
FAILED test_average.py::test_average_basic_3[values5-0] - ZeroDivisionError: ...
========================= 4 failed, 15 passed in 0.09s =========================
</pre>

<p>Existuje však ještě jeden způsob zobrazení nazvaný &bdquo;long&ldquo;, který
se povoluje takto:</p>

<pre>
$ <strong>pytest -v --tb=long</strong>
</pre>

<p>Ve výsledku získaném po spuštění jednotkových testů se nyní zobrazí výpis
získaný průchodem zásobníkovými rámci, zde konkrétně celé pořadí volaných
funkcí (to se týká zejména části označené komentáři &bdquo;špagetový
kód&ldquo;):</p>

<pre>
============================= test session starts ==============================
platform linux -- Python 3.6.6, pytest-5.4.2, py-1.5.2, pluggy-0.13.1 -- /usr/bin/python3
cachedir: .pytest_cache
benchmark: 3.2.3 (defaults: timer=time.perf_counter disable_gc=False min_rounds=5 min_time=0.000005 max_time=1.0 calibration_precision=10 warmup=False warmup_iterations=100000)
rootdir: /home/ptisnovs/src/python/testing-in-python/pytest/average14, inifile: pytest.ini
plugins: voluptuous-1.0.2, benchmark-3.2.3, cov-2.5.1
collecting ... collected 19 items
&nbsp;
test_average.py::test_average_basic_1[values0-1] PASSED                  [  5%]
test_average.py::test_average_basic_1[values1-1.5] PASSED                [ 10%]
test_average.py::test_average_basic_1[values2-0.5] PASSED                [ 15%]
test_average.py::test_average_basic_1[values3-2.0] PASSED                [ 21%]
test_average.py::test_average_basic_1[values4-0.5] FAILED                [ 26%]
test_average.py::test_average_basic_2[1,1] PASSED                        [ 31%]
test_average.py::test_average_basic_2[1,2] PASSED                        [ 36%]
test_average.py::test_average_basic_2[0,1] PASSED                        [ 42%]
test_average.py::test_average_basic_2[1,2,3] PASSED                      [ 47%]
test_average.py::test_average_basic_2[0,10] FAILED                       [ 52%]
test_average.py::test_average_basic_3[values0-1] PASSED                  [ 57%]
test_average.py::test_average_basic_3[values1-1.5] PASSED                [ 63%]
test_average.py::test_average_basic_3[values2-0.5] PASSED                [ 68%]
test_average.py::test_average_basic_3[values3-2.0] PASSED                [ 73%]
test_average.py::test_average_basic_3[values4-0.5] FAILED                [ 78%]
test_average.py::test_average_basic_3[values5-0] FAILED                  [ 84%]
test_average.py::test_average_empty_list_1 PASSED                        [ 89%]
test_average.py::test_average_empty_list_2 PASSED                        [ 94%]
test_average.py::test_average_five_values PASSED                         [100%]
&nbsp;
=================================== FAILURES ===================================
______________________ test_average_basic_1[values4-0.5] _______________________
&nbsp;
values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize("values,expected", testdata)
    def test_average_basic_1(values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
test_average.py:29: AssertionError
__________________________ test_average_basic_2[0,10] __________________________
&nbsp;
values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize("values,expected", testdata, ids=["1,1", "1,2", "0,1", "1,2,3", "0,10"])
    def test_average_basic_2(values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
test_average.py:37: AssertionError
______________________ test_average_basic_3[values4-0.5] _______________________
&nbsp;
values = (0, 10), expected = 0.5
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize(
        "values,expected",
        [
            pytest.param(
                (1, 1), 1
            ),
            pytest.param(
                (1, 2), 1.5
            ),
            pytest.param(
                (0, 1), 0.5
            ),
            pytest.param(
                (1, 2, 3), 2.0
            ),
            pytest.param(
                (0, 10), 0.5
            ),
            pytest.param(
                (), 0
            ),
        ],
    )
    def test_average_basic_3(values, expected):
        """Otestování výpočtu průměru."""
        result = average(values)
&gt;       assert result == expected, "Očekávaná hodnota {}, vráceno {}".format(expected, result)
E       AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
E       assert 5.0 == 0.5
E         +5.0
E         -0.5
&nbsp;
test_average.py:67: AssertionError
_______________________ test_average_basic_3[values5-0] ________________________
&nbsp;
values = (), expected = 0
&nbsp;
    @pytest.mark.smoketest
    @pytest.mark.parametrize(
        "values,expected",
        [
            pytest.param(
                (1, 1), 1
            ),
            pytest.param(
                (1, 2), 1.5
            ),
            pytest.param(
                (0, 1), 0.5
            ),
            pytest.param(
                (1, 2, 3), 2.0
            ),
            pytest.param(
                (0, 10), 0.5
            ),
            pytest.param(
                (), 0
            ),
        ],
    )
    def test_average_basic_3(values, expected):
        """Otestování výpočtu průměru."""
&gt;       result = average(values)
&nbsp;
test_average.py:66: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
&nbsp;
x = ()
&nbsp;
    def average(x):
        """Výpočet průměru ze seznamu hodnot předaných v parametru x."""
&gt;       return f1(x)
&nbsp;
average.py:6: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
&nbsp;
x = ()
&nbsp;
    def f1(x):
        """Část špagetového kódu testovaného modulu."""
&gt;       return f2(x)
&nbsp;
average.py:11: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
&nbsp;
x = ()

    def f2(x):
        """Část špagetového kódu testovaného modulu."""
&gt;       return f3(x)
&nbsp;
average.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
&nbsp;
x = ()

    def f3(x):
        """Část špagetového kódu testovaného modulu."""
&gt;       return f4(x)
&nbsp;
average.py:21: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
&nbsp;
x = ()
&nbsp;
    def f4(x):
        """Část špagetového kódu testovaného modulu."""
&gt;       return sum(x)/float(len(x))
E       ZeroDivisionError: float division by zero
&nbsp;
average.py:26: ZeroDivisionError
=========================== short test summary info ============================
FAILED test_average.py::test_average_basic_1[values4-0.5] - AssertionError: O...
FAILED test_average.py::test_average_basic_2[0,10] - AssertionError: Očekávan...
FAILED test_average.py::test_average_basic_3[values4-0.5] - AssertionError: O...
FAILED test_average.py::test_average_basic_3[values5-0] - ZeroDivisionError: ...
========================= 4 failed, 15 passed in 0.09s =========================
</pre>

<p><div class="rs-tip-major">Poznámka: předchozí volby ovlivňují i výstup do
XML i dalších podporovaných výstupních formátů.</div></p>



<p><a name="k15"></a></p>
<h2 id="k15">15. Spuštění nástroje Pycodestyle přímo z&nbsp;testů</h2>

<p>Často se setkáme s&nbsp;použitím nástrojů typu <a
href="https://www.pylint.org/">pylint</a>, <a
href="https://pycodestyle.pycqa.org/en/latest/">pycodestyle</a> či <a
href="https://github.com/psf/black">black</a> pro kontrolu formátování
zdrojového kódu, použití idiomatických konstrukcí apod. Tyto nástroje se
typicky spouští samostatně (ideálně v&nbsp;rámci commitu), ovšem pokud
z&nbsp;nějakého důvodu budete potřebovat jejich spuštění přímo v&nbsp;rámci
testů, je to možné. Následující skript projde všemi soubory s&nbsp;koncovkou
&bdquo;.py&ldquo; umístěných v&nbsp;aktuálním adresáři i jeho podadresářích a
pro každý takový soubor spustí nástroj <i>pydocstyle</i>. Na konci se vyhodnotí
počet souborů obsahujících chyby či jiné nedostatky:</p>

<pre>
<i>"""Simple checker of all Python sources in the given directory (usually repository)."""</i>
&nbsp;
from pathlib import Path
from sys import exit
import pycodestyle
&nbsp;
&nbsp;
def <strong>main</strong>():
    files = list(Path(".").rglob("*.py"))
&nbsp;
    style = pycodestyle.StyleGuide(quiet=False, config_file='setup.cfg')
    result = style.check_files(files)
    print("Total errors:", result.total_errors)
    if result.total_errors &gt; 0:
        exit(1)
&nbsp;
&nbsp;
if __name__ == "__main__":
    main()
</pre>

<p>Způsob detekce a výpisu problémů tímto skriptem:</p>

<pre>
issue.py:15:1: E302 expected 2 blank lines, found 1
issue.py:15:101: E501 line too long (147 &gt; 100 characters)
issue.py:19:1: W293 blank line contains whitespace
issue.py:25:1: W293 blank line contains whitespace
issue.py:42:1: E305 expected 2 blank lines after class or function definition, found 1
issue.py:47:101: E501 line too long (212 &gt; 100 characters)
pytest/average14/test_average.py:102:101: E501 line too long (104 &gt; 100 characters)
unittest_mock/mock-test3/test.py:42:101: E501 line too long (102 &gt; 100 characters)
unittest_mock/mock-test2/test.py:38:101: E501 line too long (102 &gt; 100 characters)
unittest_mock/mock-testB/main.py:8:16: E231 missing whitespace after ','
unittest_mock/mock-testB/main.py:9:16: E231 missing whitespace after ','
unittest_mock/mock-testB/main.py:10:16: E231 missing whitespace after ','
unittest_mock/mock-testC/module2.py:4:1: E302 expected 2 blank lines, found 1
unittest_mock/mock-testC/module2.py:7:1: E302 expected 2 blank lines, found 1
Total errors: 14
</pre>

<p>Převod na jednotkový test (resp.&nbsp;kód, který dodržuje konvence
jednotkového testu) je snadný:</p>

<pre>
<i>"""Implementace jednotkových testů."""</i>
&nbsp;
from pathlib import Path
from sys import exit
import pycodestyle
import pytest
&nbsp;
from average import average
&nbsp;
&nbsp;
def <strong>test_code_style</strong>():
    files = list(Path(".").rglob("*.py"))
&nbsp;
    style = pycodestyle.StyleGuide(quiet=False, config_file='setup.cfg')
    result = style.check_files(files)
    print("Total errors:", result.total_errors)
    assert result.total_errors == 0, "Detected {} code style problems".format(result.total_errors)
</pre>

<p>Chybný formát zdrojových kódů se stane součástí výsledku běhu jednotkových
testů:</p>

<pre>
FAILED test_average.py::test_average_basic_1[values4-0.5] - AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
FAILED test_average.py::test_average_basic_2[0,10] - AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
FAILED test_average.py::test_average_basic_3[values4-0.5] - AssertionError: Očekávaná hodnota 0.5, vráceno 5.0
FAILED test_average.py::test_average_basic_3[values5-0] - ZeroDivisionError: float division by zero
<strong>FAILED test_code_style.py::test_code_style - AssertionError: Detected 6 code style problems</strong>
</pre>



<p><a name="k16"></a></p>
<h2 id="k16">16. Automatický záznam chyb v&nbsp;repositáři na GitHubu</h2>

<p>U některých projektů může být výhodné zaznamenat nalezené chyby přímo ve
formě <i>issue(s)</i> v&nbsp;repositáři s&nbsp;projektem. Samozřejmě není nutné
tyto chyby zapisovat ručně (přes tlačítko &bdquo;New Issue&ldquo;), ale můžete
použít následující skript (určený pouze pro GitHub), jemuž je nutné přes
parametry příkazové řádky předat skupinu, repositář (z&nbsp;těchto dvou údajů
se složí cesta k&nbsp;repositáři), token uživatele (získaný opět přes web UI,
ten uchovejte v&nbsp;tajnosti), titulek issue i vlastní text s&nbsp;popisem
(body), který může v&nbsp;případě potřeby obsahovat značky jazyka Markdown.
Tento skript je možné spouštět v&nbsp;návaznosti na výsledky nástroje
<strong>pytest</strong>, ovšem existuje omezení na počet požadavků posílaných
přes REST API (5000 za hodinu pro jednoho uživatele, což by mělo být pro tyto
účely více než dostatečné):</p>

<pre>
<i>"""Create an issue on github.com using the given parameters."""</i>
&nbsp;
import os
import sys
import requests
import json
&nbsp;
from datetime import datetime
from argparse import ArgumentParser
&nbsp;
&nbsp;
def <strong>current_time_formatted</strong>():
    <i>"""GitHub API accepts timestamp in following format: '2020-03-10T16:00:00Z'."""</i>
    return datetime.utcnow().strftime('%Y-%m-%dT%H:%M:%SZ')
&nbsp;
&nbsp;
def <strong>make_github_issue</strong>(title, body=None, created_at=None, closed_at=None, updated_at=None,
                      assignee=None, milestone=None, closed=None, labels=None, token=None,
                      organization=None, repository=None):
    <i>"""Create an issue on github.com using the given parameters."""</i>
    <i># Url to create issues via POST</i>
    url = 'https://api.github.com/repos/%s/%s/import/issues' % (organization, repository)
&nbsp;
    <i># Headers</i>
    headers = {
        "Authorization": "token %s" % token,
        "Accept": "application/vnd.github.golden-comet-preview+json"
    }
&nbsp;
    <i># Create our issue</i>
    data = {'issue': {'title': title,
                      'body': body,
                      'created_at': created_at,
                      'assignee': assignee}}
&nbsp;
    payload = json.dumps(data)
&nbsp;
    <i># Add the issue to our repository</i>
    response = requests.request("POST", url, data=payload, headers=headers)
    if response.status_code == 202:
        print('Successfully created Issue "%s"' % title)
    else:
        print('Could not create Issue "%s"' % title)
        print('Response:', response.content)
&nbsp;
&nbsp;
def <strong>cli_arguments</strong>():
    <i>"""Retrieve all CLI arguments."""</i>
    parser = ArgumentParser()
&nbsp;
    <i># Authentication for user filing issue (must have read/write access to</i>
    <i># repository to add issue to)</i>
    parser.add_argument("-t", "--token", dest="token", help="authentication token",
                        action="store", default=None, type=str, required=True)
&nbsp;
    <i># The repository to add this issue to</i>
    parser.add_argument("-o", "--organization", dest="organization",
                        help="organization or repository owner",
                        action="store", default=None, type=str, required=True)
    parser.add_argument("-r", "--repository", dest="repository", help="repository name",
                        action="store", default=None, type=str, required=True)
&nbsp;
    <i># Issue-related options</i>
    parser.add_argument("-i", "--title", dest="title", help="issue title",
                        action="store", default=None, type=str, required=True)
&nbsp;
    parser.add_argument("-b", "--body", dest="body", help="body (text) of an issue",
                        action="store", default=None, type=str, required=True)
&nbsp;
    parser.add_argument("-a", "--assignee", dest="assignee", help="default assignee",
                        action="store", default=None, type=str, required=True)
&nbsp;
    <i># Other options</i>
    parser.add_argument("-v", "--verbose", dest="verbose", help="make operations verbose",
                        action="store_true", default=None)
&nbsp;
    return parser.parse_args()
&nbsp;
&nbsp;
def <strong>main</strong>():
    <i>"""Entry point to this script."""</i>
    timestamp = current_time_formatted()
    args = cli_arguments()
    make_github_issue(args.title, body=args.body, created_at=timestamp, assignee=args.assignee,
                      organization=args.organization, repository=args.repository, token=args.token)
&nbsp;
&nbsp;
if __name__ == "__main__":
    main()
</pre>

<p>Příklad použití je vypsán po zadání přepínače <strong>--help</strong>:</p>

<pre>
usage: issue.py [-h] -t TOKEN -o ORGANIZATION -r REPOSITORY -i TITLE -b BODY
                -a ASSIGNEE [-v]
&nbsp;
optional arguments:
  -h, --help            show this help message and exit
  -t TOKEN, --token TOKEN
                        authentication token
  -o ORGANIZATION, --organization ORGANIZATION
                        organization or repository owner
  -r REPOSITORY, --repository REPOSITORY
                        repository name
  -i TITLE, --title TITLE
                        issue title
  -b BODY, --body BODY  body (text) of an issue
  -a ASSIGNEE, --assignee ASSIGNEE
                        default assignee
  -v, --verbose         make operations verbose
</pre>



<p><a name="k17"></a></p>
<h2 id="k17">17. Obsah následující části seriálu</h2>

<p>V&nbsp;navazující části seriálu o testování s&nbsp;využitím programovacího
jazyka Python se již začneme zabývat dalšími typy testů v&nbsp;testovací
pyramidě. Bude se jednat o testy komponent a taktéž o integrační testy.</p>



<p><a name="k18"></a></p>
<h2 id="k18">18. Repositář s&nbsp;demonstračními příklady</h2>

<p>Zdrojové kódy všech dnes použitých demonstračních příkladů byly uloženy do
nového Git repositáře, který je dostupný na adrese <a
href="https://github.com/tisnik/testing-in-python">https://github.com/tisnik/testing-in-python</a>.
V&nbsp;případě, že nebudete chtít klonovat celý repositář (ten je ovšem &ndash;
alespoň prozatím &ndash; velmi malý, dnes má přibližně několik desítek
kilobajtů), můžete namísto toho použít odkazy na jednotlivé demonstrační
příklady a jejich části, které naleznete v&nbsp;následující tabulce:</p>

<table>
<tr><th> #</th><th>Příklad</th><th>Stručný popis</th><th>Cesta</th></tr>
<tr><td> 1</td><td>issue.py</td><td>automatický záznam chyb v&nbsp;repositáři na GitHubu</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/ci/issue.py">https://github.com/tisnik/testing-in-python/blob/master/ci/issue.py</a></td></tr>
<tr><td> 2</td><td>run_pycodestyle.py</td><td>skript pro spuštění nástroje <i>pycodestyle</i> a výpis všech nalezených chyb</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/run_pycodestyle.py">https://github.com/tisnik/testing-in-python/blob/master/run_pycodestyle.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 3</td><td>main.py</td><td>vstupní bod do testované aplikace</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/printer/main.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/printer/main.py</a></td></tr>
<tr><td> 4</td><td>average.py</td><td>modul s&nbsp;funkcí pro výpočet průměru</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/printer/average.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/printer/average.py</a></td></tr>
<tr><td> 5</td><td>test_average.py</td><td>implementace jednotkových testů používajících <i>test fixture</i> <strong>printer</strong></td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/printer/test_average.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/printer/test_average.py</a></td></tr>
<tr><td> 6</td><td>run</td><td>skript pro spuštění aplikace</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/printer/run">https://github.com/tisnik/testing-in-python/blob/master/pytest/printer/run</a></td></tr>
<tr><td> 7</td><td>test</td><td>skript pro spuštění jednotkových testů</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/printer/test">https://github.com/tisnik/testing-in-python/blob/master/pytest/printer/test</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td> 8</td><td>test_module.py</td><td>funkce <strong>setup_module</strong> a <strong>teardown_module</strong></td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/lifecycle_module/test_module.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/lifecycle_module/test_module.py</a></td></tr>
<tr><td> 9</td><td>test_class.py</td><td>třídní metody <strong>setup_class</strong> a <strong>teardown_class</strong></td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/lifecycle_class/test_class.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/lifecycle_class/test_class.py</a></td></tr>
<tr><td>10</td><td>test_method.py</td><td>metody <strong>setup_method</strong> a <strong>teardown_method</strong></td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/lifecycle_method/test_method.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/lifecycle_method/test_method.py</a></td></tr>
<tr><td>11</td><td>test_function.py</td><td>funkce <strong>setup_function</strong> a <strong>teardown_function</strong></td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/lifecycle_function/test_function.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/lifecycle_function/test_function.py</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>12</td><td>main.py</td><td>vstupní bod do testované aplikace</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/main.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/main.py</a></td></tr>
<tr><td>13</td><td>average.py</td><td>modul s&nbsp;funkcí pro výpočet průměru</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/average.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/average.py</a></td></tr>
<tr><td>14</td><td>test_average.py</td><td>implementace jednotkových testů používající mj.&nbsp;i <i>test fixture</i></td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/test_average.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/test_average.py</a></td></tr>
<tr><td>15</td><td>run</td><td>skript pro spuštění aplikace</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/run">https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/run</a></td></tr>
<tr><td>16</td><td>test</td><td>skript pro spuštění jednotkových testů</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/test">https://github.com/tisnik/testing-in-python/blob/master/pytest/average14/test</a></td></tr>
<tr><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td><td>&nbsp;</td></tr>
<tr><td>17</td><td>main.py</td><td>vstupní bod do testované aplikace</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/tests_in_class/main.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/tests_in_class/main.py</a></td></tr>
<tr><td>18</td><td>average.py</td><td>modul s&nbsp;funkcí pro výpočet průměru</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/tests_in_class/average.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/tests_in_class/average.py</a></td></tr>
<tr><td>19</td><td>test_average.py</td><td>implementace jednotkových testů založených na použití třídy namísto &bdquo;pouhých&ldquo; funkcí</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/tests_in_class/test_average.py">https://github.com/tisnik/testing-in-python/blob/master/pytest/tests_in_class/test_average.py</a></td></tr>
<tr><td>20</td><td>run</td><td>skript pro spuštění aplikace</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/tests_in_class/run">https://github.com/tisnik/testing-in-python/blob/master/pytest/tests_in_class/run</a></td></tr>
<tr><td>21</td><td>test</td><td>skript pro spuštění jednotkových testů</td><td><a href="https://github.com/tisnik/testing-in-python/blob/master/pytest/tests_in_class/test">https://github.com/tisnik/testing-in-python/blob/master/pytest/tests_in_class/test</a></td></tr>
</table>



<p><a name="k19"></a></p>
<h2 id="k19">19. Předchozí články s&nbsp;tématem testování (nejenom) v&nbsp;Pythonu</h2>

<p>Tématem testování jsme se již na stránkách Rootu několikrát zabývali. Jedná
se mj.&nbsp;o následující články:</p>

<ol>

<li>Použití Pythonu pro tvorbu testů: od jednotkových testů až po testy UI<br />
<a href="https://www.root.cz/clanky/pouziti-pythonu-pro-tvorbu-testu-od-jednotkovych-testu-az-po-testy-ui/">https://www.root.cz/clanky/pouziti-pythonu-pro-tvorbu-testu-od-jednotkovych-testu-az-po-testy-ui/</a>
</li>

<li>Použití Pythonu pro tvorbu testů: použití třídy Mock z knihovny unittest.mock<br />
<a href="https://www.root.cz/clanky/pouziti-pythonu-pro-tvorbu-testu-pouziti-tridy-mock-z-knihovny-unittest-mock/">https://www.root.cz/clanky/pouziti-pythonu-pro-tvorbu-testu-pouziti-tridy-mock-z-knihovny-unittest-mock/</a>
</li>

<li>Použití nástroje pytest pro tvorbu jednotkových testů a benchmarků<br />
<a href="https://www.root.cz/clanky/pouziti-nastroje-pytest-pro-tvorbu-jednotkovych-testu-a-benchmarku/">https://www.root.cz/clanky/pouziti-nastroje-pytest-pro-tvorbu-jednotkovych-testu-a-benchmarku/</a>
</li>

<li>Nástroj pytest a jednotkové testy: fixtures, výjimky, parametrizace testů<br />
<a href="https://www.root.cz/clanky/nastroj-pytest-a-jednotkove-testy-fixtures-vyjimky-parametrizace-testu/">https://www.root.cz/clanky/nastroj-pytest-a-jednotkove-testy-fixtures-vyjimky-parametrizace-testu/</a>
</li>

<li>Behavior-driven development v Pythonu s využitím knihovny Behave<br />
<a href="https://www.root.cz/clanky/behavior-driven-development-v-pythonu-s-vyuzitim-knihovny-behave/">https://www.root.cz/clanky/behavior-driven-development-v-pythonu-s-vyuzitim-knihovny-behave/</a>
</li>

<li>Behavior-driven development v Pythonu s využitím knihovny Behave (druhá část)<br />
<a href="https://www.root.cz/clanky/behavior-driven-development-v-pythonu-s-vyuzitim-knihovny-behave-druha-cast/">https://www.root.cz/clanky/behavior-driven-development-v-pythonu-s-vyuzitim-knihovny-behave-druha-cast/</a>
</li>

<li>Behavior-driven development v Pythonu s využitím knihovny Behave (závěrečná část)<br />
<a href="https://www.root.cz/clanky/behavior-driven-development-v-pythonu-s-vyuzitim-knihovny-behave-zaverecna-cast/">https://www.root.cz/clanky/behavior-driven-development-v-pythonu-s-vyuzitim-knihovny-behave-zaverecna-cast/</a>
</li>

<li>Validace datových struktur v Pythonu pomocí knihoven Schemagic a Schema<br />
<a href="https://www.root.cz/clanky/validace-datovych-struktur-v-pythonu-pomoci-knihoven-schemagic-a-schema/">https://www.root.cz/clanky/validace-datovych-struktur-v-pythonu-pomoci-knihoven-schemagic-a-schema/</a>
</li>

<li>Validace datových struktur v Pythonu (2. část)<br />
<a href="https://www.root.cz/clanky/validace-datovych-struktur-v-pythonu-2-cast/">https://www.root.cz/clanky/validace-datovych-struktur-v-pythonu-2-cast/</a>
</li>

<li>Validace datových struktur v Pythonu (dokončení)<br />
<a href="https://www.root.cz/clanky/validace-datovych-struktur-v-pythonu-dokonceni/">https://www.root.cz/clanky/validace-datovych-struktur-v-pythonu-dokonceni/</a>
</li>

<li>Univerzální testovací nástroj Robot Framework<br />
<a href="https://www.root.cz/clanky/univerzalni-testovaci-nastroj-robot-framework/">https://www.root.cz/clanky/univerzalni-testovaci-nastroj-robot-framework/</a>
</li>

<li>Univerzální testovací nástroj Robot Framework a BDD testy<br />
<a href="https://www.root.cz/clanky/univerzalni-testovaci-nastroj-robot-framework-a-bdd-testy/">https://www.root.cz/clanky/univerzalni-testovaci-nastroj-robot-framework-a-bdd-testy/</a>
</li>

<li>Úvod do problematiky fuzzingu a fuzz testování<br />
<a href="https://www.root.cz/clanky/uvod-do-problematiky-fuzzingu-a-fuzz-testovani/">https://www.root.cz/clanky/uvod-do-problematiky-fuzzingu-a-fuzz-testovani/</a>
</li>

<li>Úvod do problematiky fuzzingu a fuzz testování – složení vlastního fuzzeru<br />
<a href="https://www.root.cz/clanky/uvod-do-problematiky-fuzzingu-a-fuzz-testovani-slozeni-vlastniho-fuzzeru/">https://www.root.cz/clanky/uvod-do-problematiky-fuzzingu-a-fuzz-testovani-slozeni-vlastniho-fuzzeru/</a>
</li>

<li>Knihovny a moduly usnadňující testování aplikací naprogramovaných v jazyce Clojure<br />
<a href="https://www.root.cz/clanky/knihovny-a-moduly-usnadnujici-testovani-aplikaci-naprogramovanych-v-jazyce-clojure/">https://www.root.cz/clanky/knihovny-a-moduly-usnadnujici-testovani-aplikaci-naprogramovanych-v-jazyce-clojure/</a>
</li>

<li>Validace dat s využitím knihovny spec v Clojure 1.9.0<br />
<a href="https://www.root.cz/clanky/validace-dat-s-vyuzitim-knihovny-spec-v-clojure-1-9-0/">https://www.root.cz/clanky/validace-dat-s-vyuzitim-knihovny-spec-v-clojure-1-9-0/</a>
</li>

<li>Testování aplikací naprogramovaných v jazyce Go<br />
<a href="https://www.root.cz/clanky/testovani-aplikaci-naprogramovanych-v-jazyce-go/">https://www.root.cz/clanky/testovani-aplikaci-naprogramovanych-v-jazyce-go/</a>
</li>

<li>Knihovny určené pro tvorbu testů v programovacím jazyce Go<br />
<a href="https://www.root.cz/clanky/knihovny-urcene-pro-tvorbu-testu-v-programovacim-jazyce-go/">https://www.root.cz/clanky/knihovny-urcene-pro-tvorbu-testu-v-programovacim-jazyce-go/</a>
</li>

<li>Testování aplikací psaných v Go s využitím knihoven Goblin a Frisby<br />
<a href="https://www.root.cz/clanky/testovani-aplikaci-psanych-v-go-s-vyuzitim-knihoven-goblin-a-frisby/">https://www.root.cz/clanky/testovani-aplikaci-psanych-v-go-s-vyuzitim-knihoven-goblin-a-frisby/</a>
</li>

<li>Testování Go aplikací s využitím knihovny GΩmega a frameworku Ginkgo<br />
<a href="https://www.root.cz/clanky/testovani-go-aplikaci-s-vyuzitim-knihovny-gomega-mega-a-frameworku-ginkgo/">https://www.root.cz/clanky/testovani-go-aplikaci-s-vyuzitim-knihovny-gomega-mega-a-frameworku-ginkgo/</a>
</li>

<li>Tvorba BDD testů s využitím jazyka Go a nástroje godog<br />
<a href="https://www.root.cz/clanky/tvorba-bdd-testu-s-vyuzitim-jazyka-go-a-nastroje-godog/">https://www.root.cz/clanky/tvorba-bdd-testu-s-vyuzitim-jazyka-go-a-nastroje-godog/</a>
</li>

<li>Použití Go pro automatizaci práce s aplikacemi s interaktivním příkazovým řádkem<br />
<a href="https://www.root.cz/clanky/pouziti-go-pro-automatizaci-prace-s-aplikacemi-s-interaktivnim-prikazovym-radkem/">https://www.root.cz/clanky/pouziti-go-pro-automatizaci-prace-s-aplikacemi-s-interaktivnim-prikazovym-radkem/</a>
</li>

<li>Použití Go pro automatizaci práce s aplikacemi s interaktivním příkazovým řádkem (dokončení)<br />
<a href="https://www.root.cz/clanky/pouziti-go-pro-automatizaci-prace-s-aplikacemi-s-interaktivnim-prikazovym-radkem-dokonceni/">https://www.root.cz/clanky/pouziti-go-pro-automatizaci-prace-s-aplikacemi-s-interaktivnim-prikazovym-radkem-dokonceni/</a>
</li>

<li>Použití jazyka Gherkin při tvorbě testovacích scénářů pro aplikace psané v Clojure<br />
<a href="https://www.root.cz/clanky/pouziti-jazyka-gherkin-pri-tvorbe-testovacich-scenaru-pro-aplikace-psane-v-nbsp-clojure/">https://www.root.cz/clanky/pouziti-jazyka-gherkin-pri-tvorbe-testovacich-scenaru-pro-aplikace-psane-v-nbsp-clojure/</a>
</li>

<li>Použití jazyka Gherkin při tvorbě testovacích scénářů pro aplikace psané v Clojure (2)<br />
<a href="https://www.root.cz/clanky/pouziti-jazyka-gherkin-pri-tvorbe-testovacich-scenaru-pro-aplikace-psane-v-nbsp-clojure-2/">https://www.root.cz/clanky/pouziti-jazyka-gherkin-pri-tvorbe-testovacich-scenaru-pro-aplikace-psane-v-nbsp-clojure-2/</a>
</li>

</ol>



<p><a name="k20"></a></p>
<h2 id="k20">20. Odkazy na Internetu</h2>

<ol>

<li>pytest 5.4.2 na PyPi<br />
<a href="https://pypi.org/project/pytest/">https://pypi.org/project/pytest/</a>
</li>

<li>Awesome Python &ndash; testing<br />
<a href="https://github.com/vinta/awesome-python#testing">https://github.com/vinta/awesome-python#testing</a>
</li>

<li>pytest Plugins Compatibility<br />
<a href="http://plugincompat.herokuapp.com/">http://plugincompat.herokuapp.com/</a>
</li>

<li>Selenium (pro Python)<br />
<a href="https://pypi.org/project/selenium/">https://pypi.org/project/selenium/</a>
</li>

<li>Getting Started With Testing in Python<br />
<a href="https://realpython.com/python-testing/">https://realpython.com/python-testing/</a>
</li>

<li>unittest.mock — mock object library<br />
<a href="https://docs.python.org/3.5/library/unittest.mock.html">https://docs.python.org/3.5/library/unittest.mock.html</a>
</li>

<li>mock 2.0.0<br />
<a href="https://pypi.python.org/pypi/mock">https://pypi.python.org/pypi/mock</a>
</li>

<li>An Introduction to Mocking in Python<br />
<a href="https://www.toptal.com/python/an-introduction-to-mocking-in-python">https://www.toptal.com/python/an-introduction-to-mocking-in-python</a>
</li>

<li>Mock - Mocking and Testing Library<br />
<a href="http://mock.readthedocs.io/en/stable/">http://mock.readthedocs.io/en/stable/</a>
</li>

<li>Python Mocking 101: Fake It Before You Make It<br />
<a href="https://blog.fugue.co/2016-02-11-python-mocking-101.html">https://blog.fugue.co/2016-02-11-python-mocking-101.html</a>
</li>

<li>Nauč se Python! - Testování<br />
<a href="http://naucse.python.cz/lessons/intro/testing/">http://naucse.python.cz/lessons/intro/testing/</a>
</li>

<li>Flexmock (dokumentace)<br />
<a href="https://flexmock.readthedocs.io/en/latest/">https://flexmock.readthedocs.io/en/latest/</a>
</li>

<li>Test Fixture (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Test_fixture">https://en.wikipedia.org/wiki/Test_fixture</a>
</li>

<li>Mock object (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Mock_object">https://en.wikipedia.org/wiki/Mock_object</a>
</li>

<li>Extrémní programování<br />
<a href="https://cs.wikipedia.org/wiki/Extr%C3%A9mn%C3%AD_programov%C3%A1n%C3%AD">https://cs.wikipedia.org/wiki/Extr%C3%A9mn%C3%AD_programov%C3%A1n%C3%AD</a>
</li>

<li>Programování řízené testy<br />
<a href="https://cs.wikipedia.org/wiki/Programov%C3%A1n%C3%AD_%C5%99%C3%ADzen%C3%A9_testy">https://cs.wikipedia.org/wiki/Programov%C3%A1n%C3%AD_%C5%99%C3%ADzen%C3%A9_testy</a>
</li>

<li>Pip (dokumentace)<br />
<a href="https://pip.pypa.io/en/stable/">https://pip.pypa.io/en/stable/</a>
</li>

<li>Tox<br />
<a href="https://tox.readthedocs.io/en/latest/">https://tox.readthedocs.io/en/latest/</a>
</li>

<li>pytest: helps you write better programs<br />
<a href="https://docs.pytest.org/en/latest/">https://docs.pytest.org/en/latest/</a>
</li>

<li>doctest — Test interactive Python examples<br />
<a href="https://docs.python.org/dev/library/doctest.html#module-doctest">https://docs.python.org/dev/library/doctest.html#module-doctest</a>
</li>

<li>unittest — Unit testing framework<br />
<a href="https://docs.python.org/dev/library/unittest.html">https://docs.python.org/dev/library/unittest.html</a>
</li>

<li>Python namespaces<br />
<a href="https://bytebaker.com/2008/07/30/python-namespaces/">https://bytebaker.com/2008/07/30/python-namespaces/</a>
</li>

<li>Namespaces and Scopes<br />
<a href="https://www.python-course.eu/namespaces.php">https://www.python-course.eu/namespaces.php</a>
</li>

<li>Stránka projektu Robot Framework<br />
<a href="https://robotframework.org/">https://robotframework.org/</a>
</li>

<li>GitHub repositář Robot Frameworku<br />
<a href="https://github.com/robotframework/robotframework">https://github.com/robotframework/robotframework</a>
</li>

<li>Robot Framework (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Robot_Framework">https://en.wikipedia.org/wiki/Robot_Framework</a>
</li>

<li>Tutoriál Robot Frameworku<br />
<a href="http://www.robotframeworktutorial.com/">http://www.robotframeworktutorial.com/</a>
</li>

<li>Robot Framework Documentation<br />
<a href="https://robotframework.org/robotframework/">https://robotframework.org/robotframework/</a>
</li>

<li>Robot Framework Introduction<br />
<a href="https://blog.testproject.io/2016/11/22/robot-framework-introduction/">https://blog.testproject.io/2016/11/22/robot-framework-introduction/</a>
</li>

<li>robotframework 3.1.2 na PyPi<br />
<a href="https://pypi.org/project/robotframework/">https://pypi.org/project/robotframework/</a>
</li>

<li>Robot Framework demo (GitHub)<br />
<a href="https://github.com/robotframework/RobotDemo">https://github.com/robotframework/RobotDemo</a>
</li>

<li>Robot Framework web testing demo using SeleniumLibrary<br />
<a href="https://github.com/robotframework/WebDemo">https://github.com/robotframework/WebDemo</a>
</li>

<li>Robot Framework for Mobile Test Automation Demo<br />
<a href="https://www.youtube.com/watch?v=06LsU08slP8">https://www.youtube.com/watch?v=06LsU08slP8</a>
</li>

<li>Gherkin<br />
<a href="https://cucumber.io/docs/gherkin/">https://cucumber.io/docs/gherkin/</a>
</li>

<li>Selenium<br />
<a href="https://selenium.dev/">https://selenium.dev/</a>
</li>

<li>SeleniumLibrary<br />
<a href="https://robotframework.org/">https://robotframework.org/</a>
</li>

<li>The Practical Test Pyramid<br />
<a href="https://martinfowler.com/articles/practical-test-pyramid.html">https://martinfowler.com/articles/practical-test-pyramid.html</a>
</li>

<li>Acceptance Tests and the Testing Pyramid<br />
<a href="http://www.blog.acceptancetestdrivendevelopment.com/acceptance-tests-and-the-testing-pyramid/">http://www.blog.acceptancetestdrivendevelopment.com/acceptance-tests-and-the-testing-pyramid/</a>
</li>

<li>Tab-separated values<br />
<a href="https://en.wikipedia.org/wiki/Tab-separated_values">https://en.wikipedia.org/wiki/Tab-separated_values</a>
</li>

<li>A quick guide about Python implementations<br />
<a href="https://blog.rmotr.com/a-quick-guide-about-python-implementations-aa224109f321">https://blog.rmotr.com/a-quick-guide-about-python-implementations-aa224109f321</a>
</li>

<li>radamsa<br />
<a href="https://gitlab.com/akihe/radamsa">https://gitlab.com/akihe/radamsa</a>
</li>

<li>Fuzzing (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Fuzzing">https://en.wikipedia.org/wiki/Fuzzing</a>
</li>

<li>american fuzzy lop<br />
<a href="http://lcamtuf.coredump.cx/afl/">http://lcamtuf.coredump.cx/afl/</a>
</li>

<li>Fuzzing: the new unit testing<br />
<a href="https://go-talks.appspot.com/github.com/dvyukov/go-fuzz/slides/fuzzing.slide#1">https://go-talks.appspot.com/github.com/dvyukov/go-fuzz/slides/fuzzing.slide#1</a>
</li>

<li>Corpus for github.com/dvyukov/go-fuzz examples<br />
<a href="https://github.com/dvyukov/go-fuzz-corpus">https://github.com/dvyukov/go-fuzz-corpus</a>
</li>

<li>AFL &ndash; QuickStartGuide.txt<br />
<a href="https://github.com/google/AFL/blob/master/docs/QuickStartGuide.txt">https://github.com/google/AFL/blob/master/docs/QuickStartGuide.txt</a>
</li>

<li>Introduction to Fuzzing in Python with AFL<br />
<a href="https://alexgaynor.net/2015/apr/13/introduction-to-fuzzing-in-python-with-afl/">https://alexgaynor.net/2015/apr/13/introduction-to-fuzzing-in-python-with-afl/</a>
</li>

<li>Writing a Simple Fuzzer in Python<br />
<a href="https://jmcph4.github.io/2018/01/19/writing-a-simple-fuzzer-in-python/">https://jmcph4.github.io/2018/01/19/writing-a-simple-fuzzer-in-python/</a>
</li>

<li>How to Fuzz Go Code with go-fuzz (Continuously)<br />
<a href="https://fuzzit.dev/2019/10/02/how-to-fuzz-go-code-with-go-fuzz-continuously/">https://fuzzit.dev/2019/10/02/how-to-fuzz-go-code-with-go-fuzz-continuously/</a>
</li>

<li>Golang Fuzzing: A go-fuzz Tutorial and Example<br />
<a href="http://networkbit.ch/golang-fuzzing/">http://networkbit.ch/golang-fuzzing/</a>
</li>

<li>Fuzzing Python Modules<br />
<a href="https://stackoverflow.com/questions/20749026/fuzzing-python-modules">https://stackoverflow.com/questions/20749026/fuzzing-python-modules</a>
</li>

<li>0x3 Python Tutorial: Fuzzer<br />
<a href="http://www.primalsecurity.net/0x3-python-tutorial-fuzzer/">http://www.primalsecurity.net/0x3-python-tutorial-fuzzer/</a>
</li>

<li>fuzzing na PyPi<br />
<a href="https://pypi.org/project/fuzzing/">https://pypi.org/project/fuzzing/</a>
</li>

<li>Fuzzing 0.3.2 documentation<br />
<a href="https://fuzzing.readthedocs.io/en/latest/">https://fuzzing.readthedocs.io/en/latest/</a>
</li>

<li>Randomized testing for Go<br />
<a href="https://github.com/dvyukov/go-fuzz">https://github.com/dvyukov/go-fuzz</a>
</li>

<li>HTTP/2 fuzzer written in Golang<br />
<a href="https://github.com/c0nrad/http2fuzz">https://github.com/c0nrad/http2fuzz</a>
</li>

<li>Ffuf (Fuzz Faster U Fool) – An Open Source Fast Web Fuzzing Tool<br />
<a href="https://hacknews.co/hacking-tools/20191208/ffuf-fuzz-faster-u-fool-an-open-source-fast-web-fuzzing-tool.html">https://hacknews.co/hacking-tools/20191208/ffuf-fuzz-faster-u-fool-an-open-source-fast-web-fuzzing-tool.html</a>
</li>

<li>Continuous Fuzzing Made Simple<br />
<a href="https://fuzzit.dev/">https://fuzzit.dev/</a>
</li>

<li>Halt and Catch Fire<br />
<a href="https://en.wikipedia.org/wiki/Halt_and_Catch_Fire#Intel_x86">https://en.wikipedia.org/wiki/Halt_and_Catch_Fire#Intel_x86</a>
</li>

<li>Random testing<br />
<a href="https://en.wikipedia.org/wiki/Random_testing">https://en.wikipedia.org/wiki/Random_testing</a>
</li>

<li>Monkey testing<br />
<a href="https://en.wikipedia.org/wiki/Monkey_testing">https://en.wikipedia.org/wiki/Monkey_testing</a>
</li>

<li>Fuzzing for Software Security Testing and Quality Assurance, Second Edition<br />
<a href="https://books.google.at/books?id=tKN5DwAAQBAJ&pg=PR15&lpg=PR15&q=%22I+settled+on+the+term+fuzz%22&redir_esc=y&hl=de#v=onepage&q=%22I%20settled%20on%20the%20term%20fuzz%22&f=false">https://books.google.at/books?id=tKN5DwAAQBAJ&pg=PR15&lpg=PR15&q=%22I+settled+on+the+term+fuzz%22&redir_esc=y&hl=de#v=onepage&q=%22I%20settled%20on%20the%20term%20fuzz%22&f=false</a>
</li>

<li>libFuzzer – a library for coverage-guided fuzz testing<br />
<a href="https://llvm.org/docs/LibFuzzer.html">https://llvm.org/docs/LibFuzzer.html</a>
</li>

<li>fuzzy-swagger na PyPi<br />
<a href="https://pypi.org/project/fuzzy-swagger/">https://pypi.org/project/fuzzy-swagger/</a>
</li>

<li>fuzzy-swagger na GitHubu<br />
<a href="https://github.com/namuan/fuzzy-swagger">https://github.com/namuan/fuzzy-swagger</a>
</li>

<li>Fuzz testing tools for Python<br />
<a href="https://wiki.python.org/moin/PythonTestingToolsTaxonomy#Fuzz_Testing_Tools">https://wiki.python.org/moin/PythonTestingToolsTaxonomy#Fuzz_Testing_Tools</a>
</li>

<li>A curated list of awesome Go frameworks, libraries and software<br />
<a href="https://github.com/avelino/awesome-go">https://github.com/avelino/awesome-go</a>
</li>

<li>gofuzz: a library for populating go objects with random values<br />
<a href="https://github.com/google/gofuzz">https://github.com/google/gofuzz</a>
</li>

<li>tavor: A generic fuzzing and delta-debugging framework<br />
<a href="https://github.com/zimmski/tavor">https://github.com/zimmski/tavor</a>
</li>

<li>hypothesis na GitHubu<br />
<a href="https://github.com/HypothesisWorks/hypothesis">https://github.com/HypothesisWorks/hypothesis</a>
</li>

<li>Hypothesis: Test faster, fix more<br />
<a href="https://hypothesis.works/">https://hypothesis.works/</a>
</li>

<li>Hypothesis<br />
<a href="https://hypothesis.works/articles/intro/">https://hypothesis.works/articles/intro/</a>
</li>

<li>What is Hypothesis?<br />
<a href="https://hypothesis.works/articles/what-is-hypothesis/">https://hypothesis.works/articles/what-is-hypothesis/</a>
</li>

<li>Databáze CVE<br />
<a href="https://www.cvedetails.com/">https://www.cvedetails.com/</a>
</li>

<li>Fuzz test Python modules with libFuzzer<br />
<a href="https://github.com/eerimoq/pyfuzzer">https://github.com/eerimoq/pyfuzzer</a>
</li>

<li>Taof - The art of fuzzing<br />
<a href="https://sourceforge.net/projects/taof/">https://sourceforge.net/projects/taof/</a>
</li>

<li>JQF + Zest: Coverage-guided semantic fuzzing for Java<br />
<a href="https://github.com/rohanpadhye/jqf">https://github.com/rohanpadhye/jqf</a>
</li>

<li>http2fuzz<br />
<a href="https://github.com/c0nrad/http2fuzz">https://github.com/c0nrad/http2fuzz</a>
</li>

<li>Demystifying hypothesis testing with simple Python examples<br />
<a href="https://towardsdatascience.com/demystifying-hypothesis-testing-with-simple-python-examples-4997ad3c5294">https://towardsdatascience.com/demystifying-hypothesis-testing-with-simple-python-examples-4997ad3c5294</a>
</li>

<li>Testování<br />
<a href="http://voho.eu/wiki/testovani/">http://voho.eu/wiki/testovani/</a>
</li>

<li>Unit testing (Wikipedia.en)<br />
<a href="https://en.wikipedia.org/wiki/Unit_testing">https://en.wikipedia.org/wiki/Unit_testing</a>
</li>

<li>Unit testing (Wikipedia.cz)<br />
<a href="https://cs.wikipedia.org/wiki/Unit_testing">https://cs.wikipedia.org/wiki/Unit_testing</a>
</li>

<li>Unit Test vs Integration Test<br />
<a href="https://www.youtube.com/watch?v=0GypdsJulKE">https://www.youtube.com/watch?v=0GypdsJulKE</a>
</li>

<li>TestDouble<br />
<a href="https://martinfowler.com/bliki/TestDouble.html">https://martinfowler.com/bliki/TestDouble.html</a>
</li>

<li>Test Double<br />
<a href="http://xunitpatterns.com/Test%20Double.html">http://xunitpatterns.com/Test%20Double.html</a>
</li>

<li>Test-driven development (Wikipedia)<br />
<a href="https://en.wikipedia.org/wiki/Test-driven_development">https://en.wikipedia.org/wiki/Test-driven_development</a>
</li>

<li>Acceptance test–driven development<br />
<a href="https://en.wikipedia.org/wiki/Acceptance_test%E2%80%93driven_development">https://en.wikipedia.org/wiki/Acceptance_test%E2%80%93driven_development</a>
</li>

<li>Gauge<br />
<a href="https://gauge.org/">https://gauge.org/</a>
</li>

<li>Gauge (software)<br />
<a href="https://en.wikipedia.org/wiki/Gauge_(software)">https://en.wikipedia.org/wiki/Gauge_(software)</a>
</li>

<li>PYPL PopularitY of Programming Language<br />
<a href="https://pypl.github.io/PYPL.html">https://pypl.github.io/PYPL.html</a>
</li>

<li>Testing is Good. Pyramids are Bad. Ice Cream Cones are the Worst<br />
<a href="https://medium.com/@fistsOfReason/testing-is-good-pyramids-are-bad-ice-cream-cones-are-the-worst-ad94b9b2f05f">https://medium.com/@fistsOfReason/testing-is-good-pyramids-are-bad-ice-cream-cones-are-the-worst-ad94b9b2f05f</a>
</li>

<li>Články a zprávičky věnující se Pythonu<br />
<a href="https://www.root.cz/n/python/">https://www.root.cz/n/python/</a>
</li>

<li>PythonTestingToolsTaxonomy<br />
<a href="https://wiki.python.org/moin/PythonTestingToolsTaxonomy">https://wiki.python.org/moin/PythonTestingToolsTaxonomy</a>
</li>

<li>Top 6 BEST Python Testing Frameworks [Updated 2020 List]<br />
<a href="https://www.softwaretestinghelp.com/python-testing-frameworks/">https://www.softwaretestinghelp.com/python-testing-frameworks/</a>
</li>

<li>pytest-print 0.1.3<br />
<a href="https://pypi.org/project/pytest-print/">https://pypi.org/project/pytest-print/</a>
</li>

<li>pytest fixtures: explicit, modular, scalable<br />
<a href="https://docs.pytest.org/en/latest/fixture.html">https://docs.pytest.org/en/latest/fixture.html</a>
</li>

<li>PyTest Tutorial: What is, Install, Fixture, Assertions<br />
<a href="https://www.guru99.com/pytest-tutorial.html">https://www.guru99.com/pytest-tutorial.html</a>
</li>

<li>Pytest - Fixtures<br />
<a href="https://www.tutorialspoint.com/pytest/pytest_fixtures.htm">https://www.tutorialspoint.com/pytest/pytest_fixtures.htm</a>
</li>

<li>Marking test functions with attributes<br />
<a href="https://docs.pytest.org/en/latest/mark.html">https://docs.pytest.org/en/latest/mark.html</a>
</li>

<li>pytest-print<br />
<a href="https://pytest-print.readthedocs.io/en/latest/">https://pytest-print.readthedocs.io/en/latest/</a>
</li>

</ol>



<p></p><p></p>
<p><small>Autor: <a href="http://www.fit.vutbr.cz/~tisnovpa">Pavel Tišnovský</a> &nbsp; 2020</small></p>
</body>
</html>

